# Dialog 00803

**Transcript ID:** work_0543

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Nope, that sounds good.

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I work for a university that has set a strict AI policy. We are only allowed to use certain types of AI for certain types of tasks. So, for example, you could never put protected information (like student or donor information) into a task because of FERPA and other regulations. What we are allowed to use it for is stuff like brainstorming, refining our language, changing our writing for different audiences. We're not generally supposed to be composing entire external-facing articles or papers with AI (though internal communication like e-mail is fine.)

AI: That's really interesting - it sounds like your university has created pretty specific guardrails around AI use. 

Within those boundaries they've set, how often would you say you're actually using AI tools during a typical work week? And when you do use them for things like brainstorming or refining language, what does that process usually look like for you?

User: I work in donor relations at my subsection of the university, specifically. For brainstorming, I might ask the AI to come up with more clever ways to come up with a donor recognition wall with imagery that would resonate with our audience, or types of articles in a donor newsletter that might engage X or Y type of donor. We have boilerplate information about our programs, but we have to tell the story about our programs differently to the different donors. AI is useful for saying something like, "Tell me which parts of this letter would be most compelling if you were a retired farm bureau executive and what appeals or missing."

AI: That's a fascinating application - using AI to help tailor your messaging for different donor audiences. It sounds like you're really leveraging its ability to shift perspectives.

When you're working on something like adapting a program story for different donor types, can you walk me through what that interaction typically looks like? Are you going back and forth with the AI to refine the messaging, or do you usually get what you need in one exchange?

User: Back-and-forth is the most useful, sometimes even asking it to adapt different personas within the same conversation. In the conversation about the same letter, I might tell the same model, "Now imagine that you're a retired home economics teacher and grandmother of a grandchild with autism..." or "Imagine you are an expert in rural entrepreneurship who is passionate about empowering immigrant businesses" or "Now imagine that you are a Junior League member who is passionate about gardening and women's empowerment" - because the multifaceted work that we do would theoretically reach all of these audiences.

AI: That's such a clever approach - having the AI switch between different personas within the same conversation to help you understand how your message might land with various audiences.

I'm curious about your preferences when working with AI. Are there certain tasks in your donor relations work that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: There are some tasks we simply aren't allowed to use AI for. For example, it would be really helpful/useful to just take the entire dataset of donors and say "build me a giving profile of each person, based on our demographic information and giving research, and then segment them into "character" categories. Then convert the boilerplate information into messages which might appeal to them" - this would be a great way to persuade people to give at scale, but there's no way you can put real donor information into an AI right now (according to the University's standard's, but it also seems to be the prevailing standard in fundraising too.) So that's just a long-term task that I have to work on myself. I don't necessarily "prefer" to handle it, I just have to handle it. There are some tasks like composing hand-written thank you letters, sympathy cards, attending funerals, sending flowers, going to in-person events, etc. that probably cannot be replicated by AI, and frankly shouldn't. If I get to the point that I have to outsource my brain to an AI for, "Draft a heartfelt thank you note to a donor that I can put on a thank you card", that would be a bad sign. Also, in general, I think it is best for me to write a first draft myself and then have an AI refine it rather than have an AI write the whole first draft, because there are just inevitably going to be some annoying "tells" that I know I have to edit out of the AI draft.

AI: That's really insightful - you've touched on both the regulatory constraints and something deeper about maintaining authenticity in relationship-building work. The distinction you made about handwritten notes being something that "shouldn't" be outsourced, even if it could be, really stands out.

You mentioned preferring to write first drafts yourself and then having AI refine them. Can you tell me more about what you mean by those "annoying tells" that you have to edit out? What are you typically looking for when you review AI-refined content?

User: Annoying tells: overuse of emojis where they aren't needed, overuse of the "you're not just X, you're Y" structure, overuse of certain words like delve, tapestry, remarkable... I could go on

AI: That's a great observation - it sounds like you've developed a pretty keen eye for AI's stylistic patterns! Those repetitive structures and word choices would definitely stand out in professional communications.

When you use AI for work, could you describe your typical interaction pattern? From what you've shared, it sounds like you lean more toward collaborating with it throughout a task rather than just handing off complete tasks - is that accurate, or does it vary depending on what you're working on?

User: The directive at my workplace is "treat AI like an overenthusiastic intern. Only fully outsource projects to it that you would feel comfortable outsourcing to an overenthusiastic intern." Because you have to treat ever donor as so precious, there really is no direct communication with a donor that I'd ever feel comfortable fully outsourcing to an AI. I think it makes more sense to treat it as a collaborator. We are obligated to check anything an AI gives back and not just copy-paste it straight for our use, so I don't think I'd ever give it a full task that is ever presented to an external audience. I might give an overenthusiastic intern a task like, "go find me some interesting recent news stories about how beekeeping can be therapeutic for different populations" or "come up with merchandise ideas that we can sell at the anniversary fundraiser" - they're helpful to my work, but they wouldn't ever fully reach an external audience without thorough checking by human eyes.

AI: That "overenthusiastic intern" framing is brilliant - it really captures both the potential and the limitations perfectly. It sounds like your workplace has thought this through quite carefully.

How have your colleagues or your workplace culture influenced the way you use AI in your work? You've mentioned the policies, but I'm curious about the more informal aspects - do people talk about their AI experiences, share tips, or have different comfort levels with it?

User: My coworkers are pretty split about AI. There are some who work more heavily in the communication side who don't use it on principle. The ones in the fundraising side, who are very results-oriented, tend to be more open to using it. The comm team has an editorial process that would probably be embarrassing for someone who is overusing AI in their work, so I think it's not really a norm to just be fully outsourcing your brain to AI. I did have a colleague who was very clearly generating donor acknowledgment letters with AI and because they were crappy, vague, and awkward, they got reprimanded for it. I was tasked with going in and fixing them afterward.

AI: That's a telling example - it sounds like the quality issues made the AI usage pretty obvious to everyone. It really reinforces what you said earlier about the importance of that human oversight.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I personally do not like webinars because I don't like being chained to the desk for an hour listening. I read a lot faster than I listen. AI has been great for taking the transcript of an existing webinar, summarizing it, and then applying the insights to work we are already doing. For example, I might tell an AI to summarize a webinar on recent donor communication research, then tell it to apply the knowledge from the summary to a recent campaign we did or an audience segment. This has been great because I always half-dreaded, half-enjoyed webinars before. I wanted the knowledge but didn't want to have to actually sit through it, so this makes it much faster.

AI: That's such a smart use case - you've essentially found a way to get the value of professional development content in a format that works much better for how you process information. It sounds like it's transformed something that felt like a chore into something genuinely useful.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: It does concern me. On one hand, in fundraising, everything is about being donor-centered, and so much of that involves the human touch. However, that's directed toward an older audience of the people who have the most concentrated wealth right now. I don't know what the difference in approach looks like for the next generation of potential donors. The rise of Donor Advised Fund (DAF) giving, where you just get a mysterious check in the mail with anonymous information -- sometimes driven by the fact that people do NOT want to have any "human touch" type interactions with the organization -- indicates to me that the playbook is going to have to change. The fundraising landscape is already hard enough as it is. People always say that fundraisers' jobs are safe because there's always a need to bring in money, but the question is whether institutions decide that a major gifts officer + AI Model could replace people in a specialized donor communications role.

AI: That's a really thoughtful perspective on how generational shifts in donor preferences might change the entire landscape. The DAF example is particularly striking - it suggests some donors actively prefer less personal interaction, which could really reshape what "relationship-building" means in fundraising.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think you'll be using it differently a year or two from now?

User: By that point, I would assume that adoption of AI will be so widespread that we're going to swing around the other direction and have to find ways to communicate that don't sound like AI. It'll be a matter of how to catch people's attention in human-facing, in-person, authentic ways, even if they're wacky, homespun, or don't feel polished. There could also be backlash against AI. So, if I'm using AI the same way I am now, I think that I (and the rest of my institution) probably wouldn't be proudly parading around how AI integrated we are. People will probably still use AI on the back end a lot -- and maybe AI will improve so much it'll be completely seamless and there will be no obvious "AI tells" -- but by two years from now, I think everyone's relationship to it will have changed.

AI: That's a fascinating prediction - the idea that widespread AI adoption could create a premium on authentically human communication. It makes me think of how handwritten notes became more meaningful as email became ubiquitous.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how generational differences in donor preferences might reshape the entire fundraising landscape, and that "overenthusiastic intern" framework your workplace uses.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: AI has been a boon for my colleagues in fundraising who do not speak English as a first language. Many of them are warm, collegial people who present themselves well in-person, but couldn't get their foot in the door over email or written communication because of communication differences. People in the fundraising space always talk about how much they want to diversify the field, and I do think that AI shouldn't be overlooked as a tool that can help them accomplish it.

AI: That's such an important point that I hadn't considered - AI as a tool for leveling the playing field in written communication. It really highlights how technology can sometimes address barriers that weren't immediately obvious.

Thank you again for your time and for sharing your experiences so openly. Your insights about the regulatory landscape, the generational shifts in donor behavior, and especially that perspective on how AI might help diversify fundraising have been incredibly valuable for our research on human-AI interaction in professional contexts.
