# Dialog 00903

**Transcript ID:** work_0695

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good to you? Do you have any questions before we begin?

User: Nope, that sounds good to me!

AI: Perfect! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: One of the main tasks we use AI for on my daily tasks is a tool that redacts all PII from video/screenshots. You feed the video into the AI tool, add a number of words to specifically redact and a few that you don't want it to redact, and the AI Tool is supposed to do this (and quickly) for you. It will also redact common words/concepts even if not specifically told to do so that fall within concepts of PII: account numbers, phone numbers (but it leaves the area code so you can tell it is a phone #), email addresses (before the @ symbol and after that @ symbol as well if they are personalized domains), SSN, etc. I also use CoPilot when I'm stuck on something.

AI: That's really interesting - it sounds like you're using AI for some pretty specialized tasks. 

Tell me more about that PII redaction tool. What kind of work do you do that requires redacting so much personal information from videos and screenshots?

User: I work in financial market research as an editor. We have videos that include customers' personal information for our various clients. We cannot publish reports with customer's PII, so it must be redacted before we finish the reports and publish them for the clients/those following the clients' brands.

AI: That makes perfect sense - financial research would definitely require careful handling of personal information. 

I'm curious about your experience with that PII redaction tool. You mentioned it's "supposed to" redact things quickly for you. How well does it actually work in practice? Do you find yourself having to go back and fix things it missed or correct things it redacted that it shouldn't have?

User: It's pretty abysmal. We've fed it a white list of words it should not redact. It cannot seem to keep this contextual information. Words like "account" and "balance" should not ever be redacted, but they are frequently. It also can't seem to understand that "Bill Pay" is different than the name "Bill." Then it will leave PII it's not supposed to, especially if it is in the background of a screenshot with a popup window in front of information. So if there is an account number on the screen but in a greyish area because a pop-up window is in the foreground, this AI tool misses the number in the background even though it is paramount we redact account numbers.

AI: That sounds incredibly frustrating - especially when you're dealing with something as critical as protecting customer PII. It seems like the tool is both over-redacting things you need to keep and under-redacting the sensitive information you absolutely must remove.

When the AI tool misses things or gets it wrong, what do you end up having to do? Are you essentially having to review everything manually anyway to catch these errors?

User: As the report editor, it is my job not just to edit the report but to check every single screenshot used within the report. If PII has been left in the images, we have to then redact them by hand by blurring the information with an image editing tool. This takes time away from the other tasks I need to do for the day.

AI: So you're essentially doing double work - using the AI tool first and then having to manually review and fix everything it gets wrong. That definitely sounds like it's adding time rather than saving it.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different from something like the PII redaction where you're willing to try the AI approach first?

User: I like using AI to help me when I have a question or to help me ideate things. It would be great if I could trust it with this repetitive task, but I cannot.

AI: That's a really clear distinction - you trust AI more for creative or problem-solving support, but not for tasks where accuracy is absolutely critical.

When you use AI for those questions or ideation, could you describe your typical interaction pattern? Are you more likely to have a back-and-forth conversation with it throughout your thinking process, or do you tend to give it a complete request and let it handle things independently?

User: I prefer to have a back-and-forth as I don't find AI to ever be spot-on with the ideation process. It sends me in a direction and then we discuss possible outcomes.

AI: That collaborative approach makes a lot of sense for ideation work - using the AI as a thinking partner rather than expecting it to deliver a perfect solution on the first try.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Are other people at your company using these tools, and does that affect how you approach them?

User: The Powers That Be have spent a lot of money on the redaction tool, so they want/need it to work. When we tell them about its shortcomings, we are told it is our fault. (It is not.) Or they simply ignore our concerns. My colleagues struggle in the same way to get it to work, lamenting that it adds time to their day instead of making things more efficient.

AI: That sounds like a really challenging situation - being blamed for the tool's failures when you're the ones actually trying to make it work day-to-day. It must be frustrating to have your professional judgment questioned when you're reporting real problems.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I was able to have an LMM help me keep track of the edits I had to make to the other homegrown redaction tool so that I could write a report for the bosses to let them understand how much I was having to edit the AI's work. Now, nothing came of that report, but it felt good to write it.

AI: That's a really interesting use case - using AI to help document the failures of another AI tool. It sounds like you found a way to make the technology work for you even in a frustrating situation, even if the end result didn't lead to the changes you were hoping for.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I've considered it. I'm an editor. That feels like something AI could do. However, when I watch it make basic mistakes over and over again, I know I exist for a reason. Will it get better? Probably. My job is to stay on top of all AI tools so that I can prove/show I am an asset on top of AI. This is a time of being adaptive and flexible if you want to keep your job.

AI: That's such a thoughtful perspective - staying ahead by understanding the tools rather than avoiding them, and recognizing both their current limitations and future potential.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it changing as the technology improves, or do you think your approach will stay fairly similar?

User: I currently don't have a good feel on this particular question. We are constantly trying to get the current redaction tool to work better/properly. I know some other colleagues above me are using AI in similar ways as me to ideate and stay on top of things. I think it will always continue to evolve as we watch AI evolve alongside us.

AI: That makes complete sense - it's hard to predict the future when you're still wrestling with getting the current tools to work properly.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how you're staying adaptive and using AI as a thinking partner for ideation while remaining realistic about its current limitations for critical tasks.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Nope! That's all. Thank you so much!

AI: Thank you so much for your time and for sharing your experiences so openly! Your insights about the gap between AI promises and real-world performance, especially in high-stakes situations like PII redaction, will be incredibly valuable for our research on human-AI interaction in professional contexts.

I really appreciate how candid you were about both the challenges and the ways you've found AI genuinely helpful. Take care!
