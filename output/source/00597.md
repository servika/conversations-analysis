# Dialog 00597

**Transcript ID:** work_0224

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: No that all sounds good

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I rarely use AI in my typical workday. Occasionally I might perform an AI-assisted web search, but that's about it.

AI: That's interesting - so AI hasn't become a regular part of your workflow yet. When you do use those AI-assisted web searches occasionally, what prompts you to turn to that instead of a regular search? What are you typically looking for in those moments?

User: AI is increasingly embedded in most search engines anyway, so it's the path of least resistance. But if there's a very specific research question I have whose answer might not be easy to find on the first page of a regular search, I might ask a chatbot. That's fairly rare though.

AI: That makes sense - you're encountering it almost by default in search rather than seeking it out. When you do have those specific research questions that lead you to a chatbot, what types of questions are those usually? Can you give me an example of when you last did that?

User: For example, a few weeks ago I asked a chatbot about the contents of an economic report from the early twentieth century. This was related to my own research/reading.

AI: That's a great example. So you were looking for information about historical economic content that might not be readily indexed or summarized elsewhere. 

When you used the chatbot for that research question, how did that interaction go? Did you get what you needed right away, or did you find yourself going back and forth with follow-up questions?

User: I sensed it didn't have direct access to the report in question - it knew of the broad outlines but not the specific details.

AI: Interesting - so you could tell it had some general knowledge but lacked the specific depth you were looking for. In that situation, what did you do next? Did you abandon the AI approach and go look for the report through other means, or did you try a different way of asking?

User: I think I asked one more question to see if it was capable of being more precise, then found the report online myself.

AI: That's a helpful example. Given that experience - where the AI gave you general knowledge but you ultimately needed to find the primary source yourself - I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: Yes, there are many tasks like that. Theoretically AI could mark student work, for example, but I would consider it irresponsible not to do it myself.

AI: That's a really clear example. What makes marking student work feel irresponsible to delegate to AI? What is it about that particular task that feels like it requires your direct involvement?

User: Firstly, I wouldn't trust the accuracy as much as I trust myself. Secondly, direct involvement is in the nature of teaching work, which is a qualitative and social activity that probably shouldn't be outsourced.

AI: That's a thoughtful distinction - both the accuracy concern and the idea that teaching is fundamentally social and qualitative work. 

When you do use AI for work, like with that research question about the economic report, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to ask it to handle something complete and discrete?

User: So far it's been nothing more than a single discrete task

AI: That fits with what you've described - just those occasional specific research questions. 

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you hear much discussion about it, or have there been any policies or expectations set around AI use?

User: I work freelance so there are no workplace policies or specific expectations. My students often mention AI but that's about it.

AI: Ah, working freelance definitely changes that dynamic. When your students mention AI, what kinds of things are they saying about it? Are they talking about using it for their work, or asking about it in some other way?

User: They're often registering a vague anxiety about plagiarism - "Does this sound too AI" is a phrase I've heard a few times (referring to their own writing)

AI: That's fascinating - they're worried their own natural writing might sound artificial. When students express that concern to you, how do you typically respond? What do you tell them about distinguishing between their own voice and AI-generated content?

User: I tell them that it's fine to use AI as a research tool but that one can generally detect AI-generated writing.

AI: That's interesting - so you do see a legitimate role for AI as a research tool in student work. Can you share a time when using AI at work - whether for your own research or in your interactions with students around AI - made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I had one student who clearly *was* using AI to generate their work. That was frustrating, and it was difficult to coax them towards using their own intellect instead.

AI: That sounds like a challenging situation. When you say it was difficult to coax them towards using their own intellect - what did that process look like? What approaches did you try, and what made it particularly difficult?

User: For example. I would ask them a question and they would take their phone out to look up the answer.

AI: That's a vivid example - reaching for the phone instead of engaging with their own thinking. It sounds like it goes beyond just AI-generated writing to a deeper pattern of avoiding intellectual engagement. 

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, given your field?

User: I tend to assume human labor will always be needed, so I think more in terms of having to work alongside AI and what that will entail.

AI: That's an interesting perspective - focusing on working alongside rather than being replaced by AI. When you think about what working alongside AI will entail in your field, what do you envision that looking like? How might that partnership evolve?

User: I would hope the routinized computer-based tasks would be increasingly automated, so more time would be freed up for irreducibly human tasks like teaching itself. But that may be optimistic

AI: That vision makes sense - AI handling the administrative and routine tasks so you can focus more on the teaching and human connection aspects. You mentioned that might be optimistic though. What makes you think it might not work out that way?

User: Because more likely AI will be employed wherever it is profitable, sometimes for better, sometimes for worse.

AI: That's a realistic assessment - the profit motive driving adoption rather than what might be best for education or human flourishing. 

Looking ahead, how do you envision your own relationship with AI at work evolving, given that perspective about how it will likely be deployed?

User: I expect minimal change in the short term with regard to my teaching work, given the lack of institutional pressures etc I mentioned. In terms of research, I expect to use it more as a research tool as it becomes more reliable over time.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on the tension between AI as a potentially useful research tool versus the profit-driven deployment that might not always serve educational goals best.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, that covers it I think

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about the nuanced ways AI fits (or doesn't fit) into freelance teaching work, and especially your observations about students' relationships with AI, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!
