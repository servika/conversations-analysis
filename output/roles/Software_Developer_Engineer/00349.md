# Dialog 00349

**Transcript ID:** work_0740

---

Assistant: Hi! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: That sounds good

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I'm a software developer so it heavily depends on what my task for the day is. I've found that AI coding in general is pretty hit or miss. What AI excels at is creating features from scratch though. You may have to do quite a bit of debugging and steering the model but I think that it spins up new features faster than I could without AI. So I use it mainly to spin up new features quickly, or sometimes I use the research functions if I'm completely new to an area and want to learn more before diving in

AI: That's really helpful context. When you mention that AI excels at creating features from scratch but requires debugging and steering - can you walk me through what that process typically looks like for you? 

What does that back-and-forth interaction feel like when you're guiding the AI through building a feature?

User: So first I will sketch out what I want the feature to do and tell the model. I try to be as specific as possible with as many constraints as I can think of. But usually the model will get at least one thing wrong, or there will be at least one bug. So once the feature is spun up, I will start making tiny iterations. Sometimes the model will get stuck so that is when I will manually go into the code and tell the model exactly what's wrong and what it needs to fix. Sometimes if it's super minor I'll just do this myself and tell the model that was done and the next topic to move onto.

AI: That's a really detailed picture of your workflow. It sounds like you've developed a pretty specific approach to working with AI on these features.

I'm curious about your decision-making process when something goes wrong. How do you decide whether to let the AI keep trying to fix an issue versus jumping in and handling it yourself?

User: If the AI starts to do the same response twice in a row I jump in and fix it. Or if I'm fairly sure I know exactly what's wrong, I'll manually confirm that before sending the model on a wild goose chase. I've had situations too where the task I gave AI was just way too large. I make commits very often working with AI so I can easily roll back and have it try again

AI: That makes a lot of sense - using commits as your safety net and recognizing those patterns when the AI gets stuck. The detail about catching repeated responses is particularly interesting.

You mentioned earlier that you sometimes use AI's research functions when you're new to an area. How does that experience compare to the feature-building work? Do you find yourself interacting with the AI differently when you're learning versus when you're building?

User: I don't think I interact with it much differently. But when I research I try to give the model context as to why I'm asking the question I am. For example I'm new to game development right now. I researched Phaser and the animation system. I really wanted to understand how Phaser loads and uses animations, so I made sure to tailor my request in a way that would work through all the animation systems Phaser used.

AI: That's a thoughtful approach - giving the AI that context about your learning goals. 

I'm curious about your preferences when working with AI. Are there certain tasks in your development work that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: The only thing I'm very against using AI for is any sort of artistic endeavor. I do not think AI should be in the business of image/video generation and even spanning to content/written generation. Any sort of code or technical job I'm happy to let AI do. I just also would like it to explain what it is setting up so I can manage it myself.

AI: That's a clear distinction you draw between technical and creative work. 

When you say you want the AI to explain what it's setting up so you can manage it yourself - can you tell me more about what that looks like in practice? How important is it to you that you understand what the AI has built, versus just having something that works?

User: So for instance I'm building my game. It's helping me set up a Railway server that I've never dealt with before. I don't want to be beholden to AI every time I need to do any sort of maintenance with the server. I would like to know what's going on. Also sometimes AI makes bad suggestions, and I would like to have enough technical knowledge to challenge it. For example before we were going the Railway route, it had me set up a DigitalOcean droplet. After researching this though I found it was going to be way more expensive for my use case to justify

AI: That's a really insightful example - it shows how your understanding helps you make better strategic decisions, not just maintain what's built.

When you work with AI on these technical tasks, would you say you're more likely to collaborate with it throughout the process, or do you tend to give it complete tasks to handle independently and then review the results?

User: I would say a share of both. I usually try to collaborate though, as I have a very clear vision of what I want

AI: That vision-driven approach makes sense given what you've described. 

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find yourself using it differently based on team dynamics or company policies?

User: I actually didn't use much AI until my workplace really started to adopt it. One of my managers strongly encouraged use of it. I was reluctant until I saw how much my coworkers were getting done with it and then I started to adopt it as well.

AI: That peer influence sounds like it was pretty significant in shifting your perspective. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I know it has made me frustrated before when it gets stuck in the loop of trying to debug. it gets frustrating after the 15th attempt of debugging. That is why I commit often though so it doesn't get stuck. I'll route it a different direction when I start a new chat

AI: The frustration with those debugging loops really comes through - and it sounds like you've developed some smart strategies to manage that.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Yes I do actively try to do that so I know in what direction to steer the AI. Sometimes it can give bad technical advice so I like to understand what I'm trying to build. I'll often ask clarifying questions if I don't feel like I fully understand what's going on.

AI: That makes a lot of sense - staying knowledgeable enough to be a good guide for the AI.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I think I will probably use more AI at work and integrate it as it becomes available. The things I work with are proprietary though, so I have to be careful which models I use

AI: That's a practical consideration with proprietary work. 

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how you've developed strategies like frequent commits and starting fresh chats to work around AI's limitations, and how peer influence shifted your initial reluctance.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about the iterative nature of working with AI, the importance of maintaining technical understanding to guide it effectively, and how workplace culture can influence adoption will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk me through your workflow and decision-making process in such detail. Have a great rest of your day!
