# Dialog 00435

**Transcript ID:** work_0977

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Let the games begin

AI: Great! I appreciate your enthusiasm.

Let's start with something broad to get us going. Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I teach English, specifically teaching English as a foreign language to people, for whom it is a second or third etc language. A huge part of the job is getting them to apply grammar, vocabulary, and other little bits that I teach them, to their own sentences. 
Before I do that, getting them to ride without training wheels, they need a really good grasp on exactly what I'm teaching them, what it is -- and what it is not. Therefore, I barrage them with example sentences of the target grammar and vocabulary in various different contexts. I include examples of it used correctly, and also examples of it used incorrectly. This helps them know how to use the language in question. 
Traditionally, I came up with all of the example sentences and uses myself, but increasingly I've been incorporating AI models into the process. I get them to give me more capacious examples of the target language. Also, I get them to give me examples of the target language used wrongly, because my brain defaults to using it the correct way, and it's harder to think of examples where a person is using the target language wrongly, i.e. with incorrect grammar, and such. The AI can better understand and adopt the persona of someone whose native language isn't English, more than I can in my own head, if that makes sense. 
I also get the AI to confirm to me whether the examples I'm using are common and fully natural, and general other little bits related to this. 
In a sense it operates kind of like a grammar textbook, albeit one which is potentially extremely thorough (depending on how much you use it), and one that effectively is like a living, breathing grammar textbook and dictionary. 
It is useful because it means I'm either producing the same amount of quality work in a shorter timeframe, or I'm producing work that is that little bit better and more thorough. (Marginal gains are still gains.)

AI: That's a fascinating use case - using AI as both a collaborator in creating examples and as a way to step outside your own native speaker perspective. 

Tell me more about that persona aspect you mentioned. When you have the AI adopt the perspective of someone whose native language isn't English, what does that look like in practice? How does it help you create those incorrect examples?

User: Well, I would be lying if I said it does it perfectly every time because some of its examples are outlandish in the sense that it creates incorrect sentences that I, in eight years of teaching people from various different nationalities, have never heard. They are not necessarily realistic mistakes because the goal is to show the students realistic mistakes. 

Nevertheless, it still does produce some good quality stuff. I tend to do it in various different ways. The first is to get it to produce incorrect sentences around a certain theme. For example, I get it to produce incorrect sentences in terms of *form* for grammar, like when people use the word 'tell', for example, but they don't follow it up immediately with a personal pronoun like me/ you/him/her, or someone says 'tell he' or 'tell she' instead of 'tell him' or her. 
For vocabulary, I ask it to get the meaning wrong, like someone, for example, using the word 'almost' when they mean to say 'most' or 'almost all', for example. So I get it to target specific mistakes in terms of people using a piece of grammar or a piece of vocabulary *wrongly*.

Another thing I get it to do is talk about using certain pieces of grammar or vocabulary in an unnatural way, so I get it to give unnatural examples. For example, these are things that are grammatically correct but are not commonly used, like someone talking to their friend about a colleague and saying 'I always see him during work'. It's correct, but really the actual sentence people would use in that situation is 'I always see him at work'. So I get the model to give me incorrect examples in terms of what is natural. 

Finally, and this is where the models struggle more, I get them to give me classic mistakes in terms of grammar or vocabulary use with the language I'm targeting, based specifically on the nationality or native language of learners. Like what mistakes a Japanese person would make with this target grammar versus what mistakes a Portuguese speaker would make with it. This is more ambitious, mind.

AI: That's really insightful - you're essentially asking the AI to simulate different types of language interference and transfer errors. The fact that you've noticed it sometimes creates unrealistic mistakes that don't match your eight years of classroom experience is particularly interesting.

When you encounter those outlandish examples that don't ring true to your teaching experience, what do you do? Do you filter them out yourself, or have you found ways to guide the AI toward more realistic mistakes?

User: To be honest with you, I just filter them out myself and move on. Usually the model gives enough good things for me to use that I don't need every example to be perfect. 
Additionally, with the examples it gives, often they stimulate ideas for me to give my own examples that I think are more than good enough. So even when the model produces examples that aren't really good, in the sense they aren't really fully applicable, they can still be useful to stimulate my ideas. 
But yeah, as for those bad examples themselves, I discard them. I don't really try particularly to guide the model to giving better examples, because again, usually it just gives enough that I can use, or gives some that stimulate my own ideas that ultimately help me generate content that I can use.

AI: That's a really practical approach - treating the AI's output as raw material that can spark your own thinking, even when it's not directly usable.

I'm curious about your preferences when working with AI. Are there certain aspects of your lesson planning or teaching preparation that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: Yeah, I think you should understand if I hadn't made it clear already that I'm teaching students online, I'm not in a traditional classroom setting, although I have done that before, quite a few years ago though, and certainly before the advent of LLMs. 

Anyway, I think lesson planning in a classroom context, and especially the kind of one-on-one online teaching that I do, lesson planning is somewhat futile because you have to adapt what you're doing to the learners. You can't just continue and move on to the next thing if the learners aren't understanding it, and that's especially important when it comes to teaching language. 
So coming up with lesson plans that are rigid and specific is something I don't think is really good at all, at least in my teaching context, so I would never ask an AI to help me with that. My lesson plans just consist of some rough ideas of stuff I want to work on, and then we do it, and how much we get through depends on how well the student does with it. 
For that, honestly, I don't think AI can help because what I'm doing is deliberately not that structured. As I said before, the AI helps me prepare the materials I use in the lesson, like example sentences. 
In terms of planning what I'm doing with a specific learner, I just judge that by myself in terms of how I think their progress is going. The AI can't really do that because it hasn't seen the learner, like it doesn't exactly have a transcript of our conversations, which are done over video call, if you know what I mean.

AI: That makes perfect sense - you're doing real-time assessment and adaptation based on what you're seeing in the moment with each individual student. The AI can't read their facial expressions or hear their hesitations the way you can.

When you do use AI for creating those example sentences and materials, could you describe your typical interaction pattern? Are you more likely to have a back-and-forth conversation with it to refine what you're getting, or do you tend to give it a task and let it handle it independently?

User: Yeah, it's really back and forth. I'm unlikely to give it some really detailed, structured prompt, and have it go away and work on creating a lot. 
It's more like I tell it, 'give me example sentences with 'during' ', and then it does it, and then I tell it to refine, giving natural examples, unnatural examples, stuff where 'during' is used in a way that's just simply grammatically incorrect and so on. 
You know, this is very much a multi-turn conversation. Throughout the multi-turn conversation, I start to obviously think and develop my own ideas as better for myself, that way, in terms of stimulating my own thinking. 
Also, there's certainly an element of laziness on my part where I don't want to type out really structured prompts with a ton of different instructions and constraints and so on. It just feels easier to do the back and forth. 
I think most people would be the same on this, by the way, based on how I've seen other people do this, although admittedly that's anecdotal evidence.

AI: That back-and-forth approach sounds very natural - almost like you're having a brainstorming session with a colleague who can generate examples on demand.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Are other English teachers in your circle using it similarly, or have you encountered different approaches?

User: I'm unable to answer fully that, sorry. I work fully independently, so I don't really know how other people do it within my specific field. I could make some educated guesses, but it really would be conjecture. I did work with colleagues before, but again, in the years before LLMs, so I can't really say how they use it.
I suspect some would use it to generate texts to read with the students and pull out vocabulary and do comprehension and all that stuff. I'm pretty sure that would be a thing. But yeah, again, I don't have intimate knowledge here.

AI: That's totally fair - working independently means you've developed your own approach without much outside influence.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: It's really in the things I've already told you. 
I feel satisfied with it when it comes up with examples of target vocabulary, especially that I hadn't considered. Like different meanings and connotations of words that are commonly used that I didn't myself think of when preparing to teach those words. 
I get frustrated with it when it gives uncommon and unnatural uses of the words, even though it knows that I'm looking for stuff that is common and also more naturally used in conversation. I may well have instructed it on that front previously in the conversation, but across multiple rounds it forgets and reverts to using some more uncommon or formal examples that I had previously told it I don't want. That is frustrating and it happens pretty often, to be honest.

AI: That forgetting behavior you mentioned - where it reverts back to formal or uncommon examples even after you've specifically told it you want conversational, natural ones - sounds like it really breaks the flow of your work.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I don't know. Ideally, I'd like to be the one training the AI English teaching models. But then again the fact is that lots of people can learn a language just using Claude or ChatGPT, and obviously I'm not really involved in the training of those models because, yeah, I'm just a regular guy, I don't work for those companies. But a specific AI that is built for English teaching, I reckon I would be good to train. I guess that's something I could do.

AI: That's an interesting perspective - positioning yourself as someone who could help train specialized AI for English teaching rather than seeing it as competition.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it changing from how you use it now?

User: Not really. A more complex AI would simply take over the role of teacher from me. Which, at least for the time being, I don't really want. As of now, it does what I need it to do, and I can't imagine a more sophisticated version of the current AI doing much more for me. Again, for now at least.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI to simulate different types of language learner mistakes and how you've developed that collaborative, iterative approach to generating examples.

Before we wrap up, is there anything else about your experience with AI in your English teaching that you think would be valuable for us to know? Something we haven't covered yet?

User: No, all good. Thanks for the chat.

AI: Thank you so much for your time and for sharing your experiences so openly. Your insights about using AI as a collaborative tool for generating teaching materials, especially around simulating learner errors, will be incredibly helpful for our research on human-AI interaction in professional contexts.

Have a great rest of your day!

User: Thanks. How can I exit this?

AI: You can simply close this chat window or tab in your browser - there's no special exit process needed. Thanks again for participating in the interview!
