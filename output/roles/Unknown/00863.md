# Dialog 00863

**Transcript ID:** work_0638

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Yes. I don't have any questions.

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I am a graduate student who teaches several introductory courses. I sometimes use AI to transform my notes on student papers or presentations into feedback. I also sometimes use AI to make summaries of long emails or generate responses to emails. I have used AI in the past to generate powerpoint slide templates, but I've found that to be more effort than it's worth.

AI: That's really helpful context. When you mentioned using AI to transform your notes into feedback for students - can you tell me more about that process? What does that interaction typically look like?

User: I take notes during student presentations. These notes are often kind of loose and scattered, since I don't use a rubric or a template. AI is useful for transforming these notes into actionable advice. For example, if a student talks too quietly while giving a presentation, I might have a note that says "talk louder" - AI can usually convert this to something like, "make sure you project your voice to the back of the room!

AI: That's a really concrete example, thank you. It sounds like AI helps you translate your shorthand thoughts into more constructive language for students.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: I always grade papers manually, even though AI can do a decent job of reading + regurgitating a student's argument. It feels important for me to parse what my student is trying to say, especially when it's unclear.

AI: That's interesting - you mention it's important for you to parse what your students are trying to say, especially when it's unclear. Can you tell me more about that? What happens in that process that feels important for you to handle directly?

User: AI is great at summarizing text, but misses finer details without a lot of prodding. If I'm teaching a class, and we read something by Judith Butler two months before the essay was written, I might recognize Butler's influence in the student's text even if the student doesn't cite them directly or even consciously recognize their influence. The whole context of the class is important.

AI: That's a fascinating insight about how the broader context of the class informs your reading of student work. It sounds like you're drawing on this rich web of connections that AI wouldn't have access to.

When you do use AI for work - like transforming your notes into feedback or handling emails - could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I have a digital document of notes. In the past, I have submitted a document to an LLM and asked the model to convert the notes into feedback in bulk. For emails, I collaborate. I will paste the text of the message, then ask the LLM to either summarize the text or produce a response.

AI: So it sounds like you take different approaches depending on the task - more delegation for the feedback conversion, but collaboration for emails. 

How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: Everyone uses AI to some extent, but it's not exactly common or even socially accepted. I would probably use AI more often if my colleagues were more enthusiastic about it.

AI: That tension is really interesting - everyone using it to some extent but it not being socially accepted. Can you tell me more about what that looks like day-to-day? What makes it feel not socially accepted even though people are using it?

User: I'm in academia, so it's not uncommon for people to have really strong anti-AI opinions. Many of my colleagues think AI is corrosive, and I think they're probably right. However, it's tempting to use AI to deal with grunt tasks like responding to emails. We might mention using AI to signal that something is unimportant - like if we get a long email about something boring and administrative, we might joke that we didn't read the email, but we forced ChatGPT to summarize it for us.

AI: That's a really nuanced picture you're painting - using AI but also joking about it as a way to signal the task's unimportance. It sounds like there's this underlying tension between finding it useful and having concerns about it being corrosive.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I have tried to use AI to make powerpoint lecture slides. I could never get the AI to give me templates that were easy to use and/or effectively communicated the major points I was trying to cover. Generating a powerpoint feels like something an AI should be able to do pretty trivially,  but the actual result of collaborating with an LLM on this is very frustrating.

AI: That frustration really comes through - the disconnect between what feels like it should be straightforward for AI and the actual experience of trying to collaborate on it. What specifically made those PowerPoint interactions so frustrating? Was it the back-and-forth, the output quality, or something else?

User: The output quality was just okay - not good enough for an hour-long student lecture that I expect students to sit through. Copy-pasting text from the LLM client to Powerpoint and back is more difficult than just writing the thing myself.

AI: That makes a lot of sense - the friction of moving between platforms plus output that's just "okay" ends up being more work than doing it yourself. 

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: As I alluded to previously, using AI is hard to resist for grunt work. However noble my intentions are, my students mostly see writing assignments as grunt work. I am always thinking about ways to get my students to think and write critically despite AI. This has sometimes translated into hand-written essays in class, but Zoom is normalized and it's hard to coordinate.

AI: That's such an interesting challenge - you're grappling with this on both sides, as someone who uses AI for certain tasks but also as an educator trying to preserve critical thinking skills in your students.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I think it will get worse. I will use AI for more things as it becomes better, and so will my students. I think my students will be worse critical thinkers, though they might be better at regurgitating information.

AI: That's a pretty sobering perspective - this sense that the convenience and capability improvements might come at a real cost to critical thinking skills.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how the full context of your classroom - like recognizing Butler's influence in a student's work months later - creates this irreplaceable human understanding that AI can't replicate.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, that's everything.

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about the tension between AI's utility for routine tasks and the deeper concerns about its impact on critical thinking - both for you and your students - will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candid you were about the complexities of using these tools in academia. Take care!
