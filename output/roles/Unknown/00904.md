# Dialog 00904

**Transcript ID:** work_0696

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: No, I feel good.

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Right now, AI is used mostly by the people that I do quality assurance for. They use it to see why customers are reaching out for support and how they can help. It also can help them pull up helpful internal articles. My work just started experimenting with using AI more in our chat bot capacity and also having it write follow up notes for conversations, so soon I'll be dealing with that more. The only thing I really use AI for is that it automatically pulls up related internal articles based on the chat when I am reading through it. I also have to read what the current AI chat bot says to our customers and what information it passes on to our workers.

AI: That's really interesting - so you're in a unique position where you're quality assuring work that involves AI, rather than using AI directly for most of your own tasks.

When you're reviewing the work that your team does with AI assistance, what do you notice? How does their work look different when they're using AI to understand customer issues or pull up articles compared to when they work without it?

User: AI has a lot of trouble understanding anything but the most basic questions. A lot of our customers have to reach out because something specific is wrong, but the AI chat bot can only understand a simple query. It also often pulls up the wrong articles because it misunderstands what the customer is asking about and just sees a keyword that it latches onto. I've found that I typically need to ignore whatever the chat bot has said and our workers are better off when they do too. I'm curious if the new ones will be better.

AI: That sounds frustrating to work with - essentially having to work around the AI rather than with it.

Tell me more about what you see when your team members do choose to rely on the AI's article suggestions or interpretations. How does that typically play out in their customer interactions?

User: Typically, it will lead to the customer having to repeat themselves over and over. For example, if they have a question about returning a garment, but write it with any background information besides just "help with return" or something similar, the AI will keep looping them back again and again saying it can help, while the customer is trying to get help from a real person. Then, when a real person does connect, they aren't sure why the customer was reaching out so they provide an acknowledgement based on the wrong thing and the customer has to repeat it all again.

AI: That cycle of miscommunication sounds exhausting for everyone involved - the customers, your team, and you as the person reviewing these interactions.

When you're doing quality assurance on these cases, what patterns do you look for to identify when the AI involvement has helped versus when it's created more problems?

User: I can usually tell within the first few messages if the AI has gotten a handle on what the customer is asking or not. The conversations all start with AI before moving to a real person, so I look for that endless loop of a customer having to repeat before a person finally comes in to support. I can also see a pattern of a worker using the wrong acknowledgement because they were confused by what the AI said. This is super common and something I often am on the lookout for.

AI: So you've developed these diagnostic patterns to spot AI-related issues quickly. That's really valuable insight.

I'm curious about your preferences when it comes to AI involvement in your work. Even though the current system creates challenges, are there aspects of customer service where you think AI assistance could actually be helpful, or do you find yourself preferring when your team handles things without AI involvement altogether?

User: I personally prefer things without much AI, mostly because I worry about the loss of human jobs. I know that our customers have mentioned our quality of customer service going down even when we started doing more outsourcing of our work to external vendors. I think that adding AI in will cost our company more jobs for people to do and also create a worse experience for our customers. Typically, if someone is reaching out to customer service, something is going wrong in a way that AI can't fix easily. For things like returns, tracking orders, looking up information on stores, etc., customers can just do that on their end. I feel like AI just adds another barrier between people getting help from another human, and I also selfishly don't want all the jobs to be taken by AI because there aren't that many!

AI: You've touched on something really important - the tension between efficiency and human employment, and also the reality that customers reaching out often have complex issues that require human judgment.

When you think about your own job security, how does watching AI being integrated into your workplace affect you day to day? Does it influence how you approach your work or think about your role?

User: It's really scary honestly. We're in a weird place where my company keeps talking about how more and more AI is going to be integrated, and they say it won't affect our jobs, but how could it not? Obviously a company would rather save money by having an AI do the work than pay humans to do it. It makes me anxious about my future at the company, where previously I felt fairly secure. Now I'm not sure how long we'll be employed or what our role will even look like.

AI: That uncertainty about your future role sounds really stressful, especially when you're being told one thing but seeing changes that suggest something different might happen.

Can you share a specific moment recently when using or working with AI at work made you feel particularly frustrated or concerned? What was happening in that situation?

User: It wasn't necessarily working with AI, but my boss mentioned that in a year or so likely my job will just be fact checking and reading over what an AI writes instead of doing the work myself. That freaked me out and made me feel like my job is not valued or seen as something a human needs to do. I also don't agree that an AI could do it as well as a person since AI finds patterns well, but doesn't necessarily grasp all the nuances that a human does.

AI: That conversation with your boss sounds like it really shifted how you see your role and value at the company. When you think about those nuances that you bring as a human that AI might miss, what are some specific examples from your quality assurance work where that human judgment has been crucial?

User: So many! Human conversations take such weird pivots and turns. As I mentioned before, the AI chat bot can't keep up with human conversations because it often doesn't understand why something is being brought up. It's looking for consistent patterns, and a lot of human connection doesn't have that. For example, a human might say something snarky about a return that an AI would completely miss the tone of. Or a human might clearly be frustrated, and an AI can fake empathy, but it can't really feel it and perform it like a human can. There are also lots of edge cases where it's not black and white and human judgment is needed. For example, if someone wants to return something that technically isn't within the policy or if they have a weird mail situation or any number of things. My work also involves a lot of grey areas and deciding if what a worker did was ultimately helpful or harmful for a customer. AI can see objectively if what was done was "right" based on information it's given, but it can't understand why, for example, a worker might make an exception for one customer but not another.

AI: Those examples really highlight the complexity of human interaction - the tone, the exceptions, the contextual judgment calls. It sounds like you see a lot of value in that human element that might get lost.

How do you think about maintaining and developing those uniquely human skills you've described, especially as your workplace moves toward more AI integration? Is this something you actively consider or plan for?

User: I'm not worried about myself keeping those human skills. I honestly think my company will either not be able to get the AI to do what they want and have to scale way back on what they plan to do, or they'll go full steam ahead and have to see the human price in customer satisfaction dropping, backlash from laying off workers, etc. and learn that way. I like my job fine, but I'm not worried about the company surviving as much as I am worried about my personal job.

AI: That's a really pragmatic way to look at it - you're confident in your abilities but realistic about the business decisions that might affect you regardless.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself adapting to work more closely with it, or do you think you'll continue to work around it as much as possible?

User: I think if I could feel confident that it really was there to help us and not a way for corporate to eventually replace us, I would find things about it useful! It would be nice to have AI that could pick out interactions that would be good for quality assurance purposes, for example. However, a lot of my work is picking those interactions so again, if AI is doing that, what am I doing? I will continue to work around it as much as I can for as long as I can, but I know that my superiors are very invested in getting it more integrated, no matter the cost.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how AI struggles with the nuanced, contextual aspects of human interaction that you see every day in customer service.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: The only other thing I wanted to touch on was that I know AI, and especially the more powerful ones, use up so many natural resources. My company has lots of commitments to the environment that they claim as part of their ethos, so I am interested how they will balance using AI with those commitments. I haven't heard any of my leaders talk about it, so I'm not sure if there's a plan in place for that or if it's just seen as part of the price to pay.

AI: That's a really important point about the environmental impact - the tension between corporate sustainability commitments and AI adoption is something that doesn't get discussed much in these workplace conversations.

Thank you so much for your time and for sharing your experiences so openly. Your insights about the gap between AI capabilities and human judgment, the anxiety around job security, and the environmental considerations will be incredibly helpful for our research on human-AI interaction in professional contexts. You've given us a lot to think about.
