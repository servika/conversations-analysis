# Dialog 00195

**Transcript ID:** work_0316

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. Does that sound good? Do you have any questions before we begin?

User: That sounds great, Im ready to begin!

AI: Wonderful! Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I am a developer at a small startup, I currently use cursor as my IDE. I typically use the AI to help with autocomplete of code while I'm working in jupyter notebooks (most of my work). I sometimes use the inline agent to generate a cell if I feel I don't immediately know how to perform a dataframe transformation (pandas) or something similar but I am sure that an AI will be able to easily complete the task. An example of this would be asking for a model to remove all of the row in which the end date and start date are within three days of eachother. This kind of task is pretty simple, but I don't immediately know how to do it so it's convenient to use AI.

The most impactful use of Cursor for me is using the full chat for help with more complex problem, such as times I'm really struggling with solving a difficult problem, or trying to debug something with no luck. I tend to find the AI has many inaccuracies when completing the investment backtest work I do, but the solution it provides usually provides a great start or sparks some ideas of possible implementation. So although the AI cannot do the job for me, it's a great helper for ideas.

AI: That's really helpful to understand your setup. I'm particularly interested in what you mentioned about the AI having inaccuracies with your investment backtest work, but still being valuable for sparking ideas.

Can you walk me through what that looks like in practice? When you're working on a complex backtesting problem and turn to the AI chat, what typically happens in that interaction?

User: Backtesting is incredibly prone to error. Any small assumptions can lead to major distortions in the results. I find that AI agents make many incorrect assumptions, or don't account for certain cases (such as shorting stocks, or opening an closing a position multiple times in a single day). One specific example I can think of was for calculating the time-weighted performance of a portfolio given a pricing history, the model did not understand the specifics of calculating time-weighted performance and made many errors and incorrect assumptions.

In practice I tend to use the 'ask' feature in cursor because I rarely actually use a model response in my code, and the code style never fits into our project. I prefer to just see a prototype solution and then use that as inpiration for my solution. The conversation is usually just a single turn

AI: That's a fascinating distinction - using it more as inspiration rather than direct implementation. It sounds like you've developed a pretty specific workflow around that.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different from the ones where you're comfortable using AI assistance?

User: Any task that requires a high-level of attention to detail, such as mapping a transaction history from a foreign format into our internal format, I prefer to do as it makes me feel in control of the outcome. I don't feel I can trust an AI model to identify subtle issues in a transaction history mapping. I feel much more comfortable completely handling this kind of data manipulation work myself to ensure data quality is the best possible.

I also do unit testing myself for the same reasons. I find models find it hard to understand how our financial modules work and create very poor unit tests for them. I like to really think through all the cases and create very high-quality unit tests myself

AI: That makes a lot of sense - there's clearly a trust element when it comes to data quality and testing critical financial logic.

When you do use AI for work, could you describe your typical interaction pattern? You mentioned mostly single-turn conversations with the 'ask' feature, but I'm curious - are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I typically start with a problem I need to solve, I brainstorm solution ideas, and if I can't find one that doesn't have clear problems, I consult AI and see how I can navigate the problem. I provide all the ideas I've come up with and their specific issues. The AI really helps to suggest other possible approaches and provide feedback of my potential solutions (in terms of best practice). I rarely delegate large tasks to AI, only small bit-sized tasks are delegated fully.

AI: That collaborative brainstorming approach sounds really thoughtful - bringing your own ideas and their limitations to get alternative perspectives.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that being at a small startup affects how you and your team approach AI tools?

User: This has been a big conversation point on the development side of my company. We're trying to figure out the best way to use AI to improve our productivity as a small team. So far the major issues are just quality of responses from the AI models. It feels like we need to provide an essay of details to descibe exactly what we want done, but models tend to perform poorly with super long prompts in my experience.

One idea we've had is creating a some cursor rules that we can distribute within our team to improve model performance and ensure the generated code meets certain standards

AI: That's an interesting challenge - balancing the need for detailed context with prompt length limitations. The cursor rules idea sounds like a practical team-level solution.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I was doing custom work for a client and they wanted a correlation analysis of their portfolio. We had never done this and it felt like a large, challenging thing to complete well. I started by asking AI to do it and was amazed when it created a massive robust correlation analysis of the portfolio. There were a few small bugs but overall it blew me away. I find the robustness of data analysis by current models feels better than anything I could create myself. The solutions still have lots of bugs, but the high-level ideas are amazing

AI: That sounds like a really satisfying moment when the AI exceeded your expectations! The fact that it provided such robust high-level analysis for something you'd never tackled before must have been quite impressive.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I personally find AI helps me learn quickly. Instead of searching stack overflow for ages trying to figure stuff out, I can ask AI and get the answer plus an explanation. I find this really helps to quickly learn new things (especially in my work with pandas).

I personally think that anything AI is really good at and can complete well I shouldn't concern myself with maintaining skills in. I think my skill as a code reviewer and knowledge of high-level coding practices is most important with the improvement of AI in development. I want to use it to automate the simpler tasks as much as possible while I fill in the more complex parts and fit everything together

AI: That's a really strategic way to think about skill development - focusing on the higher-level orchestration and review capabilities while letting AI handle the simpler implementation details.

Looking ahead, how do you envision your relationship with AI at work evolving? Where do you see this partnership heading?

User: I see AI becoming more and more powerful, and my role of a developer turning more into the role a code reviewer, rather than a developer. I see myself writing less code, and spending most of my time coding with AI and ensuring quality and testing the solution

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on evolving from a developer to more of a code reviewer role, and how you've developed such a strategic approach to when to trust AI versus when to maintain direct control.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No that's all

AI: Perfect! Thank you again for your time and for sharing your experiences so openly. Your insights about the balance between AI assistance and maintaining control over critical tasks, especially in financial work where accuracy is paramount, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candidly you discussed both the benefits and limitations you've encountered. Have a great rest of your day!
