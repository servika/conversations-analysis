# Dialog 00379

**Transcript ID:** work_0837

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Let's begin.

AI: Great! Let's start with something broad to get us going.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I work as a bioinformatician, and use AI in my day work pretty much daily. This includes direct conversations with models, primarily to help me with programming (e.g., asking for what packages to use or outright code generation). AI-based systems are also used in another way as part of my work, for example in predicting the functional relevance of a genetic variant to the context of the sample.

AI: That's really interesting - it sounds like you're using AI in two distinct ways. You mentioned direct conversations with models for programming help, and then AI-based systems that are more embedded in your workflow for variant prediction.

When you're having those direct conversations with AI models for programming - can you walk me through what that typically looks like? Are you usually asking for specific code snippets, or is it more about getting guidance on approach?

User: It can be both. For example, I may have a particular adjustment to something that I am already doing, such as 'I also want a vertical line at x=100 in my plot'. This would be asking for a specific code snippet. On other occasions, I would be discussing the approach to use, such as 'would it be better to perform a before or after b, now that I know there's a specific limitation in the environment that I'm working in?'

AI: That gives me a good picture of the range. It sounds like you're using AI both for quick tactical help and for more strategic thinking about your approach.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: I have programming experience, so if I already know how to do something, I prefer just doing it. Even if the AI generates code for me, I would look through the code snippet to make sure that it is sound before using it - I never use code I don't understand. These habits arise from me not having full confidence in the quality of the code being generated by a model.

AI: That makes a lot of sense - you're maintaining that quality control layer. It sounds like your programming experience gives you the ability to evaluate what the AI produces rather than just trusting it blindly.

When you do use AI for programming tasks, could you describe your typical interaction pattern? Are you more likely to go back and forth with it throughout solving a problem, or do you tend to ask for what you need and then take it from there independently?

User: Both. Sometimes it's a back and forth thing when I add layer upon layer to the code. Other times, I only need a quick hint and I'll be able to proceed without assistance.

AI: Got it - so it really depends on the complexity of what you're working on and how much scaffolding you need.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Are people generally open about using these tools, or is there any particular attitude toward AI use in your environment?

User: In our bioinformatics office, pretty much all bioinformaticians use AI to support their work. We do discuss our experiences with these tools - we go to them, but are fully aware that they sometimes take us in circles without solving our problem. This usually comes up from the problem is very complex and/or very niche.

AI: That's fascinating that it's so widely adopted and openly discussed in your team. You mentioned that AI sometimes takes you in circles on complex or niche problems.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I had a previous attempt when I wanted to convert a bash script into a Nextflow pipeline, and I thought AI could help me save time. What actually happened was that a lot of unusable rubbish was generated, and I ended up spent more time cleaning it than I probably would've writing it by myself from scratch.

AI: That sounds like a really frustrating experience - especially when you were hoping it would save you time but it ended up costing you more. 

What do you think made that particular task so difficult for the AI to handle well? Was it the complexity of the conversion, or something about the specific nature of Nextflow pipelines?

User: I believe it was both - the pipeline was pretty complex, so it was probably difficult for the AI to get the logic accurately and as intended. The AI model that I was using also seemed to have low proficiency with Nextflow syntax.

AI: That makes complete sense - a complex pipeline plus unfamiliarity with the specific syntax would be a challenging combination for AI to handle well.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I think it is very important for my field - I have to be responsible for the work I put out. Therefore, I need to keep on top of things to make sure I have the capability for quality control. I don't view AI as a threat that will replace me, but a helpful collaborator/assistant.

AI: That's a really thoughtful perspective - viewing AI as a collaborator while maintaining your role as the one responsible for quality control.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself using it differently as these tools improve, or do you think your approach will stay fairly similar?

User: For sure - I have already gone through this shift from the improvements to the many models available in the past year or two. I used to only ask for what package to use (which saved me a lot of time that I would've spent on Google and other forums). Nowadays I take code snippets generated from the AI if they look good. As they get more and more reliable, I save more time in my work.

AI: That's a great example of how your usage has evolved with the technology. It's interesting that you've gradually moved from just asking for package recommendations to actually using code snippets as your confidence in the output has grown.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on maintaining that quality control responsibility while still embracing AI as a helpful collaborator.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I think our conversation summed up my experience pretty well. I am happy to end the conversation here.

AI: Perfect! Thank you again for your time and for sharing your experiences so openly. Your insights about how AI fits into bioinformatics work, the importance of maintaining quality control, and how your usage has evolved over time will be incredibly helpful for our research on human-AI interaction in professional contexts.

Have a great rest of your day!

User: See you!

AI: Take care!
