# Dialog 00873

**Transcript ID:** work_0653

---

Assistant: Hi! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Sounds good. Just want to check that this is a text only conversation?

AI: Yes, exactly - this is a text-only conversation. We'll be chatting through written messages like this throughout the interview. 

Perfect, let's get started then. Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: My school district discourages the use of AI in general, so when I use it, it's "off-the-record". However, there is one AI tool they have us use to automatically translate mass communications we send to parents to the home language listed in the student file. In terms of what I use it for, I have ChatGPT or Gemini identify the objectives and can-do statements for my lesson plans because it's a task that I don't see a lot of value in and is tedious, so I have AI do it. It does take a bit of time to copy/paste the lesson ideas, so it's tedious to use AI in that way but it saves me the tedious thinking aspect of doing it. I also use it to brainstorm project ideas and simplify some of the more complex concepts into words students will better grasp.

AI: That's really interesting - it sounds like you're navigating some tension between official policy and practical utility. 

When you mention using AI for objectives and can-do statements because you don't see a lot of value in that task, could you tell me more about what makes certain tasks feel valuable to you versus not worth your time?

User: In this case, I have to write these on the board daily. Most days, we're just working on a grammar topic, so the objective is "learn how to write sentences with X grammar" and the can-do is "I can write X grammar in sentences". It's repetitive, and I don't think students even glance at it. But if they come in to my classroom, I get marked down if it's not on the board. So it's work that I don't think adds value to the students, and it doesn't help me as an instructor either. Tasks like this that are mandated by higher ups but don't seem to add real value don't feel like they're worth my time.

AI: That makes a lot of sense - you're describing administrative requirements that don't seem to connect to actual learning outcomes.

When you use AI to brainstorm project ideas or simplify complex concepts for students, how does that feel different? What makes those uses feel more worthwhile to you?

User: Honestly it saves me some brain power, and I do get a little worried that I'm being "lazy" and lowering my creativity by outsourcing these tasks. The AIs do come up with great ideas, so that's why I keep using them for these purposes.

AI: That's a really honest reflection - the tension between efficiency and concern about creativity seems significant. 

When you say the AIs come up with "great ideas," what does your process look like after that? Do you typically use their suggestions as-is, or do you find yourself modifying and building on them?

User: I definitely modify and build off of them because I know all of the context of the class - individual student interests, strengths, difficulties, current or past events that are especially important to them or our school/community, etc. I'm sure if I put every single detail about my class into a prompt, the AI could come up with an idea that I wouldn't need to modify at all, but that would be basically impossible to do that amount of knowledge transfer. Therefore, I get seeds of ideas and modify from there.

AI: That's a really insightful way to think about it - using AI for "seeds of ideas" that you then cultivate with all your contextual knowledge about your students and community.

When you're in that process of modifying and building on AI suggestions, how does that interaction typically unfold? Are you going back and forth with the AI as you develop the idea, or do you tend to take the initial suggestions and then work on them independently?

User: Mostly I get some good ideas on the first round, but sometimes I'll continue if the AI is missing some important context that I forgot to tell it or if it's ignoring important context.

AI: That gives me a good picture of your workflow. I'm curious about the workplace dynamics you mentioned earlier - you said your school district discourages AI use in general. 

How has that policy environment influenced the way you actually use these tools? Does it affect which tasks you're willing to use AI for or how you go about it?

User: Yes, I don't use it for anything that the admin would see directly (besides the objectives/can-dos, but those are generic enough that you can't tell it's AI). I also don't really talk about using it because I don't want other teachers to gossip. I just use it privately, basically.

AI: That sounds like you're being quite strategic about maintaining privacy around your AI use.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: The first year I taught [REDACTED], I had so many ideas swimming in my head and a SUPER tight schedule for getting my class through all the readings, doing text prep, exams, etc. I used it after braindumping what I wanted to teach my students about a text, and it heled me break it all down and outline it for me to make a PPT off of it. That was so helpful, and probably the biggest relief I got from using AI so far.

AI: That sounds like it was a really pivotal moment - having all those ideas organized when you were under so much pressure. 

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I know it's a hot topic being discussed right now - AI taking over teaching. I really don't see how it's possible with the models right now. There is so much more to teaching than just instruction. That portion of the pie chart is not very big. However, it is SUPER important. I think AI can definitely help students practice and quiz themselves. I tell my students to use the AI chatbot on Quizlet to practice chatting in Spanish. It's a great tool, but it doesn't recreate the work I do as a teacher.

AI: That's a really thoughtful perspective on the broader context of teaching versus just instruction.

Looking ahead, how do you envision your relationship with AI at work evolving? What do you think might change about how you use these tools?

User: I would like to do more lessons on teaching students about how to use AI without falling into academic dishonesty. However, it's hard to fit it into a Spanish class. I think if my district doesn't change its policy, I'm not going to rock the boat and go out on a limb advocating for AI usage or anything. It's not that important to me to promote it or oppose it. I think it's a tool that can be used for good and bad, so the education for admin, teaching staff, and students needs to be how to use it for good.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI for "seeds of ideas" that you then develop with your deep knowledge of your students and community context.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I am getting a lot of feedback from fellow teachers and have felt this myself - when students use AI, it's quite obvious, but many times, districts/admin don't have teachers backs and say we can't prove it. I was told that I'm not a detective - I'm a teacher, so just grade the work and move on. This is not a problem unique to the dawn of this new age of AI. It's always been like this. There are some school cultures that excuse cheating and academic dishonesty. The admin don't want to deal with it. Students and parents become incensed, and giving true consequences can lead to more students failing classes, not graduating, or being held back a year. They'd rather pass students along than give consequences for academic dishonesty, and I think it is just becoming more rampant with easy, universal access to AI.

AI: Thank you for sharing that - it sounds like AI has amplified existing tensions around academic integrity and administrative support that were already present in education. That's a really important perspective on how these tools intersect with broader institutional dynamics.

Thank you again for your time and for sharing your experiences so openly. Your insights about navigating policy restrictions, using AI as a starting point for your own expertise, and the broader challenges around academic integrity will be incredibly helpful for our research on human-AI interaction in professional contexts.
