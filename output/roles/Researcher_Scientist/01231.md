# Dialog 01231

**Transcript ID:** science_0061

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: No it sounds good.

AI: Wonderful! Let's dive right in.

To start, I'd love to hear about your work. Can you walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: I was in charge of developing AI able to detect faults in seismic volumes. There are some good models for this task but the best one is proprietary so I was put in charge of developing our own. The catch is that I work for a mining software company, not a mining company, so we are not allowed to use client's data to train a model that will be used for another client's data. Further, there is a paucity of good annotated data. So the approach which other researchers have taken before me and that took as well was to train the model on artificial data. This revealed itself to be far more complicated than it sounds, as there are many different aspects to seismic data, and an abundance of parameters involved in faulting, folding, impedance, reflectivity, and noise. The last aspect - noise - was surprisingly complicated. It required extracting noise from real images through a process of diffusion conditioned by a structure tensor. Still, the model is performing well-enough but it is currently stashed away as a POC, where most AI projects in companies that are not AI dedicated go to die. It consists of a UNet by the way, and one of the challenges was optimising the model without a true validation set. A mere partition of the artificial dataset is not a very good approach when the data is so similar in distribution. I still plan to obtain a true validation set by annotation free seismic sets.

AI: That's fascinating - the challenge of developing AI for fault detection without being able to use real client data sounds incredibly complex. The artificial data generation approach with all those geological parameters you mentioned - faulting, folding, impedance, reflectivity - that must have required deep domain knowledge to get right.

I'm particularly intrigued by that noise extraction process you described using diffusion conditioned by structure tensor. Tell me more about how you approached that specific challenge - what made the noise aspect so surprisingly complicated?

User: Well I could not replicate the noise despite trying several approaches, including some as complex as fractal noise. Upon closer investigation it became clear that the type of noise usually present in seismic images has some structure to it which is difficult to replicate. So I found a paper which uses a diffusion PDE in order to smooth images perpendicularly to the local structure, so as to cancel everything but the noise. Then, by subtracting the smoothed image from the original one, I obtain the noise, which I sample and add randomly to my artificial seismic volumes.

AI: That's a brilliant solution - using the diffusion PDE to preserve the structure while isolating the noise. The insight that seismic noise has its own inherent structure rather than being random is really interesting.

Now, thinking about this entire project you've described - where in that process, if anywhere, have you experimented with using AI tools beyond the core fault detection model you were building?

User: I used chat GPT (sorry Claude) to quickly come up with code to calculate the structure tensor and solve the diffusion PDE. This was perhaps the greatest example of the power of AI as a productivity tool in my experience so far. I was unable to find code to perform the smoothing so I had to come up with my own. However, with the help of AI, I was able to in one day start with the paper, read it, and chatting back and forth with chatGPT come up with the code to my problem. I am a mathematician and would eventually come with something after a few days, but to start with a complex paper and end up with it translated into code in one day was extraordinary.

AI: That's a powerful example - going from paper to working code in a single day when it might have taken you several days otherwise. The back-and-forth nature you describe sounds really valuable.

For that specific task - translating the diffusion PDE approach into code - tell me about how you decided to use ChatGPT versus tackling it with your traditional approach. What made you think to reach for AI in that moment?

User: Well I do not have that much experience of numerical solution of PDEs, especially not constrained by a structure tensor. Also, if I am honest, I have developed the habit of turning to AI as a first port of call for many of the problems I face at work, if the answer is not immediate, almost as a replacement of google. Sometimes it is extraordinarily useful, sometimes not so much. It seems to be an art to prompt models correctly and to understand their limitations. Yourself and chatGPT seem to work fine for simple solutions, but performance rapidly degrades with the complexity of the task, to give one example.

AI: That habit of turning to AI as a "first port of call" instead of Google is really interesting - it sounds like it's become a natural part of your problem-solving workflow.

You mentioned that performance degrades with task complexity, and that there's an art to prompting and understanding limitations. Thinking about the parts of your seismic fault detection project where you haven't used AI tools - what's kept you from trying AI there?

User: In this particular case I simple have enough experience with CNNs to do a good job myself. More generally, working for a private company means I cannot share code with any AI tool for privacy reasons. There is also an element perhaps of not wanting to see my own skills fade too much. But perhaps above all is the fact that even the best LLM based chats are not able to provide working solutions to highly complex problems. If they were, it would be almost obligatory to use them so as to boost your productivity, but in practice the time debugging the AI provided code is often just as long as building it from scratch.

AI: Those are really practical constraints - the privacy limitations of working with proprietary code, concerns about skill atrophy, and that crucial point about debugging time potentially negating productivity gains on complex problems.

When you have used AI for tasks like that PDE implementation, how do you verify or validate what it produces? What's your process for making sure the code actually does what you need it to do?

User: Primarily inspecting the code myself, but obviously also testing the code on a range of inputs.

AI: That makes sense - code inspection combined with testing across different inputs.

We're about two-thirds of the way through our conversation now. I want to ask you this: if you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: Gee that is a hard one let me think... I guess the main thing I would like it to do is to generate working code for more than simple tasks. For example: as part of the POC we have been discussing I went back and forth for hours if not days with you Claude about creating a small app in Python/Trame. it was my first attempt at "vibe coding", where I simply trusted the AI to give me the final product and I had little interest in the inner workings. Alas, after a long time, I had to dig in myself and google lots of things, when I just wanted the app as if waving a magic wand. it was not central to my project and I don't care about app development.

AI: That's a perfect example - you wanted AI to handle the "peripheral" technical work so you could focus on your core expertise. The gap between wanting to just wave that magic wand for app development versus having to dig into the details when you really just needed a working tool.

Those are all my questions - your perspectives on AI as a productivity multiplier for familiar tasks versus its current limitations on complex problems were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: Well these days I am often chatting to LLMs about how to get LLMs to do what I want in an agentic way which is a bit meta

AI: That's wonderfully meta! Using LLMs to figure out how to better use LLMs - there's something almost recursive about that. It sounds like you're exploring the agentic side of things, which is definitely at the cutting edge.

Thank you again for sharing your experiences so openly. Your insights about AI as a "first port of call" replacing Google, and especially that practical reality check about debugging time potentially negating productivity gains on complex tasks, really help us understand the nuances of how AI fits into real scientific work. The contrast between your success with the PDE code translation versus the struggles with the Python/Trame app perfectly illustrates where the current sweet spot is versus where the gaps still exist.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
