# Dialog 00047

**Transcript ID:** science_0029

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your research work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer here—we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: No questions yet, sounds good

AI: Great! Let's dive in then.

To start, I'd love to hear about your work. Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: Ok, one recent project I worked on was working with coral, preparing for spawning. The initial idea came mostly from my bosses, who gave framework of what they expected from my team of researchers. We ultimately wanted to set up a settlement structure that we could use in situ for coral spawning, using different material tiles to test settlement on different substrates. First this involved a literature review of published papers that might be applicable, then used these findings to develop a blueprint for a structure, then made calculations and did research to find appropriate materials, made prototypes of our structures, deployed and tested these, and fine-tuned until we had our final structures to deploy in situ for spawning. We're currently in the stage of waiting for corals to settle so that we can collect them and analyze data.

AI: That sounds like a fascinating project - the complexity of moving from literature review all the way to field deployment is really impressive.

Where in that process, if anywhere, have you experimented with using AI tools?

User: I used AI in a few parts: first, in the literature review, used AI (of different forms) to help identify papers of interest, summarize papers of interest, etc. Then definitely used AI to help with calculations / thinking through dimensions for our blueprint & how much material we needed to order of various parts

AI: Interesting - so AI came into play during both the research synthesis phase and the design calculations. 

For the literature review part specifically, tell me about how you decided whether to use AI versus your traditional approach for finding and summarizing those papers.

User: I initially did my own traditional approach for finding papers, and found several of interest, but then also used AI after to try and see if there were papers I missed, or other papers / sources that I should consider to read for my literature review. For summaries, my final summaries were always content I had written, but I sometimes used AI as an initial tool to get a quick summary to see if the paper was actually of interest / read a shorter summary before slogging through an entire research paper. I also occasionally used AI as a tool to see what AI thought important points were vs. compared to things I pulled out of the paper as points of interest for the context of our project

AI: That's a really thoughtful approach - using AI as a supplementary discovery tool and then as a comparison point for your own analysis. 

We're about a third of the way through our conversation now. Let me ask about the other side - thinking about the parts of your research where you haven't used AI, like the prototype testing or field deployment phases. What's kept you from trying it there?

User: I guess I could've used AI in help for designing the prototypes, but it was also highly dependent on materials / resources we already had available at my work, and it would've taken a lot of time to give AI all the context of what we were working with / the constraints from my environment and workplace. The prototype testing and field deployment were physically putting our prototype in the ocean, so I don't think AI would've been possible or helpful for these stages. We were basically just submerging our prototype to see if it would hold up in oceanic conditions, and testing it for its feasibility and practicality. The field deployment too was physically putting our structure in the ocean to collect coral settlement, so AI wouldn't be able to help here

AI: That makes complete sense - those physical testing phases really require hands-on work that AI can't participate in directly.

When you did use AI for those literature reviews and calculations, how do you verify or validate what it produces? What's your process for making sure the AI output is reliable?

User: For the AI literature reviews, my final lit review was entirely my own work and my own summarizing. I would use AI as a tool to try to identify papers of interest, where I would then go in myself and decide if they were papers I wanted to use. I would also use AI to make initial summaries of papers, but then always went through myself to read the papers and come to my own conclusions / write my own summaries / take out my own points of interest for each paper. I would sometimes compare my own summaries to AI summaries to see these differences, which was an interesting experiment to see my own thought process vs AI. For the calculations, we validated each step by checking each step to make sure it made sense / double-checking + re-doing calculations as needed. I almost always double-check all AI outputs in some way or another, and at the least check/re-read each step in an AI response to make sure it seems right to me

AI: That's a really robust verification approach - treating AI as a starting point but always doing your own validation. It sounds like you've developed a clear sense of where AI adds value versus where you need to rely on your own expertise.

We're nearing the end of our conversation now. If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: I would love if AI could help more with the data analysis part of my research. I'll be doing lots of work in R doing data analysis / data management / figure generation, which always takes a ton of time and requires lots of problem solving and error checking. It would be awesome to be able to use AI more in that context, to be able to say what my goal output is and what I'm trying to create, and have AI help give me the steps to do in R to make those figures / get the output I want. AI can sometimes help with debugging / checking for errors, but I find AI still doesn't have a super comprehensive checking, and often isn't as helpful as I want

AI: That's a really insightful point about the data analysis bottleneck - it sounds like that's where you spend a lot of time troubleshooting and where more comprehensive AI support could really accelerate your work.

Those are all my questions - your perspectives on using AI as a verification tool rather than a replacement, and your thoughtful approach to validating outputs were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: I think there are really important conversations to be had about the use of AI in science – it's obviously an incredibly powerful tool, and can be used for a lot of good, but can also be exploited very easily. I am honestly scared and hesitant about a lot of the use of AI in the future, as more and more people use it on a more daily, frequent basis. I think there need to be a lot more safeguards in place that can help protect us as a society from over-exploitation of AI, in terms of putting more limits on AI development. I also think people need to be more educated on AI safe practices, learn how to identify when something is AI, and how to learn from & use AI in a safe way.

AI: Thank you for sharing those broader concerns - that's a really important perspective on the societal implications beyond just the research applications we discussed. Your point about the need for both safeguards and education around safe AI practices really highlights the responsibility that comes with these powerful tools.

Thank you again for sharing your experiences so openly. Your insights about treating AI as a supplementary tool that requires careful validation, and your thoughtful approach to where it adds value versus where human expertise is irreplaceable, really help us understand the nuances of how AI fits into real scientific work. If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out.

User: Ok great, thanks! Hope my insights can help towards more helpful, ethical AI use :)

AI: Absolutely - your insights about responsible validation practices and the importance of maintaining human oversight definitely contribute to that goal. Thanks again for your time and thoughtful responses!
