# Dialog 00503

**Transcript ID:** work_0083

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: sounds good to me

AI: Perfect! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: It is beginning to fit in more and more.  My use is primarily is regarding transcription and capture of actions and key discussion points.  My role is mainly virtual and so 90% of my meetings take place online and using AI compared to an individual to capture notes and key actions is significantly quicker.

AI: That sounds like a really practical application. Tell me more about how you use AI for transcription and capturing those key points - what does that process actually look like for you during a meeting?

User: I'll come back to the transcription point in a moment. Alongside this I have also attempted, but so far been let down, in using AI to take a lengthy, in depth paper and produce a set of slides that can be presented.  AI struggles to do this in a punchy, effective way as it seems to lack to contextual understanding required to pull out what is relevant to the audience.  By the time I've explained what I want/need I could've done it already

AI: That's a really interesting contrast - AI working well for transcription but struggling with that presentation task. 

When you say AI lacks the contextual understanding for pulling out what's relevant to the audience, can you walk me through what specifically goes wrong? What does AI miss that you have to end up fixing or doing yourself?

User: So, I frequently have to produce lengthy, detailed papers that provide large amounts of context and background (either within the paper or attached as annexes) to support a series of key recommendations at board/CEO level.  What I would really love is for AI to review the paper and be able to produce set of slides that lifts out enough of the key points, decisions and supports my communication and influence skills while complementing the paper.  Often AI overloads the slides with too much detail, or misses the key points, or too closely follows the flow of the paper when a rejigged flow would work better for the slides.  I understand and appreciate that a lot of these issues are due to the subjectivity of what I would require, but the initial understanding as to rough audience appropriateness is often missing.  Would you like me to go back to the transcription issue?

AI: Yes, I'd love to hear about the transcription side - it sounds like that's working much better for you. What makes that different from the presentation task?

User: the transcription issue is far better - I think that is due to the relative lack of subjectivity required.  It is simply capturing what is said, who is said it, and then ascertaining the key actions and activities.  It gets this right most of the time, but sometimes misses the implicit/inferred detail (especially when "ok - so you and you can take that forward then) or timelines.  In an ideal world I would love to trust this enough that it automatically sent out key actions or set up meetings without my input, but its not quite there yet, however it is far superior to the majority of human minute/note takers due to the speed at which it can follow conversation

AI: That's a fascinating distinction - the objectivity versus subjectivity factor. 

When you think about that gap between where AI transcription is now and where you'd need it to be to fully trust it - like automatically sending out actions or setting up meetings - what would need to change for you to feel comfortable letting it handle those tasks independently?

User: Probably accuracy and familiarity.  But also acting like a new member of staff.  So if I treated AI doing this as I would a new member of staff, for the first few times I would offer to help the new member of staff review and double check their understanding/draft outputs, suggesting changes and improvements so that after a few goes at it they understood exactly what I wanted and by when.  They would likely still though check for my sign off before sending stuff out - this is a helpful QA check for both the staff member and me.  So I guess building in that approach to mainly assure me/build that confidence would be a strong start.  

Also, being asked clarification questions by AI if it wasn't sure would, for me at least, be a great confidence builder as it would show me it knows what it doesn't know and that is more useful than pretending to/feeling the need to know everything and be perfect

AI: That's such a thoughtful way to think about it - treating AI like you would a new team member with that learning and check-in process. 

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: For me I think it is all contextual.  So depending on the importance or impact of the task is where I would want to have control over it.  For example, sending an email to my CEO I would want to at least review before hand, versus a reminder email to one of my team members ahead of a deadline or meeting I would be happy for it to be undertaken by AI.  There is probably shades of grey here though across all of these things - there'll be some stuff I would always be happy for AI to do, some stuff I would always want to do, some stuff I would always want to review, and some stuff that depending on the topic, audience or scale.  

However, I would always be willing to at least try AI initially for everything, but again  think taking the new team member approach.

AI: That makes a lot of sense - the stakes and audience really driving how much control you want to maintain.

When you do use AI for work tasks, can you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to give it something complete to handle independently?

User: I would normally say "here's what I need to happen, I will give you xyz, from that I want you to do abc" and then depending on the output either take it or ask for revisions.  So more independently than ongoing collaborations

AI: That's helpful - so more of a briefing and review approach rather than working through it step by step together.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Has that shaped how you approach it at all?

User: Almost the opposite.  My workplace culture is quite risk averse and given the public facing nature of my organisation, often gripped by a fear of bad headlines.  This means the organisational approach is more slow and steady, whereas I have embraced it more wholeheartedly and push the organisation to use it more quickly and more broadly and try and fail fast

AI: That's really interesting - you're kind of leading the charge despite the organizational caution. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: More frustration. Particularly when trying to compose a progress update paper for a single project while required reviewing multiple documents/emails/messages from multiple people in multiple formats.  The AI could not get it despite me providing clear direction and steer.  A human colleague in this example would've far better understood the ask and requirement.

AI: That sounds really frustrating. What specifically made the human colleague better at understanding that ask - was it their familiarity with the project, or something else about how they could process all those different inputs and formats?

User: Definitely not the project familiarly.  But familiarly/experience with the type of request.  So knowing what type of information was important, what to exclude, what to rephrase and what to leave verbatim.  Its the experience that you can only get by teaching, but I don't have the time to sit there and teach AI this sort of experience and exposure

AI: That makes perfect sense - it's that learned intuition about what matters and what doesn't that comes from experience.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I actively consider in so much as it frees me up to develop or hone my skills in other areas.  I see opportunity in building my capability on how to utilise AI as a much more sensible thing to do rather than compete with it.  To me it is no different as to how I rely on the expertise and experience of my team and my role is to pull out those strengths rather than compete with them

AI: That's a really positive perspective - seeing AI as another capability to learn to leverage rather than something to compete against.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: To become ever more commonplace and to definitely treat it as much more a team member.  For me, the best performers on my team are the ones who proactively spot stuff or produce things without my input and if AI could start to do some of that it'd be great - at the moment my workplace use of AI is entirely responsive to my requests rather than it proactively producing stuff or suggesting ideas

AI: That's fascinating - moving from responsive to proactive AI that could anticipate needs and spot opportunities like your best team members do.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on treating AI like a new team member and that distinction between objective tasks like transcription versus the more subjective, contextual work.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: that's all from me thanks

AI: Perfect! Thank you so much for your time and for sharing your experiences so openly. Your insights about the importance of context, the new team member approach, and that balance between delegation and control will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!
