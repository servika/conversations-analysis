# Dialog 00323

**Transcript ID:** work_0652

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Sounds good, no questions.

AI: Perfect! Let's dive right in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I am a software engineer who works extensively with a complex interactive AI platform on a daily basis. I mostly use AI for help in debugging errors, making code modifications and performing code review. Sometimes, at the start of a major task, I ask AI for help in considering different approaches to solve a problem

AI: That's really helpful context. It sounds like you're using AI across several different phases of your development work - from initial problem-solving through to final review.

When you mention asking AI for help considering different approaches at the start of major tasks, can you tell me more about what that process looks like for you?

User: When I need to add new features to the platform it may help to consider all possible approaches to implement it. Even just the process of crafting the prompt for the LLM puts into perspective the requirements and scope of the task. AI itself then suggests ways I can solve the problem on a technical basis with tradeoffs for each option.

AI: That's fascinating - it sounds like the act of formulating your question for the AI actually helps clarify your own thinking about the problem, even before you get the response.

When the AI presents you with these different technical approaches and their tradeoffs, how do you typically proceed from there? Do you usually pick one of its suggestions, or does it lead you to develop your own hybrid approach?

User: Any new change that needs to be made usually makes its way through a few levels at the company. AI just helps ensure all approaches are considered. Since it's impossible for it to have complete context of our vision for the platform as well as the existing infrastructure, it's rare for us to pick a certain approach. We end up using a hybrid approach or add our own spin to it

AI: That makes a lot of sense - the AI helps expand your thinking but can't fully understand your specific platform context and company vision.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: Any repetitive tasks can usually be automated through tests and aliases. I also avoid having AI create its own code from scratch - I limit it to code modifications. If I require help in starting with something I study the sample code it writes and implement it myself.

AI: That's an interesting distinction - you'll use AI for modifications but not for creating code from scratch. 

Can you tell me more about what drives that choice? What concerns you about having AI generate initial code versus modifying existing code?

User: In my experience AI models are very verbose in their code output. The code is far too convoluted for me to understand at first glance. Writing the code myself ensures I catch any possible errors. In my initial time just copy-pasting LLM generated code, I'd find myself spending more time just debugging bugs that were hard to find because it was not code that I wrote

AI: That's a really valuable insight - the debugging overhead from unfamiliar, verbose AI code actually made you less efficient overall.

When you use AI for code modifications instead, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout the modification process, or do you tend to give it a complete modification request and let it handle it independently?

User: I have started to use Github copilot's agent mode. I usually have Sonnet as my agent of choice. In copilot, you can provide it with certain context that it needs and then ask it to modify the code. The agent then makes the necessary modifications in a format where I can choose to accept each change individually. In most cases I give it a piece of work at a time and then look through the changes. It is rare for me to accept most changes, but I learn from what the model does and write the code myself. Then I move onto the next step. However, I very rarely have long conversations with these chatbots. I like to break up tasks and I find it more efficient for token usage as well

AI: That workflow sounds very deliberate - breaking tasks into pieces and using the AI's suggestions as learning material rather than direct implementation. The individual change review process gives you a lot of control.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you see different approaches among your team?

User: There was initial hesitation in AI adoption due to data security concerns but we came around to adopting cloud auto regressive models eventually. My colleagues seem to have a similar use pattern with AI chatbots but may differ in models of choice or certain tasks. I have learned a lot of possible use cases through my colleagues and other people in the tech industry

AI: It's interesting how data security was initially a barrier but you eventually found ways to work with cloud models. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I can give an instance where I was pretty satisfied with the results but a closer look revealed a lot of flaws. I requested for a model training script to conditionally save certain checkpoints. Additionally, I wanted the change to be visually reflected in the frontend. This required the script, the backend and the frontend to be modified. While within the first try the agent was able to find all requested files and successfully made the changes, the code review revealed that there was a lot of unused code and clutter in the output. For instance, the agent implemented reactive signals on the frontend but they were not even used on the template. This code was found unused later.

AI: That's such a perfect example of the complexity of working with AI - it seemed to nail the task at first glance, hitting all the right files and making the connections between frontend and backend, but then the deeper review revealed all that unnecessary complexity.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I understand some tasks may not be done as efficiently by humans than AI. In these areas I find a way to utilize AI to increase my throughput rather than try to beat it. I believe that finding more innovative ways to use AI across my work day will supplement my skills rather than replace them

AI: That's a really thoughtful perspective - viewing AI as a throughput multiplier rather than a replacement, and actively looking for innovative integration points.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I think with AI getting stronger and faster at research I will be better equipped to give it stronger reasoning tasks that it can really help me solve which require more context and technical depth to answer.

AI: That's fascinating - you see the trajectory moving toward more sophisticated, context-heavy reasoning tasks as AI capabilities advance.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI modifications rather than generation from scratch, and how you've evolved toward viewing AI as a throughput multiplier rather than a replacement.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No I think we covered everything

AI: Perfect! Thank you so much for your time and for sharing your experiences so openly. Your insights about the evolution from initial hesitation due to security concerns, to finding that sweet spot of using AI for modifications rather than generation, and your deliberate approach to breaking down tasks - these will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candidly you shared both the successes and the pitfalls, like that example with the model training script that seemed perfect at first but had all that unused code lurking underneath. Those kinds of real-world details are exactly what help us understand how this technology actually works in practice.

Thanks again, and have a great rest of your day!
