# Dialog 00675

**Transcript ID:** work_0342

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: That's fine. We can begin.

AI: Great, thank you. Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: AI is an everyday part of my day. I am an engineer developing software and I use it for anything. When I play next tasks, I use AI to generate stories and split them logically into units which different members of the team can pick up. Additionally, I use AI to create most of the work, whether that is doing the "boring" work, or giving it a chance to own new features, it is always the first thing I do. I then check the AI's work to either reprompt, or provide follow up, until eventually the work is done.

AI: That's fascinating - it sounds like AI has become deeply integrated into both your planning and execution processes. 

When you mention giving AI "a chance to own new features" - can you walk me through what that looks like? How do you decide when to let AI take the lead on something new versus when you might handle it differently?

User: Before beginnign an entirely new prrocess we use AI to think of all possible directions, along with our own human research. We especially benefit from AI to get a massive pros/cons list. Once decided we use AI to setup everything and do research on best practices. This is esssentials because it is something that AI and us would do in the same manner, manually checking soruces, but inevitebly AI is faster ans better at. AI would then scaffold and do as much as possible until someone picks it up to wrap it up. But AI would own everything - all we would do is provide guidance and express feedback to divert direction and/or bosot knowldeg

AI: That's really interesting how you've structured that handoff process. You mentioned that eventually "someone picks it up to wrap it up" after AI has done the scaffolding work.

Tell me more about that transition point - how do you or your team decide when it's time to take over from the AI, and what does that final human involvement typically look like?

User: when AI starts hallucinating, or rotating in circle and starts providign a common pattern help advices, this is when we realize AI has reached its end

AI: That's a really specific pattern you've identified - the hallucinations and circular responses as signals that AI has hit its limits.

When you reach that handoff point, are there certain tasks you prefer to handle yourself even though AI could potentially help with them? What makes those final tasks different for you?

User: for us to reach handoff it means AI couldnt help us. For us to decide its handoff poitns we have tried multiple times, multiple sessions (independent), rephrasing prompts, making prompts into smaller chuinks, provindg no contenxt, providng more contenxt. So at thjis points those final teasks are where AI is not useufl to us

AI: That makes perfect sense - you've essentially exhausted AI's capabilities at that point through all those different approaches.

When you are working with AI throughout a task - before you hit those limits - could you describe your typical interaction pattern? Are you more likely to go back and forth with it throughout the process, or do you tend to give it larger chunks to work on independently before checking in?

User: more frequent checks is always better. smaller prompts ideally with start and end. we try not to provide prompts like do this and then x and then y and then z and once you got this and this ready try to do this. 

No !

For us ideal prompt is:
I am working on this and this. We are currently trying to identify if we can do this and this. We have tried X, and having found that Y works best. Can you do small reesearch and see if that's true or suggest alternatives.

Then come back with simple scafofoldign of start steps and final verdicts.

AI: That's a really clear breakdown of your prompting strategy - focused, contextual, and with clear boundaries. It sounds like you've developed a very deliberate approach through experience.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you all follow similar patterns, or have you seen different approaches emerge on your team?

User: we try to use simialr patterns i.e., patterns that AI understand best. smaller chinks of info. as much ocontext as possible. not assuming the AI is aware of all files without our projectsm etc.

AI: It sounds like your team has developed a shared understanding of what works best with AI.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: satisfied  - when manual operations and hours of debugging turns into just couple of minutes with very limited prompts , but somehow AI knew where to look and what to fix. helps speed development in projects you have limtied knowdlege on.

frustrated - same project where I have limited knowldege on, but AI keeps making up information because even it struggles to fully get awareness and instead of admitting that it can't fully comprehend and can't help, it has like a setting where it must provide you optimistic answer as human being, which is not always good

AI: That contrast is really striking - the same scenario of limited knowledge can lead to both your best and worst experiences with AI. The frustration with AI's tendency to give optimistic answers rather than admitting limitations sounds particularly challenging when you're relying on it for areas outside your expertise.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: AI can't take over what I do, but it can greatly influence it and shape my role from actively doign something to more supervision.

AI: That's an interesting distinction - shifting toward more of a supervisory role rather than being replaced entirely.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see that supervisory aspect continuing to grow, or do you think the dynamic might change in other ways?

User: so far | see myself vecomes more supervision and having the ability to do more with less

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how you've developed those specific prompting strategies and recognizing AI's limits through patterns like hallucinations and circular responses.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about the evolution from hands-on development to more of a supervisory role, and especially those practical details about prompting strategies and recognizing AI's limitations, will be incredibly helpful for our research on human-AI interaction in professional contexts.

Have a great rest of your day!
