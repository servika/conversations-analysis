# Dialog 01072

**Transcript ID:** work_0945

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Sounds great lets get started

AI: Perfect! Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I am a Software Engineer so I naturally use AI quite extensively. I am early in my field as I recently graduated. I tend to receive tasks from my Senior manager and after thinking about it for some time, prompt Copilot with a similar version of the task (my understanding of it) to see how it navigates it. I use it for a lot of my tasks and essentially augment it to how I think a task might get completed.

AI: That's really interesting - it sounds like you're using AI as a thinking partner to validate your approach. 

When you say you prompt Copilot with your understanding of the task, what happens next? Do you typically take its suggestions and run with them, or do you find yourself going back and forth with it to refine the solution?

User: I tend to take its suggestions and run with them, testing the application with the changes and re-prompt as necessary whenever some aspect of the task was not completed adequately. Whenever a final solution is devised, I oftentimes find myself cleaning the solution up, ensuring it fits a similar structure to the rest of the codebase (i.e far more minimal comments as it tends to offer documentation that is far too detailed).

AI: That cleanup process you mention is fascinating - it sounds like you've developed a pretty specific workflow where you're the final editor, making sure everything integrates well with your team's standards.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: Honestly there isn't a huge amount that I reserve to myself but whenever it comes to pushing changes or dealing with GitHub I tend to ensure I am the one performing the task. This kind of task is different because I feel there is only a tiny hallucination needed to do something dreadful like pushing to main directly or introducing some other issue. Basically anything that can be done quickly and is not worth the hassle of dealing with a hallucination, I will deal with.

AI: That makes a lot of sense - you're being strategic about where the risks are highest. It sounds like you've identified that boundary between "safe to experiment with" versus "too risky for potential errors."

When you are using AI for those coding tasks, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I tend to do a mix of both. It really depends on the type of task that it is and the amount of changes being made. For example, if it is a very simple CSS fix or a quick one-liner that needs changed, I'd prefer just asking Copilot since it will locate the file and line faster than I will. Now, if we are making modifications that are more significant, like adding Server-Side Rendering for a specific page for example, I will usually think about the change on my own, ask Gemini or some other LLM from an architectural standpoint, devise a workflow, then prompt the coding agent to make an attempt. Larger changes almost always require refining to be done after-the-fact.

AI: That's a really nuanced approach - you're essentially triaging tasks based on complexity and using different AI tools for different purposes. I like how you distinguish between Copilot for quick location tasks versus other LLMs for architectural thinking.

How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: In my 2 months so far at my job, I have been prompted once to use Copilot to validate a task of mine. Aside from this there is a lot of noise in the organization around getting developers to utilize the tool extensively to increase output. Personally, none of this has really influenced me. I have had a streamlined approach since I was in college working on my side project. I adapted AI awhile ago and feel I utilize it in a way that is maximizing efficiency whilst still using it safely.

AI: It's interesting that you had already developed your own approach before starting the job and haven't felt the need to change it much based on workplace pressure. It sounds like you're confident in the system you've built.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I was attempting to make an addition to the system to flag for Mobile devices in a more responsive way. Surprisingly the agent could only ever devise a plan that affected 100+ files. I attempted to augment it explaining it was unnecessary and that there would be a more centralized way to make the modification. though it wouldn't understand. The bulk of my frustrations come from a lack of understanding most of the time, like not grasping the entirety of the codebase.

AI: That's a really concrete example of where the AI's limitations become apparent - it sounds like it was missing the forest for the trees, not understanding the broader architecture well enough to suggest an elegant solution.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: It's something I actively consider very frequently. I am almost positive the job I am currently doing is the same one that AI could do years from now. I am all but certain AI will be able to act as a Junior developer and propose solutions back to Seniors. Thus, I am actively pursuing different areas in Tech that I feel will be safer, and I am also trying to push for higher levels faster than normal to make it out of the Junior role.

AI: That's a very forward-thinking perspective - it sounds like you're using your current role almost as a stepping stone while actively planning your next moves. The urgency you feel about advancing quickly is really telling.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I envision a more hands-off approach where AI I am less interacting with the codebase itself and more-so devising a specifications sheet more or less that gets sent to an agent and 15-30 minutes later I see the proposed changes and can test / approve them as necessary. Basically an infinitely faster Junior developer at my fingertips.

AI: That vision of AI as an "infinitely faster Junior developer" really captures how you see this evolving - much more automated but still with you in the oversight role.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated how clearly you've thought through the risk management aspects and your strategic approach to career planning in light of AI advancement.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Nothing else thank you.

AI: Perfect! Thank you so much for your time and for sharing your experiences so openly. Your insights about developing your own AI workflow early on, the strategic way you think about risk management, and especially your forward-looking perspective on career development have been incredibly helpful for our research on human-AI interaction in professional contexts.

It's been really valuable to hear from someone who's both embracing AI tools while simultaneously planning for how the field might evolve. Thanks again for participating!
