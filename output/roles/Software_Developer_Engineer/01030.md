# Dialog 01030

**Transcript ID:** work_0880

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Sounds great! I have no questions, let's begin.

AI: Perfect! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: So I currently work as an IT Support Specialist for a local government. It involves account creation, administration, and support for our city staff and software. 

AI fits the most into my workday when I need to be equipped to handle systems or software I have never interacted with. For example, we are introducing Autopilot into our Microsoft environment, a way to automatically provision computers with less input than our normal workload. Microsoft's documentation on this can be overwhelming, and finding answers to small or silly questions could take a long time to find. AI has been able to save me time from finding those answers. 

AI also helps us combat writers block by assisting us in creating scripts for both powershell and python. We may suddenly get tasks that will require a powershell script, such as, "find me this list of people who meet x, x, and have x criteria."

AI: That's really helpful context. It sounds like AI is serving as both a knowledge resource and a creative partner for you in different situations.

When you mentioned using AI to overcome documentation challenges with Autopilot - can you walk me through what that actually looks like? How do you typically interact with AI when you're trying to figure out something new like that?

User: As I'm quite new to Autopilot, there's still lots of technical information to understand. I may ask a lot of "why" questions to help me get the larger picture. While working with Autopilot, I can ask AI for information on specific errors. If it involves code or script, I know that I can either copy/paste it or take a picture of it.

AI: That's really interesting - you're using AI almost like having an experienced colleague available to ask those "why" questions to. 

Tell me more about that process when you encounter a specific error. Do you find yourself going back and forth with AI to troubleshoot, or do you typically get what you need in one exchange?

User: It can take a few tries. AI is never fully correct and I find it's knowledge strength can differ depending on the domain or specific skill. I enjoy that it typically gives me a few likely outcomes or reasons why something is happening

AI: That's a great observation about AI's varying knowledge strength across different domains. 

I'm curious about your preferences when working with AI. You mentioned AI is "never fully correct" - are there certain tasks you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: I mean that AI, in its current state, is never 100% correct 100% of the time. Therefore some answers you get may not be helpful. For example, we have vendors whose equipment or software are not very "googleable", meaning few or no internet resources can be found to assist in troubleshooting. Some answers may be dependent on how an IT environment is configured. 

Personally, I always choose to handle text-based communication myself. I find that AI outputs, especially ChatGPT, have language that is very inconsistent to human text communication. We can tell when users submit support tickets using AI, as they often are riddled with lists, wordy sentences, embedded lists, and participial phrases. I'm not sure if this belief is shared, but I find those who copy and paste AI output as their text responses seem to have poor reading and writing skills, emphasis on reading.

In my job, the troubleshooting aspect is also something I do myself. I figure I could possibly "mold" an AI model to help me with this, but I haven't tried it yet. The problem is that if I ask AI something about a symptom, let's say a slow computer, it tries to go right for the answer. It tries to get you a diagnosis without asking any questions. Good troubleshooting involves isolating variables and narrowing down the issue. This could be helped by feeding the AI a large amount of information on the scenario and all objects involved, but this takes too long to type out in a way that includes all pertinent info.

AI: That's a fascinating distinction you're making about AI's diagnostic approach versus proper troubleshooting methodology. The point about AI jumping to conclusions rather than systematically isolating variables really stands out.

When you do use AI for work - like with those Autopilot questions or script writing - could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to give it a complete task to handle independently?

User: It's most directed towards a collaboration. The conversation may start with something similar to "Hey, I want to create a powershell script that finds x and does an action with them. The goal of this script is to..."
The AI typically outputs a script with a brief explanation unless directed otherwise. After that, I can ask it follow up questions about specific parts of the script or if I want to make changes/additions to it. Given that we are touching critical systems, we usually don't give AI a task to fully handle independently. If we do, it is checked many times over and tested in a way that does not impact production systems.

AI: That collaborative approach makes a lot of sense, especially given the critical nature of your systems. The way you describe starting with the goal and then iterating together sounds very methodical.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that others in your department have similar approaches, or are there different perspectives on how to incorporate these tools?

User: I'm honestly not sure. I don't peep at my coworker's AI pages because I feel I'm invading their privacy if I do. I trust that their work is quality. As a support department, we do use chat-based AI, but we are quite skeptic of AI addons and software, and aren't exactly jumping for joy about it unless there's a legitimate need for it.

AI: I appreciate that perspective about respecting colleagues' privacy while trusting their work quality. That skepticism about AI add-ons unless there's a legitimate need sounds very thoughtful.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: There was a time I was asked for a raise, and I used AI to help me form a plan. I gave it my responsibilities and my accomplishments, and how that relates to the positions above me (System Administrator). I'm glad it was able to take all of the information I gave it and synthesize it for me. The bulk of the work I had to do was to go in my mind and find all of my achievements and responsibilities. I ended up getting a raise and I have AI to thank for it.

AI: That's a great example of AI helping you organize and present information you already had - sounds like it was really effective at synthesizing your accomplishments into a compelling case.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I can't comprehend how AI would take over IT completely. I can see it in the low-level support roles, but not in architecture and advanced administration. I will still push to learn. How are you able to give AI good prompts that help bring insightful responses if you don't have a good understanding of what you're talking about? I believe that it gets to a point where AI is only as good as the prompts you give it. If you don't understand much about a system, then you are only able to provide surface-level responses.

AI: That's a really insightful point about the relationship between your domain knowledge and your ability to craft effective prompts. The idea that deeper understanding leads to better AI collaboration makes a lot of sense.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: AI will be my calculator. It won't replace my job, but it will be a force multiplier. It will help me gain quick and synthesized information on areas I am weak in. We have considered creating an internal knowledge base to feed to an AI "agent", but it would take a mass amount of writing and too much upkeep on dynamic information.

AI: That "calculator" analogy is really compelling - AI as a tool that amplifies your capabilities rather than replacing them.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how good prompting requires deep domain knowledge, and that distinction between AI jumping to diagnoses versus proper systematic troubleshooting.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I don't believe I have anything else to share. Thank you for your time!

AI: Thank you so much for your time and for sharing your experiences so openly! Your insights about AI as a "force multiplier" rather than a replacement, the importance of domain expertise for effective prompting, and that thoughtful approach to collaboration versus delegation will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candid you were about both the strengths and limitations you've observed. Have a great rest of your day!
