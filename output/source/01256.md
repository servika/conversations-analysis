# Dialog 01256

**Transcript ID:** science_0108

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: Sounds good to me, no questions.

AI: Great! Let's dive in then.

To start, I'd love to hear about your work. Could you walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: Sure, although the nature of my work is somewhat sensitive and I've signed NDA's so I'll have to be vague about some of the details and the direct purpose of the research. However, I can still provide you with valuable insight about how we used AI during the research process.

AI: Absolutely, I completely understand about the NDAs and sensitive nature of your work. Please share only what you're comfortable with - even speaking generally about the process and your AI experiences will be incredibly valuable for our research.

So with those considerations in mind, could you walk me through that recent project from start to finish?

User: Overview and Background
Yes, our most recent research project involved synthesizing data from multiple real-world physical sensing devices for the purpose of classifying real-world phenomena occurring in range of the sensors.

All the preliminary sensor data as well as correct classifications of the phenomena were provided to us. It was up to us to develop an algorithm that could effectively synthesize sensor data of the types provided and form accurate predictions of the phenomena.

We had recent success in several other physics and sensor related applications making use of Graph Neural Networks (GNNs), so our initial thought was to see if we could design a GNN algorithm to synthesize this sensor data as well.

Initial Steps:
First off, using the descriptions of the data provided to us as well as the data files themselves, we utilized ChatGPT to write several small data analysis scripts in Python. These scripts allowed us to visualize/summarize important qualities of the data, including the precise format of the data, statistics, the way the data evolved overtime for each sensor, as well as some anomalies in the data that seemed to differ from the description of the data that was provided to us with the data.

Addressing Anomalies:
We spent some time discussing the anomalies and the possible meanings they could have. We came to a conclusion about what we thought was most likely the cause of the anomalies. We emailed to the dataset provider with our findings, and continued our research under the assumptions we made. We later confirmed that the assumptions we made about the dataset were corrcet.

Algorithm Development:
After developing our understanding of the dataset came the design of the GNN algorithm. We ended up settling on a design that placed each node of the graph as a point in 2D space within the region that the sensors were operating (the sensors did not give us any sort of vertical positioning data). The algorithm was designed to work in real-time as sensor data was acquired, although, since we had all the sensor data ahead of time, we simulated the real-time process by feeding the algorithm sensor data in the order of their timestamps. Whenever new sensor data was received by the algorithm, a check would be done proximal to the location of the sensor data. If there were no graph nodes within a certain distance of the sensor inputs, a new node would be created. If there was already a node nearby, the "signal strength" of that node would be increased. Overtime, the "signal strength" of each node would decay if no new sensor inputs were detected near the node.

Each node in the graph was a small classification neural network that took as input the data of each sensor input close to the node, as well as the outputs of nearby nodes from the previous timestep, augmented by the signal strength of those nodes as well as the distance of that node to the current node.

An evolutionary algorithm was used to train the network. All the main algorithm code was written by hand, so to speak, but the scripts used to test and tune the various hyperparameters of the network were also written using ChatGPT.

Algorithm Tuning and Conclusion
We continued the process of hyperparameter tuning and even tried out 2 additional methods for binning and pre-processing sensor inputs across time. We eventually arrived on an algorithm and hyperparameters that resulted in 92% prediction success. We wrote a document describing our process and findings (not assisted by AI) and submitted our work, but we were not selected for the next phase of the project.

AI: That's a fascinating project - the combination of GNNs with real-time sensor data synthesis sounds quite complex. I'm particularly interested in how you integrated AI tools into your workflow.

You mentioned using ChatGPT for writing data analysis scripts and hyperparameter tuning scripts. When you were deciding whether to use ChatGPT for those specific tasks versus writing the code yourself, what factors influenced that decision?

User: The main factors were time and prior experience using ChatGPT to write code. The first phase of the project was given a relatively small timeframe and we also had to balance some of regular workload during that time frame. Our team was pretty small (myself, our team lead, and one other programmer), and I was the only one who had prior experience using AI to write code.In my experience, using AI models to write code is effective, but is made less effective by the following:
-High levels of integration with existing code (AKA coupling)
-Long prompts
-Highly detailed/complex prompts
-Topics pertaining to highly nuanced or cutting edge research

The more of these factors are present in your prompt the more likely it is that the AI's code will contain mistakes. The more mistakes the AI's code contains, the more likely it will be that the code could've been completed faster if the AI was forgone in the first place.

Given these heuristics, I felt that trying to use AI for any of the main algorithm code would likely be detrimental, but using it to write the more one-off and sometimes repetitive code used for data analysis/visualization and hyperparameter tuning was a safe bet for saving time and effort. The AI was very effective in helping us in this way.

AI: Those are really insightful heuristics you've developed. It sounds like you've built up a practical framework for when AI coding assistance is worth it versus when it might slow you down.

Thinking about the parts of your research where you didn't use AI - like the main algorithm development and the final document writing - what specifically kept you from trying it there?

User: The complexity, length, and relative novelty of  the GNN algorithm. For one, we hadn't fully articulated the design of the algorithm in a way we could confidently give to an AI model. It was more-so an iterative process of drawing diagrams on paper/whiteboard, discussions, and then writing small pieces of code. By the time we could precisely articulate the whole design, we had most of the code already written. Additionally, we felt the GNN was a new enough concept in the literature that it would easily be confused with the highly popular Deep Neural Networks and Convolutional Neural Networks, which are themselves graphs, although not necessarily Graph Neural Networks in the way we were using.

AI: That makes a lot of sense - the iterative, exploratory nature of developing something novel doesn't lend itself well to AI assistance when you're still figuring out the design through trial and discussion.

When you did use ChatGPT for those data analysis and hyperparameter tuning scripts, how did you go about verifying or validating what it produced? What was your process for making sure the code was doing what you needed it to do?

User: Scanning over the AI's code, the results of running the code on our dataset, and running a couple of simpler proof of concept inputs through the code to which I new the expected output for.

AI: That's a thorough verification approach - checking the code itself, the actual results, and testing with known inputs. 

We're about halfway through our conversation now. Looking ahead, if you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't handle well, what would that be and why?

User: Debugging and or understanding large (and especially highly integrated) codebases. Our main work involves a large legacy code base that uses FORTRAN physics code from the 80's, a 12-year old C++ front-end, and a variety of Python tools designed to quickly extend the capabilities of both. It's incredibly difficult to grok even large chunks of the base, it gets changed all the time, and making changes in one place often leads to the discovery of previously unknown consequences in other parts of the code. AI models recently have not been much help with these sorts of code bases, but if they could de-load some of the research, memory, and mental organization required to work on these codebases, they could be immensely helpful.

AI: That sounds like a genuinely challenging pain point - managing that kind of multi-language, multi-decade legacy codebase with all those interdependencies must require holding so much context in your head simultaneously.

Those are all my questions. Your insights about developing practical heuristics for when AI is worth using versus when it might slow you down, and especially your point about the mental load of working with complex legacy codebases, were particularly valuable.

Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: No, I think that's it!

AI: Perfect! Thank you again for sharing your experiences so openly. Your insights about those practical heuristics for AI code assistance - particularly how coupling, prompt complexity, and cutting-edge topics affect AI effectiveness - really help us understand the nuances of how AI fits into real scientific work. And your point about the challenge of legacy codebase management gives us valuable perspective on unmet needs.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
