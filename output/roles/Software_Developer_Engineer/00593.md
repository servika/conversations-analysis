# Dialog 00593

**Transcript ID:** work_0219

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: No questions, I can start.

AI: Perfect! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: As a software engineer, I use AI tools daily for things like rewording/reformatting my emails (one on one emails, and emails to large groups) so it suits my intended tone better, rewording my internal documentation so it is more concise overall, assist with small-large coding related tasks, request to explain technical concepts in laymen's terms, and provide solutions to new ideas I present the model with.

AI: That's a really interesting range of uses across both technical and communication tasks. 

Tell me more about how you decide when to use AI for coding tasks versus handling them yourself. What makes you think "I'll tackle this one on my own" versus "I'll bring AI into this"?

User: For the majority of the time, I use AI tools for coding tasks most of the time, even when I tackle coding solutions on my own. The only exception to this is if it is simply faster for me to write code myself as opposed to explaining to the AI chatbot what I want it to write. I bring AI into my coding tasks at different stages, and would depend on the complexity of the task itself. For example, I might ask the chatbot to write a ServiceNow background script using JavaScript to fetch certain records for me as it would be faster for the chatbot to write the query for me and for the majority of the time, the answer it gives is valid and correct. Other times I might have a complex coding requirements and I would ask the chatbot to brainstorm different methods to tackle this problem in case I silo my thinking to one particular solution only. In these instances, the Ai tool has helped me look at coding problems much more holistically as opposed to focusing on one specific coding solution I would have had in mind.

AI: That's fascinating how you use AI strategically at different stages of the coding process. The way you describe it as helping you think more holistically about problems really stands out.

When you use AI for brainstorming different approaches to complex problems, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout the problem-solving process, or do you tend to delegate complete tasks for it to handle independently?

User: I tend to collaborate with the AI model throughout the problem-solving process. I would go about this by providing as much initial context as possible in my initial prompt, and then sprinkle in further context to refine potential solutions further.

AI: That collaborative approach sounds really intentional. I'm curious about the context you mentioned - when you're sprinkling in further context to refine solutions, what does that back-and-forth typically look like?

Can you walk me through a recent example where you collaborated with AI this way on a complex coding problem?

User: An example that I can give is when I tried to find the most optimal solution for turning file download links that are currently only accessible on-premise and connected to our internal network, and making it available on the ServiceNow Platform, which is a Cloud Platform as a Service used for managing our internal data such as laptops computers, servers, applications, etc. In order to find potential solutions I had given the AI tool this context, and further refined its potential solution by providing additional context such as our internal file download links are authenticated using NTLM which ServiceNow does not support. This in turn caused the model to rethink its solution and find other potential solutions for resolving this request of making these file download links more accessible by making it available as ServiceNow links.

AI: That's a great example of how the collaborative process works in practice. It sounds like the AI's initial suggestion hit a roadblock with the NTLM authentication limitation, and then it had to pivot to other approaches.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that your team has particular attitudes or practices around AI tools?

User: At the moment, I am just starting to see my team start to use AI tools now because I can tell by the responses they give sometimes. An example is the way they provide messages to me which I can tell is very AI-like. This shows that they are quite at an amateur stage of using these AI tools like I had a few years back. Overall, I think it is a good thing that they are leveraging AI to build responses as English is also not necessarily their strong suit as well. I am also starting to find other members of the team using this tool to generate code as well. My biggest concern here is for them to use these tools properly by fact-checking all claims and code it provides before pushing this code into produciton.

AI: That's really insightful - you're seeing this shift happen in real time with your team. Your concern about fact-checking is interesting, especially since you mentioned you've been using AI tools for a few years now.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I know I feel frustrated using AI tools when I attempt to prompt the AI models to think in a certain way or provide a certain vague solution that I may have in mind, but the model does not go anywhere with it. This is almost always a problem of myself veering the model off into a tangent. As I believe it is always a human problem, when I reach these stages I usually try and cool off and find a different approach at resolving problems by finding alternative approaches, or providing the model with different context.

AI: That's a really thoughtful way to handle frustration - recognizing it as a prompt engineering challenge rather than a limitation of the tool itself. The fact that you step back and try different approaches shows real maturity in working with AI.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I actually don't consider myself to be the best coder of all time, but with the advent of AI, it has allowed me to abstract certain coding challenges further. This has actually allowed me to tackle coding problems much more holistically now as opposed to being hyper-focused on one specific coding problem I am trying to resolve. Additionally, the solution these AI models provide are far from perfect (but is almost there), and as such I believe there will always be a need for a human to vet the responses these AI tools give because if the AI response cannot be 100% correct, then a human must always vet its solution first. As a result, I don't believe AI tools could take over my role fully, but instead we must adapt and augment ourselves with these new AI tools, similar to the advent of cars not requiring horses, or calculators not requiring so much mental thought.

AI: That's a really compelling analogy - the idea of adaptation rather than replacement, like cars and calculators. Your point about abstraction helping you think more holistically is particularly interesting.

Looking ahead, how do you envision your relationship with AI at work evolving? What do you think will change about how you work together?

User: I envision my relationship with AI to be almost like working with a junior assistant. It will help me deal with admin tasks in my day to day job much more quickly (documentation, email communication, and small coding problems), which will then allow me to push my focus on a much more broader perspective in my role, which in turn will allow me to tackle much more bigger and pressing problems in my job.

AI: That vision of AI as a junior assistant handling the smaller tasks while you focus on bigger, more strategic problems really captures the evolution you've described throughout our conversation.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how AI has helped you think more holistically about coding problems, and your mature approach to handling the collaborative process when things get frustrating.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about the collaborative nature of working with AI, the importance of fact-checking, and that evolution from tactical to strategic thinking will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk through those detailed examples - it gives us such a clear picture of how this technology is actually being integrated into real work environments. Have a great rest of your day!
