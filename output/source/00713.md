# Dialog 00713

**Transcript ID:** work_0395

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: While I do use AI personally in my professional position, I also have team members that use it and I would like to share my opinions on how they use it in their roles. Would that be okay?

AI: Absolutely, that sounds perfect! Your perspective on how your team members use AI will be incredibly valuable for our research. You have a unique vantage point seeing both your own usage patterns and observing how others on your team interact with AI tools.

Feel free to share insights about your own experiences, your team members' approaches, or both throughout our conversation. Whatever you're comfortable discussing will help us better understand the full picture of how AI is being integrated into workplace environments.

Let's get started then. Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Personally I use ChatGPT sprinkled throughout my day sort of like a personal assistant. I assign it tasks such as proofreading emails, suggesting different ways to word things, giving it a framework of facts to build out a document, and things like that. I will also of course ask it questions that I would historically enter into Google. The heaviest task I will ask of ChatGPT is to help me write code, typically in Python or MATLAB. This is generally data analysis code that is in the non-critical path of work we do. That way if the code breaks, which is often the case, it doesn't affect our products and has minimal impact on my teams work.

AI: That's really interesting how you've built in those safety guardrails around the code generation - keeping it in the non-critical path. It sounds like you've developed a pretty strategic approach to where and how you deploy AI.

Tell me more about that coding work specifically. When the code breaks, as you mentioned often happens, what does that experience look like for you? How do you handle those situations?

User: If the error or incorrect result from the code is easy to fix, I generally do it myself as I value being able to learn how to perform tasks independently. However if the problem starts taking too much of my time, I will describe the problem to ChatGPT and ask it for suggestions. This is typically fine, but if the script I am running is lengthy, ChatGPT often forgets bits and pieces of my code that we have already written (code that was even written by the model itself and is displayed just above in the ChatGPT chat) and leaves the hooks or capabilities from those code portions out of the generated solution. So I often find myself having to augment ChatGPTs generated solution and re-enter it into the conversation to remind the model of where we are in the development process.

AI: That's a fascinating dynamic you've described - having to essentially manage the AI's memory and context awareness while working together on longer coding projects. It sounds like you've become quite skilled at navigating those limitations.

I'm curious about your preferences when working with AI. You mentioned valuing learning to perform tasks independently when fixes are straightforward. Are there other tasks beyond the simple code fixes where you prefer to handle things yourself, even though AI could potentially help with them?

User: Yes, for example I like solving physics-related problems by hand. There are some questions I can ask an AI (e.g. what thickness of PTFE should I use for my radome at some frequency) but I almost always double check the answers by hand anyways.

AI: That makes a lot of sense - especially with physics problems where the underlying principles and calculations are so fundamental to your understanding. 

When you do those hand calculations to double-check AI responses, what have you found? Do the AI answers typically hold up, or have you caught errors that way?

User: They can be pretty spot-on in simple cases. But often times it makes assumptions that you need expert knowledge to understand that it is making. For example when it reports the dielectric properties of PTFE, you have to understand that it generally uses the properties of virgin, solid PTFE even though there are many literature sources that use non-virgin and/or non-solid versions of PTFE from which it could be pulling its responses.

AI: That's a really insightful observation about those hidden assumptions. It sounds like the AI can give technically correct answers that might be completely wrong for your specific application if you don't catch those underlying assumptions.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: Definitely more of a collaboration. I would describe it more like holding its hand through a task. While this does use more of my time than total delegation, it gives me more confidence in the end solution and still saves a ton of time compared to doing it myself.

AI: That "holding its hand" description really captures something important about how you've learned to work with AI effectively. It sounds like you've found a sweet spot between efficiency and confidence in the results.

You mentioned earlier that you also observe how your team members use AI. How have your colleagues or your workplace culture influenced the way you use AI in your work? And what differences do you notice in how your team members approach AI compared to your own methods?

User: Good job remembering that I mentioned this. And yes absolutely they have. One team member in particular has used AI to generate probably 80-90% of the code for a critical-path project. It has given us some results and very quickly. However we are starting to uncover some serious technical debt because the AI code is far from perfect and now since he didn't really write it, he doesn't know how to debug it. Now when we encounter, e.g., a memory leak, he cannot think through it logically and instead decides to simply cut out that piece of code entirely, reducing the capability of the project. It has been very frustrating, and I think it serves as an example of how not to use AI in your work. I believe AI is a great tool to speed work up or even expand your knowledge, but it has to be handled very carefully.

AI: That's a really striking example of the risks when AI delegation goes too far. It sounds like your team is experiencing firsthand what happens when someone becomes overly dependent on AI without building their own understanding of the underlying work.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: A time when AI made me satisfied was when I was able to simply ask it for a set of MATLAB commands to extract data and plot it and I could do it in no time. My downfall is remembering syntax, and I think keeping syntax straight is where AI really helps me the most. The time I think I have been most frustrated was just what I was telling you previously about how I kept having to correct and remind ChatGPT of what we were doing.

AI: That's a great contrast - AI really shining when it helps you get past those syntax hurdles versus the frustration of having to constantly manage its context and memory during longer collaborative tasks.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Well, yes. I have been working with DataAnnotations and some other companies to try to teach physics to AI. My active worry is of course making my job less useful because who would employ an expensive physicist when they could just get a solution from an AI model?

AI: That's such an interesting paradox - you're actually contributing to training AI in your own field of expertise. It sounds like you're very aware of the potential implications for your profession.

What drives your decision to participate in training AI in physics despite those concerns about your field's future?

User: I think AI is here to stay, so I don't want to get  left behind in the AI tech sphere. If I gain experience using AI, particularly pertaining to my field of study, I am in a sense potentially future-proofing myself. I now realize this is perhaps even more paradoxical to what I just stated about potentially making my job less relevant, but at the same time it would be hopefully an adaptation to overcome that exact problem.

AI: That's a really thoughtful way to navigate that tension - essentially betting that being part of the AI development process will position you better than trying to avoid it altogether. 

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think you'll continue with that collaborative "holding its hand" approach, or do you see it changing as the technology improves?

User: I would like to develop more trust with the models so that I can take a more hands-off approach to it. But that trust will come slowly and will have to build over time.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on that balance between collaboration and delegation, and how you're navigating the paradox of training AI in your own field while being mindful of its implications.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No I don't believe so. But if "Claude" becomes the real version of Hollywood's Skynet, would you make a note that [REDACTED] and his family can be passed over?

AI: Haha, I'll be sure to put in a good word for [REDACTED] and family if that situation ever arises! 

Thank you again for your time and for sharing your experiences so openly. Your insights about the careful balance needed when working with AI, especially that contrast between your collaborative approach and your team member's experience with over-delegation, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!
