# Dialog 00700

**Transcript ID:** work_0374

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: I understand

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Copilot is provided by my company.  We have a license that allows for its extension to be installed in our IDE.  I use it when I need ideas, explanations, syntactical questions, or to get examples to help with coding or structuring my project.  Sometimes, I use AI to help me proofread my email and make it easier to understand.  At times, I also leverage it to help me write documentation given some context.

AI: That's a helpful overview of how you're using AI tools. I'd like to dig a bit deeper into your experience with these different uses.

When you mention using Copilot for "ideas" in your coding work, can you walk me through what that typically looks like? What's happening in your workflow when you turn to it for ideas?

User: Sure, one example recently, I  asked it for refactoring ideas.  I had two methods that did exactly the same thing, but the difference was the parameter type that it takes in.  Validation happens differently because of the type, but in the end it calls the same service that accepts either type.

AI: That's a concrete example, thank you. So you had this duplication issue and turned to Copilot for refactoring suggestions.

Tell me more about that interaction - did you describe the problem to Copilot and ask for suggestions, or did you share your actual code with it? How did that conversation with the AI unfold?

User: Since Copilot was an extension installed into my IDE, it was able to see any "active document" I was on.  So I didn't have to share my code, but it had access to read the code.  Copilot ended up suggesting to make an interface and have the methods refactored to do validation separately, and then refactor the common part to take in a func

AI: Interesting - so Copilot could see your code directly and suggested creating an interface with separate validation and a common function approach.

What did you do with that suggestion? Did you implement it as Copilot recommended, or did you modify the approach somehow?

User: Copilot wasn't 100% perfect but it was close. I ended up using most of the code given with some modifications to how the inner workings of the common function worked.

AI: That's a really insightful example of how the collaboration played out. You took most of what Copilot suggested but made your own adjustments to the implementation details.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: I like to rely on myself for almost everything else that is not related to coding.  When I do research, I tend to rely on searching the web, and then conversing with AI to validate my understanding.  Nothing really different about those tasks. I think it's just been muscle memory to do my own research first.  Or sometimes, I even forget AI is there for me to bounce ideas off of.

AI: That's really interesting - so you have this established pattern of doing your own research first, and AI comes in more as a validation tool afterward. And sometimes you just forget it's available as an option.

When you do use AI to validate your understanding after your own research, what does that conversation typically look like? How do you present what you've learned to get that validation?

User: I pretend I don't actually know the topic.  I think a better way to describe it is it's like getting the AI's understanding to complement anything that I've learned from the web search.  

So for example, if I'm researching when to use an Array versus a list, I would go read articles online about the performance or coding examples.  Then, I would go back and ask AI, when should I use arrays and when should I use a list.  Afterwards, I would throw in some facts I find from articles like "As of version x.y.z, it looks like lists are more performant than arrays. Should I still use arrays?" or things like that

AI: That's a fascinating approach - you're essentially getting two independent perspectives on the same topic and then bringing them together with follow-up questions.

When you use AI for work, like in that validation example or with the coding assistance, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: Typically it starts off with a background or some context of what I am trying to achieve. Then, I give the problem statement.  Depending on the feedback I get, it will either confirm what I know or give me some alternative approaches. That is when I will ask why it suggests a certain approach rather than what I've research. Which I will then validate on my side by doing a web search.  I tend to collaborate with AI rather than delegate a complete task. The only time I delegate tasks are for mundane or quick boiler plate code.  Like "write me powershell script that posts to http://fakewebsite.com/user with headers blah blah blah"

AI: That's a clear picture of your collaborative approach - you're having this back-and-forth dialogue where you're constantly validating and cross-checking between AI suggestions and your own research.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Has the fact that your company provides the Copilot license affected how you or your team approach using these tools?

User: Overall, the culture has been encouraging to use Copilot to help speed up the development process.  However, it has created some issues.  I'm the solutions architect for my team, and I end up reviewing all the code that comes through.  Sometimes, I see developers getting lazy and solely rely on Copilot. This affects me greatly.  I have to be more careful while reviewing since I noticed code is overcomplicated, not performant, or doesn't meet all acceptance criteria(causing bugs or unwanted side-effects)

AI: That's a really significant insight - you're seeing both the benefits and the downsides from your perspective as a solutions architect. It sounds like you're dealing with a quality control challenge when others rely too heavily on AI.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I remember there was a complex coding issue, but  I can't remember the exact problem.  After asking Copilot for advice, it kept giving me a "fix" that is the exact same code as what I already had.  After numerous attempts of telling Copilot that no code changes happened, it still kept giving me the same code snippet.

AI: That sounds incredibly frustrating - being stuck in this loop where Copilot wasn't understanding that its suggestion wasn't actually changing anything. 

What did you end up doing to resolve that situation? Did you eventually get Copilot to understand the issue, or did you have to find another way forward?

User: I eventually abandoned copilot and attempted the fix myself and asking other senior leads

AI: That makes sense - sometimes you just have to step away from the AI tool and go back to human expertise. 

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: This is something I never really considered. However, for my field of work, I need to always stay sharp anyways.

AI: That's an interesting perspective - that staying sharp is already just part of what your field requires regardless of AI.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I hope to see AI evolve into the next stack overflow where 90% of the time it is correct with its information.  In other words, hoping Ai can better complement my work.

AI: That's a great analogy - AI as the next evolution of Stack Overflow with much higher accuracy. 

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on the quality control challenges you face as a solutions architect when reviewing code from developers who rely heavily on Copilot.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No thank you

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about how you balance collaboration with AI while maintaining quality standards, and your unique perspective as both a user and reviewer of AI-assisted work, will be incredibly helpful for our research on human-AI interaction in professional contexts.

Have a great rest of your day!
