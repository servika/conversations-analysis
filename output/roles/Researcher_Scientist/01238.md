# Dialog 01238

**Transcript ID:** science_0074

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: yep sounds good lets begin

AI: Great! Let's dive right in.

Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: I recently worked on a project in the field of molecular physics. I used an existing density partitioning method and modified it in order to calculate certain quantum properties more accurately. It began with a literature review - I read all the new research and also lots of the older stuff again. Then I had the idea for the project, what I wanted to do, what methods I would use in theory. Then to make the ideas reality I got on the computer and started by collecting a small sample of(15 small molecules) data from the existing density partitioning method and looking at those in depth. Then I wrote up a bit of code to test a method I had been reading a lot about online - ran that on some molecules and checked with datasets that I was getting the right numbers. With those parts figured, I was able to start building my new model which combined and modified aspects of both of the existing models I had tested. This was the longest process of trial and error until I finally got numbers which were consistent with expectations. Once I had collected data for my 15 small molecules, I analysed that looked for trends make sure all is good then extended my data set to another 15 slightly larger molecules. Following that conducted some secondary studies of areas I would like to explore more... Commenced by completing presentations getting feedback modifying report and writing up for review

AI: That's a really thorough overview of your process - from literature review all the way through to writing up for review. It sounds like there were several distinct phases involving both theoretical work and hands-on coding and analysis.

Where in that process, if anywhere, have you experimented with using AI tools?

User: Yes, a few places. I actually used AI tools quite a lot throughout this process. In the literature review portion I used AI tools to quickly scan any papers before I read them to check how relevant they are to my research (sometimes the titles and abstracts alone are a bit deceiving). Though, I found I didn't feel very trusting sometimes and would often worry the AI had missed a nuance in the paper which would be essential to me - so my use of the AI in the field was only brief. I often tried to use AI chats to help me with the brainstorming process - bouncing ideas of, asking for advice on certain aspects. But my area of research seemed to be just too novel/niche/difficult (?) to get any valuable help from the AI and often just ended up wasting a lot of my time whilst I tried to "set the scene" and explain the concepts we were working with. So, at this stage, was still a bit of a bust but I kept trying. I also tried using it to spot things in big groups of data for me, but the accuracy was a bit too low for it to be helpful. My favourite use it turned out for the AI tools was when writing up my final report. Trying to put pages of complex mathematical formula into Latex is a pretty long job. Screenshots of the equations into an AI chatbot was all it took to get immediate output of the latex I needed and really cut the method section of my paper in half. That was a great use.

AI: That's really insightful - it sounds like you found a sweet spot with the LaTeX conversion, but ran into some challenges in other areas. You mentioned that with the brainstorming, your research area seemed "too novel/niche/difficult" for the AI to provide valuable help.

Tell me more about what happened when you tried to "set the scene" and explain the concepts to the AI during brainstorming - what made that feel like it was wasting your time?

User: Yes sure. My research was all about subtle nuances. I was studying properties of atoms in molecules. To the untrained eye the method I was using as my start point already looked like it was correctly calculating the properties I was looking for. In reality there was an entire piece of the puzzle missing from the existing data that was not well recorded in any online sources. I tasked myself with finding a method to put those missing pieces back in, which required a method which was extremely different to existing works. I modified a model which usually has an entirely different role, to fit my purpose. No matter how I explained this to the AI systems I could not effectively communicate why this was necessary - it just could not understand. I would give all the scientific background I could, lay out my exact plan and reason for the study and it would go one of two ways. 1. It would retort with an answer which was not even close to what I was asking or 2. It would reply something which made me feel it understood just to reply to a follow up question that demonstrated it was just a fluke. You can image how that would waste a lot of time.

AI: That really paints a clear picture - it sounds incredibly frustrating to spend time laying out all that scientific background only to get responses that showed the AI fundamentally didn't grasp the subtlety of what you were trying to achieve. The fact that it would sometimes seem to understand and then reveal it didn't with follow-up questions must have been particularly maddening.

For the LaTeX conversion task where you found AI really helpful - how did you decide to try AI for that versus your traditional approach of manually coding the equations?

User: To be honest, I just thought what could go wrong? I had seen people using the AI tools for coding help with some success which gave me the idea. I figured I would try giving it an equation, pasting it into Latex and generating and seeing what happened. When it worked my first trial I knew this would be how I would do it from now on. There are some tasks which you could get AI to do - but I wouldn't - because I simply enjoy doing themself, and I suppose I also believe I could do a much better job than the AI could (i.e. writing up the publication - I prefer my own writing style). And there are some jobs like this latex where you can't really say you enjoy it - it's laborious. Also, it makes no difference about who did that task, it doesn't look better because a human wrote it in - it's the same, I would've written it up the same way. So really it only saves time so of course you would do it.

AI: That makes perfect sense - you identified a task that was purely mechanical with no creative or interpretive value, so there was really no downside to trying AI for it. It sounds like you have a clear sense of which tasks you value doing yourself versus which ones are just tedious necessities.

We're about halfway through our conversation now. Thinking about the parts of your research where you haven't used AI - like the core model development and analysis phases - what's kept you from trying it there?

User: In terms of the core model development I did use it here and there for bits of coding / debugging help. But I felt if I let the AI tools do too much of the coding I would kind of lose sight of what was going on if that makes sense? If something is going wrong in my own code I feel I always know where to start when trying to fix it, but if the code mostly came from an AI tool I would feel a bit. out of my depth where to start. I also came from a pure physical science background and only transitioned to the computational world a couple years ago so I also like to take to chance to practice where I can. The analysis phase was a big no to me to receive the AI help. It didn't feel worth the chance of errors. I knew if I was taking on something it had told me I would have to spend time checking every aspect to be safe - so it didn't feel too worth it. I also knew that I had insights on the science that the AI tools just wouldn't. So it felt like asking a first year undergraduate student for help writing a PhD thesis - not really worth it

AI: That analogy of asking a first-year undergraduate to help with a PhD thesis really captures it well. You mentioned that even if you did use AI for analysis, you'd have to spend time checking every aspect to be safe.

When you've used AI for tasks like the LaTeX conversion or debugging help, how do you verify or validate what it produces?

User: The latex conversion is super easy to check which is why I loved it for that - paste it into latex, recompile and if it compiles how you wanted it then it's done. If it's not you just delete it and try again - no time taken at all. Same with the debugging - if I understand its reasoning and like the fix I'll just try it and if we run without errors I'm happy and we move on. That's why I like it for those kind of tasks because they're more of if it works it works kind of tasks.

AI: That's a great distinction - tasks where the verification is immediate and obvious versus ones where errors might be subtle or harder to detect. It sounds like you've developed a pretty clear framework for when AI is useful versus when it's not worth the risk.

If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: It would be that early brainstorming / bouncing off ideas phase. I mean that's why I had so much to say about that - because I desperately wanted it to work and be a partner for me. My field is niche, and because of that a bit lonely when it comes to sharing ideas. I know my supervisor, and that is pretty much the extent of the audience I can discuss my work with and have understanding from the partner. Obviously I could attempt to start an email conversation with someone in another institution which may eventually blossom into someone I can converse with regularly, but that is not necessarily a small feat. I would love an AI which could feel like a valuable research partner. An AI with human-like ideas and thought processes. Or even one that could just bring something new to the table - they could be distinctly non-human in their reasoning as long as it was a fresh perspective. I want it to feel like a two way conversation - rather than a one sided almost teacher to student like relationship where the student refuses to learn.

AI: That longing for a true research partner really comes through - the idea of having something that could offer a fresh perspective, whether human-like or distinctly non-human, as long as it brings something genuinely new to the conversation. The isolation of working in such a niche field makes that need for intellectual collaboration even more acute.

Those are all my questions - your perspectives on finding that sweet spot between leveraging AI for mechanical tasks while maintaining control over the creative and analytical work were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: Nope I think that's all. glad it was useful

AI: Thank you again for sharing your experiences so openly. Your insights about the loneliness of niche research and your desire for AI to be more of a true intellectual partner really help us understand the nuances of how AI fits into real scientific work. The way you've carved out specific use cases where verification is straightforward while being appropriately cautious about areas requiring deep domain expertise shows a really thoughtful approach to AI integration.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
