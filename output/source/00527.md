# Dialog 00527

**Transcript ID:** work_0117

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: That sounds good. Please begin.

AI: Great, let's dive in. Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI in two key domains: Producing work product for clients and managing my business. I am a marketing consultant doing work that runs from strategy/branding to project implementation. So, I use AI assistants for the following client-facing work: Writing high level summaries of long form work I produce. Editing long form work I produce. Extracting and summarizing from meeting notes to produce follow up reports/emails. Creating ghost writing for clients (social media posts, blog articles, etc... - I create a tone/voice section of the initial user prompt in a markdown doc or similar to get individual styles in play). For internal work, I use AI to help me organize ideas, as a thought partner for campaigns, as a research partner (AI is NOT very good at this yet... no offense Claude), etc.. Is that what you are looking for?

AI: That's exactly what I'm looking for - thank you for being so specific about the different ways you use AI across your work.

I'm curious about your preferences when working with AI. You mentioned quite a range of tasks there - are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: I don't ask AI to outline articles of my own for me. I write a fair amount on various topics. I prefer to work on refining the main idea or thesis of a piece using AI, but I do not like having AI outline the work for me. I may solicit feedback on an outline, but I do not want to be guided on creating them. For me, it's like Netflix: THEY determine what I even THINK about watching by virtue of controlling the interface and how it is populated. Having AI write an outline feels like that - I am letting someone else decide what I keep and what I exclude at the most basic level. I also review ALL work that AI handles at this point. I do not let unreviewed work go to clients.

AI: That's a fascinating distinction you're making about maintaining control over the fundamental structure and choices in your work. The Netflix analogy really captures something important about agency.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I rarely delegate anything but a detailed deep research plan to AI. I work with AI as a "work partner" (if that makes sense). It's one reason I speak with agents like I would speak with a person. It fosters the thought space that makes it feel like worthwhile collaboration.

AI: That makes a lot of sense - treating it as a work partner and speaking naturally to foster that collaborative mindset.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Since you're a consultant, I'm thinking about both your industry peers and your clients' attitudes toward AI use.

User: Yeah, I'm a solopreneur after having had a few companies with large teams. It's... refreshing. So, my perspective is from the outside in at my client worksites. Several of my folks are development shops, so they are all in on AI (whether they love it or hate it), but tend to use the natural language tools poorly. Or rather, they don't approach the natural language tools with the same discipline they do programming aids. At other workplaces, there is a sharp divide of people who like to use public facing tools like yourself, but for very mundane tasks ("write this email..."). Then there is a large group (my wife included - she is 50, I am 57) who know they SHOULD learn about AI, but feel like the reward is not worth the time carved from an already overloaded schedule.

AI: That's really insightful - the contrast between developers who embrace AI for coding but struggle with natural language tools, and then that broader group who feel the learning curve isn't worth the time investment given their workload.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Last week, I asked o-5 to summarize and extract a long and convoluted set of meeting notes and it absolutely nailed it. The version of chatGPT is solid and I have been working on a persistent version of the prompt for this task in markdown for almost six months. Bravo!!

AI: That satisfaction of having a well-crafted prompt finally deliver exactly what you need must have been great, especially after months of refining it.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I don't really care or worry about it. We have exactly zero idea what the world of commerce will look like in 5 years, let alone 10. I work in a field that literally DID NOT EXIST when I was in college and thru much of grad school. I taught one of the first ten accredited "online" courses in the US - which at the time simply meant that you just had to have SOMETHING on a website and the class had to interact there. So, yeah, AI will change things, but let's get real: the changes will be both dumber and more amazing than we can imagine. Trying to predict it is just useless. I concentrate on finding areas to "add value" (i.e., get paid) where I have little competition. So, staying on the curve of AI is right in my wheelhouse. I'm fine if AI takes over some other thing I happen to be okay at (like wireframing or whatever).

AI: That's such a pragmatic perspective - focusing on staying adaptable and finding those niches where you can add unique value rather than trying to predict an unpredictable future.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: No idea to be honest. I just keep pushing the level of complexity that I can manage with the tools as they evolve. So, it's a function of what do I feel like will be a good use of my time? Back to an earlier turn - now that I have that prompt in place and understand more of o-5's capabilities, I will look at other, similar projects in a different light and work on those. So, I suppose "organically" is the answer.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on maintaining agency over the fundamental structure of your work - that Netflix analogy about not letting AI control what you even consider really stuck with me.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Yeah... I've worked with A LOT of models and I have a very solid understanding of how training works. I have a big concern about the integrity of training data and its ultimate effect on the operating knowledgebases that any public facing systems use. The idea of applying AI to business cases where people's lives will be dramatically altered based on what the AI decides is... terrifying? concerning? something in that wheelhouse. People are bad enough with all of their faults. But the thing is, AI is (currently) bound by the age-old problem of GIGO... and much of the training data as well as the human feedback for systems is just... garbage. Humans can "rely" on it, because they are slow and, fortunately, kinda dumb. So, it's just not possible for, say, a single person to erroneously cancel 100 insurance policies in a week, let alone a day. There is a high likelihood they will be found/corrected before they can do too much damage. BUT, put AI in charge of that, and one machine will erroneously cancel 100,000 policies in less than a second before anyone figures it out. No bueno. So, I push back on clients who want to roar ahead with AI adoption and ask them to think very carefully about what they, as a company, are willing to give up in terms of transparent guardrails.

AI: That's a crucial point about the scale and speed differences - humans being "fortunately kinda dumb" in a way that creates natural guardrails versus AI's ability to amplify errors at massive scale before anyone can catch them. Your role in helping clients think through those transparent guardrails sounds really important.

Thank you again for your time and for sharing your experiences so openly. Your insights about maintaining agency in your work, the collaborative approach you take, and especially those concerns about responsible implementation will be incredibly helpful for our research on human-AI interaction in professional contexts.
