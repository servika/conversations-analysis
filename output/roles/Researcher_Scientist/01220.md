# Dialog 01220

**Transcript ID:** science_0042

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: No questions, that sounds fine, go ahead.

AI: Great! Let's dive in then.

Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: A recent research project involved the design of bio-inspired quadruped robot end effectors (feet) to help them move around in difficult terrain, like debris and such, without falling or slipping. The initial idea came from previous research on the capabilities of a particular animal to move in their environment based on their anatomy and passive anatomical structures. Then came an ideation stage of how to translate these features effectively into a robotic part. Then there was a long prototyping/RnD process that involved repeated iteration on the different designs and some informal testing, before the final design was chosen and tested in the lab and in the field.

AI: That's fascinating - bio-inspired robotics with such a practical application. The process you described sounds quite iterative, moving from biological inspiration through ideation, prototyping, and testing.

Where in that process, if anywhere, have you experimented with using AI tools?

User: The informal testing and the final quantitative testing both required us to design testing apparatus in-house, the code for which I wrote and I used AI tools (primarily Chat GPT at that point) to help with debugging and understanding APIs and syntax, etc.

AI: Tell me more about how you decided whether to use AI versus your traditional approach for that coding and debugging work.

User: Using AI seemed like a no-brainer at that point for productivity purposes, because learning a new API or debugging can be a time consuming process and we were often working "against the clock" with deadlines and things. For debugging and code explanation there are no perceived "risks" or downsides to using AI in research in my opinion.

AI: That makes sense - sounds like the time pressure and low-risk nature made it an easy decision for the coding aspects. 

Thinking about the other parts of your research process - the biological research, ideation phase, or the design iterations - what's kept you from trying AI tools there?

User: For the initial research and literature search section, I think for something as fundamental as scientific research the confidence in AI results is just not there yet. By that I mean confidence in the comprehensive nature of AI searching and its reporting of details and facts from papers - in my experience it frequently makes mistakes and gets confused between papers with similar authors and dates, or similar information. For ideation it could be useful, but this is a process that I find is usually engaging enough on its own and so there isn't the same desire to offload that task onto some AI assistant. In addition, I think that I personally still wouldn't assume that an AI chatbot would provide me with very creative, out-of-the-box ideas, given the nature of their training. For the design process, this was all done with CAD software which is still something that AI isn't really used for yet (in my experience) and it isn't really necessary for someone who knows how to use the software already.

AI: Those are really insightful distinctions you're making about different types of tasks and risk levels. You mentioned that for literature search, you've experienced AI making mistakes with details and getting confused between similar papers.

When you have used AI for the coding and debugging work, how do you verify or validate what it produces?

User: For code debugging the validation is usually part of the process because you can tell whether or not the bug is fixed. This is especially true for high level languages like Python, or specific application languages like MATLAB and R, since you don't have the same sneaky safety issues that you have with other languages like C/C++. For languages like that I think it's important, at this stage, to only use the AI to *help* you find and fix bugs and not to apply bits of code that you don't understand yourself, at least for important applications.

AI: That's a really practical distinction about verification being built into the debugging process itself. You're about halfway through our conversation now.

If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: For sure the literature search and research, it would be very helpful to have the bulk of that done by an AI assistant and I think it's definitely feasible with an increase in confidence in search results, and integration into whatever university access system you might have to view specific journals. The act of finding literature and being comprehensive and such can be a long process and it's easy to miss things, like obscure papers. I suppose it could also help with summarising some of that information, but that might be a slippery slope because I think it's important to properly read and understand that background research or any research you might be citing.

AI: That's a great point about the tension between efficiency and the need to truly understand what you're citing. The literature search automation with proper journal access integration sounds like it would be a real game-changer for that comprehensive discovery piece.

Those are all my questions - your perspectives on how task risk and verification methods influence your AI usage decisions were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: I think this is a very sensitive area for AI adoption, since the state of research is already quite delicate and the literature is filled with problems. However, many researchers are definitely already using AI tools in every part of the research process, and will continue to use it, and for that reason I think it's very important that those tools become much more reliable in their results to foster confidence in what can be a very sceptical community.

AI: Thank you again for sharing your experiences so openly. Your insights about the tension between the research community's existing skepticism due to current literature problems and the inevitable adoption of AI tools really help us understand the nuances of how AI fits into real scientific work. That perspective on reliability being crucial for gaining trust in a naturally skeptical community is especially valuable.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time today!
