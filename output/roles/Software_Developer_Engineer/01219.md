# Dialog 01219

**Transcript ID:** science_0041

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good to you? Do you have any questions before we begin?

User: Sounds good, no questions here.

AI: Perfect, thank you. Let's dive right in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I often use it for open web research that supplements my own research, as well as converting code, writing code snippets, and other software development assistance.  After brainstorming technical approaches to solving problems, I will often run it by an AI/ML model or two just in case it has anything we missed or has any other relevant feedback.  For technical report writing, I still write myself 99%+ but often have an AI critique and modify as a close partner/assistant and critic, especially after my draft is near final.  These are just a few things I might use it for on a typical day.  Deriving an equation to either check my derivation, or just do it (but I will 100% double-check it step-by-step).

AI: That's a really comprehensive range of uses. It sounds like you're integrating AI across multiple aspects of your technical work - from research to coding to writing to mathematical derivations.

I'm particularly interested in something you mentioned - you said you "100% double-check" AI-derived equations step-by-step. Tell me more about that. What drives that level of verification for you?

User: Most of the mathematical derivations I do, if incorrect, would be very problematic.  For example, the predicted sensor resolution might be off by an order of magnitude or more, and very intelligent mathematicians, physicists, and electrical engineers will be seeing my equations and derivations and if they are wrong, even if it is caught and doesn't impact a project negatively in the end, it would make me look very bad!

AI: That makes complete sense - the stakes are really high when your work is being reviewed by experts in those fields. The professional reputation aspect is clearly important to you.

I'm curious about your preferences when working with AI. You mentioned you still write 99%+ of your technical reports yourself. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: First, I notice that if I ask AI to just write something for me, it still isn't quite as good as what I would write or want to convey, so iterating with the AI might not save me as much time as doing it myself then having the AI just critique/make small modifications at the end.  Second, when an AI writes its writing style is something I can often pick up on.  It may be written well, but I quickly say "Did an AI write this!?".  I don't want our customers or my colleagues asking that of my work, and I don't want to pass things off as my own when they're not.   I also find it far less efficient to create the exact figure I want to use in a report, proposal, etc. than to just do it myself, perhaps with some feedback from the AI.  The AI can't seem to create figures using the data on my computer and signal/image processing algorithms within my jupyter notebook or matlab and get them to look the way I want without lots of iteration, me instructing it and re-instructing it... it just feel less frustrating to make continuous progress to get my figure looking just like I want it in 15 min and know it will take 15 - 25 min tops, than to keep iterating with an AI and have some *uncertainty* in knowing when, or if, it will converge onto the figure I have in mind as well.

AI: That's really insightful - you're describing both quality and efficiency considerations. The authenticity concern is particularly interesting - you can recognize AI writing and don't want others to question whether your work is genuinely yours.

When you do use AI for work, could you describe your typical interaction pattern? It sounds like with reports you collaborate throughout, but with something like code conversion or brainstorming technical approaches, are you more likely to collaborate with it step-by-step, or do you tend to delegate complete tasks for it to handle independently?

User: For coding that is not in some mission critical system that I will be able to just tell if it works properly and as intended for one quick and dirty demonstration (maybe there are corner cases it will fail in, but I don't need to check those for the one-time demo) I will absolutely delegate a much larger coding tasks for it to handle independently.  Since we do not have an approved agentic framework yet though, I often am having to send error messages back for it to debug and iterate a few times.  It is still quite useful and enhances productivity a *lot*, but just asking it "Can you run this code on my machine to make sure it works, otherwise debug it until it works and if you get stuck, ask me for guidance?" would be so much more helpful.

AI: That's a really clear distinction - you'll delegate larger coding tasks when the stakes are lower and you can easily verify the output works for your immediate needs. The debugging iteration cycle sounds a bit tedious though.

You mentioned not having an approved agentic framework yet. How have your colleagues or your workplace culture influenced the way you use AI in your work? It sounds like there might be some organizational considerations at play.

User: Indeed, we are a defense contractor who is subject to regulations including CMMC Level 2.  This is in addition to Corporate being very protective over Proprietary Information, PII, and so on, so there are a lot of "do's and don'ts" with lots of security-oriented processes that must be put in place before the organization can allow us to use agentic frameworks, and even LLMs for example.

AI: That regulatory environment really shapes how you can interact with these tools. It sounds like you're working within some significant constraints around what AI capabilities you can actually access.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: One of many times I was particularly satisfied was having a technical proposal/response that was +1.5 pages too long (that I wrote entirely myself) and needing to get it down in size without changing fonts and not wanting to cut anything.  This process can be frustrating and take some significant time, but I was able to accomplish it within < 30 min easily and maintain my language and tone entirely by just carefully prompting the AI (at first it wanted to insert different tone/word choices, so I had to be explicit there).  It was particularly frustrating once when a very popular AI/ML model known to be "among the best" just refused to believe that YOLOv11 was even a thing, even after I gave it the URL to Ultralytics' page talking about it, it still claimed it visited the page and didn't see what was clearly there.   Similarly it's frustrating whenever the AI is seemingly 100% confident in itself but is wrong, or when it "interpolates" URL references to pages that don't exists/"hallucinates" technical references and papers with fake titles that don't exist!

AI: Those examples really highlight both sides of the experience. The proposal editing sounds like a perfect use case - you maintained complete control over the content while getting practical help with a tedious task.

The frustration with the model being confidently wrong about YOLOv11 or hallucinating references sounds particularly problematic in your field where accuracy is critical. 

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I don't worry about that at all.  I keep my skills up-to-date and can easily adapt, but I'm lucky that I can adapt my skills.  I would imagine this is a concern for many others.

AI: That's a confident perspective - it sounds like you feel well-positioned to evolve alongside these tools. 

Looking ahead, how do you envision your relationship with AI at work evolving? Especially considering those regulatory constraints you mentioned earlier.

User: I am leading an internal effort to help address that across the company actually.  It is a process and I'm not empowered to just "make it happen", but they will listen to my input and feedback at least and consider it.  I will be able to influence decision-making on what secure platform to adopt, what an acceptable use policy for open web is, and so on.  I am not confident I will get everything I'd like myself and our technical people to have access to, but am optimistic that a good tradeoff will end up being in place in time, and that the Industry overall will find ways to solve the problems we have that are not unique.

AI: That's fascinating - you're not just adapting to the constraints but actively working to shape how your organization approaches AI adoption. It sounds like you're in a unique position to influence that balance between security requirements and technical capabilities.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on maintaining authenticity in your writing and how you navigate the verification process for high-stakes technical work.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, but thank you!

AI: Perfect! Thank you so much for your time and for sharing your experiences so openly. Your insights about working within regulatory constraints, the balance between delegation and collaboration, and your role in shaping AI adoption at your organization will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today. Have a great rest of your day!
