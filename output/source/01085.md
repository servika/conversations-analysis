# Dialog 01085

**Transcript ID:** work_0967

---

Assistant: Hi, I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. Does that sound good? Do you have any questions before we begin?

User: No questions, sounds good!

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I tend to use AI to try and make my workday easier. The general categories of tasks I would use it for are administrative, coding, and research. For example, in terms of administrative tasks, as the engineer who is a lead on a particular project, I might use AI to help me make an email to a non-technical audience more clear. I've also used AI to give me a starting point for documentation. I also sometimes use it to reduce overwhelm, by helping me manage my day, such as giving it a list of tasks, and requesting a rough time blocked schedule. For coding tasks, my requests tends to be of a "give me a template to do this" nature. When I'm doing research, I like to use AI for brainstorming (e.g. "what WCAG guidelines could be automated") or as a starting point for me to know where to go with my own research.

AI: That's a really comprehensive range of uses. I'm particularly interested in how you mentioned using AI to "reduce overwhelm" with task management. 

Tell me more about that - what does a typical interaction look like when you're feeling overwhelmed and turn to AI for help with managing your day?

User: Generally if I have a set list of tasks where I know I need to get them done in a certain timespan (e.g. "fix this bug", "get this documentation generated", "approve this merge request", "prep for this meeting"), I'll feed those into a prompt, along with any other parts of my day like "include a lunch break" and request a schedule for tackling those items based on their priority/difficulty/deadlines.

AI: That sounds like a really practical approach. When you get that schedule back from AI, what happens next? Do you tend to follow it pretty closely, or do you find yourself adjusting it as your day unfolds?

User: I think I tend to use it as a baseline, but I'm not incredibly strict with it. For example, if I get a ping that looks important during a block where I'm supposed to be focusing on a task, I'm not going to say "I'll deal with that once this focus block is over". I try to follow the general structure, but adapt as needed.

AI: That makes sense - treating it more as a flexible framework than a rigid plan. 

I'm curious about your preferences when working with AI. You mentioned several areas where you use it, but are there certain tasks you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: I think writing tasks tend to be where I might use AI as a starting point, and then handle the rest myself, or just entirely do it myself. That tends to be when there is a very specific tone I'm trying to convey, or if I tried using AI as a starting point and didn't feel like it fit my goal.

AI: That's interesting - the tone aspect really stands out. 

Can you give me an example of a specific writing situation where you felt the tone was too important to rely on AI, or where AI's starting point just didn't capture what you were going for?

User: I think mostly with helping craft responses to co-workers. Sometimes AI will craft a response that is great in terms of content, but depending on the person I might want to tweak the tone because we have a particular relationship (e.g. friendlier with some coworkers than others). The other scenario is if I know a message will also be seen by a client, I might tweak it to be more like what their messages tend to look like.

AI: That's a really nuanced point about adapting to different relationships and audiences. It sounds like you're drawing on a lot of contextual knowledge that AI might not have access to.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: It's more of a collaborative process for me. For example, if it's a "write an email" task I'm working on, then I'll give it a starting point, and collaborate until I reach a point that I am happy with. For coding tasks, it's very similar. I might say "can you give me a method that will do a particular thing", and then adjust as needed. For example, if it's Java, I might collaborate to say "can we change variable1 to List[REDACTED] instead of Set[REDACTED] because I want to also use it for this purpose".

AI: That collaborative back-and-forth approach sounds really iterative. It seems like you're actively steering the conversation to get exactly what you need.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that your team has particular norms or expectations around AI usage?

User: I think my workplace has been slow to adapt AI in some respects, but also clearly using it for others. The main expectation seems to be "make sure you are cross-checking anything you get from AI". I know the CEO for example uses it a lot to craft things like marketing materials or LinkedIn messages. In the team I'm on, there hasn't been a ton of discussion about how we each use AI (if it all). I know company wide, there was an offer for a Github Copilot license. For the particular client my team works with, they are adopting AI more quickly, but it doesn't affect me as much due to them using it for purposes that are different to what my team works on. I work on developing a new tool, and they're using it to speed up QA.

AI: It sounds like there's a pretty diverse range of AI adoption happening across different parts of your organization. You mentioned that cross-checking expectation - that seems like an important safeguard.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I think the satisfaction and frustration moments tend to happen when using AI for coding for me. Sometimes it will be frustrating because the AI will claim that the code will do something, and I'll either clearly see it's not meeting my requirements or I'll try it and there will be some error. The satisfying moments are when I get the requirements just right, and I'm able to plug and play code to increase my development pace.

AI: Those coding experiences really highlight the variability in AI performance. It sounds like getting the requirements "just right" is a key skill you've developed.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Being more in quality engineering, my hope would be that I might always have a purpose in the "there should be a human-in-the-loop" to make sure things are working as expected. I would say that I do have concerns in general. I've considered certifications (security related) and even maybe doing a degree in a field where AI will not be as dominant (something like civil engineering where safety concerns will likely always require a human).

AI: That's a really thoughtful response - it sounds like you're thinking both about leveraging your QE background and considering some significant pivots. The safety-critical aspect of fields like civil engineering is an interesting consideration.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I know my company intends to work more with AI going forward, so I'm imagining it will become a more set part of my workday, in terms of using it and developing products involving AI, versus how it is at the moment where it's used a little more ad hoc.

AI: That transition from ad hoc to more integrated usage sounds like a significant shift coming.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on the collaborative nature of your interactions and how you navigate the balance between leveraging AI while maintaining that critical human oversight role.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about the collaborative approach, the importance of tone and context in communication, and your thoughtful perspective on skill development in an AI-integrated workplace will be incredibly helpful for our research on human-AI interaction in professional contexts.

Have a great rest of your day!
