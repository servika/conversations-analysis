# Dialog 00155

**Transcript ID:** work_0191

---

Assistant: Hi! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. Does that sound good? Do you have any questions before we begin?

User: I'm happy to begin. Where would you like to start?

AI: Perfect! Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI at work in a few different ways: I use it for content generation, for assistance with coding (in VS Code copilot), for general question-and-answer assistance, and for automated web scraping price information.

Some more about this:
* I work for an electronics retailer and I'm responsible for maintaining product listings across different marketplaces (our own Shopify shop, Amazon, Best Buy, Walmart, New Egg). This requires a lot of descriptions and other content about the product. We use the brand product pages as the source for this, but for SEO and other reasons we do not copy it verbatim. Instead, I use AI to generate the content.
* I happen to be a programmer, so part of my work includes integrating AI and other automation into our operations. When I write code, I use VS Code, and I often use the AI Copilot because it can be faster to explain the code I want than to think about it and type it manually.
* I use AI rather than web searching when I have a question about something generally, as I find this is faster.
* One of the automations I am working on implementing is an AI agent that can operate an automated browser and collect our competitor price information, so that we are always offering the lowest price to our customers. Keeping the track of competitor pricing takes up a great deal of time for our staff.

AI: That's a really comprehensive use of AI across different aspects of your work. I'm particularly intrigued by how you've integrated it into both creative tasks like content generation and technical work like coding.

When you're generating product descriptions, can you walk me through what that process typically looks like? How do you actually interact with the AI to get the content you need?

User: When I first started in the role, I used a chat assistant and our process was to copy-paste a prompt requesting a description based on the text of the brand product page, which was then also copy-pasted. Since then I have developed a web app which uses an LLM API and web scraping tools to do this, in order to streamline the process.

AI: That's fascinating how you evolved from manual copy-pasting to building your own web app. It sounds like you identified a pain point and then automated it.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: I can't really think of many tasks that I would not delegate to AI if I thought it could effectively handle them. Are there particular tasks you had in mind?

AI: That's really interesting - it sounds like you're quite open to AI assistance across the board. Let me ask this differently then.

When you do encounter tasks where you choose to handle them yourself instead of using AI, what's usually driving that decision? Is it more about AI limitations, or are there other factors at play?

User: Often the limitation is integration. I need to integrate our systems (Shopify, Amazon, Google Workspace, etc) with the LLM in order for it to handle the work. There is also an issue convincing the team to adopt AI for this-or-that because they are not convinced it's able to do so without significant errors. Then, yes, AI is not generally useful yet for many tasks. I feel it is currently only effective when given relatively narrowly constrained tasks. For instance, my price scraping agent needs to have the context very carefully managed or else it burns through many tokens before producing interesting output.

AI: That's really insightful - so it sounds like the barriers are often more about technical integration challenges and team adoption rather than your personal preference to keep tasks for yourself.

When you do use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: Both. When coding I work collaboratively with the AI, sometimes asking it to write something for me, sometimes asking question about the code, and sometimes I just go off on my own. The content generation tasks I have placed in an automated workflow so there isn't any interaction, the model just receives prompts and the output is used; in this sense it works independently. The pricing agent is a work in progress; ideally it will work independently.

AI: That's a great distinction - you've got this spectrum from real-time collaboration in coding to fully automated workflows for content generation. 

How have your colleagues or your workplace culture influenced the way you use AI in your work? You mentioned earlier that the team needs convincing about AI's capabilities - tell me more about that dynamic.

User: Yes. Our management is aware that AI will be transformative in the next few years, and so there is a big push to be implementing it in some way. However, the staff is concerned about potential errors (for example, a product listing that says something about a product that isn't true) or taking automated actions that will negatively impact business (for example, price-matching an unauthorized reseller below a price that is profitable for us).

AI: That tension between management's push for AI adoption and staff concerns about errors sounds like a significant dynamic. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: As I mentioned, our management is very gung-ho about implementing AI. After discussion, I agreed to set up an AI to check pricing and send an email, giving the caveat that initially this would be just to demonstrate where the technology is at and that the output would probably not be useful. Despite warning about this clearly, when the email went out and, as expected, contained unusable information (hallucinated web addresses, for instance), there was great deal of excitement from management. Many staff members were distracted in checking this information and discussing it, a complete waste of time since I had already set the expectation that it would not be usable. This was a very frustrating situation.

AI: That does sound incredibly frustrating - you set clear expectations about the limitations, but the excitement overshadowed the actual usability issues you predicted.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I think about it sometimes, but I'm convinced that in the not-too-distant future humanity will lose control to superintelligent AI and be wiped out. So, maintaining marketable skills is the least of my worries.

AI: That's quite a perspective on AI's future trajectory. 

Given that view, I'm curious - how does that belief influence your day-to-day decisions about implementing AI at work? Does it change how you approach these projects?

User: No, it doesn't influence how I use AI at work. I approach projects believing that even if they don't work today because of model limitations, 6 months from now those limitations may not exist.

AI: That's a fascinating approach - planning for rapid capability improvements even while holding concerns about the long-term trajectory.

Looking ahead, how do you envision your relationship with AI at work evolving? What do you think your role might look like in the coming months or years?

User: I'm not sure. If I stay in this role, probably I will personally implement more AI in the near future.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on the disconnect between management excitement and practical implementation challenges, and how you're approaching AI projects with future capability improvements in mind.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, thank you for your time.

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about the technical integration challenges, team dynamics, and the evolution from manual processes to automated workflows will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candid you were about both the successes and frustrations you've encountered. Have a great rest of your day!
