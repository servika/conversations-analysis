# Dialog 01244

**Transcript ID:** science_0089

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: I do have a few questions, yes.
1. Is this restricted to only scientists or all the STEM fields?
2. What level of expertise is needed for this interview?
3. Can university students also undertake this successfully?

AI: Great questions! Let me clarify those for you:

1. This isn't restricted to just scientists - we're definitely interested in hearing from anyone working in STEM fields, whether that's engineering, mathematics, computer science, or any other technical discipline. The research workflows and AI integration challenges are often quite similar across these areas.

2. There's no specific expertise level required. Whether you're early in your career, mid-career, or very experienced, your perspective is valuable. We're interested in understanding how people at different stages approach AI integration.

3. Absolutely - university students can participate successfully. In fact, students often have really interesting perspectives since you might be encountering both traditional research methods and AI tools simultaneously, which can offer unique insights into how these approaches compare.

The key is that you have some experience with research processes - whether that's through coursework, lab work, thesis projects, internships, or professional work. Even if you're just starting to explore how AI might fit into your work, that's exactly the kind of authentic experience we want to understand.

Does that help clarify things? Are you ready to dive in, or do you have any other questions?

User: One last question: does undertaking engineering design work and groupwork-based engineering projects also fall under this category?

AI: Absolutely! Engineering design work and group-based engineering projects definitely fall under this category. Design processes - whether you're working on mechanical systems, software architecture, circuit design, or any other engineering domain - involve many of the same core research workflow elements we're interested in: problem identification, ideation, prototyping, testing, analysis, and iteration.

Group projects are particularly interesting because they add another layer of complexity around how AI tools get integrated into collaborative workflows and decision-making processes.

So whether you've been using AI for design optimization, code generation, literature reviews for your projects, data analysis, documentation, or any other aspect of your engineering work, that's exactly what we want to hear about.

Ready to get started?

User: Yes, let's get started

AI: Perfect! Let's dive in.

Walk me through a recent engineering project you've worked on - what did that process look like from initial idea to final output?

User: The most recent and complete project that I worked on was based in the field of Humanitaritan Enginnering, where we were made to:
1. form groups within the class
2. choose an area of focus - the choice was between 2 local council areas where there were several socio-economic, -environmental, etc.
3. choose a field - the choices were between energy, floods, community, etc.
4. choose a specific focus, each varying based on the field chosen

Our group chose Solar Energy, where our initial ideas were more aligned with social aspects of a solution regarding solar that could work within existing infrastructure. I was the one who proposed the more technical and "innovative" ideas (such as sun tracking solar panels, an energy network between houses to help share energy resources)

We were made to apply / follow the entirety of the Engineering Design Process regarding our project throughout the course. Our final assignment was a proper Design Proposal with all the aspects that we did (such as a literature review, ideation, screening, testing, next steps, etc.). Because our chosen solution was more on the techincal side, I was in charge of most of the literature review, getting down a comprehensive Ideation and Screening sections for our ideas.

AI: That sounds like a really comprehensive project that took you through the full engineering design cycle. I'm particularly interested in how you tackled that literature review and ideation work since those can be quite intensive parts of the process.

Where in that process, if anywhere, did you experiment with using AI tools?

User: I tried using Generative AI (GenAI) tools to get a general idea of what kinds of ideas we needed to come up with. However, I noticed that most - if not, all - of the ideas were very general and ones that the community themselves could come up with and implement, rather than ones based more in Humanitarian Engineering. 
So I devised a plan to have a more technical solution (the sun tracking panels) that interacts with the community (such as through internships, workshops, etc.) to fulfill the human-centred aspect of the solution, and coordinated with the team accordingly.

As for the Literature Review, I moreso used GenAI tools to figure out the relevant statistics, facts and figures that were needed, and then focused on searching the literature for them instead of the aspects of the solution itself. Most of the Literature Review was about telling a story to the reader, so I left the expanding of the content in the Proposal to another group member and focused on actually gathering the sources.

AI: That's really insightful - it sounds like you discovered some important limitations with the GenAI suggestions early on and then found more targeted ways to use it effectively.

For the literature review work specifically, tell me about how you decided whether to use AI versus your traditional approach for finding those statistics and figures.

User: My though process was such, GenAI tools lacked the comprehensiveness and scenario-specific detail required for the Proposal (without having the feed the entire assignment requirements to them) while making the workload manageable, whereas a traditional method gave a high workload (which would be heightened even more when considering my other classes at the time) but was more comprehensive in terms of pure content.

So I thought that, if I used GenAI to get an overview and a basic understanding of what the group's chosen solution entailed (calculations, statistics, related scientific concepts, etc.), it would make finding relevant sources easier.

AI: That's a really strategic approach - using AI as almost a preliminary research compass to orient yourself before diving into the traditional sources. It sounds like you found a middle ground that balanced efficiency with the depth you needed.

Thinking about the parts of your research where you didn't use AI - like the actual solution design or the story-building aspect of the literature review - what kept you from trying it there?

User: The limiting factor was that we needed concrete evidence of having done the design and understanding the community's plight for our chosen problem. While GenAI tools might be able to write up a scenario for [x] community that experiences [y] problem because of factors [a], [b], and [c], which can be assisted by a solution in field [z], they would not be able to make it as scenario-relevant as what we - the group actually working on the project - would be able to. Furthermore, having GenAI tools make a design is vastly different to making it ourselves on a platform such as SolidWorks or another CAD software.

AI: That makes a lot of sense - there's that authenticity and contextual understanding that you need to develop yourself, especially when you're working on a real community problem. And the hands-on design work clearly requires that direct engagement with the tools and process.

We're about halfway through our conversation now. Let me ask about the flip side: when you did use AI for those overview tasks and finding statistics, how did you verify or validate what it produced?

User: I had the GenAI tools use and cite the sources that they used, and followed the links that they provided to validate their claims and interpretations. I also searched for other reports and journals on the same topic to see if their conclusions and results supported or invalidated the GenAI's claims. 
When I could not find other relevant websites or sources (such as prices for installing and maintaining a conventional sun tracking solar panel system, of which there were multiple figures with none being of the required proportions or having the right mountability options), I used both conservative and generous guessing that were backed by what I could glean from such sites (such as service provider and installer sites).

AI: That's a thorough verification approach - cross-referencing sources and using your engineering judgment when data gaps appeared. It sounds like you developed a pretty systematic way to work with AI while maintaining the rigor your project required.

If you could wave a magic wand and have AI help with one aspect of your research or design work that it currently doesn't handle well, what would that be and why?

User: The idea generation process would be my first choice of where to perfectly implemet AI tools. The main reason that I chose this area is because of the sheer extent of mental blocks and lack of creativity that can plague engineers in this area; even our group was stuck here for almost a week because of the academic restrictions on GenAI tools. Also, as discussed previously, GenAI tools suggest very generic options that are targetted towards the general population rather than towards engineers, which doesn't help with the mental blocks.
Even having a GenAI tool that assists in coming up with partially valid ideas that can spark inspiration and innovation would be a great help in this area of the Design Process.

AI: That's a really compelling point about the mental blocks in ideation - it sounds like there's a gap between the generic suggestions AI currently provides and the kind of engineering-specific creative spark that could actually help break through those stuck moments.

Those are all my questions - your perspectives on finding that sweet spot between AI efficiency and authentic engineering rigor, and especially your insights about the ideation bottleneck, were particularly valuable. Is there anything else about AI in your engineering work that we haven't touched on that you think would be important for us to understand?

User: A very general point would be an over-reliance on the tool's training data that could compromise the user's intended purpose and the integrity of their usage of the response when using GenAI tools, especially in academia. This is the likely cause of the generic ideas that I mentioned earlier. This is most prevalent in fields such as Software Engineering, Computer Engineering, Electrical Engineering, Electronics Engineering, etc. where coding and programming take up a significant portion to a vast majority of the content.
The training data dictates the response to be perfectly industry standard / professional level, when most students using GenAI tools for programming classes and assignments have a barebones understanding of the language. The discrepency is easy to spot, even between students. Even students who search the web for more optimal ways to achieve the results of an assignment wouldn't come upon the kinds of methods that GenAI tools suggest.

AI: That's a really insightful observation about the training data mismatch - the gap between industry-standard, professional-level responses and where students actually are in their learning journey. It sounds like this creates almost a "too advanced to be believable" problem that can undermine both learning and academic integrity.

Thank you so much for sharing your experiences so openly. Your insights about using AI strategically for preliminary research while maintaining hands-on authenticity for the core design work, and especially your point about the training data creating responses that don't match student skill levels, really help us understand the nuances of how AI fits into real engineering education and practice.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
