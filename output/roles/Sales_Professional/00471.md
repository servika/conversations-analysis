# Dialog 00471

**Transcript ID:** work_0034

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good to you? Do you have any questions before we begin?

User: Sounds good - let's go!

AI: Great! Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI a few times a week, usually for coding questions and troubleshooting. I am not a coder, but I do use R and SQL for work. I recently started using SQL again after about six years away from it, so I frequently ask AI questions about code to use or to troubleshoot errors. I've been using R more continuously the last few years, but I still use AI to ask questions, get tips, or troubleshoot.

AI: That's really interesting that you're using AI to get back into SQL after that six-year gap. 

When you're working with these coding questions and troubleshooting, can you walk me through what that typically looks like? Do you usually copy and paste your code and ask for help, or are you asking more conceptual questions about how to approach a problem?

User: A bit of both. An example recently had to do with geocoding in R using the tidygeocoder package. I've used this package to geocode lists of addresses to make maps for years. I always use 'method = census' - probably the tutorial I looked at years ago used that. But asking AI some questions, the response involved method = osm, so I asked about that. When I ran it the code took forever, so I asked AI about that, and eventually I got a good process where now I run my addresses through the census method first because it is fast and then run the remainder through osm because census usually misses about 10% of the dataset. I would never have come up with that on my own.

AI: That's a fascinating example - you ended up with a much more sophisticated approach than what you started with. It sounds like through that back-and-forth conversation, you discovered a two-step process that's both faster and more comprehensive.

Tell me more about that interaction process. When you were working through that geocoding problem, how did the conversation with AI unfold? Were you asking follow-up questions based on what you were seeing in your results, or was there something else driving those additional questions?

User: Yes, I would run the code, then ask AI about it. Sometimes I ask for suggestions and then paste the AI code into R Studio, and sometimes I paste error messages I get in the code environment into AI for an explanation. That has really been a gamechanger. I think R error messages are particularly opaque!

AI: R error messages really can be cryptic! It sounds like you've developed a pretty interactive workflow - running code, seeing what happens, then bringing those results or error messages back to AI for the next step.

I'm curious about your preferences when working with AI on these coding tasks. Are there certain parts of your R or SQL work that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: I try to think about it like studying a foreign language -- just using a translator app isn't going to teach you anything, but having a tutor who can answer questions and customize for your needs is  really going to help. So that's how I try to approach coding - I try to figure it out myself and then use AI as my tutor. But before I would spend hours searching online and reading message boards to see if anyone had a problem like mine. Much faster now with AI.

AI: That's a really insightful analogy - using AI as a tutor rather than just a translator. It sounds like you're being intentional about maintaining that learning aspect rather than just getting quick answers.

When you do interact with AI during your coding work, could you describe your typical pattern? Are you more likely to have an ongoing conversation with AI throughout working on a problem, or do you tend to work independently and then bring specific questions when you get stuck?

User: The latter - I'm still getting used to the idea of having my on-call tutor always available. I think it will become more second nature as I use it more.

AI: That makes sense - it's probably a pretty big shift to go from those hours of searching message boards to having immediate access to help.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Are people talking about it, sharing approaches, or is it more something you've been exploring on your own?

User: More on my own. We're fully remote, and no one really has a job like mine. We have hardcore data people and then the sales/cs team and I'm kind of in the middle.

AI: Ah, so you're kind of in a unique position - bridging between the technical data folks and the business side, and figuring out AI use pretty independently.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: This happened at my last job. I work in politics/election engagement, so there are a lot of tasks I do once a year or once every two years before the election, which makes it hard to get really good at those tasks. Last September, I was geocoding the list of early voting locations in North Carolina so that when we made GOTV calls to voters we could recommend the closest site to their precinct. The problem is that you can only go to ev locations in your county, and sometimes the closest one is in another county, so the standard geospatial intersects operations don't always work. I had found a solution for this in 2022 and was reusing that code, but it just wasn't working. I spent hours trying to get it right to no avail. Finally I broke down and asked AI -- like a lot of people I hadn't used it before out of a combination of fear and pride. It wrote a for loop for me (I am terrible at for loops) that solved the problem and I was done so fast. It was very satisfying to solve the problem and also a 'road to Damascus' moment where I realized I needed to be more open to AI.

AI: What a perfect example of those cyclical tasks in politics - where by the time you need to do something again, you've forgotten the nuances from two years ago! And that "road to Damascus" moment is really striking.

It sounds like that breakthrough overcame both technical and emotional barriers for you. How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, especially given that tutor approach you mentioned earlier?

User: Yes, I'm very conscious of this issue. I have talked with other people (at work and socially) about the idea of AI replacing human coders, and the approach that I have settled on is the idea of having a 'reading knowledge' of coding languages. My first career was classical languages, so that is very familiar to me. For R and SQL I want to really learn those, but for Python, which I have tried to learn and just never got it, I am excited to think that I could develop a reading knowledge of Python with AI writing code and I understand it without being able to generate it.

AI: That's such a thoughtful framework - the reading knowledge concept from classical languages is a brilliant way to think about it. It sounds like you're making strategic choices about which languages to truly master versus which ones to understand at a comprehension level.

Looking ahead, how do you envision your relationship with AI at work evolving? Especially as you get more comfortable with having that "on-call tutor" always available?

User: I will definitely keep using AI for coding help, and I want to build a 'what am I missing?' question into my current approach. Solving error messages is important, but I should also use it to grow and think about new ways of doing things. Having that thought partner is probably the best benefit. I'm also trying to be more strategic about AI as a research assistant. This is an area where I like doing research and don't feel like I need help, so I have been hesitant to replace something I enjoy with something I would have to fact-check anyway. But that's the next step, probably.

AI: That "what am I missing?" question is such a smart evolution - moving beyond just fixing problems to discovering new possibilities. And I can really understand that hesitation around research - when it's something you genuinely enjoy and you'd still need to verify everything anyway.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your AI experience, especially that classical languages analogy for developing reading knowledge and your intentional approach to balancing learning with efficiency.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: This has been interesting. When I think about people using AI at work, I think it's important to keep in mind how scary this idea is to people in white collar work who felt safe from automation. The most push-back I've received to my idea of a 'reading knowledge' approach has been from professional coders, and it was hard not to perceive a defensiveness there based on self-interest. I also  think that a lot of the hand-wringing about environmental costs from progressives comes from people sublimating their generic fears about the unknown and becoming obsolete into general negativity. That's why I think you can't rebut this arguments with facts and figures about greater energy efficiency; it's not really about that. When photography was invented, some artists leapt at the opportunity for new ways to make art, but some were just threatened. The result, however, if you believe Walter Benjamin, was a literal change the way we perceive the world around us. Perhaps we have gone from The Work of Art in the Age of Mechanical Reproduction to The Art of Work in the Age of Mechanical Creation.

AI: That's a really profound observation - the idea that the environmental concerns might be sublimating deeper anxieties about professional obsolescence. And that connection to Benjamin's work is fascinating - "The Art of Work in the Age of Mechanical Creation" - what a compelling way to frame this moment we're in.

Your point about the defensiveness from professional coders when you mention the reading knowledge approach is particularly striking. It suggests these conversations aren't just about technical capabilities but about professional identity and security.

Thank you so much for your time and for sharing your experiences so openly. Your insights - from that practical tutor framework to these broader reflections on how people are processing this technological shift - will be incredibly helpful for our research on human-AI interaction in professional contexts. This has been a really thoughtful conversation.
