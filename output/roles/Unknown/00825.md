# Dialog 00825

**Transcript ID:** work_0576

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good to you? Do you have any questions before we begin?

User: all good

AI: Great! Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I teach math, so i use it a lot to create examples. It saves time, when it's correct, lol. Sometimes if I ask for a bunch of examples at once, they will all be too similar or too easy or have mistakes or whatever, but if you can be specific enough and spend some time crafting good prompts, you can get some good help.

AI: That's really interesting - it sounds like there's definitely a learning curve to getting useful results. When you mention spending time crafting good prompts, can you walk me through what that process looks like for you? How do you go from getting those too-similar or mistake-filled examples to getting the good ones?

User: For example, if i say I needed 5 questions on derivatives, I might get a 5 different rules to practice, but they might be all polynomial. Or if I asked for a test on the material, I still have to go through every example with a fine tooth comb to be sure that it is correct, is at the appropriate difficulty level, will take a reasonable amount of time, etc. But if I said: I need a test with 10 multiple choice (10 points) that test only objective-style questions and a constructed response section with no more than 10 questions, valued at no more than 5 points each, covering a broad range of derivative topics from limits through to related rates and optimization. Include trigonometric, logarithmic and exponential functions, then that might give me something much better in return.

AI: That's a perfect example of how specificity makes all the difference. It sounds like you've developed quite a systematic approach to prompting. 

When you get that better result from the more detailed prompt, do you still find yourself having to go through it with that "fine tooth comb" you mentioned, or does the quality improve enough that your review process changes?

User: Always always always. Some problems might need an unexpected theorem or something that students don't know how to deal with, for example, often related rates require formulas that should be provided.

AI: So even with your most carefully crafted prompts, you're still doing that thorough quality check every time. That sounds like a significant part of your workflow.

Tell me more about what you're looking for during that review process. What are the most common issues you catch when you're going through the AI-generated problems?

User: Well, it's the time spent making up the style of questions too. Like I might need to make sure I cover all the learning outcomes of a course on a final exam. That requires very careful attention and I don't think I'd trust any model (yet) to be able to do that. At least not without looking at examples of exams that were constructed properly with links to learning outcomes.

AI: That's a really important distinction - it sounds like there's this deeper layer of instructional design that you need to maintain control over. The learning outcomes mapping and ensuring comprehensive coverage seems like something that requires your professional judgment.

When you think about the tasks you use AI for versus the ones you handle yourself, what makes you comfortable delegating the example creation but not that broader exam construction and learning outcomes alignment?

User: I can let AI give me questions for multiple choice style questions, but often the distractor answers supplied by AI aren't related to common mistakes made by students (and ai!) make. For example, switching a negative sign might lead to one answer, flipping a fraction incorrectly might lead to another.

AI: That makes so much sense - you're looking for distractors that actually reflect the real mistakes your students make, not just mathematically plausible wrong answers.

It sounds like there's this deep pedagogical knowledge you have about common student errors that the AI doesn't possess. How do you typically handle that gap? Do you end up rewriting the distractors yourself, or have you found other ways to work around it?

User: I take the questions and look through to see what I can use first. I will usually be able to use some of the constructed response as-is since these types of problems are standard (ie, optimization and related rates in derivatives). But I'll always have to make sure there is a good spread of question types that cover all learning objectives, that the difficulty level is moderate with some more challenging questions, and that there is nothing repetitive about the questions. For example, I don't need students to show me more than once that they know the derivative of sinx is cosx.

AI: That quality control process you describe sounds quite thorough. It seems like you're essentially curating and editing the AI's output rather than just using it directly.

I'm curious - when you're working through this process of reviewing, selecting, and modifying the AI-generated content, how would you describe your interaction pattern? Are you going back and forth with the AI to refine things, or do you tend to take what it gives you and then do your own editing separately?

User: I cannot deal with AI formatting, so I'm going back and forth to Word - grabbing a question from ai, usually typing it myself in Word because math formatting never translates, checking the question to make sure it's appropriate first. Then having to assign the correct values to questions is important as well. If we spent 10% of class time talking about one topic, it needs to be worth 10% on the exam. Approximately. Ai can help with that a little

AI: It sounds like there's a lot of manual work involved - especially with that formatting issue and having to retype the math. That must be time-consuming.

When you think about the whole process from start to finish - the prompting, reviewing, reformatting, checking appropriateness, assigning values - how do you feel about the time investment? Does it still end up saving you time overall compared to creating everything from scratch?

User: I still think I make up better questions faster with AI. Imagine me doing all the work the AI is doing AND all the vetting that I have to do too

AI: That puts it in perspective - even with all the quality control and reformatting, you're still coming out ahead. It's handling that initial creative work while you focus on the pedagogical refinement.

Can you share a time when using AI for this work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I was happily shocked the first time I went looking for integration problems and got a decent list from AI, actually. The only problem was the formatting, maybe a small error and repitition. Now I'm much more discerning and expect more out of the tools I pay for. So when there's some repetition or some nuance that didn't translate somehow in the prompt, it can be frustrating. Especially the models that are taking 2 or 3 minutes now to think before responding to questions and I don't think the new responses are all that much better than they were a few months ago when it wouldn't take so long to get the responses. does that make sense?

AI: That makes complete sense - your expectations have evolved as you've gotten more experienced with the tools, and now slower response times feel especially frustrating when the quality improvement doesn't seem to match that extra wait time.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, especially given how much it's helping with question creation?

User: Of course, I'm just a math teacher, so essentially my skills in the future will have to become more technical to teach online or to teach actual ai. I suppose we will never get rid of the K-12 school system so I could always go back there but I don't want to do that! Once you've taught adults at the college level, you don't want to go back to what feels like prison.

AI: That's a really candid perspective! It sounds like you're thinking strategically about how your role might evolve - moving toward more technical skills or potentially teaching about AI itself.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself using it differently as the tools improve, or as you get even more experienced with them?

User: I'm sure I'll have to keep using them to keep up. Students get bored faster and faster now, I'll probably start using AI to show simulations of adding the area under a curve, for example.

AI: That's a fascinating shift - from using AI primarily for content creation to potentially using it for dynamic demonstrations and engagement. The idea of AI-generated simulations to help students visualize concepts like area under a curve sounds really compelling.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how your expectations have evolved and become more discerning as you've gained experience with these tools.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I wish there was a way to make students want to learn the material is all. Motivating them when AI is so readily available is difficult. Lots of students don't bother to do their own work anymore, which is really depressing for me because I love my job and I love math.

AI: That sounds like a really challenging and emotionally difficult aspect of this whole shift. It's one thing to adapt your own workflow with AI, but it's quite another when it's affecting your students' engagement with learning itself.

Thank you so much for sharing that - and for being so open throughout our conversation. Your insights about the practical realities of using AI in education, from the detailed prompting strategies to the broader challenges with student motivation, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate the time you took to walk me through your experiences today.

User: Thanks for listening!

AI: You're very welcome! Thank you again for sharing your experiences so thoughtfully. Take care!
