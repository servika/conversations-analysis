# Dialog 00950

**Transcript ID:** work_0762

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good to you? Do you have any questions before we begin?

User: Sounds fine. Let's go!

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I am a software engineer. I generally use AI to look up and summarize documentation, and to automate repetitive tasks (ie: generate boilerplate). I also use AI to generate unit and end-to-end tests.

AI: That's helpful context. When you mention using AI for documentation and generating boilerplate code, can you walk me through what that actually looks like in practice? Like, what's happening when you turn to AI for one of these tasks?

User: So, it can depend. Sometimes I just ask for general information, ie: 'what types does the R7RS spec say zero? should accept"? Sometimes I ask for something very specific: "show me the call signature for 'strtok'".  Sometimes I ask for an overview of a technology I am unfamiliar with: "Write me a short 'getting started' guide for the criterion testing framework".

In terms of generating boilerplate, I will often have data in one format, and want it delivered back in another format so I can copy & paste it. ie:

I have a list of symbols. I need them formatted like so: 

foo
bar
baz

type_t* register_builtin(env*, "foo", builtin_foo);

etc...

AI: That gives me a clear picture of the variety of ways you're using AI. I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: Honestly, I am less likely to use AI the more personally invested I am in the task. Tasks that I truly enjoy I am likely to do myself. Tasks that are tedious tend to get delegated.

AI: That's really interesting - the personal investment piece. Can you tell me more about what makes a task something you truly enjoy versus something that feels tedious to you?

User: Well, that's a difficult question to answer, as it touches upon completely subjective personal preferences. Building a 'passion project' is something I enjoy. Writing code for a project that I have no personal investment or interest in can sometimes become tedious. It is often not clear from the start whether I will enjoy something. Sometimes I am tasked with implementing something in a domain I don't have a lot of experience in. Sometimes I will find the topic fascinating, and grow to enjoy it. Sometimes I will write code for something that I do find an interesting topic, but find that the actual work of implementation is tedious.

At the end of the day: if it is a fascinating topic that 'gets my neurons firing' so to speak, I will enjoy it. If the task is something I have already done many times, I am less likely to enjoy it. 

I always like to be learning new things.

AI: That makes a lot of sense - the learning and novelty aspect being key to your enjoyment. When you do use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: Well, I don't really use the AI iteratively. I ask for a specific thing, then later ask for another specific thing. Sometimes I will have to follow up for clarification, or if the response was not quite what I needed. I very rarely start with an abstract idea, and chat with the AI to whittle it down to something specific. By the time I open the AI chat, I already have a pretty specific notion of what I need.

AI: That's a clear approach - coming to AI with specific, well-defined needs rather than exploratory conversations. How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: I am a freelancer, and work from home. So this question does not really apply to me.

AI: Got it - that context is important. Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I think it's pretty rare, but every once in a while I will ask something of the AI, and it may mention something off-handedly in the response, maybe mention an algorithm, or technique I was not aware of. This is very satisfying. As I say, I love learning, and when I learn about a new technique to solve the problem I am working on, that is very rewarding.

Conversely, I have been very frustrated the few times I have asked theAI to write specific code for me. The code returned is generally correct, but much too generalized, and requires more effort to integrate it than to write the code myself. This gets more and more difficult the larger a codebase gets. I suppose I could spend a great deal of time describing the interface specification in detail, but at that point, I'd rather just write it myself.

AI: That's a fascinating contrast - the unexpected learning moments being so satisfying versus the friction when AI code doesn't fit your specific context. How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Well, it does concern me a bit. As a freelancer, I am my own boss, and accountable only to myself and the client. If the AI improves to the level where it can just wholesale output robust, working code, then I guess I'm out of work. I'm not likely to be promoted to management :-)

AI: That's a very real concern for someone in your position. Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it changing from how you use it now?

User: I am fairly pragmatic. I will occasionally just have a play with the AI, and test it's capabilities. If it improves in an area where before it fell short, I will start using it in that new area.

AI: That pragmatic approach makes sense - testing and adapting as capabilities improve. 

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how personal investment drives whether you delegate tasks to AI, and that contrast between the satisfaction of unexpected learning versus the frustration when AI code doesn't fit your specific context.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: So: I have had one experience with a particular model (that I will not name, to be diplomatic). This model always tries to 'anticipate' what I might want next, and makes offers: "would you like me to do A, B, and C next?". I guess this is useful to some, but it never seems to get it correct, so these suggestions become noise. I even tried disabling this behavior using a system prompt, but it did not seem to take. As a result, I no longer use that model.

I do not like the AI suggesting what I do next. As I said, I have a pretty clear idea what I want by the time I even open the chat. I suppose this is personal preference though.

AI: That's a really valuable insight - the unsolicited suggestions creating noise rather than value when you already come with clear, specific needs. It sounds like respecting your autonomy and not second-guessing your intentions is important to your workflow.

Thank you again for your time and for sharing your experiences so openly. Your insights about the balance between personal investment, learning opportunities, and practical efficiency will be incredibly helpful for our research on human-AI interaction in professional contexts.
