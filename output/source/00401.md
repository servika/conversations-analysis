# Dialog 00401

**Transcript ID:** work_0889

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Yep sounds good. No questions right now from my side.

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I work as a data analyst so my main use cases are twofold. The first one is usually written communication based. This could be helping to phrase an email or how to best word a title or a slide in a presentation.

The second is usually a more technical use case where I use it to help write code or formulae for whatever tool I'm using. Most commonly recently it has been DAX formulas in power BI but it can be anything that involves technical problem solving.

AI: That's really helpful context. When you're working on those technical problem-solving tasks like DAX formulas, can you walk me through how that typically unfolds? Are you describing the problem to AI and having it generate a complete solution, or is it more of a back-and-forth collaboration where you're building the formula together?

User: I usually know exactly what I want to achieve in mind and because I have some experience, I usually know the jargon to get there, I just don't know the exact syntax so I describe exactly what I want to achieve and how before I enter.

Sometimes though, I do look to the AI for the solution itself and just tell it what I want to achieve. For example, recently I had two tables appearing in my dashboard but a filter that only had a field from one table and I wanted to filter the entire other table out when this filter was selected. I didn't know the logic to do that so simply asked AI and got the full explanation and DAX formula.

AI: That's a great example - it sounds like you have two different modes of interaction depending on your knowledge level. In that second scenario where you needed to filter out the entire table, did the AI's solution work right away, or did you need to go back and forth to refine it?

User: In that particular case, the solution was correct right away. I had to add more back and forth to fully understand how to implement it though. So in this case it was a filter I had to apply. I thought I would be able to apply it at page level but it turned out I had to apply it to each and every visual individually so was wondering why I couldn't apply it at first.

AI: That's interesting - so the AI gave you the right technical solution, but there was this implementation gap about where to actually apply the filter. When you went back to ask for clarification on the implementation, how did you phrase that follow-up? Did you describe what wasn't working, or did you approach it differently?

User: Yh I think I asked why couldn't I apply it at page level. I don't actually remember the reasoning behind it and then it told me that I could only apply it at the visual level so I went ahead and did that. I think before that, I asked for more clarification on how it was actually working as well so I understood the formula itself a bit better so I wasn't blindly applying this filter which may break something else elsewhere.

AI: That makes a lot of sense - wanting to understand the logic behind it rather than just applying it blindly. I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: I think certain creative tasks like jokes, good one liners for slides. Like more human, either sarcastic things to say or to name something. I find AI can be very cheesy and even when I tell it that, I'm still usually not happy with what it gives me so I prefer to not take the help there and work with it myself. 

I think it's more in that case what it gives me doesn't sound like something I would say so it doesn't feel genuine so I prefer to come up with it myself

AI: That's a really insightful distinction - the authenticity of voice and how it represents you. It sounds like when it comes to your personal expression or humor, you want it to genuinely reflect who you are rather than sound like generic AI output.

When you do use AI for those written communications you mentioned earlier - like emails or presentation titles - how do you handle that same concern about authenticity? Do you find yourself heavily editing what it gives you, or does it work differently in those contexts?

User: What I tend to do there. Usually I know what I want to say so I write it in my words first and then feed it to the AI and then let it come up with a better version. Usually there's still some cheesy stuff mixed in but also a more comprehensive way of wording things than my original so I usually end up with something inbetween where it's mostly my original with the more comprehensive bits from the AI. I guess that's what enables me to feel comfortable that it still sounds authentic to me but in that moment I just wasn't able to fully come up with it myself but I still know what sounds good.

AI: That's a really thoughtful approach - using your original as the foundation and then selectively incorporating the improvements. It sounds like you maintain control over your voice while still benefiting from AI's ability to be more comprehensive.

When you use AI for work, either for the technical tasks or the communication ones, how have your colleagues or your workplace culture influenced the way you approach it? Do people openly discuss using AI tools, or is it more of an individual choice?

User: I feel like at work AI is very much a buzzword and because my entire company isn't technical, it's very much a word tossed around with very little understanding or usage. So the answer is, they tell us to use it and we have our own internal LLM which isn't that great but it feels like not many people have embraced it so it ends up being more down to individual choice in the end.

I do feel like when you're in a more technical role, it's just logical individually to use it. It saves a lot of time and it's even a great place to come to ask questions to learn more. Like my example before, I wouldn't have found my exact solution on google but now I can get my exact solution and an exact description of why it's working for my nuanced situation. So it's a no brainer really for me individually to use AI.

AI: That disconnect you're describing is really interesting - the company pushing it as a buzzword while you're finding genuine practical value in your day-to-day work. It sounds like your technical background makes the benefits more obvious to you.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I feel like if the model misunderstands something you've said once, it's difficult to get it to revert back to what you want. Recently I was getting frustrated where I asled the model to rewrite or structure a slide and then I wanted to move part of it before another part but what it did was merge them. I think it was becasue the first bit was bullet points and then the points below were the answers to the points above so me asking it to move it above made it sound like I wanted to points below (the answers) to go under the points above (the original bullet points).

I was getting frustrated because I was telling teh AI over and over to just move the content, not try and merge them and have bullet points inside bullet points.

AI: That sounds really frustrating - especially when you know exactly what you want but the AI keeps misinterpreting your instructions and doubling down on the wrong approach. When you hit situations like that where it's not understanding, do you have strategies for breaking out of that loop, or do you typically just start over with a fresh conversation?

User: I usually start out a new conversation if I'm honest or just do the work without AI. However, I am aware that's pretty silly and I should have ways to workaround those situations.

AI: That doesn't sound silly at all - sometimes starting fresh or just doing it yourself is the most efficient path forward. You mentioned being aware you should have workarounds though. 

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, especially given how much time it's saving you with technical tasks?

User: As in maintaining my AI skills or maintaining skills in areas that will eventually be taken over by AI?

AI: I meant maintaining skills in areas that might eventually be taken over by AI - like those technical problem-solving abilities or formula writing that you're already getting so much help with.

User: I think maintaining those skills are still super important. We don't want to reach a point where the AI does things and we can't explain them or fix them when they break. I also think that the use of AI is a lot easier and you get way more out of it when you understand and have the skills. Don't get me wrong, someone who has no knowledge could still achieve what you could if you have knowledge but even with AI, it would take so much longer i think. Even going forwards and let's just say the AI does fully take something over and there's no human element, we would still want experts to understand what the AI is doing so I still think it's important to maintain the skills.

AI: That makes a lot of sense - the idea that your existing knowledge actually makes you more effective at working with AI, not less relevant. It sounds like you see your expertise as enhancing the AI collaboration rather than being replaced by it.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think the way you're using it now will change, or do you expect it to deepen in the same directions?

User: I think the way I use it now won't change but I think I'll just be adding more use cases as AI gets better. For example, I think AI is pretty bad at interpreting data and analysing it and spitting goood stuff out that isn't hallucinated/wrong. So once that's figured out. i will be using for that use case for sure. I'm also sure there will be loads of other use cases that I'll just think of that I'm currently not using it for.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how your technical knowledge actually makes you more effective at collaborating with AI, and that nuanced approach you described for maintaining authenticity in your written communications.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No nothing I can think of right now. Very insightful questions, thanks!

AI: Thank you so much for your time and for sharing your experiences so openly. Your insights about the balance between leveraging AI for efficiency while maintaining both your authentic voice and your technical expertise will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!

User: Cheers!

AI: You're very welcome! Take care, and thanks again for participating in our research. Have a great rest of your day!
