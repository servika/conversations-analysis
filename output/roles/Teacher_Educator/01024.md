# Dialog 01024

**Transcript ID:** work_0870

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: No questions, Claude. Go ahead.

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I don't necessarily use AI every day, I teach at a college. I really enjoy using AI to brainstorm ideas about classroom discussion questions and activities. I feel like it helps me to make more engaging class sessions. These kinds of brainstorming sessions are what I tend to use it for the most. I also have been trying to find activities that students can use AI for such as in class research. Less often I use it for organizational tasks. Because the semester just started,  I've recently  attempted to use Ai to try and help refresh some of my older classroom slide shows. I've also used it to help with my syllabi and exam layouts. Soon I will be using it to help organize my rubrics in a clearer and easier to read manner. So while I don't use every day, the things I do use it for are important.

AI: That's really interesting - it sounds like AI has become a valuable planning and preparation tool for you, even if it's not part of your daily routine. 

Tell me more about those brainstorming sessions for discussion questions and activities. What does that process typically look like for you?

User: I've been teaching for some time, and generally I will read an article or have an idea about something that I would like to use as a discussion question. I may ask the AI something like, "Help me think of some discussion questions about Rudolph Otto's idea of the numinous that make it more relatable to students? Can we find something that asks them how one might communicate such experiences, like music or art?" Or I may ask it to help me reorganize a lecture to more closely fit a text I am using. I may upload my lecture notes and ask for input. Sometimes I don't agree and then there is more back and forth exchange.

AI: That back and forth exchange you mentioned is fascinating. Can you walk me through what happens when you don't agree with AI's suggestions? What does that conversation look like?

User: So for example if I am asking for a review of a lecture to make sure I am being clear. I may add a joke to it, which I tend to do. The AI might originally tell me to omit the joke because it changes the tone. I might say that I do not agree. This usually happens when I need to lecture about something too heavy on theory. This tends to bore student a little and a joke may snap them to attention a bit. Or a pop cultural reference. For the AI this change of tone is sometimes seebn as jarring. I will generally explain. Other times AI doesn't necessarily like the order that I am explaining something in and I have to justify myself. Sometimes it still does not agree, sometimes I end up agreeing with the points it makes. Generally not on the bad jokes, though.

AI: I love that you're standing your ground on the jokes! It sounds like you have a pretty clear sense of your teaching style and what works for your students.

When you're in those moments where the AI is pushing back on something - like suggesting you remove a joke or change your order - how does that feel? What's going through your mind during those exchanges?

User: When it does this, I know that it does not understand that sometimes when things are too heavy or depressing students (humans) need a way to release. A little non-offensive (usually deprecating humor is safe) joke or pun, a small story, these things can keep an audience engaged and also help them connect. They can offer memory points. AI doesn't necessarily understand speaking engagement versus reading engagement.  Classroom lectures are very different than research papers and AI does not always understand.

AI: That's a really insightful distinction - the difference between speaking engagement and reading engagement. It sounds like you've identified a specific gap in how AI understands your context as an educator.

Are there other tasks where you prefer to handle things yourself, even though AI could potentially help? What makes those different for you?

User: My lecture content. Especially in subjects like Native American Religions and culture. AI asks if I would like research suggestions or information, and quite honestly the information LLMs have on this topic is so broad as to be useless in many instances. I can tell when students use it for papers right away because the information generally does not highlight the diversity of Indigenous peoples but rather tends to lump Native peoples as one monolith. The other issue is that I have seen it suggest scholars and authors that are highly problematic, such as Andrea Smith who claimed Cherokee Nation status when she was not actually Cherokee.

AI: That's a really important example - it sounds like there are areas where your expertise and judgment are absolutely irreplaceable, especially around nuanced cultural topics and scholarly credibility.

When you do use AI for work tasks, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I tend to be more collaborative with the discussion questions and brainstorming, of course, but tasks like formatting I would prefer it handle independently.

AI: That makes sense - different tasks seem to call for different approaches. 

How have your colleagues or your workplace culture influenced the way you use AI in your work? Have you noticed any particular attitudes or practices around AI at your college?

User: People in academia are still pretty scared of AI. Some ignore it completely, others have gone back to paper tests and written in-class assignments. I've always done paper tests so not an issue for me. I am not sure if other Professors are using AI because they really aren't talking about it. When I told my students that they could use it to summarize an article in class, they seemed surprised, so my guess is that most are not incorporating it openly. It's an issue because of the tendency for students to submit AI written work.

AI: It sounds like there's a real tension there - this fear of AI misuse creating an environment where even legitimate uses aren't being discussed openly.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Yes, as I mentioned the new semester just started. I love teaching, but the syllabi, excel sheets, exam organization are my least favorite parts. While the AI used was unable to create a syllabus that I liked, it was able to look over what I created and find holes. It gave me suggestions on how to organize information for clarity. It noticed that I had the wrong date in one spot. It found a typo. This was great and it saved my time in editing, but also in student questions.

AI: That sounds like a perfect example of AI complementing your strengths - you handled the creative and substantive work of the syllabus, and AI caught the details that could have caused problems later.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: It is something I consider. I don't think AI is going to be an expert on Indigenous Religions any time soon. But I do worry that people may think it is. The information LLMs put out on that topic isn't great. Indigenous people have been misrepresented since the 15th century. I'd hate for AI to continue that.

AI: That's a powerful point about the responsibility that comes with expertise, especially in areas where there's already a history of misrepresentation.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I think that I'd like to be able to use AI in the classroom more effectively. If this is where the future is going, I would like my students to have a deeper understanding of how to use it ethically and well. I think I will use it for syllabi and other clerical type work.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on understanding where AI's limitations are - especially around cultural nuance and the difference between speaking and reading engagement. Your approach of standing firm on your pedagogical choices while still being open to collaboration seems really thoughtful.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, I think we are all good. Thank you.

AI: Thank you so much for your time and for sharing your experiences so openly. Your insights about the nuanced ways you navigate AI collaboration - from defending your teaching style to recognizing where your expertise is irreplaceable - will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!
