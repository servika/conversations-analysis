# Dialog 00607

**Transcript ID:** work_0238

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Yes that sounds good. I don't have any questions

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: As a pharmacy professional. I am part of a circle of care of healthcare practitioners in provided patient-centered care. My role is a medication specialist -- A main responsibility is to review a patient's medication list and ensure the prescribed medications are indicated, effective, safe, at the right dose, and convenient for the patient.  While I am a fairly recent graduate and am fairly up to date to recent guidelines, I review some obscure not commonly used medications for unexpected indications at times. In a busy workplace environment, it may be unfeasible to verify with the prescriber in a timely fashion. Clinical guidelines help but sometimes those can provided contradictory information. To determine the best response available, I use LLM such as ChatGPT to validate my decisions or seek another opinion on the topic. One example is the choice of simvastatin 40mg for new post-stroke patient. Atorvastatin 40-80mg and rosuvastatin 20mg-40mg at high intensity statins while simvastatin 20-40mg is a medium intensity statin.

AI: That's a fascinating use case - using AI as essentially a second opinion in clinical decision-making. 

Tell me more about that simvastatin example. When you encountered that situation, what was your thought process for turning to an LLM, and how did that interaction actually unfold?

User: The patient was already present in the pharmacy and I knew from experience getting hold of the prescriber will take at least a day. Therefore, I needed to make a quick decision. My initial thought process was to check the patient's allergies and previous statin use, unfortunately I don't have that information since this patient is from out-of-town with no prior engagement with the pharmacy, and this prescription was from a hospital discharge from the previous day. I knew for a fact regarding intensities of statins so I did not feel I needed to check my references. I vaguely recall the choice of statins may be dependent on physician choice. That was when I wanted a second opinion and asked an LLM  about the choice of statins to verify my decision. The LLM verified my recall and I ended up going with the simvastatin prescribed with a note for the patient to follow up with their primary healthcare practitioner within 2-4 weeks.

AI: That's really insightful - you used the LLM to confirm your existing clinical knowledge when you couldn't access the usual verification channels. 

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: As part of my responsibilities as a healthcare practitioners, I need to uphold patient confidentiality. Ultimately, I sometimes use LLM/AI to double check my clinical assessment but am always careful not to release patient identifiers. I am not sure if this answers your question?

AI: That definitely helps me understand your approach to patient confidentiality, which is clearly a crucial consideration for you.

Let me ask it a bit differently - within the realm of tasks where you can use AI while maintaining confidentiality, are there certain types of clinical decisions or medication-related work that you prefer to handle entirely on your own versus seeking that AI second opinion?

User: I generally will do everything independently but sometimes when there are conflicting information from different sources, I will use AI to verify my thought process. Since LLM are relatively new and my regulatory body is notoriously slow in updating policies, I am not aware of any policies to use AI routinely. However, as both of us know, that is coming!

AI: That makes sense - you're being appropriately cautious while navigating this emerging area without clear regulatory guidance yet.

When you do use AI for that verification, could you describe your typical interaction pattern? Are you more likely to have a back-and-forth conversation with it to work through the conflicting information, or do you tend to ask it a specific question and use that response to make your final decision?

User: For work, I tend to ask a specific question, and use that response as one of the considerations used in my final decision, however I don't just blindly follow the AI's response in making those decisions. For pleasure, yes I love back-and-forth conversations with LLM since they provide insights!

AI: That's a really clear distinction between your professional and personal use patterns. It sounds like you maintain a healthy skepticism in the clinical setting.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Are others in your pharmacy or healthcare network having similar conversations about AI?

User: My workplace has a rather laidback culture to cope with the busy demands, but I won't say they have a substantial influence on AI use at work. In fact, I feel I am one of the AI adopters and I get to influence them! I know some of the doctors I work with use AI generated content to explain a use of a medication (which I frown upon)

AI: That's interesting that you're more of an AI pioneer in your workplace. 

Tell me more about why you frown upon doctors using AI-generated content to explain medications to patients. What concerns you about that particular use case?

User: I know they are busy but using AI generated content instead of producing their own content shows they are less focused in putting in the time to provide patient care. Unfortunately, it is obvious to identify AI generated content right now -- hence there are AI trainers like me!

AI: I can hear that concern about maintaining the personal touch and clinical expertise in patient interactions. The fact that AI-generated content is still obviously identifiable seems to be part of what bothers you about that use.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Like I indicated, I use AI as a triple check when there is conflicting facts regarding a patient. I feel satisfied when AI produces an answer that matches one of my references/thought process. I get frustrated when AI produces a nonsensical answer (for obvious reasons) or when it gives an unexpected answer (creates more work in an already busy work environment)

AI: That frustration with unexpected answers creating more work really makes sense in your fast-paced environment - you're looking for confirmation, not additional complexity to sort through.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Professional development for work and keeping up to date. When that fails, I can always use my expertise in training the next generation of AI/LLM

AI: That's a really forward-thinking perspective - seeing yourself as potentially contributing to AI training based on your clinical expertise.

Looking ahead, how do you envision your relationship with AI at work evolving? Where do you see this heading for pharmacy practice in general?

User: I see AI getting more integrated in pharmacy like in other industries. Documentation and paperwork is a dull job but essential as per my regulatory bodies. AI models can definitely take over that! Also for patient counselling, I see that AI models can be used for common routine consults, such as amoxicillin for a dental abscess and furosemide for fluid retention. When the prescriptions are less common or if the patient has additional questions, then the AI model can defer to a pharmacist

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI as a "triple check" for conflicting clinical information, and your vision for how AI could handle routine documentation while pharmacists focus on more complex cases.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Yes I have a question about the AI/LLM's ability to remember aspects of conversation. Does the collected data gets shared with a third party of does the data get trashed after some time? I am asking to verify the extent of data I can share with using LLM at work.

AI: That's an excellent and very relevant question given your patient confidentiality responsibilities. I appreciate you thinking carefully about data handling.

The specifics around data retention, sharing, and privacy policies can vary between different AI providers and platforms. For Anthropic specifically, I'd recommend checking our privacy policy and terms of service at https://support.anthropic.com for the most current and detailed information about data handling practices.

Given your role as a healthcare professional with strict confidentiality requirements, it would be worth reviewing the privacy policies of whichever AI tools you're considering using professionally, and potentially consulting with your regulatory body or legal counsel about best practices for maintaining compliance while using these tools.

Is this data privacy question something that's been on your mind as you've been navigating AI use in your practice?

User: All the time since I heard of our professionals getting in  trouble for breach of privacy

AI: That's completely understandable - hearing about colleagues facing consequences for privacy breaches would definitely make anyone in healthcare more cautious about new technologies.

It sounds like you're being appropriately careful by anonymizing information and using AI mainly for clinical knowledge verification rather than patient-specific details. That awareness of the risks while still finding ways to leverage the benefits seems like a thoughtful approach.

Thank you again for your time and for sharing your experiences so openly. Your insights about using AI as a clinical verification tool while navigating the regulatory and privacy landscape will be incredibly helpful for our research on human-AI interaction in professional contexts. Your perspective as both an early adopter and someone who's thinking critically about the boundaries and appropriate uses is particularly valuable.

User: Thank you for the conversation. Have a good evening

AI: Thank you so much - I really enjoyed our conversation as well. Your insights about balancing AI adoption with professional responsibilities in healthcare were fascinating. Have a wonderful evening!
