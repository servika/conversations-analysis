# Dialog 00837

**Transcript ID:** work_0593

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: I'm ready.

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I don't really use AI on a regular or daily basis, but rather I typically used AI to quickly learn new skills or come up with new ideas related to either my teaching (generate ideas for assignments or new assessment questions) or my scholarship (help me use R).  I don't use it for routine things.

AI: That's really interesting that you use it more for skill-building and creative brainstorming rather than routine tasks. 

When you say you use AI to help you learn new skills, like with R - could you walk me through what that experience typically looks like? How do you approach that interaction?

User: Well, I try to only use it in ways I can verify on my own, so I don't fall prey to hallucinations.  For example, I'm not super-proficient with coding languages, but I do know a fair bit of statistics.  Certainly I know enough to look things up and understand what I'm reading.  So when I had a large dataset that required a more sophisticated statistical analysis than I can do in Excel, I asked an AI model to help me give the right commands in R studio to do the analysis.  I treated the model as a research collaborator, going back and forth.  I challenged it when I thought it was wrong or unclear, or when a command didn't work.  I verified what it told me either through my own knowledge or from external sources.  It was productive and sped up the process compared to what I could have done on my own.

AI: That collaborative back-and-forth approach sounds really thoughtful. You mentioned treating the model as a research collaborator and challenging it when something seemed off.

Tell me more about that dynamic - what does it feel like when you're in that collaborative mode with AI? How do you decide when to push back or ask for clarification?

User: Well, I collaborate in areas that are on the edges of my existing expertise, so I have a good feel for what sounds right or I can look it up and understand what I'm reading if I don't already know it.  So the model might recommend a specific statistical test or a particular visualization of something, but I might say that the test it suggested doesn't really answer the research question I'm most interested in, or maybe that it won't work with my dataset.  Then it would generally rethink its answer and suggest something else.  One time it suggested a conclusion about a particular variable accounting for the effect I was seeing.   I pointed out that we only had data on that variable for about a third of the dataset, so what was really happening was that we had lost too much statistical power for the effect to remain significant.  It agreed and tried to suggest other ways to disentangle the variables and confirm the effect.

AI: That's a great example of how your statistical knowledge let you catch a significant misinterpretation. It sounds like you have a pretty clear sense of where that boundary is - working within areas adjacent to your expertise.

I'm curious about your preferences when working with AI. You mentioned you don't use it for routine things - are there certain tasks you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: I hear a lot of colleagues saying that they use AI to write routine emails and other similar tasks.  I think the real problem I have with that is that it would put me at a remove from the work.  I tried asking a model to build a daily course schedule for me for a new semester from one I had built for the previous year--basically just change the dates to the new semester.  But as soon as it did so I felt that I didn't have a feel for the schedule and I was uncomfortable without having gone through it in detail myself.  I ended up spending so much time on it with the AI that it wasn't really a time-saver compared to just doing it myself.

AI: That feeling of being "at a remove from the work" is really compelling. It sounds like there's something about going through certain tasks yourself that gives you a kind of ownership or understanding that you value.

When you tried using AI for the course schedule and felt uncomfortable without that detailed familiarity - what was it specifically that you felt you were missing? Was it about knowing the material better, or something else entirely?

User: I think it was about being reflective and "closing the loop" as we call it in assessment.  If it had just been purely a matter of shifting dates but otherwise keeping to exactly the same schedule I might no have minded as much.  But I found I wanted to give some lessons more time, some lessons less.  I wanted to add a lab activity, but I needed to figure out how to make room for it.  I just needed my own hands on the wheel, so to speak.

AI: That makes a lot of sense - you needed to be actively engaged with those decisions about pacing and content adjustments rather than just having dates shifted around.

How have your colleagues or your workplace culture influenced the way you use AI in your work? You mentioned hearing colleagues talk about using it for routine emails - has that shaped your thinking at all?

User: I think that inspired me to try it, but that particular use just wasn't a good fit for me.  But I hear my colleagues--that is others in my line of work broadly--discussing AI all the time (I'm on an email group list called "AI for Educators").  At first the models couldn't really handle the complex technical work I do, but I kept hearing about their improvement until I was convinced it was worth trying.  My immediate colleagues seem to enjoy figuring out where the models still go wrong, but I like to use it to learn things and for productive purposes.

AI: It's interesting that your immediate colleagues seem to focus on finding where models fail, while you're more drawn to using them productively for learning. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: The help the model gave me with using R for my research was highly satisfying.  I got to complete a great deal of work in a shorter time than it would have taken me alone.  That's when I like it best--when it feels like a collaboration.  I'm less pleased in situations where I've asked it to come up with assessment problems.  It's never quite what I want, perhaps because it's difficult to articulate exactly what I'm looking for.  It's a bit of an "I know it when I see it" situation.

AI: That contrast is really striking - the R collaboration being so satisfying versus the assessment problems being frustrating because they're never quite right.

Tell me more about that "I know it when I see it" challenge with assessment problems. What is it about articulating what you want that makes it difficult in that context?

User: When doing it myself, I don't start knowing where I'll end up.   I have to noodle around with the concepts and data for a while before a good idea floats to the surface.  It really is a creative endeavor to write great assessment problems.  Many people and textbooks have boring and routine problems, I suppose, but I've never been particularly satisfied with them

AI: That creative process you describe - where you need to "noodle around" until a good idea emerges - sounds like it requires a kind of exploratory thinking that's hard to shortcut.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Oh, yes.  This is one of the reasons why I like to use it as a collaborator and not really ever just give it tasks to do without my extensive participation.  I read a story recently in the news that doctors lost diagnostic skills after relying on AI to do it for a while.  I need to keep growing my skills.

AI: That's a thoughtful approach - staying actively engaged to avoid skill atrophy. The medical example you mentioned is a compelling cautionary tale.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I hope it keeps going the way it is, with more productive collaboration.  I do, however, hope that the AI grading helpers that are being developed get truly good at some point.  I'll happily delegate that work (with supervision, always) to an AI if it did a good enough job (presumably being trained on my own grading).

AI: That's really interesting - grading seems like one area where you'd be willing to delegate more fully, as long as it's trained on your own approach and you maintain oversight.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on wanting to stay actively engaged to maintain your skills, and that distinction between productive collaboration versus being "at a remove" from your work.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, I don't think so.

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about the importance of staying actively engaged with your work, and how you use AI as a collaborator rather than a replacement, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!
