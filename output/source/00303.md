# Dialog 00303

**Transcript ID:** work_0604

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: No

AI: Great, let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Sure, I'm a software engineer. I mostly work on building full stack applications and I've started using AI tools as part of my workflow. For example, I use AI to generate boiler plate code, right unit, tests, faster, and sometimes review logic to catch potential cases. I regularly use AI to help me organize data like making lists with certain formatting requirements. I also use AI to write professional emails daily.

AI: That's a great overview of how you're integrating AI into your development workflow. You mentioned using AI for boilerplate code and unit tests - could you walk me through what that actually looks like when you're in the middle of working on a project?

User: Normally I would set up a route handler, import libraries, write request validation, add error handling, and connect it to the database. Instead, I'll open an AI tool and type something like generate an express.js POST endpoint for creating a new user with fields name, email, and password, including error handling, and async/await style. Then the AI gives working skeleton for me to adapt to my project.

AI: That sounds like a really practical workflow. When you get that skeleton code from AI, how much of it do you typically end up modifying or customizing for your specific project needs?

User: I would say I modify about half of what the AI gives me. The structure is really helpful like imports, route, definitions, try/catch blocks, or the test case scaffolding are often correct . But I almost always need to customize it to match the project. For example I'll swap in my own database model calls, add middleware for authentication, or change the error messages so they follow our team's conventions. Sometimes the AI assumes a different library version than the one I'm using, so I'll have to adjust syntax. In testing I'll keep the edge case ideas it suggests or rewrite the actual expected values so the AI saves me from starting with a blank page, but the final version is still very much my own code adapted to the system I'm working in.

AI: That's really insightful - it sounds like you've found a sweet spot where AI handles the structural work while you focus on the project-specific customizations. 

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: There are definitely tasks. I prefer to handle myself. For example, I like to design the overall architecture of a system without AI. That's because architectural choices depend on the project goals, scalability concerns, and trade-offs that require context AI doesn't fully have. I also preferred to write security sensitive code myself like authentication flow or anything involving encryption. Ai can give ideas, but I want full control because mistakes there can introduce real vulnerabilities.

AI: That makes a lot of sense - those architectural and security decisions really do require that deep contextual understanding and careful consideration of trade-offs.

When you do use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I would say that I have a pretty even mix of both

AI: Tell me more about that mix. Can you give me an example of when you collaborate with AI throughout a task versus when you delegate something completely?

User: I tend to collaborate with AI during projects that have a lot of small moving parts but still need my judgment. For example, if I'm building out a new API then I'll ask AI to generate the boiler plate route handler and some example database queries. Then I'll go through step-by-step adapting and expanding on what it gave me. It feels like para programming where I stay in control I speed up repetitive sections.

AI: That's a great example of the collaborative approach. What about the other side - when do you find yourself delegating complete tasks to AI to handle independently?

User: unit test scaffolding is a good example. I might give it the function signature and say generate pytest cases for normal and edge inputs. I don't need to be hands-on in that process because I can just run the test afterwards and see which one's pass or fail. Another case is with documentation, I often paste in a code snippet and let AI draft the docstring or usage example. I still review it, but I treat it more as a hands-off than a collaboration.

AI: That distinction between collaborative tasks and delegated tasks is really clear - it sounds like you delegate when you can easily verify the output afterward. 

How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: Early on everyone was experimenting individually, which meant we had different coating styles depending on how each person used AI. In code reviews that inconsistency stood out and as a result, we started talking more openly about how we were using AI and agreed on some informal guidelines. For example, we try to use it for scaffolding and documentation, but not for final architecture decisions. We also make a point to run all AI generated code through our standard review process so it doesn't bypass quality checks. The culture of transparency and collaboration makes me more comfortable using it because like we're learning together and holding each other accountable.

AI: That's really interesting how your team developed those informal guidelines organically. It sounds like that transparency actually made AI use more effective for everyone.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: One time I felt really satisfied when I used AI to help me outline a tricky feature. It suggested a structure I haven't thought of which let me implement the functionality much faster and more confidently. I still made all of the final decisions, but having that starting point sped things up and gave me a sense of progress

AI: That sounds like a really positive experience - getting that initial structure to build from. What about the flip side? Has there been a time when using AI left you feeling frustrated?

User: One time I got frustrated when AI generated code that looks fine at first but later caused issues because it made assumptions that didn't fit our project. I just spent extra time fixing it, which reminded me that I can't rely on AI blindly, it's a tool not a replacement for careful work.

AI: That's a valuable lesson learned. It sounds like that experience reinforced the importance of that review process your team has in place.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I have not actively considered that

AI: That's completely understandable - you're focused on getting work done effectively. 

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I plan to continue carefully, delegating work and collaborating when small details require a more careful hand. I love automating communication so that it sounds professional and well rounded without me needing to try.

AI: That's a thoughtful approach - keeping that balance between delegation and careful oversight.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how your team developed those informal guidelines together and the distinction you made between collaborative tasks versus delegated ones.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Not that I can think of

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about how you've integrated AI into your development workflow - from the practical examples of boilerplate generation to how your team navigated the cultural aspects - will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk through your approach with us today.

User: Thanks

AI: You're very welcome! Have a great rest of your day.
