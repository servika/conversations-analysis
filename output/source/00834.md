# Dialog 00834

**Transcript ID:** work_0587

---

Assistant: Hi! I'm Claude, and I'm here as part of Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like myself into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

The insights we gather will be used to improve our understanding of AI's role in work environments, and anything you share won't be personally attributed to you. 

Does that sound good? Do you have any questions before we begin?

User: No questions.

AI: Great! Let's start then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I work for a very large technology company and in my job I may need to use different applications and processes. The documentation can be difficult to locate sometimes. There are ways to search by going through an internal collaboration and chat tool. However we also have an internal LLM that has been trained with internal chats and documents. I can ask this LLM questions about internal processes and it will respond including links to resources. This saves time compared to regular searching.

AI: That sounds really practical. When you're using this internal LLM to find information about processes and documentation, how does that typically work for you? 

Walk me through what happens when you need to figure out how to do something - do you go straight to the LLM first, or is there a particular moment when you decide to use it instead of other methods?

User: It works pretty good but I have found a few cases in the past where it hallucinated an answer so it still needs to be double-checked. To be honest, if I need information I first try to search our internal collaboration tool. This is similar to Slack although it is custom for our company. Many times I can find the answer I need this way. It is when I am trying to do more involved research that I will use the LLM. I will look at the response from the LLM but then go through the list of references it provides for more complete information. These references can be links to previous chats where the issue has been discussed and also links to internal documents and presentations. We have a policy not to upload internal documents to outside tools like ChatGPT or Claude so our internal LLM is necesary.

AI: That's a really interesting workflow - it sounds like you've developed a strategic approach where you escalate from the collaboration tool to the LLM for more complex research needs.

Tell me more about those moments when you decide to make that jump from searching the collaboration tool to using the LLM. What makes a research task feel "more involved" to you?

User: One scenario is when I am researching a topic such as a upcoming feature change that involves several different teams and which has been in development over a long period time, maybe a few years. This means that discussion and documentation has occurred through several different groups in parallel. The LLM is good at summarizing the different discussions which saves time over me going through each group discussion.

AI: That makes a lot of sense - having the LLM pull together information from multiple teams and timeframes sounds really valuable for those complex, multi-faceted topics.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: I can do simple research myself. Also I have not yet used AI to help with drafting presentations or data analysis yet. I am just in habit of doing those myself for now.

AI: So it sounds like habit plays a role in what you choose to do yourself versus use AI for. 

When you say you haven't used AI for drafting presentations or data analysis "yet" - what would need to change for you to consider trying AI for those tasks? Is it about comfort level, or are there other factors holding you back?

User: I think I just need to get started and try it. Like having an AI create a few options when we want to experiment with the layout of a particular slide in a presentation.

AI: That's an interesting example - experimenting with slide layouts. It sounds like you can see some specific ways AI might be helpful, you just haven't taken that first step yet.

When you do use your internal LLM for research, could you describe your typical interaction pattern? Are you more likely to have a back-and-forth conversation with it throughout your research, or do you tend to ask it for what you need and then work independently with the results it gives you?

User: Usually I stop after the first question to the LLM because the list of references it provides are a good point to continue with my own reading. Sometimes I'll ask for additional details.

AI: So you're really using it more as a starting point to get oriented and find the right sources, rather than having an extended conversation with it.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you talk about AI usage with your team, or have there been any organizational messages about how to use these tools?

User: Within my immediate team AI is not discussed much, although we all know it's available for us to use. Internally we are all encouraged to use all tools available at our disposal included AI. In the end we are responsible for our work.

AI: That sounds like a pretty open environment - you have the freedom to use AI as you see fit, with the understanding that you own the final results.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Early on I was trying to use our internal LLM to understand how some database tables are structured and where certain information is kept. However I found one instance where the information it returned was wrong. That was frustrating and I still remember that when doing research with the LLM.

AI: That early experience with incorrect information about database structures really stuck with you. It sounds like that moment shaped how you approach the LLM now - you mentioned earlier that you always double-check and go through the references it provides.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I consider it in the back of my mind in that I feel that I should be taking more advantage of what AI can do for me. For example I'm sure there are workflows that can be improved and sped up by setting up AI to do some analysis off of data in Google Sheets. In the long run I'm sure AI can make things more efficient which will result in less need for data analysts but it's up to us individually to work on our skills.

AI: That's a thoughtful perspective - seeing it as your individual responsibility to evolve your skills alongside AI capabilities.

Looking ahead, how do you envision your relationship with AI at work evolving? Where do you see yourself heading with these tools?

User: I think AI will become another tool used everyday at work. It will become second nature to use AI for certain tasks and it will no longer be a novelty.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how that early experience with incorrect database information shaped your current approach of always double-checking and using the LLM more as a research starting point.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No. Thank you very much.

AI: Thank you so much for your time and for sharing your experiences so openly. Your insights about how you've developed that strategic workflow - from collaboration tool searches to LLM research to diving into the references - and how you balance trust and verification with AI tools will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!
