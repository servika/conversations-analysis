# Dialog 01077

**Transcript ID:** work_0951

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: That's great. No questions so far!

AI: Perfect! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: If I am being totally honest, I would usually opt to complete a task by myself rather than use an AI tool to do it. I still don't have complete trust over the accuracy of the models yet and I am handling clinical and patient data which is very important and cannot be managed inefficiently. I do use AI sometimes and that will be for routine tasks like summarising which patients are coming in to the clinic to make it easier to plan for a given week or trial.

AI: That makes a lot of sense, especially given the critical nature of clinical and patient data. It sounds like accuracy and reliability are paramount in your work environment.

Tell me more about those routine tasks like summarizing patient schedules. What does that process look like when you do use AI for planning your week?

User: So when planning a week it will be using AI to work out the best schedule for patient visits based on the availability of the patients and the availability of the clinicians and clinical trial assistants. It is not always right but gives me a head start when planning out the week, or weeks for a given clinical trial when patients will come into the clinic.

AI: That's really interesting - it sounds like AI gives you a foundation to build from, even if it's not the final answer. 

When you say it's "not always right," what kinds of mistakes does it typically make with the scheduling? And how do you catch those errors before finalizing your plans?

User: Like I said, I still don't fully trust the models as I have seen so many previous mistakes, so I always fully check the AI prepared schedule over myself to see if there are any discrepancies or double bookings. It will be these sort of things that the model will make a mistake in, double booking clinicians or opting for patients to come in to the clinic at a time that they said they were not available. It is just little mistakes here and there, the majority is correct and useful.

AI: That thoroughness makes complete sense given what's at stake. So you're essentially using AI as a draft that you then verify completely - it sounds like you've developed a system where you get the efficiency benefit but maintain full oversight.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: Yeah to be honest the majority of the tasks I complete myself, just because of the nature of the role. You cannot make any mistakes as the data we use is so important as it is clinical and patient related. For example, I would not use any AI models for any data input, management, handling tasks. I would also not use AI models for a confidential tasks/ paperwork filling in etc.

AI: That's a really clear distinction you're making - it sounds like there's a bright line for you between tasks where accuracy is absolutely critical versus those where a starting point or draft can be helpful.

When you do use AI for those routine scheduling tasks, could you describe your typical interaction pattern? Are you more likely to go back and forth with it throughout the process, or do you tend to give it the information and let it generate a complete schedule that you then review?

User: Yeah it would usually be at the start of setting up a given phase of a clinical trial that I would utilise the AI models help. I would input the availability of the differing staff and patients (which would be anonymised for safety) and would then ask it to generate a brief schedule of patient visits and which appointments would happen on which day. This would not really be a back and fourth process, I would just provide the initial information and then get a complete schedule that I review and alter myself to make it perfect. It is just like an initial starter...

AI: That's a really clear workflow - using it as that initial starter to get the framework in place, then you take full control from there. It sounds like you've found a way to get some efficiency while maintaining the level of control you need.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do others around you approach it similarly, or have you seen different attitudes?

User: It has definitely been spoken about in the workplace, but like I said previously because of the nature of the work I think everyone is slightly reserved over how much we use it. So I would say overall the attitude is quite widely shared in my workplace, rather than there being different attitudes. My colleagues only ever use it for tasks that are not handling important data but are more mundane tasks, such as scheduling.

AI: That consistency across your team is really interesting - it sounds like there's a shared understanding about the boundaries of where AI fits appropriately in clinical work.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Yeah I definitely agree, I think that boundary is important moving forward in clinical research, it is a useful tool for some aspects but I don't think it will ever be that heavily integrated. And yeah well one time I input a lot data about availability of lots of different type of staff and many different patients for a big trial that we were starting up. The model got the schedule completely correct with no clashes, I was shocked as it has never done that before!

AI: That must have been such a pleasant surprise! It sounds like that moment really stood out because it was so different from your usual experience of having to catch and fix those little mistakes.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, especially given how careful you are about where you use it?

User: To be honest I think everyone within clinical research doesn't really worry about it too much. The advice we get is to always complete critical tasks when handling important data or filling out important legislative forms without the use of AI at all. That is the advice that we get and so I don't think there is a worry that AI will take over as the vast majority of our work does not utilise it at all and I think it will be that way for a very long time. We will see..

AI: That makes a lot of sense - it sounds like the regulatory and safety requirements in clinical research create a natural boundary that keeps most of your core work squarely in human hands.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it staying in that same narrow lane of routine tasks, or do you think there might be other ways it could fit into your work over time?

User: To be honest, I think it will stay in the narrow lane of routine tasks. AI is great but really important data entry and handling tasks are going to be completed by humans for a long time. I could see the use of AI models increasing slightly in my field but not too that great of an extent if I am being totally honest.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how the critical nature of clinical data creates such clear boundaries around where AI can and can't fit appropriately.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No that's all I've got, I am glad you liked my input

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about working with AI in clinical research - especially how you've found that sweet spot of using it for scheduling while maintaining strict boundaries around patient data - will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate your honesty about both the benefits and limitations you've experienced. Take care!
