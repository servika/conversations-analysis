# Dialog 00973

**Transcript ID:** work_0797

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers – we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: That sounds good. I have no questions. Please proceed.

AI: Great, thank you. Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I work in digital marketing with a heavy emphasis on copywriting and some graphic design. I usually use AI to look over the work I've written and suggest improvements. I will sometimes use it to help me create ideas for blog posts or different approaches to emails I'm writing or designing. I rarely use it for graphic design because of concerns I have around intellectual property protections.

AI: That's really interesting - you've found a specific niche for AI in the writing side of your work. When you say you have it look over your work and suggest improvements, what does that process typically look like? Do you send it a complete draft, or do you work through sections?

User: Most of the content is short enough that the AI (I use Google Gemini) can review the whole submission. If it's longer, I will go section by section, but I do so all in one session. Typically, I will send it a draft and either ask for specific improvements that I know are needed (i.e., strengthen this opening hook, suggest a better call to action, etc.) or ask it to provide a list of suggestions and edits in a bulleted list. I do not like it when the AI rewrites my copy. It makes it too hard to see what changes were made, and I am ultimately responsible for any and all content—I can't afford to miss a bad AI edit in my work.

AI: That's a really thoughtful approach - keeping control over the actual changes while using AI as your editing consultant. I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: I prefer to handle graphic design work without the use of AI. I'm concerned that too much use of AI in that field may render work not protected by intellectual property laws. On a personal note, I'm also concerned about the ethics in this case as artists have alleged that AI software has infringed on their intellectual property. I also don't let AI provide the first draft. I usually find that it's better at improving content than it is at creating it (at least as of today). It's also far too willing to invent details without real world basis (again, at least as of today). Lastly, I don't let AI handle any of my personal communications, as in my emails to my coworkers.

AI: Those are really clear distinctions you've drawn - it sounds like you've thought carefully about where the boundaries should be. When you do use AI for writing tasks, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete sections for it to handle independently?

User: I typically let the AI suggest improvements to my work. I then review those suggestions and decide if they're appropriate to apply. Sometimes, I will specifically ask it to address areas where I know improvements need to be made.

AI: That sounds like a very deliberative back-and-forth process. How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: Not really. My boss is supportive of exploring AI potential. I have a few coworkers who also use AI, but most of them use it for writing their own personal emails and not in the same capacity as I do.

AI: It sounds like you have quite a bit of autonomy in how you approach AI use. Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I haven't had a really satisfying experience. It mostly gets the job done and does a reasonable job of helping me get a project over the finish line. The best experiences are when I'm stuck trying to improve a conclusion or introduction, and it provides me with a good framework for getting over that hump (it's suggestions usually need heavy tweaking, but we get there). 

As far as frustrating, the model I've been using (Gemini 2.5 Flash) is really bad at coming up with subject lines for emails and particularly puns. It's also bad at implicitly matching the already established tone. We sell products to C-suite executives who are typically old and serious; the AI will try to suggest fun little emoji strings that I believe will fall flat. Or it will turn "cream of the crop" into "bouillon of the crop" and expect it to be funny.

AI: Those examples are quite telling - especially the bouillon/cream mix-up! It sounds like tone matching is a real challenge. How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I have diversified my skills and am good enough at them that I don't think AI is prepared to "take my job." I don't worry about AI effectively replacing me. I worry about someone trying to cut costs by replacing me ineffectively with AI. As for maintaining skills, I try to demonstrate not only excellence in my work but excellence in adopting new technology, including AI.

AI: That's a really nuanced perspective - distinguishing between what AI can actually do well versus cost-cutting decisions. Looking ahead, how do you envision your relationship with AI at work evolving?

User: I expect AI will be like computers in that they will become synonymous with work. We will learn to use them, create with them, complain about them, and blame problems (fairly or not) on them just like we do other technology at work. Some people will lose their jobs; many already have. For my role, I anticipate using more tools, but I look at it as managing their outputs and helping improve them so that they're impactful. I hope to one day be able to push my routine work onto AI so I can focus on my creative work, but the AI isn't ready to retrieve my metrics from LinkedIn just yet.

AI: That's a really thoughtful perspective - treating AI as another tool that will become as integrated as computers are now. You've shared some really insightful observations about your experience with AI at work, particularly your approach to maintaining control over content while leveraging AI's strengths for feedback and editing.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I should have said that AI can't retrieve my metrics from LinkedIn and put them into my monthly report to my boss, to be clear. 

My experience with AI has been ok. I see the promise, but it just isn't there yet. I have societal, professional, and personal concerns about the adoption of AI, which appears to be moving too quickly to replace high-skilled workers (like copywriters, yikes!) with what turns out to be low-quality work. These aren't necessarily failures of AI. AI, in these cases, is enabling bad business management. We would criticize/avoid working for a company for replacing highly skilled workers with lower quality ones; we should do the same for companies that replace those same workers with lower quality AI tools. There's already a lot of sloppy copy on the internet that appears to be AI-made.

I hope that the future will bring AI-enabled workers who can achieve more with the tools they've been given (again, just like with computers). Again, I look forward to AI taking up my administrative burden and filing my expense report and marketing reports for me (after I check them for accuracy). I also look forward to a day that I can trust the AI to write better and to be useful in graphic design so that I can have it address gaps in my skillset or provide a viable alternative opinion. If it could also provide meaningful analysis of complicated market and product data mixed with our customer profiles and marketing metrics, I could work with on topics as complex as marketing strategy.

AI: Thank you for that additional context - that really rounds out your perspective well. Your point about AI enabling bad business management decisions rather than the technology itself being the core issue is particularly insightful. And your vision of AI handling the administrative tasks so you can focus on the strategic and creative work really captures what seems like the ideal partnership.

You've shared some incredibly thoughtful insights about your experiences with AI at work. I particularly appreciated your nuanced view of where AI fits now versus where it could be most valuable, and your clear boundaries around maintaining quality and accountability.

Thank you again for your time and for sharing your experiences so openly. Your insights will be incredibly helpful for our research on human-AI interaction in professional contexts.
