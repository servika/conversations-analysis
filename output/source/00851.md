# Dialog 00851

**Transcript ID:** work_0614

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: All good, lets get started

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: As a software developer, I use AI to quickly mock up interfaces in React, before fine tuning and creating the more technical detail myself. It's particularly handy for coming up with layouts and visuals when I'm given a vague brief to work from.

AI: That's really interesting - it sounds like AI serves as a starting point for your creative process when you're dealing with unclear requirements.

Tell me more about that process when you have a vague brief. How do you typically work with AI to transform that into something more concrete?

User: So the usual process is that my manager gives me a document containing a list of requirements, these specify targets to hit or features to include. I then feed this document into an AI model which converts it into a simple React interface, I run this code and compare it to the brief to ensure compliance and then work on the technical features to make this work.

The company I work at builds web products for other businesses, therefore I do usually start with a fresh interface rather than be given existing components to refine.

AI: That workflow makes a lot of sense - using AI as that initial translator between requirements and visual implementation.

When you're comparing the AI-generated interface to the original brief, what kinds of things do you typically find yourself needing to adjust or refine? What does AI tend to get right versus what usually needs your touch?

User: I tend to find that AI is usually very good at hitting the explicit goals, if something is written in the brief it'll almost certainly be included. However implicit requirements occasionally get missed, I'll either need to engage with the model to add this in or simply adjust it myself. Other things that are frequently incorrect include commands to build the React project (these often are outdated and do not work well with Tailwind CSS) or occasional minor exception errors in the code. Other than this the actual layout and visuals of the projects are consistently very helpful.

AI: That's a helpful breakdown - it sounds like AI excels at the explicit but struggles with reading between the lines.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: Some of the fine tuning I'll do myself includes the visuals of elements, things such as CSS effects that I can much more quickly make myself rather than describe to an AI that may then generate them incorrectly. I can see how this would be more useful to an inexperienced developer though. 

Also both the extremely technical and extremely basic functions I generally choose to handle myself - basic functions as I can often modify them quicker than copying and explaining to a model; and technical functions for a similar reason, it would take too long to explain the function to a model and the risk of it generating an error is too large (as that would waste my time).

AI: That's a really insightful way of thinking about it - there's almost a "sweet spot" where AI is most useful, avoiding both the too-simple and too-complex ends of the spectrum.

When you do use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I generally delegate it complete tasks, such as small functions or working on individual components. However occasionally if there is a task I know is too big to handle (such as a whole project) I can collaborate with the model on smaller parts and then stitch them together myself.

AI: That distinction between delegation and collaboration based on task size is really clear. 

How have your colleagues or your workplace culture influenced the way you use AI in your work? Has the company taken any particular stance, or do you see differences in how your teammates approach it?

User: My company is relatively small (less than 10 people), so we've been encouraged to embrace it quite a lot in order to noticeably increase our output. However I've got friends at much larger companied who use it far less often as the company is more reluctant to change its processes. My colleagues have widely different job roles so I haven't taken too much inspiration from them but we discuss it sometimes.

AI: That's a fascinating contrast - the size factor really seems to influence adoption speed and openness to change.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: AI is mainly satisfying when it's able to complete a task in its entirety without correction - that feeling of just having the job done in a few moments when it might have taken you 30+ minutes to put together yourself is great. Equally AI can be frustrating for the opposite reason, when it takes forever (in terms of corrections) to get a code block to run without error; sometimes this can be due to misunderstanding the error and giving bad advice to fix it, other times this can be down to general incompetence. It's very frustrating when that happens for so long that you could've built the whole thing correctly in less time, but you've started with AI now so it'd waste even more time to throw away what its generated.

AI: That frustration you described is really vivid - that sense of being "committed" to the AI path even when it's not working well. It sounds like there's almost a sunk cost element to it.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Yes, I do see a certain laziness appear in my work sometimes where I get AI to do something relatively trivial simply because I can't be bothered. As AI gets integrated into more people's workflows I do think this will lead to the loss of skills through lack of practice. The new developers that have never experienced life without AI concern me, as they can get quite far just by collaborating with a model without much technical knowledge of their own, this might lead to some serious errors one day that they do not understand how to fix.

AI: That concern about new developers is really thought-provoking - the idea that they might reach a certain level of capability without building the foundational understanding to troubleshoot when things go wrong.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I see further integration into my workflow, I know as the models improve they will be able to complete a larger percentage of my tasks. I hope that my job is not completely eradicated, however that can't be ruled out - why would I be needed if my manager could just feed his requirements into a model that could generate the entire project from scratch in a matter of moments, complete with full technical implementation.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on that "sweet spot" where AI is most useful - avoiding tasks that are either too simple or too complex - and your honest reflection about the potential skills atrophy both for yourself and newer developers.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No I think (hope) I've explained it well enough. Generally I see the AI revolution in much the same way as when computers became widespread - many jobs were eradicated but many new ones were also created. And as much as some skills were lost during that time, they're no longer necessary and we're now capable of much greater things. I see the same pattern with AI, so while it may seem scary for some, I'm sure it'll work out in the end.

AI: Thank you again for your time and for sharing your experiences so openly. That historical perspective you just offered - comparing AI adoption to the computer revolution - really rounds out your insights beautifully. Your candid thoughts about both the opportunities and challenges, from workflow efficiency to skills development concerns, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I appreciate you taking the time to walk through your process so thoroughly. Have a great rest of your day!
