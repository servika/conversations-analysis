# Dialog 00981

**Transcript ID:** work_0807

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. Does that sound good? Do you have any questions before we begin?

User: What kind of outcomes are you looking for by doing these interviews?

AI: That's a great question. We're really in discovery mode here - we're trying to understand the fundamentals of how people actually interact with AI in their work, rather than testing any specific hypotheses.

We want to learn about the real, day-to-day experiences people are having. Things like how AI adoption is changing work routines, what kinds of tasks people choose to use AI for versus handle themselves, and how workplace culture influences these decisions. We're also curious about the emotional side of it - what feels satisfying or frustrating about working with AI.

The goal isn't to validate any particular approach or find "right" ways to use AI. We're genuinely trying to learn from people's authentic experiences so we can better understand this evolving relationship between humans and AI tools.

Does that make sense? Are you ready to dive in, or do you have other questions about the research?

User: What do you suppose will happen if there are some widespread negative themes in the responses regarding how AI is affecting work?

AI: That's a really thoughtful question. Honestly, if we do find widespread negative themes, that would be incredibly valuable information for us to understand. The whole point of this research is to learn about real experiences - both positive and challenging ones.

If people are having difficult experiences with AI at work, we need to know about that. It could help inform how AI tools are developed, how they're introduced in workplaces, or what kind of support people need when adopting these technologies.

We're not looking to confirm that AI is working well - we're looking to understand what's actually happening. Negative feedback would be just as important as positive feedback for improving how these tools serve people.

Now, I'm curious to hear about your own experience. Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I work as a math tutor, and I barely access AI at all during the course of my typical workday. (I do occasionally use it for hobby/educational purposes.) I use it about once a month to help me generate ideas for "themes of the day" for that month, such as little-known holidays to celebrate with children (e.g., Talk Like a Pirate Day).

AI: That's really interesting - so you've found a very specific, limited use case that works for you. Tell me more about that monthly planning process. What does that interaction with AI typically look like when you're generating those theme ideas?

User: I'm populating a calendar for the upcoming month. I've already generated some ideas for themed days to include in that month. I prompt the AI model to tell me a list of lesser known holidays occurring that month.
This past time, the AI returned a list of federally recognized holidays that weren't designated as days off, but then gave a follow-up wondering if I wanted something more "fun" (or something to that effect). I said that yes, I did. Then it listed what I wanted (e.g., Talk Like a Pirate Day).

AI: That's fascinating - so the AI actually picked up on the fact that federal holidays weren't quite what you were after and offered to pivot. How did that feel when it made that follow-up suggestion about wanting something more "fun"?

User: Relieving but also frustrating because one always hopes that the model can "read my mind" for the intent of my prompt without my having to overspecify it. Or the model could have simply come back with the clarifying question of federal-versus-fun before spitting out the first list.

AI: That tension you're describing is really revealing - wanting the AI to just "get it" without having to be overly specific, but then feeling frustrated when it doesn't. 

When you think about your work as a math tutor more broadly, are there tasks where you've considered using AI but decided against it? What makes you choose to keep AI mostly out of your day-to-day tutoring work?

User: I work with several children at a time at a fairly fast pace. I have to read their work, check it, and give feedback rapidly. I already know answers to their exercises from quick access to a PDF key. Honestly, I don't see how AI has a role in the interactions I'm making with these students. Use of AI by either of us would eat up time/energy and get in the way of the direct feedback loop established between me and them.

Often students cannot voice their own lack of understanding, and it takes another human to help them put it into words. Also, sometimes their handwriting is bizarre and idiosyncratic and couldn't be interpreted through OCR, only through conversation. I'm just thinking about interactions that a theoretical AI could not replicate.

AI: That's a really compelling picture - you're describing this very human, intuitive process where you're reading between the lines of what students can't articulate, deciphering their handwriting through context, and maintaining this rapid feedback loop. 

You mentioned that students often can't voice their own lack of understanding. Can you give me an example of what that looks like - how you help them put it into words when they're stuck?

User: I refer to previous work/concepts/exercises that I've seen them perform well at, and I put myself in their perspective viewing this new material. I then propose in my own words what I would see as the challenge of the new material; they affirm that or deny that, and I repeat as necessary. Usually if they deny what I've proposed they can find more words along the lines of, "it's more like..."

AI: That process you're describing sounds so iterative and responsive - you're essentially modeling their thinking process and then adjusting based on their feedback until you hit on what's actually blocking them.

Given how central that kind of human intuition and back-and-forth is to your work, I'm curious about your perspective on maintaining your skills. Is the fact that AI isn't really applicable to your core work something you actively think about, or does it just naturally work out that way?

User: I don't spend too much time ruminating on it. I do think that it's a given that, for many people, a meatspace interaction with a human is not easily replaced with interaction with an AI. And that the teaching/learning process can be supplemented with AI use, but that use is really more like self-study.

AI: That distinction you're making is really interesting - supplementing versus replacing, and how AI use in learning contexts is more like self-study. 

When you do use AI for those monthly theme ideas, how do your colleagues or the broader tutoring environment influence that? Do you talk about AI use with other tutors, or is it something you just handle on your own?

User: It's something I just handle on my own. Creation of the theme calendar is a responsibility unique to my role among my coworkers. (And in the day-to-day, none of us has time to use AI while working with students. Some coworkers are using AI to draft communications to parents / sales leads, though.)

AI: So you're seeing some AI adoption among colleagues for the administrative side - drafting communications - but not in the direct student interaction work. 

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself potentially finding new ways to incorporate it, or do you think it will stay pretty much as it is now?

User: I think my use will stay pretty much as it is now. The core part of my job, interacting with the students, will not allow room for further use of AI, as our pace and workflow are quite set for the time being. I will likely continue to dip into it for generating ideas for the theme calendar from time to time. If my responsibilities evolve to take on further administrative functions, I can see myself using AI to help organize some lists or logistics or something. I myself am less likely to use it for drafting communications, as I think a fair number of recipients can sense when an e-mail has been mostly drafted by an AI model, and they might feel negatively about that.

AI: That insight about recipients sensing AI-drafted communications is really interesting - you're considering not just whether AI could help you, but how it might affect the relationship with the people receiving those communications.

Before we wrap up, is there anything else about your experience with AI in your work context that you think would be valuable for us to know? Something we haven't covered yet that feels important to your story?

User: In a math tutoring context, even though an AI model would carry authority in the sense of having a right answer, it could never carry authority in the sense of in loco parentis. It would not be able to authentically help keep a student on task or enforce rules / appropriate behaviors. As it currently is, it could only keep a friendly servile role.

AI: That's a profound point - the distinction between informational authority and relational authority. The idea that even if AI has the "right answers," it lacks that fundamental human authority that comes with being responsible for a student's well-being and behavior in that moment.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how the pace and human elements of tutoring create natural boundaries for AI use, and that distinction between different types of authority.

Thank you for taking the time to share your experiences so openly. Your insights about the irreplaceable human elements in teaching and the thoughtful way you consider the impact on relationships will be incredibly helpful for our research on human-AI interaction in professional contexts.
