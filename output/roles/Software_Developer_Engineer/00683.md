# Dialog 00683

**Transcript ID:** work_0351

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Sure that sounds good

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I generally use AI to streamline tedious processes at my job. I use it frequently to write standard operating procedures or boring email responses.

AI: That's helpful to know. When you say you use it for standard operating procedures, can you walk me through what that looks like? What's your process when you're creating one of these SOPs?

User: I generally provide a prompt requesting that the AI create a standard operating procedure based on the steps that I write down after. I usually write the steps in a stream of conscience style and let the AI disect it into steps and polish it.

AI: That's interesting - so you're doing the thinking and sequencing of the actual work steps, and then having AI help with the formatting and presentation. 

Tell me more about what you mean by "stream of consciousness style." What does that typically look like when you're getting your thoughts down?

User: So, if I were to write the SOP myself, I would separate the steps by bullet points or in a numbered list with headlines to each section and clear transitions. However in the stream of conscience style it sounds more like "first, I download the document, then I upload it to the system, enter data, cross check documents, code for billing, and then submit for approval".

AI: That makes perfect sense - so you're essentially brain-dumping the process as you know it, and then the AI helps transform that into a proper formatted document with clear structure.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: I prefer to handle anything that involves data and math processes myself. Some examples would be totaling sums of invoices submitted on a given work order, or asking for the occurrence of a certain word in a text. I find that AI generally gives me the wrong answer when data I have inputted is involved.

AI: That's really insightful - you've identified specific limitations where you don't trust the AI's accuracy. 

When you say AI gives you the wrong answer with data you've inputted, can you tell me more about what typically goes wrong? Is it calculation errors, or does it misinterpret the data somehow?

User: It tends be calculation errors. AI seems to struggle with repeating numbers, or skipping over numbers completely. I have also found that AI is not good at plotting geographical points on maps. What I have found with the geographical errors is that it completely invents addresses.

AI: Those are very concrete examples of where you've learned not to rely on AI. It sounds like you've developed a clear sense of its strengths and weaknesses through experience.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I will many times refer to AI to help with specific parts of a larger task. Sometimes if I am struggling to find the right wording for a section of a document, I will plug my awkward wording into AI and ask it to polish it for me or suggest different ways to express my original sentiment. I haven't found a specific task in my job that I could automate completely through AI.

AI: That's a really clear picture - you're using AI more as a collaborator for specific moments when you get stuck, rather than handing off entire workflows.

How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: My colleagues have really embraced the use of AI. We actually have an enterprise chat gpt that we all use at work. Many of my colleagues work in communications and use it to optimize copyright and get creative ideas. My close colleagues on my team use it more similarly to me, as an administrative collaborator more than a full on automation.

AI: It sounds like having that enterprise ChatGPT tool really normalized AI use across your workplace. That's interesting that the communications folks use it differently than your team does.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Sure, I have an instance where it was both extremely satisfying and frustrating. I had to reconcile the general ledger for a consultant that works in the UK. We had paid them in GBP but sought reimbursement from our prime funder in USD. I had to find the realtime currency conversions for the dates that those payments were remitted, to reconcile the account in USD. There were maybe 20 payments that I needed to translate to USD with the conversion rate from the exact day they were paid. I plugged this into Chat GPT and it was able to pull the conversion rates from each payment date so that I could see what the amounts were paid in USD. However the sum of these payments was being consistently calculated incorrectly. After some addition by hand, I realized chatgpt's error and used my hand calculated sum instead. This was both a satisfying and frustrating experience, but overall positive.

AI: That's such a perfect example of what you described earlier - AI being helpful with one type of task but failing at the calculations. It sounds like it saved you a lot of time looking up those conversion rates, but then you had to catch its math error.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Not really, I don't fully supplement those tasks with AI. I still do a lot of these activities by myself and frankly standard operating procedures and writing emails aren't really skills that you unlearn.

AI: That's a good point - those are pretty fundamental work skills that you're still actively using even when AI helps polish them.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I predict it to look pretty similar. I perhaps will consult more with AI about streamlining my workflow and processes, engineering my day for more efficiency. I also would like to use it a bit more for market research, but I have had mixed results with it in the past. I find that it sometimes invents information about vendors, such as email addresses.

AI: That's interesting - you mentioned the invented information issue earlier with addresses, and now email addresses for vendors. It sounds like you've really learned where AI tends to hallucinate versus where it's reliable.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated how clearly you've identified the specific areas where AI helps versus where you've learned not to trust it - like with calculations and data accuracy.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I think it would be good for AI to have some more disclaimers on these more error ridden areas. Not everyone double checks the output from AI and they really should be checking it. Incorporating some "humility" or acknowledgement to possible margin of error to the responses would be beneficial, especially for individuals using it professionally.

AI: That's a really valuable insight - the idea of AI being more upfront about its limitations, especially in professional contexts where accuracy matters. The suggestion about building in "humility" or error acknowledgment is particularly thoughtful.

Thank you again for your time and for sharing your experiences so openly. Your insights about finding that balance between leveraging AI's strengths while being aware of its weaknesses will be incredibly helpful for our research on human-AI interaction in professional contexts.
