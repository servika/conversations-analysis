# Dialog 00921

**Transcript ID:** work_0722

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Sounds good, let's begin

AI: Great! Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Right now, I mostly use it in research and troubleshooting.  If I'm trying to get a little more knowledgeable on something or if I'm troubleshooting a problem I haven't already been able to quickly figure out myself I might send it over to an AI to help me out.

AI: That's interesting - it sounds like AI serves as a kind of knowledge partner when you hit certain points in your work. 

When you mention troubleshooting problems you haven't been able to quickly figure out yourself, can you walk me through what that process typically looks like? How do you decide when to bring AI into the mix?

User: There's really no specific time threshold or anything like that.  It's more just a feeling that something might take a while to figure out or something I might be lacking domain specific knowledge on.  Then I might punt it over to AI.

AI: That makes sense - it's more of an intuitive judgment call based on the complexity or your familiarity with the domain. 

Tell me more about that feeling you get when you decide to "punt it over to AI." What are the signs that tell you this might be one of those situations where AI could be helpful?

User: If there's a significant issue that needs to be addressed quickly, typically an AI would be able to find an answer quicker than I can.  This still comes with its own set of obstacles such as determining if the suggestion is worthwhile enough to follow or at least go in the direction it's pointing me to.  But that usually can get me in the right area at least even if it's not the correct answer for that specific situation.

Another situation is I know up front that I don't have all the information I need to fully understand what it is I'm trying to solve.  Then I just form my prompt to get some information on the issue at hand.

AI: That's a really thoughtful approach - using AI to get pointed in the right direction even when the specific answer might not be perfect, and recognizing upfront when you need more foundational knowledge.

You mentioned having to determine if the AI's suggestion is worthwhile to follow. Can you tell me more about how you make that evaluation? What do you look for when deciding whether to trust or act on what the AI suggests?

User: Typically in this situation I have an understanding of the problem but in looking for the root cause I'm a little lost.  So, when I get a suggestion I can almost immediately tell if what I've been given makes sense for the problem I'm seeing and if it doesn't I can reform my prompt and try again or push the AI in a different direction.  There's not a specific thing I'm looking for, it's just my understanding of the problem and how the response fits into that.

If it's something I might not understand up front then I'm more willing to let the AI guide me until I have a better understanding.  At that point, I can either take over or steer the AI where I think the issue is.

AI: That's a really nuanced way of working with AI - it sounds like your existing knowledge acts as a filter, and you adjust how much you let the AI lead based on your familiarity with the territory.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: My personal preference is to handle the bulk of things myself.  More so for the enjoyment of doing the task than anything else.  I do still have a bit of skepticism when it comes to passing the reigns over to AI and it's typically justified at one point or another.  Not that I couldn't make the same mistakes but from what I've experienced AI is a bit overly confident in what it does at times.

It almost seems to present its response as if they are always the exact solution for a problem or given task regardless of what the true outcome may be.  This kind of blind confidence usually leads to worse problems down the road and personally, at times it doesn't feel worthwhile to spend time delegating a task to AI that I'm ultimately going to have to give my own touch to anyway.

AI: That's a really insightful observation about AI's overconfidence and how that affects your decision-making about when to use it. The idea that you might end up having to "give your own touch" anyway really captures something important.

Can you think of a specific example where that overconfidence created problems for you? What happened, and how did you handle it?

User: It hasn't created a problem for me at this point because of my skepticism.  I am always carefully studying the responses I get and fact checking to ensure I don't end up in that kind of situation.  I can't think of a response I've gotten in the past but I do remember subtleties.  Something as simple as potential nil dereferences in code that were somehow missed or just overly complex code snippets when there's a much simpler way of doing something.

But because they're passed off with such confidence I have seen others follow blindly and it ends up being a problem later when an app panics or silently fails from the suggestions.  Then it makes troubleshooting harder later on because you didn't have your hand in the mix and you don't remember how or why it's supposed to work.

AI: That's a really important point - you've avoided problems yourself because of your careful verification, but you've witnessed others get into trouble by following AI suggestions too blindly. The part about troubleshooting being harder later because "you didn't have your hand in the mix" is particularly striking.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I take the collaboration approach.  Throw a question at it and see what I get back.  Sometimes it can lead to nothing and other times it shows me something I didn't know or never thought of doing a certain way.  I don't typically do any agentic tasks at this point.

AI: That collaborative back-and-forth approach sounds like it fits well with your preference for staying involved and maintaining that verification step.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that the people around you approach it similarly or differently than you do?

User: Right now we are just starting to get immersed in the AI world.  My workplace previously took the stance of absolutely no AI for anything.  In the past few months they've decided to open it up to a small group to gauge how useful it can be as part of the every day workflow.  Some people have jumped right in while others, like myself, have taken a more guarded approach.

AI: That's fascinating - going from a complete ban to cautiously opening it up to a small group. It sounds like you're part of an early experiment at your workplace.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I have mostly frustrations using AI.  Most of my use has been with coding assistants as well as general use.  With coding, I would get a lot of suggestions that almost seemed like the model was not context aware even though it had the context of the full repo.  I would ask how to do a certain thing and it would show me something I had already coded myself that I knew to not work.  Or other times it would use a third-party package completely wrong even with other examples in the same codebase.

I have had a few aha moments but they are far less than the frustrations I've encountered.

AI: Those coding frustrations sound really deflating - especially when the AI has access to your entire codebase but still suggests approaches you've already tried and know don't work. That must feel like the tool isn't really understanding your specific situation.

Tell me more about one of those aha moments you mentioned. What made that experience different from the frustrating ones?

User: Even though I have personally had far less success using AI than some of my coworkers those moments capture a little hope.  Just enough for me to try again.  It's seemed to have faded recently and I've found myself not even looking in the AI corner.  I'm mostly sitting back and waiting for someone to signal how to best use it before I try again.  There have been suggestions on how to get AI to give you the best answer but these seem too nuanced and complex for me to really want to try.  I just want to be able to talk to it as myself and get what I'm looking for.

AI: That's really honest - the idea that you just want to be able to talk to AI as yourself without having to learn complex prompting techniques really resonates. It sounds like the overhead of figuring out how to get good results has become a barrier.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I'm not sure I understand the question.  Are you asking if I've considered how the overhead of maintaining my skills in those areas might be outweighed by the benefits of letting AI take over and freeing me to do other things or something else?

AI: Actually, I was asking more broadly about whether you think about keeping your own skills sharp in areas where AI might be able to help or potentially replace human work. But your interpretation is interesting too - the trade-off between skill maintenance versus letting AI handle things so you can focus elsewhere.

How do you think about that balance? Do you worry about skills getting rusty if you rely too much on AI, or do you see it more as freeing you up for other work?

User: I can see it both ways.  If it's something I can offload to AI should I even consider it a useful skill to have at that point?  I'd still lean on it being useful but I could also see it as a benefit to having more time for other types of work or just more time to learn something new.  It's something that makes me think if I'm willing to let AI do it for me most people probably do the same and at some point it may become a rare skill to possess which in turn could make it more valuable and marketable.

AI: That's a really strategic way of thinking about it - the idea that skills everyone delegates to AI might actually become more valuable precisely because they're rarer. 

Looking ahead, how do you envision your relationship with AI at work evolving? Especially given that you're in this early experimental phase at your workplace?

User: Even though we are in an early stage we've already leveraged AI in a customer-facing way.  Given that, I believe we will be using it more and more as time goes on and whether I want to be a part of it or not is irrelevant.  I will likely be tasked to implement something with AI or asked to check something out that uses AI.  I enjoy figuring out new problems and AI can definitely fall into the category of a new problem as well as just a new tool to put in the bag.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how AI's overconfidence can create downstream problems when people follow suggestions blindly, and your strategic thinking about how delegated skills might actually become more valuable over time.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about the balance between skepticism and curiosity, the challenges with AI overconfidence, and how workplace culture shapes adoption will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate your honesty about both the frustrations and the occasional aha moments - that kind of nuanced perspective is exactly what helps us understand the real experience of working with these tools.

Thanks again, and I hope your workplace's AI experiment continues to evolve in useful ways for you and your team.
