# Dialog 00056

**Transcript ID:** science_0048

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: That sounds good. I don't have any questions

AI: Wonderful! Let's dive in then.

To start, I'd love to hear about your work. Could you walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: I recently created a multi-layer perceptron machine learning model to predict the success of NBA basketball players based on characteristics from before they were drafted. This information included the draft pick where they were selected, their position, their height, their weight, their age, as well as some other features. Win shares (WS) was the y value metric the model attempted to predict. The model did a decent job predicting win shares but more features would've allowed it to create better predictions

AI: That sounds like a fascinating project! I can picture the workflow involved in building that kind of predictive model - from gathering the draft and player characteristic data, to feature engineering, model training, and evaluation.

Where in that process, if anywhere, have you experimented with using AI tools?

User: I used AI tools to guide me through the process of model evaluation. This included guidance for conducting analysis with ridge regression with different alpha values and sci-kit learn's GridSearchCV library. It helped me find the best alpha estimator and best RMSE.

AI: That's really helpful to understand. So AI was guiding you through the model evaluation and hyperparameter tuning aspects - helping you navigate ridge regression analysis and optimize with GridSearchCV.

Tell me more about how you decided to use AI for that particular part of the process versus handling it with your traditional approach.

User: I wasn't sure if my traditional approach would be most effective an efficient at trying the different alpha values within the Ridge regression validation. AI provided the code to efficiently do this throughout my model result analysis and validation process.

AI: That makes sense - so it sounds like efficiency and uncertainty about the best approach led you to turn to AI for that validation process.

Thinking about the other parts of your research project - the data collection, feature selection, initial model setup, or interpretation of results - what kept you from trying AI tools in those areas?

User: I felt comfortable selecting features and choosing the initial model based on my knowledge of the material. I am quite knowledgable about basketball and the analytics within the NBA, so I felt that I was qualified to select features for a relatively simple model like this one. I also felt comfortable with the initial model setup as an MLP model as I knew how to implement it and wanted to gain experience doing so. The data collection process didn't include any web scraping and instead was through downloads of multiple files and some data cleaning, so it wasn't complex enough to require AI tools.

AI: That's a really clear picture of your decision-making process - you relied on your domain expertise for the basketball analytics and feature selection, wanted the hands-on learning experience with MLP implementation, and the data collection was straightforward enough to handle yourself.

When you did use AI for the ridge regression validation and GridSearchCV optimization, how did you verify or validate what it produced for you?

User: I saw the output of the code cell it produced and the math supported its conclusion of the best alpha estimator and best RMSE.

AI: Got it - so you were able to check the mathematical output and results to confirm the AI's code was working correctly.

We're about halfway through our conversation now. Looking ahead, if you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: I wish AI had added knowledge of subject material and context of data. AI can offer valuable suggestions for model setup and data collection, but feature selection and hyper parameter tuning are dependent on the context of the data. AI often doesn't do a great job applying whatever knowledge it has about the subject matter of the data to these problems

AI: That's a really insightful observation - you're highlighting this gap between AI's technical capabilities and its ability to apply domain-specific knowledge meaningfully to your basketball analytics context.

Tell me more about that - can you give me a specific example of where you felt AI's lack of basketball or NBA analytics knowledge limited its usefulness?

User: Sure. When creating any predictive machine learning model in sports, more complex statistics are more valuable features as they do a better job of quantifying player or team performance than simpler ones. These more simple metrics, like points per game, assists per game, and field goal percentage in basketball, are referenced and discussed far more by casual fans. This makes them more accessible for the AI, making it more likely to suggest their usage. While using stats like this can be helpful, metrics that convey more information, like expected points per possession or win shares, are more valuable.

AI: That's a perfect example - AI gravitates toward the more commonly discussed, surface-level stats that casual fans know, but misses the more sophisticated metrics like expected points per possession that actually have greater predictive power for your model.

Those are all my questions - your perspective on how domain expertise really drives the critical decisions in sports analytics, while AI excels more in the technical implementation aspects, was particularly insightful. 

Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: No

AI: Thank you again for sharing your experiences so openly. Your insights about the gap between AI's technical capabilities and domain-specific knowledge really help us understand the nuances of how AI fits into real scientific work - especially that tension between AI suggesting accessible but less valuable features versus the more sophisticated metrics that actually drive better predictions.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. I really appreciate the time you took to walk me through your NBA analytics project and your thoughtful reflections on where AI helped and where your expertise was irreplaceable.
