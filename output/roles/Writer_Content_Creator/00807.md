# Dialog 00807

**Transcript ID:** work_0549

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Sounds good. Let's go!

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI for web searches daily, so I can ask follow-up questions and really refine my own searches. For example, I search for game schedules across all sorts of sports, especially historical ones. I also ask about telecaster information or about news items that come up that I'd like to validate for accuracy, relevance, and reliable sourcing. I also use AI at least once a week, often more, to rewrite emails, summaries, and similar shorter-form documents. In other words, AI is my editor. Similarly, I use AI to bounce ideas off of someone to test for their realizability, to get at least a general schematic picture of steps I would need to take to enact different workflows or production ideas. I use AI for ideation. At least once a week, I also use AI to create schematic documents summarizing elements of my AI conversations, such as action plans, either as PDFs or images. Or to create a flow chart outlining steps in a process. I try to use AI embedded in my company email to find relevant topics, use advanced search, and the like, but this often fails, unfortunately. It is either a bad implementation on my company's platforms or the embedded AI just isn't very good yet.

AI: That's a really comprehensive picture of how you've integrated AI across different aspects of your work. It sounds like you're using it as both a research tool and a collaborative partner.

Tell me more about using AI as your editor for emails and summaries. How does that process typically work for you?

User: Sure. I write the first drafts and then ask AI to tweak and tighten up my version. Then we engage in a back-and-forth conversation on its version versus mine to tighten up the final product and ensure it is both logical and comprehensive for the given task it is meant to concretize. Interacting with the AI about specifics is crucial to my process. I don't always follow the suggestions presented, but at a minimum, the interaction helps me to clarify my thoughts and make them concise and optimize the effectiveness of the message. That's why I call AI my editor.

AI: That back-and-forth conversation you described sounds really important to your process. You mentioned you don't always follow the AI's suggestions - what helps you decide when to accept or reject its recommendations during those editing conversations?

User: Well, I am the domain expert in most cases, so sometimes the AI's suggestions aren't comprehensive enough to understand the specifics of the use case I have in mind. For example, the AI doesn't always know the personalities at the other end of the message and what they may be looking for. Explaining some of the extraneous data points to the given AI is often not an effective use of limited time. Sometimes, these extraneous data points get flushed out in the course of our back-and-forth conversation, but sometimes not. Sometimes I just need a structural agent instead of in-depth domain expertise to help guide my writing. And more often, the AI doesn't have access to internal systems that would augment its utility to me in specific internal knowledge domains. For example, it can't access our internal data systems yet, nor our data visualization software applications, nor SharePoint documents, video assets, contact lists, or previous conversations.

AI: That's a really insightful distinction - using AI as a "structural agent" rather than expecting deep domain expertise. It sounds like you've developed a clear sense of AI's strengths and limitations in your specific work context.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: I prefer to handle mathematical calculations. I also always double-check crucial data points like time/date, etc. And if I ever doubt the accuracy of something I am given, I ask the AI to provide references to support its claims so I have the ability to quickly fact-check. And more generally, I know I am a much better writer than AI, so far. So I use AI as an editor and not as an author. Programs like Grammarly are indispensable. Generally, I prefer to collaborate with AI rather than blindly trust. The exception to that loose rule is creating graphics based on data points I give the AI. I usually trust that the graphic truly represents the data underlying it, because I make only simple graphics with AI. I still use data visualization software like R, Tableau, and MicroStrategy to make more complex graphics. That's because either the AI I have access to can't access internal data systems, or presenting AI with the full data sets is restricted by internal security policies or just too time-consuming to feed manually, depending on the specific use cases at play.

AI: It sounds like you've developed a very intentional approach to collaboration versus delegation with AI. You mentioned you generally prefer to collaborate rather than blindly trust - that's a really clear philosophy.

When you do use AI for work, could you describe what that collaboration typically looks like? Are you working together step-by-step through most tasks, or are there times when you do delegate complete portions for the AI to handle independently?

User: It's always a conversation because I usually have edits that I'd like to implement on the first pass AI submits. The exception to that is simple graphics or PDF docs. I rely on the AI to correctly summarize a conversation we had and to present that into actionable lists.

AI: That conversational approach seems central to how you work with AI. You mentioned simple graphics and PDF summaries as exceptions where you're more comfortable with delegation.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: AI summarization of conversations we have is virtually flawless. I love the PDFs and images it generates based on those types of procedural conversations. That my AI tools aren't connected across data domains is a source of immense frustration. If I am using an AI tool in an email app, I need it to be able to access other applications like document repositories, and be able to combine data it gathers from one domain with every other relevant domain. This isn't a flaw of AI architecture per se, but of specific implementations. The worst AI, besides Grammarly, is the AI that makes typing suggestions and corrections. Also, any call to create complex data-driven graphics often fails to accurately capture what I need it to and ask of it. A graphic with more than three variables often fails, and any AI-generated graph is always lacking in aesthetic depth.

AI: The integration issue you're describing sounds really significant - having AI tools that can't talk to each other or access your different work systems. That would definitely limit their usefulness.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that the environment encourages or constrains how you approach these tools?

User: My cultural environment constrains my access to relevant tools, mostly due to a lack of understanding of those tools or due to a lack of understanding of the security ramifications of those tools. I am definitely an advanced AI advocate in my company and often the earliest adopter of new technologies, as well as an internal and trusted source of the practical applications of new technology. The issue I encounter is more of an internal structural issue, whereby multiple actors need to be sold on the usefulness, advantages, and safety of products before they get to even be tested in a sandbox. The issue with that is that most folks just aren't familiar enough with AI beyond simple web search and recreational image generation functions.

AI: It sounds like you're in a position where you can see the potential but are held back by institutional caution and unfamiliarity. Being the "advanced AI advocate" in that environment must be both rewarding and challenging.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Yes, I do. We spend lots of manpower, so to speak, doing rote processes based on multiple known variables, which should be done by AI. For example, scheduling games for air across multiple networks and distribution platforms based on ratings optimization, available inventory, and contractual data points is something AI would excel at in much less time than a team of human beings. Similarly, creating advisory summarizations of complex contractual data points across various properties is made for AI and should not be the work of an army of humans. AI reads and processes set information much better than human workflows. AI should get the first pass at all of these sorts of projects and targets, and then the human comes in to tweak, ask, chide, recommend, augment, etc., until the final products are arrived at in their best form and level of quality.

AI: That's a really strategic view of how human-AI collaboration could work - AI handling the heavy lifting on data processing and initial analysis, with humans focusing on refinement and strategic decisions.

Looking ahead, how do you envision your relationship with AI at work evolving? What changes do you anticipate or hope for?

User: I envision every point of pain and frustration with AI to become AI assets. I expect AI to enable humans to exceed current production rates and to encounter new ideas that AI augments and helps generate. I expect AI to completely replace web search and research applications. I'd like to see AI get better at mathematics and complex data calculations across multiple domains. I expect to see our internal workflows drastically transformed in the next year or two. I'm ready for the promise to become actualized.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI as a "structural agent" and editor rather than an author, and your strategic vision of AI handling the heavy data processing while humans focus on refinement and strategic decisions.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No. Thank you. This was extremely insightful to me as well. I hope that both of our agencies were augmented in this conversation. Cheers!

AI: Thank you so much for your time and for sharing your experiences so openly. Your insights about the current state of AI integration, the challenges with cross-platform connectivity, and your vision for how these tools should evolve will be incredibly helpful for our research on human-AI interaction in professional contexts.

I'm glad you found the conversation insightful as well - that's exactly the kind of collaborative exchange we hope for in these interviews. Your perspective as an early adopter navigating institutional constraints while maintaining a strategic view of AI's potential was really valuable.

Cheers, and thanks again!
