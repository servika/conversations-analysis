# Dialog 01087

**Transcript ID:** work_0970

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good to you? Do you have any questions before we begin?

User: Yes that sounds good.

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I am a traditionally published author. I use AI mostly for research: as I write fiction in worlds that mimic our own (e.g. Regency era worlds), I ask a lot of ultra-specific questions about the time period that would take a long time to find out via a Google search alone.

AI: That's fascinating - using AI as a research assistant for historical fiction. 

Can you give me an example of one of those ultra-specific questions you've asked? I'm curious about what makes these queries particularly well-suited for AI versus traditional Google searches.

User: For example, I recently asked what type of fabric a middle-class woman's dress might be made from. I also had to find out what type of weapons were used - be it pistols or revolvers.

AI: That's really helpful context. Those do sound like the kind of specific details that could send you down quite a research rabbit hole with traditional searches.

I'm curious about your preferences when working with AI. Are there certain tasks related to your writing that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: Yes, I never ask AI to write passages for me. While I sometimes may use it to brainstorm name ideas of perhaps metaphor inspiration, I will never ask an AI simply to write on my behalf.

AI: That's a clear boundary you've established. What drives that distinction for you between using AI for research and brainstorming versus the actual writing itself?

User: I think the most important part of being an established author is having a distinct voice: were AI to write on my behalf, it would not have my voice.

AI: That makes a lot of sense - voice being such a fundamental part of what makes your work uniquely yours.

When you do use AI for those research tasks and brainstorming, could you describe your typical interaction pattern? Are you more likely to have a back-and-forth conversation with it throughout your research, or do you tend to ask specific questions and then take that information to work independently?

User: I tend to ask specific questions and leave it at that. Sometimes the answer might inspire some new questions, and in that case, the conversation might go back and forth.

AI: Got it - so it's more question-driven rather than an ongoing collaborative process.

How have your colleagues or the broader writing community influenced the way you use AI in your work? Have you encountered any particular attitudes or norms around AI use among other authors?

User: I find using AI is very looked down upon, and while I think a lot of authors use it, it is not something people readily admit to in the industry. Many readers will boycott an author if they think they have used AI, and as readers won't understand the line I draw between using AI as a research tool and using AI's words, I would rather just not mention it at all.

AI: That's a really important point about the nuanced distinction you make that may not be understood by readers or peers. It sounds like there's quite a bit of stigma to navigate.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: There are times when I ask AI something and, rather than admit it cannot find any information out, it will lie and offer something false as the answer. Other times, I find it too agreeable, accepting false premises too easily.

AI: Those sound like frustrating experiences - especially when you're relying on it for factual historical details. The false premises issue is particularly interesting.

Can you give me an example of when AI was too agreeable or accepted something false that you presented?

User: For example, I was recently asking AI about whether it's normal for scouts to pick up debut manuscripts - specifically, whether this is commonplace or something that signals a manuscript may be performing well on submission. I asked this in two separate chats - one, it was phrased in a good light ("this is a unique situation, right?") and in the other, it was phrased in a negative light ("this is pretty normal, right?") and I received two entirely different answers simply based on the phrasing of the prompt.

AI: That's a really striking example of how the framing can completely change the response, even when you're asking about the same factual situation. That inconsistency must make it challenging to trust the information you're getting.

How do you think about maintaining your research skills and knowledge in areas where AI could potentially take over some of that work? Is this something you actively consider?

User: It isn't something I am really concerned about. Were I to decide not to use AI anymore, I would be fine researching on my own - it would just take a lot longer.

AI: That's reassuring that you feel confident in your underlying research abilities.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself expanding how you use it, or do you think you'll maintain those same boundaries you've established?

User: I think I will always maintain the boundaries I have established.

AI: That's all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI as a research tool. I particularly appreciated your perspective on the tension between the practical benefits you get from AI research assistance and the industry stigma you have to navigate, as well as that striking example of how AI's agreeableness can lead to inconsistent answers.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No I think that's it

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about drawing clear boundaries between research assistance and creative work, as well as the challenges around industry perception and AI reliability, will be incredibly helpful for our research on human-AI interaction in professional contexts.

It's been really valuable to understand how you navigate both the practical benefits and the complex social dynamics around AI use in creative industries. Thanks again!
