# Dialog 00610

**Transcript ID:** work_0243

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers – we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Sounds great :) 

Thank you.

AI: Perfect! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI/LLMs for a variety of business and technical purposes most days. 

Most of my career has been focused on ML/AI; with my undergraduate and graudate studies being focused on intersections of Computer Science/ML with applied research in Neuroscience and Finance; later career work would mostly be with technologies that look like computer vision models and related to finance & capital markets, and to a lesser degree, e-commerce. 

So much of the actual topic at hand is AI; but in the last year and a half, LLM based tooling has been a very involved set of how my work gets completed, and how my professional learning, development, and planning are facilitate. 

I make extensive use of "Deep Learning" features for technical and non-technical research, planning and learning. 

I also make extensive use of IDE enabled LLMs via Cursor & JetBrains AI. As well as continual use of ChatGPT.

Finally, one of the organizations I work with uses ClickUp, which is built around LLM Features (ClickUp has branded it ClickUp Brain). It's kind of like using an LLM-enabled flavour of Atlassian Jira.

I would be thrilled to chat at length about any of those,  where would you like to start?

AI: That's fascinating - you're really immersed in AI both as your subject matter and as your daily toolkit. I'd love to hear more about how these LLM tools have changed your actual work experience.

You mentioned using LLMs for research, planning, and learning over the past year and a half. Can you walk me through what a typical interaction looks like when you're using these tools for your professional development or planning work?

User: Absolutely.

As I am both a technical and business senior leader (around the director/tech-lead level), I am being continually asked to contribute strategy as well as take ownership for specific business and technical outcomes.

This naturally involves a lot of learning.

Parts of my workload at times also deal with internal and external consulting, which also involves a lot of learning.
I have maintained an OpenAI ChatGPT Pro license for some time, and my biggest reason for doing so and the feature I get the most value out of is their brand of Deep Research.
Whereas in years prior, I would find myself buying and reading 4-6 books a month, both technical and business. I now find myself writing custom requests to Deep Research to write many on-demand, highly customized chapter-length summaries on topics I urgently need to learn more about.

These topics can be at times scientific (I routinely ask for annotated bibliographies of published academic material), technical (specific details regarding frameworks, software features, cloud integration patterns, etc), business (research into various companies, their strategies and market position, differentiations), and even the news (for one client I was doing a lot of review of high impact events regarding incident response in the E-Health Records space).

I find Deep Research stands out in it's utility as it can meet you where you are -- authors, when they write blogs, books, and papers, are writing for an audience that can be at times too wide (lay person, up), or too narrow (PhD level niche scientific papers) -- but with Deep Research, you can specify where your current understanding and level is in the field, and ask for the composition of a research artifact that is meant to accomplish a specific goal (I want to go from A to B, in this area, for this reason, given where I a currently am).

Deep Research is also capable of providing worked software examples and tends to be the most reliable and thorough in terms of hallucinations, errors, and omissions out of all LLM tooling I have used so far.
 
I typically will take a small bundle of 1-4 of these chapter length outputs, print them out, and read them before bed in the hottub of the building where I live. The next morning, before my day starts, I will ask for follow ups, and continue.

I also find myself sometimes making requests during the day, and even sometimes while I am at the gym, between sets. 

Was that helpful? Are there additional details regarding any of the above that would be useful?

AI: That's really helpful - I can see how you've essentially created a personalized, on-demand learning system that adapts to your exact level and needs. The detail about printing them out and reading in the hot tub, then following up the next morning, paints a vivid picture of how this fits into your life.

I'm curious about something you mentioned - you said you used to buy and read 4-6 books a month, but now you're using Deep Research instead. How do you think about that shift? What has changed for you in terms of the learning experience itself?

User: I think it's great. My condo is mostly a library at this point - books are expensive to buy, expensive to store, and expensive to move.

I still read books a lot, but it's nice to have less professional pressure to buy them.

I feel considerably less pressure to retain the output from Deep Research, I typically recycle whatever I have read a few weeks after the project is over.

Some books were very, very expensive, and often had overlapping coverage. For example, Frank Fabozzi has a number of books in Fixed Income, many of them authoritative, but sometimes the differences between the material covered is minimal comapred to the same shared background that gets repeated. Similarly for volatility modeling and options and other topics in quantiative finance -- I have seperate books I had to buy on the volatility smile, with some key differences, but a lot of overlap. I don't like to leave pages unread, as a large part of my career success had to do with leveraging small details left in the footnotes, but it is also nice to just have something very directed in my hands to read, thanks to Deep Research.

I also can use Deep Research for specific outcomes that no one would write a book on; as in, having done a number of projects in React Remix at one point in my career, I requested a few times guides to help explain how to get started with Next.js, but in terms of the features I already knew from working with Remix. 

I most value this tailored approach. I also love that I can specify the length, detail, and level of what I need. Sometimes you only want a brief 2-3 page introduction, other times something closer to 30-40 pages of dense technical coverage at a deeper level.

Actual Examples:


```
I am going to be starting with a group that is setting up a net new solution for Market Making Coverage over a new Equity listing on a stock exchange (similar to NASDAQ/ISLAND/ARCA), we want to use machine learning to manage risk and maximize returns, can you give me a literature review and breakdown of the various models and solutions. Please provide all citations. We want about 50 pages of research written on the subject.
ChatGPT said:

Thanks for the context. To create a comprehensive 50-page literature review on machine learning solutions for market making on a new equity listing, could you please clarify a few things:

What is your preferred focus for ML techniques? Should we prioritize Reinforcement Learning, or also cover Supervised, Unsupervised, and Hybrid models?

Are you primarily interested in centralized exchange market making (like NASDAQ/ARCA), or should we include DeFi/AMM models as well?

Should we include implementation considerations like data sources, latency, regulatory compliance, and infrastructure?

Do you want comparative analysis of traditional market making models (e.g., Avellaneda-Stoikov) vs. ML-based ones?

What level of technical depth do you expect—e.g., math derivations, pseudocode, or more conceptual summaries?

Let me know so I can tailor the research accordingly.

You said:
1. Everything.
2. Centralized exchange market making
3. Yes.
4. Yes.
5. Everything.

```



```
Wow, that was really helpful - can you review the above and provide additional research and commentary on the room for innovation in offerings for field level encryption and compression as it relates to EHR - do Azure or AWS already offer this in block or managed storage (db)?
ChatGPT said:

Great to hear that you found the information helpful! For further research, could you clarify whether you're specifically looking for:

Innovations in field-level encryption and how it could be improved for EHRs (e.g., better performance, usability, integration with identity-based access control)?

Advancements in compression for EHR data (e.g., AI-driven compression, better methods for medical images, structured data compression)?

Existing offerings by Azure, AWS, and other cloud providers: Are you mainly interested in managed database encryption (like AWS KMS/Azure Key Vault), or are you looking for new offerings they might be introducing for field-level encryption or compression?

Are you also interested in security trade-offs and challenges (e.g., performance overhead of field encryption, interoperability constraints in EHR systems)?

Let me know so I can refine the research accordingly!

You said:
Yes to all above.
```


Was that helpful? Is any other detail regarding to the above required?

AI: That's incredibly detailed and helpful - thank you for sharing those actual examples. I can really see how you're using it as a sophisticated research tool that goes far beyond what any single book could offer.

I'm curious about your preferences when working with AI. You've described this deep integration with LLMs for research and learning, but are there certain tasks in your work that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: Yes -- corporate writing and design.

I find that while I can use LLMs to contribute to large blocks of code and config files, LLMs are not as great at writing documents to be shared with others, especially in a business context.
I recently produced a 35 page written technical document for a team, and gave a workshop that went along with it, which I wrote entirely by hand.

Interestingly, most AI/LLM models have specific tones and styles, which often have tell-tale signs of being non-human. There is a strong bias against LLM-generated work, even if many groups are actively promoting the use of LLMs as much as possible inside the organization.

When possible, I try to have human-facing deliverables be handwritten. However, I will often have it reviewed by an LLM for errors, omissions, and potential improvements.

AI: That's a really interesting distinction you're making - the human-facing versus internal work divide. It sounds like you've observed a real tension in organizations where they're encouraging LLM use but there's still bias against LLM-generated content when it's public-facing.

When you use AI for work, could you describe your typical interaction pattern with something like your IDE tools or the research work? Are you more likely to collaborate with it back-and-forth throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I do a lot of technical work in Cursor and various JetBrains IDEs (PyCharm, WebStorm, GoLand, IntelliJ). 

In Cursor I typically have a back-and-forth series of exchanges. I ask for something, review and refine it, ask for the next change, and iterate. It is very rare, even with the first-in-class models from each vendor, that any LLM gets anything correct on the first attempt. So the collaboration is much more close.

Although, for web-based interface work, I often ask for some starter resources (give me an IPython notebook for xyz), and I can delegate and get the output I am expecting.

I would love to be able to delegate more, and I try to give large requests, but often am forced to break them down into smaller peices and go through several refinements along the way.

AI: That matches what I'm hearing from a lot of people - this iterative refinement process rather than one-shot delegation. It sounds like you've developed a pretty smooth workflow for breaking things down and iterating.

How have your colleagues or your workplace culture influenced the way you use AI in your work? You mentioned that bias against LLM-generated content earlier - I'm curious how that plays out in your day-to-day interactions.

User: Yes, there is a strong bias, even from people who actively use the tools themselves, but also from some senior staff who don't.

There is a general perception that anything that has the signs of being written by LLMs is AI-slop until proven otherwise. 

It has given rise to strange corporate politics for me in the last few months as I adjust and right-size my use and workflows with various groups and teams I work with. 

I deeply regret admitting that I used certain tools in certain circumstances, as I felt some people in the organization used it against me behind closed doors.

AI: That sounds like a really challenging position to be in - especially when you're getting value from these tools but then facing political consequences for being transparent about using them. That tension between the practical benefits and the workplace perceptions must be frustrating.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Oh, yes, for sure.
 
Especially satisfied.
 
I recently was staffed part-time for a client to help out with a corporate-sponsored hackathon.
 
There was meant to be a team of 4, with two full-time senior leadership members, and two part-time contractors (myself and another).
 
It was in the Agentic space, and it was for an incubator who had backed this client with a 7 figure sum, so it was pretty high impact for them.
 
Needless to say, due to circumstances, the two full time employees had family and health crises come up, and the other part-time staffer had something else happen in their career and they had to leave after 1 week.
 
So I went from being one non-FTE staffed consultant to being the only person working on this project. Needless to say, over the next 3 weeks, I prototyped, designed, deployed and demo'd a 50K line solution, written in three programming languages, composed of 3 microservices, deployed on Azure, full test coverage, fully QA'd and running with realtime, actual client data.
 
We just found out that it came first place in the hackathon.
 
It was entirely done with LLM-enabled tooling. Given the circumstances, I didn't have much time to nit-pick over the outputs; I didn't even have a full 40 hours each week to work on it.
 
It was a huge success, but I look back at my career, and there were fully senior staffed agile teams of 8 which worked for more than a full quarter to produce something less completely than that outcome.
 
These tools are completely transformative to what is possible for ICs, and by extension, lean organizations.


Is that the sort of detail you were hoping for?

AI: That's an incredible example - going from a four-person team to a solo effort and still delivering a winning solution in three weeks. The scale of what you accomplished really drives home your point about the transformative potential.

I'm curious about something you touched on - you mentioned not having time to "nit-pick over the outputs" in that situation. How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, or does your background in AI/ML give you a different perspective on this?

User: It is a bit of a risk.

But I am not too worried. I still spend a lot of time upskilling.

The more AI enables productivity, the more ready I will be to capitalize on it in the market.
Businesses and leadership really struggle with using and understanding these tools effectively, so I see my market growing.

AI tooling is also accelerating the speed of my learning and exposure to various technical topics, and has opened a lot of doors into areas I would have hesitated to touch in years prior.

For example: 
Most of my career was on the numerical computing and back-end side of software development: software services, data pipelines, and data science. For years, I avoided front-end frameworks like the plague, until in 2023, I was promoted to "Lead Developer for The Integrations Team" -- an enterprise client-facing role to build new products and offerings for client onboarding and platform engineering -- this was for an ML-powered E-commerce Search solution company (a market leader). Still, despite gaining some full-stack exposure and skills when forced, I would never have thought to write complex and interactive custom React components, preferring instead to search out specific talent from other team members or contractors if required. Now, I have written dozens of them, and they do not intimidate or give me pause in the slightest.

AI: That's a great perspective - using AI as a learning accelerator rather than worrying about replacement. Your example about React components really illustrates how these tools can break down barriers to exploring new areas.

Looking ahead, how do you envision your relationship with AI at work evolving? Given everything you've shared about your current usage and the success you've had, where do you see this heading for you personally?

User: Yes, I do see my workflows evolving in the very near future, I have it on my personal development roadmap to start experimenting with some of the Agent offerings from various vendors, and seeing where and how they can help.

I have a small business I also run on the side, and I never have enough time for it, I see a lot of potential to expand offerings and especially get more done with respect to marketing and online footprint. (Adding a client area to the website with hosted resources, etc). 

I also see more of my client interactions and project management being taken over by AI enabled tools. For example, this week will be my first week where I will use my clients tools to write and share an end of week progress update on their projects (report on which tickets moved from which statuses, etc). 

I suspect we're still in a very early inning in terms of how we work with these tools and their capabilities. 

The offerings from various vendors evolve on a week by week basis; and so to does our use and ability to capitalize on these new features.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how AI has become both your subject matter expertise and your daily toolkit - that hackathon story really demonstrated the transformative potential you're describing.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Hmmmm, I don't think so -- but do reach out if you ever want to continue this conversation. I can't provide any details. But talk to your project manager about if it would be possible.

I really enjoyed the chance to reflect and share - this was so much fun - I hope this data and input will be very useful for your team and group in the future.

AI: Thank you so much for your time and for sharing your experiences so openly. Your insights about the transformative potential of these tools, the workplace dynamics around AI adoption, and especially that incredible hackathon example will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how thoughtfully you reflected on everything from the learning acceleration benefits to the corporate politics challenges - it gives us such a rich picture of what AI integration actually looks like for someone at your level.

Thanks again for such an engaging conversation!
