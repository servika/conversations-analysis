# Dialog 00297

**Transcript ID:** work_0588

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: I don't have any questions for now.

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use it to lesson plan. AI makes it easier to create powerpoints quickly. Usually, I will do the fine-tuning of the graphics, but AI helps organize information that I give it into slides. I have also used it to second check grading student papers, just to see what the models say and avoid bias. I do most of the grading myself, but it helps to have a second pair of eyes in case I miss anything.

AI: That's really interesting - it sounds like you're using AI both for content creation and as a quality assurance tool. 

When you're creating those PowerPoints, tell me more about that process. How do you typically interact with the AI to get from your initial information to organized slides?

User: So far, I have just given the model the information I want to cover in class and AI provides a powerpoint as feedback. It has done a fairly good job so far. I sometimes have to go through and edit some of the word choices that don't sound as natural, but overall the content is organized well. This is typically just a one or two turn exchange between me and the model.

AI: That's helpful to understand. So it sounds like you give the information upfront and then do your editing work afterward, rather than going back and forth during the creation process.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: I do the writing myself when it comes to research papers for obvious reasons. Sometimes I will use AI to brainstorm or see what it can trace as far as what has been written on a given topic. But the writing itself and development of an argument are something that as an academic I need to do myself. Both for ethical reasons and personal development in the skill of developing my own thoughts on a topic.

AI: That distinction you're making is really thoughtful - using AI for brainstorming and research discovery but keeping the actual argument development and writing as your own work.

When you do use AI for that brainstorming or to explore what's been written on a topic, can you walk me through what that interaction looks like? Are you bouncing ideas back and forth with it, or is it more of a one-time information gathering exercise?

User: I do more of the bouncing back and forth kind of interaction. Sometimes the model won't quite understand what I am asking for (either because I explained it poorly or it's a niche topic). Sometimes the model provides information that may spark an idea or area I didn't consider. And so I follow up with a prompt in that given area.

AI: That back-and-forth pattern sounds quite different from the PowerPoint creation you described earlier. It seems like for research brainstorming you're more in a collaborative mode, while for lesson planning it's more of a delegation approach.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find yourself discussing AI use with other faculty members, or is it something you've navigated more independently?

User: I have navigated this more independently. Using AI is more taboo in my area (religious studies) because of fears surrounding it. Some of them have to do with our view of what human beings are and whether LLMs (and the concept of artificial intelligence itself) undermines human identity as rational creatures. Others are wary of the collection of data and how it's being used. There are many reasons for opposition to AI from them, some of which I find quite understandable. Others I find exaggerated. To me, AI is a powerful tool that can definitely shape and influence a discipline in unforeseeable ways (both good and bad), but I think it is best to understand how the tool works first-hand. Other colleague friends I have outside of my area are more willing to use AI. Some of them are more of what I would call AI optimists. I try my best to be a realist, understanding the gifts of the tool for students and teachers alike while also noting how the tool can be misused (plagiarism, the forfeiting of critical thinking). There is a bit of a cancel culture right now when it comes to AI use vs. AI prohibition. I think the polarization has made it difficult for people with concerns from both ends of the spectrum being able to have intelligent, productive conversations. I am pretty open to people having different views of this as long as they are open to conversation. Unfortunately, there aren't many.

AI: You've painted a really nuanced picture of navigating AI use in an environment where there are strong philosophical and practical concerns. It sounds like you're operating somewhat in isolation when it comes to AI use, which must create some interesting dynamics.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: The one time I can recall right now when I was dissatisfied was when I used an AI model to create a powerpoint, but it wouldn't let me download it. I've since then stopped using that model for powerpoints even though I find it more helpful for other tasks such as brainstorming. The powerpoint thing was mostly frustrating because I was in a bit of a time crunch. I was able to figure it out though because the model provided code for the powerpoint I could then use to create it.

AI: That's a great example of how technical limitations can create real friction, especially when you're under time pressure. It's interesting that you found a workaround with the code, but it sounds like that experience was significant enough to change which tool you use for that specific task.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I do. A lot actually. I've wondered about how AI will impact the job market and impact careers that currently pay well and are fairly accessible. Right now, areas like the humanities (including religious studies) do seem safer when it comes to AI not being able to replace humans so continuing my studies in that area seems like a possibly safe route. On the other hand, the centrality of AI could influence economics and what jobs are most in demand. Humanities careers are already on the decline due to the demand for STEM-based subjects. I happen to be skilled in both, though I gravitate more towards the humanities and religious studies in particular due to my ethical and life values. I've considered honing my STEM knowledge more, particularly coding and mathematics, but I have been a bit discouraged hearing about other sectors no longer needing to know code as much because of AI now.

AI: That tension you're describing between following your passions in humanities versus the practical concerns about AI's impact on different fields sounds really challenging to navigate. The uncertainty around which skills will remain valuable seems to be influencing some pretty fundamental career decisions for you.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I plan on understanding the tool better. I would like to get to a point where I understand it better to help me with planning presentations for class. Beyond the one turn exchange of creating a powerpoint, it would be good to find a way to see how the tool could help me engage my students in the classroom more. Powerpoints can be helpful, but for a lot of students they just get sleepy and bored.

AI: That's a really thoughtful direction - moving beyond just content organization to thinking about student engagement. It sounds like you see potential for AI to help with the more interactive aspects of teaching, not just the preparation side.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on navigating AI use in an environment with strong philosophical concerns, and how you're thinking strategically about both the immediate practical benefits and the longer-term implications for your field and career.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: So part of my work involves teaching. The other side is more admin assisting (helping with documents, budgets, minutes, etc.). I have been more hesitant to use AI in this area because of the privacy of data being used. I try to avoid this with my classes by removing PII. This would be more difficult with the admin side though. I'd like to try to use AI to help with, for example, cleaning up syllabi, but at this point I am not sure I feel it is safe.

AI: That's a really important point about the different privacy considerations between teaching and administrative work. It sounds like you've found ways to work around privacy concerns for lesson planning by removing personally identifiable information, but the administrative documents present a much more complex challenge.

Thank you again for your time and for sharing your experiences so openly. Your insights about navigating AI use in academia, especially in a field with philosophical concerns about AI, and the practical challenges around privacy and data security will be incredibly helpful for our research on human-AI interaction in professional contexts.
