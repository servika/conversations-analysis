# Dialog 00200

**Transcript ID:** work_0334

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Sounds good.

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: My main use of AI during a workday is to generate boilerplate code. Particularly for things like Terraform where there's a lot of stuff that's very similar every time but is quite fiddly to setup from scratch.

Sometime I'll also use it to generate unit tests for existing code.  I use this fairly often to where the existing coverage is bad and I don't have a good set of test scenarios already to hand.

AI: That's really helpful context. When you're working with AI to generate that Terraform boilerplate or unit tests, can you walk me through what that process typically looks like for you? Are you working back and forth with the AI to refine what it gives you, or do you usually get what you need in one go?

User: I usually try and pack the initial prompt with enough detail that it's completed in one shot. I've had bad luck trying to steer things back in the right direction across multiple turns, so if i do need to refine things I'll update the initial prompt and start the conversation again.

A couple of times I've had a conversation for unit test generation to work out what the tests will be then use a new conversation & expanded prompt to implement the final test suite.

AI: That's interesting - you've found a strategy that works for you by frontloading the detail rather than iterating. 

When you're deciding what to include in your work, are there certain coding tasks you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different from the Terraform and unit test work you delegate?

User: I prefer to implement the main business logic myself that way I know there's at least one person who can talk through the logic. It also means I know it fits in with the desired application architecture.

AI: That makes a lot of sense - keeping ownership of the core logic for both knowledge retention and architectural consistency.

Thinking about your workplace more broadly, how have your colleagues or your workplace culture influenced the way you use AI in your work? Are others using it similarly, or have you noticed different approaches?

User: I think everyone really develops their own style in terms of how they use it. Within work it's mostly been as an assistant, generating the repetitive code blocks or one off throwaway scripts. However we're about to get given corporate access to more and so I expect the usage to grow with that. We'll then see some attempts at more agentic style where a feature is autonomously generated.

AI: That transition from individual assistant-style use to potentially more autonomous feature generation sounds like a significant shift. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: The best satisfaction comes from the prompt and response hitting the mark first time. Especially when the 5 mins to prompt and get an answer has saved a couple of hours of wiring up a bundle of interlinked Terraform resources that you'll inevitably have check over for typos and other small mistakes.

The biggest frustrations have happened when I have used multi-turn conversations either for unit tests or experimenting with feature generation and it just doesn't get something. I'll usually end up with all sorts of unrelated changes but the issue left untouched despite being explicit about the problem.

AI: That frustration with multi-turn conversations losing focus really comes through - it sounds like those experiences reinforced your preference for the detailed single-prompt approach.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: My usage at the moment is really comparatively basic in terms of what I get the AI to generate.   Mostly it's automating the writing of what would otherwise be the tedious simple stuff rather than the truly complex work involving business logic or implementation specifics.

Since I end up being the first line of review, if anything I need to be extra vigilant about ensuring that my skills are well practiced and my understanding deep. If I'm reviewing AI output for inclusion into production systems I need to be able to very quickly understand what has been produced and identify if it is truly correct.

AI: That's a really thoughtful perspective - using AI for the tedious parts while staying sharp on the complex work since you're the quality gate.

Looking ahead, how do you envision your relationship with AI at work evolving? Especially given that corporate access expansion you mentioned earlier?

User: I'll probably start experimenting more with letting it implement the main logic. I'll keep the leash short so to speak by providing stub implementations etc and other very strong constraints  so that I'm confident it will implement something in the same style as the existing architecture.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your strategic approach to prompt design and how you're thinking about maintaining oversight as a quality gate even as you potentially expand AI's role.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: That's everything

AI: Perfect! Thank you again for your time and for sharing your experiences so openly. Your insights about developing effective prompting strategies, the importance of maintaining technical oversight, and how you're thinking about gradually expanding AI's role while keeping strong constraints will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk me through your approach today.
