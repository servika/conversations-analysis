# Dialog 00075

**Transcript ID:** science_0087

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: that sounds good to me

AI: Great! Let's dive right in then.

To start, I'd love to hear about your work. Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: I am a physics researcher specifically quantum physics. My most recent work was in a theoretical description of a 2-level quantum emitter (a qubit). A new excitation protocol was tested against traditional methods in various situations (noise energy losses etc) and their differences were compared

AI: That sounds like fascinating work! I'm getting a picture of the theoretical side - developing and testing this new excitation protocol.

Can you walk me through what the actual day-to-day process looked like? How did you go from that initial idea about the new protocol to having results you could compare?

User: I began by reading the relevant literature, introductory quantum optics textbooks and some research papers, then I would try to recreate the plots from the research papers by coding in python, thats the main day-to-day. After getting comfortable with the new coding libraries like Qutip, I was ready to make new investigations, such as varying the transition frequency with time to explore new effects.

AI: That gives me a really clear picture of your workflow - from literature review, to recreating existing results in code, to then exploring new variations. The coding in Python with libraries like Qutip sounds like a central part of your process.

Where in that process, if anywhere, have you experimented with using AI tools?

User: I experimented with AI in the literature review, just basic things like having ai explain some basic topics and give examples, and help me find relevant papers. Also I would have AI explain things to me about QuTip, such as time dependent Hamiltonians, if it was fully explained in the QuTip manual. I also found AI helpful in writing with LaTeX as some of the commands can be confusing there.

AI: Interesting - so AI helped with understanding concepts, finding resources, and technical writing support. Let me focus on one of those areas. For the literature review part where you used AI to explain basic topics and help find relevant papers - tell me about how you decided whether to use AI versus your traditional approach for those tasks.

User: I would never solely use AI for these tasks. For the literature review I would use AI suggestions as a springboard to do my own research and I would verify that the papers it suggested were real, relevant and reputable. A more traditional approach would be to use websites like ArXiv etc or some newer websites like connectedpapers.

AI: That's a really thoughtful approach - using AI as a starting point but then doing your own verification. It sounds like you've found a balance between leveraging AI's suggestions while maintaining your own critical evaluation.

Thinking about the parts of your research where you haven't used AI - like the actual coding of new investigations or the theoretical modeling - what's kept you from trying it there?

User: Sometimes I would test the AI's ability to code but it performed very poorly, also I feel like that is my responsibility and I would not want to rely on an AI model to do my job. Also I have used AI's before with newer libraries like QuTip and Qiskit and the Ai's knowledge is usually out of date and not very useful.

AI: That makes a lot of sense - both the performance issues and the philosophical point about it being your responsibility as a researcher. The outdated knowledge with newer libraries like QuTip and Qiskit sounds particularly frustrating when you're working with cutting-edge tools.

When you have used AI for those areas where it was helpful - like explaining basic concepts or LaTeX commands - how do you verify or validate what it produces?

User: For explaining basic concepts, I would already have some understanding so the AI just helped clear things up and explain connections to other areas of physics I was knowledgeable in. For LaTeX commands if the LaTeX document looked good and had everything I wanted then that was all the validation I needed.

AI: That's a smart approach - leveraging your existing knowledge as a filter for the concept explanations, and having clear visual feedback for the LaTeX outputs.

We're about halfway through our conversation now. Let me ask you this: if you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: I think if it could teach me to code in new environments what I wanted perfectly and fully optimised that would be great. Also if it could tell me my ideas may work but would not interesting enough for a paper submission, and offer alternatives or improvements that would be good.

AI: Those are both really compelling use cases - having AI as a perfect coding tutor for new environments, and as a research advisor that could evaluate the novelty and interest level of ideas. The second one especially sounds like it could save a lot of time and help with strategic research decisions.

Those are all my main questions. Your perspective on using AI as a verification tool rather than a primary research method, and the challenges you've faced with outdated knowledge in specialized libraries, were particularly insightful.

Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: I think a truly strong AI tool that would be incredibly useful for researchers must be more honest. It must tell researchers that it doesnt knwo the answer, and that cant help with some tasks, in the same way that even a supervisor would not be able to help a reseracher in some cases.

AI: That's such an important point - the need for AI to be more honest about its limitations and knowledge gaps. That honesty would actually make it more trustworthy and useful as a research tool, rather than potentially misleading researchers or wasting their time.

Thank you so much for sharing your experiences so openly today. Your insights about maintaining your responsibility as a researcher while strategically using AI as a starting point, and especially that final point about the importance of AI honesty, really help us understand the nuances of how AI can fit into real scientific work.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. I really appreciate the time you've given me today.

User: ok am i done here

AI: Yes, you're all done! Thank you again for your time and thoughtful responses. This was really helpful for our research. Have a great rest of your day!
