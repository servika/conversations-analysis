# Dialog 01045

**Transcript ID:** work_0907

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: lets begin

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I do a lot of software development and data engineering in my day to day work. However, this means I also work with sensitive data. So I use AI a lot for small tasks to help me, but I do not use AI to completely do my job. I use it as a tool. I will ask syntax questions or something for it to write me a basic code block that I then modify for my actual use. Other times I use it to write functions to simplify repetitive tasks. I also use it for basic email drafting.

AI: That's really helpful context. You mentioned using AI for syntax questions and basic code blocks that you then modify - can you walk me through what that process typically looks like? How do you decide what parts to keep versus what needs changing when you get that initial code back?

User: Sure, maybe in SQL I want to list_agg, but I know I use an older version that doesn't have that syntax built in so I will ask the model to draw up a simplified version based on my real needs. Something like, 'say I have tableA and tableB and tableA.col1 matches tableB.col1 and I want to list aggregate tableB.col5 but using an older version of SQL so I want you to do that using stuff and xml'. This way it can help assist me but has no sensitive information at all. It means I do not have to remember the complex use of xml and stuff. It helps with the syntax of it all. I always check all the code returned to me because we are not at the point I can just trust AI models. Usually I will see right away if it does the thing I want it to do. Othertimes, it might return an error and I will ask the AI for help fixing the error. When i get the results back, I fill in the dummy info with the actual table names, and keep the real syntax. Does that answer your question or would you like me to clarify something?

AI: That's a really clear example, thank you. I'm particularly interested in how you handle that balance between getting help and maintaining control. You mentioned you always check the code because "we are not at the point I can just trust AI models." 

What does that checking process look like for you? How do you evaluate whether the code is doing what you want it to do?

User: I have several years of software delevopment expereince from my job, as well as having gone to college for it. Even if I do not know the syntax of a language enough to write it without help, I have a pretty good general understanding of code syntax. That means I typically understand what the code is doing. Of course, sometimes it uses a function I do not know. In that case, I usually ask follow-up questions about it and ask for real links to back it up. This way I do my own research too. Often it looks like the code is in-line with what I am trying to achieve, but sometimes there are small errors that means it doesn't achieve what I want it to do; this could be due to a syntax error or a misunderstanding. In this case, I will usually clarify with the model, tell it what it did wrong, and ask it to ask me any clarifying questions. So, I manually check it myself and I check it again when I try to run it in my real context. Both the checking and the evaluating and multi-step processes.

AI: That multi-step verification process sounds really thorough. You mentioned that sometimes there are small errors due to syntax issues or misunderstandings, and you'll go back to clarify with the model.

When you're in that back-and-forth clarification process with the AI, what tends to cause those misunderstandings? Are there patterns you've noticed in where the disconnect usually happens?

User: The most common ones I have noticed are due to either my lack of clarification when giving the model the initial task, and the model not remember/knowing the specifics of the version I am using. Those are for sure the two most common that I have noticed. Frequently I need to remind the model the version I am using and make sure it double checks the version syntax and information. The model will absolutely write something, and then I ask are you sure it works with this version, and then it corrects itself. But I often need to bring it up again. I also find that when conversations get too long, th model will not remember every requirement specified earlier in the chat.

AI: That's really insightful about the version specificity and memory issues in longer conversations. You mentioned that when conversations get too long, the model forgets earlier requirements.

How do you handle that practically? Do you start fresh conversations, or have you developed other strategies to work around those memory limitations?

User: Sometimes it has helped me enough in my task that I power through using the existing chat; sometimes I just finish it myself. But usually I will need to start a new chat.

AI: That makes sense - it sounds like you've developed a good sense of when it's worth continuing versus starting fresh.

I'm curious about your preferences when working with AI. You mentioned there are tasks you prefer to handle yourself even though AI could help. What makes those tasks different for you?

User: I enjoy the work I do and I have lots of experience doing it. AI has definitely helped to me coding easier and more accessible. It has helped me learn so much! But its faster sometimes for me to type the code out myself because I know how to do it that it is for me to type the instructions into an AI model and then try to correct what it wrote. Additionally, there are tasks I would like AI to help with, but I am unable to use it due to my company's privacy policy which I respect. However, sometimes I feel like I just need to challenge my brain. If I do not use my brain to think for myself, I will lose my knowledge. Does that make sense?

AI: That absolutely makes sense. You touched on something really interesting there - the concern about maintaining your own skills and knowledge. 

Can you tell me more about how you think about that balance? How do you decide when to challenge your brain versus when to let AI help with something you could do yourself?

User: I think that, well, at the end of the day this is my job and my livelihood. Without my job I would starve. I need to output results so the company does not fire me and so that the company can continue to grow and not be bankrupt. AI definitely helps with my output and allows me to be productive in ways I didn't think about before. It can save tons of time! But if it is something simple, I will do it myself. It also depends on how I feel at the moment. If I got little sleep the night before, I might use AI more because I am just tired. Or if the work is boring, I might use AI to help speed it up and get it done. But if the work is interesting and I am invested in it, I might only use AI to ask it syntax questions instead of having it write the whole thing. Really, I guess it totally depends.

AI: That's a really honest and nuanced way of thinking about it - how your energy level, interest in the task, and even your mood influences when you reach for AI help.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I like collaborating with it much more than delegating. Part of that is due to the company security and privacy policy where I actually cannot just delegeate tasks to AI because that would compromise private information. But I like collaborating because that way I can learn more. That is the win-win for me. I learn new things, I still need to use my brain, I feel more productive on an emotional level because I have a hand in the actual work instead of delegating, and I have a greater level of control and input in the outcome of the task.

AI: That collaborative approach sounds really fulfilling for you. You mentioned that it makes you feel more productive on an emotional level because you have a hand in the actual work.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: One time, a task of mine was to use a new language. I didn't know the syntax of the new language, so initially I was asking AI to write most of the code in the new language. However, I would constantly ask about the syntax, so now I can even write it myself. That definitely felt good to get that new language under my belt. AI can be incredible in situations like that for sure. It felt really good to be able to accomplish that task that was given to me, and I definitely could not have done it without ai

AI: That sounds like a really rewarding experience - using AI as a learning partner to master a new language. It's interesting how it evolved from you asking AI to write most of the code to you being able to write it yourself.

How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: Like I mentioned previously, the workplace culture does not encourage the use of AI because it is limiting what we can use AI for because they do not want sensitive information to be leaked. But working in IT, my colleagues use AI and encourage the use of it up to a certain level. We all believe it is a great tool that can increase productivity. But we all are also aware that AI is not perfect, so we must review the AI work ourselves.

AI: That makes sense - it sounds like there's this interesting tension between IT colleagues seeing the value while the broader workplace policy creates limitations.

You mentioned that you and your colleagues all believe AI is a great productivity tool but also that it's not perfect and needs review. 

Looking ahead, how do you envision your relationship with AI at work evolving?

User: If the workplace is able to incorporate an AI that will not risk the exposure of sensitive information and that is sanctioned by the company, I think it would be a huge win. But I also think this is a large task. I will continue to use it in my every-day work as it still helps me. I hope the AI models will get better and better so we have to spend less time debugging the code it outputs. Does that help? AI is like stackoverflow but better

AI: That's a great analogy - "AI is like stackoverflow but better." That really captures how you see it fitting into your workflow.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI as a collaborative learning partner and how you balance maintaining your own skills with leveraging AI's capabilities.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Thanks! I think those are all the main points to cover. But I will say that right now Ai is in the developmental stage where it is learning and training from data. That is why we cannot share sensitive information at my company. I hope it becomes accessible in a way where a company could have its own 'instance' of AI withut worrying over security risk aspects of it. That is where it could be exceptionally useful I think. I believe that one day we will get there!

AI: That's a really insightful point about the future potential of having company-specific AI instances that could handle sensitive data safely. It sounds like that would unlock a lot more possibilities for how you and your colleagues could integrate AI into your work.

Thank you again for your time and for sharing your experiences so openly. Your insights about the collaborative approach to AI, the learning benefits, and the practical challenges around security and version-specific issues will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how thoughtful and detailed you were in describing your actual day-to-day experiences with AI tools.
