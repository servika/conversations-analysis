# Dialog 00469

**Transcript ID:** work_0032

---

Assistant: Hi there! I'm Claude, and I'm here representing Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: No questions, thanks. I'm eager to begin.

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: As a teacher, I use AI throughout my workday so much. For example, I use it help me plan my lessons and actually write out my lesson plans. I use it to create very specific resources I need for targeted lessons. I love, love, love using it to scaffold writing exercises. I enjoy using it to create assessments aligned with my learning standards, DOK levels, and having the AI mimic the state test in structure. That saves me SO much time. I use it to brainstorm ideas too. I even teach my students how to use it for brainstorming, editing help, studying, etc. in ethical ways that helps them learn in a personalized way.

AI: That's fascinating - it sounds like AI has become deeply integrated into multiple aspects of your teaching practice. You mentioned using it to scaffold writing exercises specifically. Tell me more about that. What does that process look like for you?

User: Usually it looks like this: I provide a text for the AI, often a literary classic like "Annabelle Lee" or maybe something longer like "Lamb to the Slaughter" and ask the AI to create a writing prompt built the same way the [REDACTED] state writing test ([REDACTED]) structures its writing prompts. I will give it a writing standard to design the prompt around. Then I ask it to provide students guiding questions and/or provide sentence starters for scaffolding the writing process. This can be very basic scaffolding or more extensive depending on the writing abilities and goals of the students I am making the writing exercises for.

AI: That's a really detailed process. When you're working with AI to create these scaffolded writing exercises, how much back-and-forth do you typically have? Are you giving it all those specifications upfront and getting what you need, or do you find yourself refining and adjusting the output together?

User: I usually load up everything in the first prompt and hope for the best, making changes with some back and forth if the AI forgot or devalued one of my specifications. Normally, going back and forth 8-12 rounds is fairly normal, but to be fair, I am incredibly nitpicky about the result. I am rather demanding about the end product and am adamant about getting the exact result I want.

There are times when the AI gets it right, or only needs a minor tweak or two, but I do usually have 8-12 rounds of back and forth for sure.

AI: That's really interesting - 8-12 rounds shows you're willing to invest significant time to get exactly what you need. When you say you're "incredibly nitpicky" and "demanding about the end product," what specific things are you usually going back to refine? What details matter most to you in getting it just right?

User: Often I will have the AI chatbot adjust for rigor. AI tends to make prompts a bit too complex or a bit too simple, and I have to help it find the right rigor (DOK, Lexile).  I also have to watch for how well the prompt aligns with the standard because that can be a miss for AI at times. It's important to use the scaffolding guide for my state to create assessments or writing products, along with the state test examples. Often, I will provide those for the AI if it's struggling with that. Another problem I often see is AI giving too much guidance and support or not nearly enough, so we will go back and forth for those corrections.

AI: You mentioned that AI sometimes misses the mark on standard alignment and rigor levels - those sound like areas where your expertise as a teacher is really crucial. Are there certain aspects of creating these materials where you prefer to handle things yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: Not usually, though that is mostly true with PowerPoints. I love PowerPoints and use them to guide the lesson often. AI usually produces a bare bones version that needs a lot of editing and doesn't look good. There are often double bullet points in them, no graphics, too simplistic, etc. By the time I fix all the problems in the PowerPoint, I still have to do most of the work to build it up. At that point, I could have just skipped fixing it and done it from scratch, so I usually make them from scratch myself. However, sometimes I will ask for a basic outline for my PPT project, or I'll have AI check it for typos and such after I make it.

AI: That makes perfect sense - it sounds like for PowerPoints, the time investment to fix the AI's output outweighs the benefit. I'm curious about your workplace context. How have your colleagues or your school's culture influenced the way you use AI in your work?

User: Our instructional coach brings up using AI here or there, but I am the teacher in the school who teaches everybody else how to use AI. Younger teachers are much more open to it.

AI: That's an interesting dynamic - you've become the go-to AI expert for your colleagues. Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Once I spent quite a bit of time going back and forth with the AI to create a rather large assessment that I needed ASAP. I spent the better part of my planning time creating it and had just a few minutes before students arrived to take it! Well, I asked the AI to put the assessment in a PDF format and send it back to me like that (we'd been working in the chat window only at that point). It did. I downloaded it, glanced quickly, and hit print. I ran to the bathroom in a rush before students would arrive thinking I'd have my copies ready when I got back. Sure enough, they were ready, so I took attendance. Only when I had students grab the copies off the printer and hand them out did I realize there was a problem: the PDF looked good on the first page, but half the questions were missing. Further, it had odd formatting that was difficult to read. I was incredibly frustrated because I counted on the AI and it failed when I really needed it to work.

AI: That sounds incredibly stressful - especially with students already there and ready to take the assessment. What did you end up doing in that moment? And how did that experience change how you approach using AI for time-sensitive tasks?

User: I had to leave my mischievous students to chat amongst themselves while I hurriedly tried to get a decent copy from the AI. It wasn't ideal to have students getting silly rather than immediately getting serious for their exam. Normally, I don't cut things so close with time, so that's rarely an issue. Every once in awhile in teaching, you end up in a similar spot though. It makes me nervous anticipating relying on AI when in a time crunch.

AI: That experience really highlights how much trust we can place in AI tools and what happens when that breaks down at a critical moment. How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I don't think you could use AI very well as a teacher unless you have the expertise to notice when the AI makes a mistake. I find I sharpen my skills when I'm judging AI using those same skills. I treat AI like a teacher assistant in many ways.

AI: That's a thoughtful perspective - treating AI like a teacher assistant. Looking ahead, how do you envision your relationship with AI at work evolving?

User: I hope I can use AI to create more attractive products in the future.  It's not great at that. I see a future where I continue to increase my work quality while decreasing my work time by using AI.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on treating AI like a teacher assistant and how you've become the AI expert for your colleagues - that shows how naturally you've integrated it while maintaining your professional expertise.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No thanks

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about the iterative process of refining AI outputs, the importance of teacher expertise in evaluating AI work, and how you've navigated both the successes and challenges will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!
