# Dialog 01205

**Transcript ID:** science_0004

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your research work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: This sounds good, what level of detail do you prefer for the responses?

AI: Great question! I'd love to hear as much detail as you're comfortable sharing. The more specific you can be about your actual experiences - the better. Think of concrete examples, specific moments, or particular projects when you can.

For instance, instead of "I sometimes use AI for data analysis," I'd be curious to hear something like "Last month when I was working on analyzing gene expression data, I tried using AI to identify patterns, and here's what happened..."

The goal is really to understand your real-world experience, so whatever level of detail feels natural to you as you're telling me about your work is perfect. Don't worry about being too verbose - I'm here to listen and learn from you.

Ready to dive in?

User: all right

AI: Perfect! Let's get started.

Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: recently I worked in a multidisciplinary team for the design and engineering of microbial strains with the goal of obtain a single strain capable to use multiple feedstocks to produce a chemical. I participated mostly in the computational design of the strain and to evaluate two potential host organisms for their feasibility as base framework for the construction of inducible genetic circuits. The research process comprised a major literature review to collect information about multiple feedstocks, theirs pathways, kinetic data, regulation and then integrate that information for the construction of genome scale models of the host organisms with the required reaction and pathways for assimilating the feedstock and to produce the target chemical. Then we estimated different parameters such as theoretical yield, yield under different conditions, energy and oxygen requirements and finally we used the estimated data to populate a techno-economical model for the evaluation of the process at industrial scale so we can evaluate the feasibility of the strategy at industrial level before to commit with the construction of the strain.

AI: That sounds like a really comprehensive computational workflow - from literature review all the way through to techno-economic modeling. That's quite a journey from initial concept to industrial feasibility assessment.

Where in that process, if anywhere, have you experimented with using AI tools?

User: Yes, we experimented with AI tools during the literature review , data extraction from websites, databases or papers, developing and organizing code for the computational analysis, fixing bug and verify calculations, to get information for the techno-economical model and in helping writing the technical report. I must say that this was some months ago, so the models we tested were not very helpful most of the time, but now I have seen improvements with the newer models.

AI: That's fascinating that you tried AI across so many different stages - from literature review all the way to report writing. You mentioned that the models weren't very helpful at the time but you've noticed improvements since then.

For one of those specific tasks you mentioned - let's say the literature review or data extraction - tell me about how you decided whether to use AI versus your traditional approach.

User: I decided to try AI because of the promise of speed up trivial or time consuming tasks such as scrapping websites looking for information to populate spreadsheets or extracting specific information such as metabolites, kinetic data, growth conditions from papers that it would take me much more time to read and analyze by my self.

AI: That makes a lot of sense - targeting those time-intensive tasks where you're looking for specific pieces of information. 

Tell me more about what happened when you actually tried using AI for those tasks. How did it go in practice compared to what you were hoping for?

User: I noticed that a simple prompt is not enough and the model had the trend to hallucinate, so it was detrimental for our process since we had to double check all the already extracted data. Even with simple tasks such as reading a website and get specific piece of information the model hallucinated. Since we where working in a team, most of the team members used simple prompts and the results were inconsistent. I prefer to take the task over all by my self and use advance prompting strategies such as provide the preprocessed text of the website and use a much more detailed prompt with specific instructions to avoid hallucinations. This was how I managed to make it work.

AI: That's a really insightful experience - it sounds like there was a real learning curve around prompting strategy, and that the team had different approaches that led to inconsistent results. When you say you used "advanced prompting strategies" and "specific instructions to avoid hallucinations," what did that look like in practice?

Can you give me an example of how you changed your approach to make it work better?

User: Sure, The simple or basic prompt that most of the team users used were giving a website link such as "[REDACTED]" and then ask to collect information to populate a spreadsheet that look like this:
id name metabolites stoichiometry gpr reversibility subsystem ec_number bigg_reaction kegg_pathway kegg_reaction_id metanetx_reaction_id pubmed rhea seed_reaction

Then some provided instructions such as do not hallucinate etc but still the results were inconsistent.
What I implemented was to preprocess the actual webpage content and provide it in the prompt, then I explained the spreadsheet format and provided examples of a couple of rows. I also added specific instructions about how to handle missing data such as to fill with NA instead of hallucinate or guess.

With this method I was able to get much more consistent and accurate data extracted from websites and papers.

AI: That's a really clear example of how much the approach matters. It sounds like preprocessing the content and providing specific examples made a huge difference compared to just giving the AI a URL and hoping for the best.

Thinking about the parts of your research where you haven't used AI - like maybe the genome scale modeling or the theoretical yield calculations - what's kept you from trying it there?

User: Actually i tried it briefly, but I noticed that it struggled with the domain-specific scientific libraries that we used, the model had a general idea about the process but lack of a deep understanding of the processes requires to complete the pipeline by itself. Instead, it worked as an assistant in code debugging and code reorganization. I think that in other areas where novelty is required such as the generation of hypothesis or initial ideas for new projects, I haven't really used them because I don't trust enough its capacity for generating truly novel ideas and not just iterations or combination of others ideas.  Also, back in the day of this project the reasoning capabilities of the model weren't great.

AI: That's really interesting - so it sounds like for the more specialized technical work, the AI lacked the deep domain knowledge to handle the full pipeline, but it was useful as a coding assistant. And for the creative, hypothesis-generating work, it's more about trust in whether it can produce truly novel insights.

We're about halfway through our conversation now. Let me ask you this: when you have used AI for tasks like data extraction or code debugging, how do you verify or validate what it produces?

User: I usually run the code and use common or simple examples

AI: So you test it against cases where you already know what the expected outcome should be. That makes sense for code validation.

What about for the data extraction tasks - how do you check that the information it pulled from papers or websites is accurate?

User: I do sampling and verify most of the data doing a quick search, but still is easier than filling the complete spreadsheet by my self

AI: That's a practical approach - spot checking a sample rather than having to manually extract everything yourself. It sounds like even with the verification step, you're still coming out ahead time-wise.

If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: discovery relevant papers or literature for my projects. Mostly, because is a time-intensive task that have high relevance to my work since I can consider new approaches or avoid duplicated work.

AI: That's a really compelling use case - literature discovery seems like it would have such a high impact on the direction and quality of your research. It sounds like current approaches for finding relevant papers aren't quite meeting your needs.

What would make an AI tool truly useful for literature discovery in your field? What would it need to do differently than what's available now?

User: It requires specific tools mostly have a paywall and is not a guarantee that they work, standard models such as LLMs are not good for literature review because they trend to hallucinate.

AI: That brings up an interesting point about access and reliability. You've mentioned hallucination as a recurring challenge throughout our conversation - from data extraction to literature review.

Those are all my questions. Your perspectives on the importance of advanced prompting strategies and the ongoing challenge of AI hallucination in scientific work were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: Yes, we require specific models trained for academic language. I have noticed that some tools use a more literacy style instead of standard academic language.

AI: That's a really valuable point - the distinction between literary style and academic language could be quite important for scientific work. It sounds like the training data or fine-tuning of current models might not be well-matched to the formal, precise language requirements of academic research.

Thank you again for sharing your experiences so openly. Your insights about the need for domain-specific training, the critical importance of prompting strategies, and the challenges with hallucination in scientific contexts really help us understand the nuances of how AI fits into real research work. The specific examples you gave - from your team's different approaches to data extraction to your sampling verification methods - paint a clear picture of both the potential and the current limitations.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out.
