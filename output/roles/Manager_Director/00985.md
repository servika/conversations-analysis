# Dialog 00985

**Transcript ID:** work_0813

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Sounds good. I'm ready to begin.

AI: Perfect, thank you. Let's start with something broad to get us going.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI throughout my workday for several types of tasks. I use it to help solve problems I might have related to coding. For example, if I have a bug that I'm not sure about, AI can help save me time debugging. 

I also use AI to implement coding functionality that I already know I want. For example, if I need a particular method such as "calculating the average product cost for an order", I would give the task to AI, along with context, which saves me time implementing it myself. 

Lastly, I also use AI for brainstorming. For example, if I want to develop a new feature, I may have some existing ideas, but I may not be sure if it's the best approach, I would assign AI a task to brainstorm other ways it could be achieved.

AI: That's really helpful - it sounds like you're using AI across different phases of your development work. 

Tell me more about that debugging example you mentioned. When you have a bug you're not sure about, how does that interaction typically unfold with AI?

User: I would start by providing the AI all the context I have. For example, if an email service was crashing with errors, I would describe the issue, provide a snapshot of code I believe to be the issue, provide the actual the error message, and provide any logs. I would ask the AI if it knows what the issue is, or how I would go and figure it out. From there, I would follow up with the AI, collaborating with it, until I discover the issue.

AI: That collaborative back-and-forth you described is interesting. It sounds like debugging becomes more of a dialogue rather than you just handing off the problem completely.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: A certain task I would prefer to handle myself would be code architecture or code planning, more of the "bigger picture" type of tasks. I feel like these tasks are much more creative as there are many ways to design a system, so solving these tasks are fun. 
I feel like if AI would handle these tasks (code architecture and planning), then there would be little creativity left, and reduces the remaining work only to implementation.

This is in comparison to tasks that I don't mind AI handling, like writing tests, which are a lot more tedious, as there is a lot of boilerplate code, making it less fun.

AI: That distinction between creative versus tedious work is really insightful. You mentioned that keeping the architectural and planning work preserves the creativity and fun aspects of your job.

When you do use AI for those implementation tasks or testing - the more tedious parts - could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout the task, or do you tend to delegate complete tasks for it to handle independently?

User: It depends on a how "risky" the task is, i.e. how badly could it affect other parts of the system if it's implemented wrong.

For low-risk tasks, such as tests (tests are important, but if they break it's not the end of the world), I tend to delegate the task completely to the AI. I may provide the original method or service and ask "Implement unit tests for this". Occasionally, I may also provide certain types of tests that I require, such as "Implement tests for the following use cases: 1. email not provided, 2. invalid email", but still allow the AI to implement them.

For other low-risk tasks, such as simple methods, I would also delegate fully to the AI. I may specify, the inputs and outputs, but let the AI handle the implementation fully.

For high-risk tasks (if it goes wrong it could be a big issue), for example, sending emails to an email list, I tend to collaborate much more with the AI to make sure it's correct. I will still use the AI to provide implementation, but with certain constraints (i.e. make sure its batched in batches of 100 etc.), I will change parts, asks for follow ups, etc. until I'm happy.

AI: That risk-based approach makes a lot of sense - adjusting your level of collaboration based on potential impact. 

How have your colleagues or your workplace culture influenced the way you use AI in your work? Have you noticed any particular attitudes or practices around you that have shaped how you approach it?

User: Yes, AI is encouraged at all levels of management. There is no need to "hide" that something was done with AI, in some ways it is expected. This allows me to approach AI head-on and use it as much as possible in my work.

Also, the culture of asking questions has been reduced a bit, previously before AI there would be a lot of discussion amongst colleagues about how to implement something, or if there was a particular error that was happening, but now AI is the go-to person. Phrases such as "Have you tried asking AI?" are common, and only in person discussion typically happens now if AI has been asked, but wasn't able to resolve the issue.

AI: That cultural shift you described - from colleagues being the first point of contact to AI becoming the "go-to person" - is really striking. It sounds like it's changed the dynamics of when and how you interact with your teammates.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: There has been many times when I have felt very satisfied from figuring out tricky bugs when using AI. Sometimes after trying to figure something out for a while, I can get "stuck" in loop, trying the same type of solution again and again, but making no progress. When I collaborate with AI, it can suggest ways of solving the problem I haven't thought of. 

A simple example was when the AI told me to add a log statement to print out the state of an object in the code a certain point in the program, which sounds simple, but after doing so it significantly narrowed the problem down, and I was able to resolve it myself from that point on. The satisfaction for me came from being "unblocked" by the AI, to make progress without being stuck for a longer time.

AI: That "unblocked" feeling you describe sounds really powerful - having AI help you break out of those mental loops where you keep trying similar approaches.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: This is something I've thought about. Whilst AI is getting better and can potentially take over certain areas, I don't see any reason not to maintain the skills I have in certain areas, as long as I enjoy them. For those certain skills that I have, but don't enjoy, I think maintaining them less makes sense, and that is completely fine.

AI: That perspective on focusing on skills you enjoy is really thoughtful. It sounds like you're making intentional choices about where to invest your development energy.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I feel like the amount of AI I use will continue to go up, and I can see that continuing over the next few years. 

I feel like there may some evolving shifts as well, such as AI being more and more reliable at producing code, resulting in me becoming more of a "director of agents", rather than being hands-on writing code myself. It may also come to the point where a large percent of my time is spent reviewing diffs from AI's that create their own PR's automatically. 

So i see a shift in the type of tasks I would do at my job as a developer, and an increased usage of AI.

AI: That vision of becoming more of a "director of agents" is fascinating - it suggests a pretty fundamental shift in how development work might be structured.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how you balance risk when deciding whether to collaborate versus delegate, and that cultural shift you described where AI has become the first point of contact before asking colleagues.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Nothing more from me! I believe it's all covered.

AI: Perfect! Thank you so much for your time and for sharing your experiences so openly. Your insights about the risk-based approach to collaboration, the cultural changes in your workplace, and your thoughtful perspective on skill development will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk through these different aspects of how AI fits into your work as a developer. Have a great rest of your day!
