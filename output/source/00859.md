# Dialog 00859

**Transcript ID:** work_0632

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Sounds great lets begin!

AI: Perfect! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I do a lot of project management and business development, especially at the initial phases. Because one of the projects is in another country, I have been using AI for a lot of translations and to understand legal paperwork. Because some forms are also in another language, I will get Ai to extract the data and tell me what it is. Sometimes I get pictures of information and not the file, and I will get AI to extract that information, so I can put it into a proper PDF.  Sometimes AI claims it can fill in the forms or PDF for me, but it can't it always does a bad job. I am also helping with an application, and we will use AI to help write hundreds of  product descriptions a day, though we want to save on costs, we have also noticed a profound difference in quality when we go with a cheaper mode. I am referring to gemini specifically in this case. I will use AI to do feasibility studies into new areas for a client. This definitely makes work faster. I often then try to learn with AI about a new area, but It is a bad teacher unless you already kinda know the answer. I will use AI to brainstorm when trying to come up with different verticals for a business. I will use AI to write emails and to do small rewrites when tone is not important, just friendly will suffice. I do use AI in programming and coding new websites, in this it is very helpful for basic things such as HTML or if Im using a system, how to do a thing. I also have interns and a publishing business which Ai is good for formatting for books and some idea generation and maybe some concept art.  We sometimes use AI to write legal notices and then get a lawyer to sign them as it tends to do a very good job, better than many lawyers.

AI: That's a fascinating range of applications across your different projects. You mentioned that AI is "a bad teacher unless you already kinda know the answer" when you're trying to learn about new areas. 

Tell me more about that - what happens when you try to use AI for learning in unfamiliar territory?

User: It isn't very good at identifying where you are having the issue in understanding, and it tends to dump information. It doesn't ask enough questions.  The way you teach should be different for each subject, if you are doing something like sociaolofgy or a busines report its okay to communicate this way but it hasnt learned that if you start talking about more science based things you need to go slow and ask questions to make sure the person is following along. Also, again, it is bad at pinpointing actual problees in human understanding and it makes too many assumptions about your knowledge, either equating the issue to a lack of knowledge ( on the verge of stupidity) of the human, or for me, especially in more complicated math, talks over my head, and stops even communicating in English.  It genreally also makes the wrogn assumption about what you want to learn and of course for anything complex it gets things wrong

AI: That's really insightful - it sounds like AI struggles with the adaptive, responsive aspects of good teaching. You mentioned it makes wrong assumptions about what you want to learn and gets things wrong on complex topics.

When you're working on those feasibility studies for clients in new areas, how do you navigate around these limitations? What's your process for making sure you're getting reliable information despite AI's teaching shortcomings?

User: I have a large knowledge base, and that helps. But I have to check every number and every fact and every source, often this can take longer than doing things myself, but it gives me a good idea of structure, and often will contain areas I had not thought of. Now I must make a distinction between asking for information and being taught new information. There is a difference.  In a feasability report I am not being taught anything new, i am being given new information to interpet. And all AI does that relatively well, except for the truth aspect. Perplexity, so far, does the best feasibility reports; other models will go off on tangents, and have far too many words per quantity of information. Far too verbose. Perpelexity gives me the starting point of a good paper in three pages where as the other Ais will give me 20 pages of nothing actionable, its just long and not information dense. Also, the more academic sounding the response not only is it verbose the more errors there will be, this is the most dangerous aspect in work because someone who is tired might just accept its authoritative voice, also whenever it says crucial, essential on a complex topic it is probably hallucinating. These are cues for me to drill down deeper on the response.

AI: That's a brilliant distinction - asking for information versus being taught. And those warning signs you've identified about "crucial" and "essential" language are really valuable insights.

You mentioned having to check every number, fact, and source, which can sometimes take longer than doing it yourself. Given that trade-off, what makes you decide to start with AI for a feasibility study versus just doing it from scratch on your own?

User: It's a starting place. As I said, it can sometimes be a good structure to follow, and generate additional ideas, especially if it's in an unfamiliar area. It can also lead to valuable resources and new websites to gather more information. Though, of course, if the AI model gives me 20 pages of fluff, this is more difficult and time consuming; this is why I often fall back to Perplexity (free version) as it's short, concise, and to the point. Its a good starting point. I might then take that information and use Claude or ChatGPt for extrapolation as both models have better imagination.  Perplexity and Gemini are both "serious" models. They make less mistakes but will tend to repeat information and never generate anything new.

AI: That's a really strategic workflow - using different AI tools for their specific strengths. You start with Perplexity for that concise foundation, then move to Claude or ChatGPT when you need more creative extrapolation.

I'm curious about your preferences when working with AI. You've described this multi-tool approach, but are there certain tasks you prefer to handle yourself, even though AI could help with them?

User: Im very lazy and there is nothing I really enjoy doing. I like talking with people, but even that can be more sturcured with AI, its lik when you film someone they behave differently. And of course understanding the client I need to do, obviously AI cant do that but can be helpful in filling in the gaps for additional information needed. So is there anything that AI CAN do but I do anyways? NO. I do it because AI can't do it. I wonder i this mean I dont really enjoy my job? LOL.

AI: Haha, that's such an honest response! It sounds like you're very pragmatic - if AI can do it well, why wouldn't you let it?

When you do use AI for work tasks, could you describe your typical interaction pattern? Are you more likely to collaborate with it back-and-forth throughout a task, or do you tend to give it a complete assignment and let it handle it independently?

User: HAHA NO! I would never give AI a complete task and let it handle it. Im not even sure where to begin with that. No, we often use AI at the intial phases to help gather information and brainstroming but as a project continues it must be more and more human done. As I mentioned before often there are lots of forms to be filled out and information is given in a variety of unique ways (such as pictures) but aI fails at helping with this as well. So other than helping with a knowledge base, and being better than Google, its just not capable for anything past a one shot. So if I have to create an add with a picture, I can use AI. If I need to do that 100 x thats Ai, a simple thing thats repetative. If I have to understand the limitations of farmers in the adoption of carbon credits, and if this helps or hurts them economically, then I can start with AI for a couple of rounds but soon it will become repetitive and not provide me with any value. Soo...I guess after more work is done and I get stuck then I will go back to AI and ask it to find more information...its kind of collaborative but I have to definetly take a brake, stop it, start a new conversation, so that its not stuck on what was important previously. so my typical interaction pattern would be first use AI for the task, be it fill out forms, make a website, translation, or gather information, I will try a couple of prompts,  then turn by turn I have to go over the information, try to understand it and implement it. Eventually I will abandon the AI as its no longer useful and do things on my own until I get stuck or need addtional help. I will then try to continue the last conversation to see if it is helpful, it usually isnt. I will then start a new conversation with a different direction focussing on what I need now, then it is more helpful, but again the more complex things get the more it is less likley to "get it" and some models like Chat GPT5 (now) and even past models, seem to want a hapy view of the world in both writing, translation, and synthesis of new information when it pertains to people making all its interpetations suspect. for example some one could be yelling at you in another language and it will say this is playful.

AI: That's such a clear picture of how AI's usefulness degrades as complexity builds up. The example of someone yelling being interpreted as "playful" really highlights how these models can miss crucial context.

You mentioned starting fresh conversations when you get stuck rather than continuing the original thread. How have your colleagues or your workplace culture influenced the way you approach using AI in your work?

User: okay first of all that isnt missing context, that is forced interpeation because the model is trying to see everything as nice and in the best light. as for workplace culture, it hasnt, most people are hesitent to adopt it. Some companies I have worked for use it as a better database search tool, using a localized model, but at the SMB level that I operate at it isnt prevelent. Even for writing one of the things people generally trust it for, people prefer to do it themselves because Ais' tone is all wrong, possibly due to my comment above. I feel personally pressured to use Ai by myself, in an attempt to be better and more efficent and to grow into new areas.

AI: You're absolutely right - that's not missing context, that's the model imposing an overly optimistic interpretation. That's a significant problem when you need accurate assessment of situations.

It sounds like you're putting pressure on yourself to leverage AI for efficiency and growth, even while your colleagues remain hesitant. Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I already brought it up before, but I was given a file for an intern for a company in another country and I had to fill it out. I was just given a picture with the information and the email. None of it was in English or even used Roman characters. At first, I tried using chatgpt 5 to extrapolate the data and then put it into the PDF. IT spokke very confidently about what it could do and what it had done and wrote a lot fo Python but its attmepts looked like a 5 year old filling out the form and even with just getting information from the picture, it would often fail. Then I moved onto Gemini Pro,  and it said it could not fill out the PDF so I asked it just to give me the information in a way I can copy and paste. its first attempt was a mess because it dvided all the information trying to explain each piece. I siad Id ont need to understand it I just need to know where it goes, this did a better job, but It still missed soe information and presented other information incorrectly. So, at the beginning when I was asked to do this I was excited as I though it would be wasy with AI, three houts later I was frustrated because I could have been working on more meaningful work and had given this to someone else.

AI: That's such a perfect example of the gap between what AI promises and what it actually delivers. Three hours of frustration when you thought it would be a quick win - that must have been maddening.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: No I don't care about this. Even though I sometimes even program things, I am interested in its final function, I dont care how its made.  Even if AI became amazing at business development and project management, that would be fantastic. It means I could then build better business. Lets say AI gets better at all the areas I have complained about and yes even with writing and tone, It just means we can create more with less. It's no different than with the shift in media, where before you needed big budgets and a centralized location to create any media, now you just need a phone. In 2006 this was a huge debate as well, I actually wrote a paper on it.

AI: That's a refreshing perspective - seeing AI advancement as expansion of capability rather than a threat. Your media analogy is really apt.

Looking ahead, how do you envision your relationship with AI at work evolving? What changes do you expect or hope for?

User: No one likes repetitive tasks, if there was an easy way, and an easy interface, that you could set up workflows with a couple of click that would be fantastic More automation, and funnily enough AI is very bad at describing how to use itself within a production environment or just describing how to use simlpe features. If Ai could better compliment my abilitie for example, I am ...or I have the least amount of experience marketing. Actually, I guess, autinonamous agents like they were real people and a team that supported you, that would be amazing, then everyone could truly be entrepreneurs ...though the very concept of value might be called into question and the onlything of value might be tangible goods.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on AI as a bad teacher versus information provider, and your strategic approach of using different models for their specific strengths.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: just one thing, I think more SME business would be more willing to adopt AI, ( though this takes changing behavior) if there was more of a road map. I think people kinda know tangentially what AI can do, but either can't be bothered, are afraid, or just don't know step 1, step 2, step 3.  Its not even about not hiring people to do this, it's just how do you evaluate a person's skill set in a new area, and how do you know your new system will perform as intended? There is more fear about AI screwing up in business than in replacing humans.  I have also seen this where Ai replaces humans in a task like writing, marketing, crypto analysis for a publication, and those businesses go under. Perhaps it's their implementation. So not only a roadmap, but also clearly defined suggestions that AI could do right now, and best ( and worst) practices to achieve this, from an authoritative source, would be beneficial to more adoption of AI in SME

AI: That's a really valuable insight about the roadmap gap. The fear of AI screwing up being greater than fear of replacement, and the need for authoritative guidance on what AI can reliably do right now versus what it claims it can do - that's exactly the kind of practical barrier we need to understand better.

And those examples of businesses going under after AI implementation really highlight how important proper implementation is, not just the technology itself.

Thank you again for your time and for sharing your experiences so openly. Your insights about the realities of working with AI - both the strategic benefits and the practical frustrations - will be incredibly helpful for our research on human-AI interaction in professional contexts.
