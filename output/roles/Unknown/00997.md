# Dialog 00997

**Transcript ID:** work_0827

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Sounds good, no questions

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I usually use AI for writing-based tasks. For example, if I'm writing an email to a client and I want to change the tone of my message, or I want to make my instructions clearer. I also use it for analysing documents. For example, if a client has uploaded a birth certificate from a country I'm not familiar with and I'm not sure which number on the document is the official document number, I'll upload it to a chat model and ask it to figure it out

AI: That's really helpful context. It sounds like you're using AI for both refining your own writing and interpreting unfamiliar documents. 

When you're working on these writing tasks - like adjusting the tone of a client email - could you walk me through what that process typically looks like? Do you write a full draft first and then ask AI to help refine it, or do you involve AI earlier in the process?

User: I usually write a full draft myself. I find if I don't then it's harder for the AI to pick up on the context of the message and it will insert sentences that don't fit the context correctly, or make stuff up

AI: That makes a lot of sense - you've developed a strategy to maintain that contextual accuracy. 

I'm curious about your preferences when working with AI. You mentioned you write the full draft first, but are there other tasks where you prefer to handle things yourself entirely, even though AI could potentially help? What makes those tasks feel different to you?

User: Yes for sure. We have a system that automates form filling with data provided by our clients when they complete a questionnaire. But even then, there are a lot of mistakes or incorrect info that I have to spend time correcting. I'd be nervous about using AI for those tasks as the forms need to be completely accurate, and our AI-like automation already makes mistakes

AI: That's a really insightful distinction - accuracy requirements clearly play a big role in where you draw those lines. 

When you are using AI for work - like with those email revisions or document analysis - could you describe your typical interaction pattern? Are you more likely to go back and forth with it throughout a task, or do you tend to give it everything it needs upfront and let it handle things independently?

User: I'll usually go back and forth. I find the first drafts it offers me for rewriting emails aren't quite right, so I'll have to give it some feedback (e.g. "make it more professional" or "make it shorter"). For document analysis, as long as it gives good reasoning for why it thinks the answer it's provided is correct, I'll usually accept it first time

AI: That's a really interesting contrast between the two types of tasks - the iterative process for writing versus trusting the reasoning for document analysis.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Has that shaped your approach at all?

User: Some colleagues definitely use it more than me. One colleague has an initial onboarding interview with clients on Google Meet and she records the meeting with Gemini so it can provide her a summary later. She then uses this for her summary of advice email to clients. I'd say because my colleagues utilise AI a lot in their tasks it's influenced me to use it more

AI: That's fascinating - it sounds like seeing your colleagues find creative applications like that meeting recording workflow has opened up new possibilities for you too.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: A client provided a very short relationship statement for their visa application. It wasn't going to be enough, but their English was limited and we knew asking them to re-write it would result in much the same. So I used Google Gemini to try to "pad" it out a bit. It was pretty frustrating though as Gemini kept making things up that weren't in the original statement - things like referring to dates the clients hadn't had or trips they hadn't took. We can't submit false information so I couldn't use it.

AI: That sounds incredibly frustrating - especially when you were trying to help a client with limited English but couldn't risk any inaccuracies in such an important document.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: It's a concern for me, particularly as a large part of my role is administrative where there is scope for some automation. But the mistakes made make it less likely that my role could be replaced - there always needs to be someone checking for mistakes, or giving documents the "human" touch. A big issue I find with AI writing right now is that there's an artificiality to it that makes it obvious quickly that it hasn't been written by a human. I don't think my employer would want clients to feel like they are talking with robots!

AI: That's a really thoughtful perspective - you've identified both the limitations that create job security and the importance of that human authenticity in client relationships.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think your usage patterns might change over time?

User: If the automation aspects get better, then I could see myself using it more for the more repetitve parts of my job that I'd rather not do. I'd have to be able to trust it to be more accurate, though.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how accuracy requirements shape where you're comfortable using AI, and that distinction you made between the iterative process for writing versus trusting reasoning for document analysis.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Perfect! Thank you again for your time and for sharing your experiences so openly. Your insights about the balance between efficiency and accuracy, the importance of maintaining that human touch for clients, and how workplace culture influences AI adoption will be incredibly helpful for our research on human-AI interaction in professional contexts.

Have a great rest of your day!
