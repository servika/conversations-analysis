# Dialog 00457

**Transcript ID:** work_0015

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Sounds great to me!

AI: Perfect! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Well, i'm a home health aide primarily. I use AI to research and find physical therapy routines that are customized to my client. I have used AI to help myself or my client understand medications or diagnoses or impact of diet on their health. I have also used AI to determine how best to handle an issue. I don't fully trust AI and typically use it as a starting point but it helps to hone in on what I am looking for

AI: That's really interesting - it sounds like AI serves as a research and guidance tool for you in caregiving. You mentioned using it as a "starting point" to "hone in" on what you're looking for. 

Can you walk me through what that process typically looks like when you're, say, researching a physical therapy routine for a client?

User: I start off describing my client, their physical ability, and general mental state and ask the model to find me specific PT routines.  So it would look something like this

AI: That sounds like a really thoughtful approach - starting with the client's specific situation. What happens after you get those initial PT routine suggestions from the AI? How do you go from there to actually implementing something with your client?

User: From there I use my judgement and pick what looks do-able for my client then I start researching, googling, watching videos to see proper implementation or ways to modify the exercise/movement if needed.

AI: So you're essentially using AI to generate possibilities, but then you're doing your own verification through other sources and applying your professional judgment. That's a really thoughtful workflow.

Tell me more about that verification step - what are you typically looking for when you're googling or watching those videos that the AI suggestions might not have given you?

User: I'm looking to be sure that the suggestions actually exist and aren't a hallucination to start, then I'm looking to see if they are recommended by professionals for the type of client I have or their specific issue. From videos I'm looking at technique and difficulty level to ensure these will actually help my client and not cause any harm.

AI: That verification process you described - checking for hallucinations and ensuring professional backing - really shows how you've developed a system to work with AI's limitations. 

I'm curious about your preferences when working with AI. Are there certain tasks in your role as a home health aide that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: Well, I wouldn't trust AI to make a decision. For example, I wouldn't just do what AI suggests without thought or further research. I wouldn't blindly submit a written summary of symptoms to my clients physician without going over it and making corrections.

AI: That makes a lot of sense - you're maintaining that human oversight and decision-making authority. It sounds like you see a clear line between using AI for information gathering versus actual decision-making or direct communication with other professionals.

When you do use AI for tasks like researching PT routines or understanding medications, could you describe your typical interaction pattern? Are you more likely to have a back-and-forth conversation with it throughout the research process, or do you tend to ask for what you need and then take that information to do your own follow-up work?

User: I find myself using both methods. Sometimes I want something fairly cut and dry like with information about a medication. I may add parameters like "I need to explain this medication, its uses, and its side effects to my client, a 50 year old male with learning and memory disabilities." and take it from there.  Depending on the model response I may ask further questions. 
I may be more conversational if I am trying to understand something myself rather than looking to explain something to my client.

AI: That's a really insightful distinction - how your interaction style changes based on whether you're gathering information for yourself versus preparing to explain something to your client. It sounds like you naturally adapt your approach based on the end goal.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you discuss these tools with other home health aides, or is this something you've developed on your own?

User: Mostly something I have developed on my own. I hesitate to speak on it with other aides as I fear some won't do the due diligence and will accept anything it tells them as it can sound fairly authoritative.

AI: That's a really thoughtful concern - recognizing that not everyone might approach AI with the same level of critical evaluation that you do. It sounds like you've developed a pretty sophisticated system of checks and balances through your own experience.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: The most helpful I found it was when my client had developed sores on his leg. I was instructed to clean and wrap the leg by his physicians, this wasn't the first time this client has had these sores though it had been quite a while. I couldn't remember which creams I should use in what order so I had a conversation with the AI. I outlined what was happening, my general instructions and what supplies the client had available. The AI made suggestions, I took that information which and was able to verify via the internet whether it was correct or not. 

As I proceeded to care for the sores I sent the AI pictures of the progress as we moved along with the treatment more so as a reality check of what I was seeing and my assessment. During this I was communicating with my clients physician as needed but they aren't always able to respond in a timely manner.

AI: That sounds like a really effective collaboration - using AI as both a knowledge resource and a way to get real-time feedback on what you were observing. It's interesting how you used it almost like a professional consultation when the physician wasn't immediately available.

You mentioned this was particularly satisfying - what made that experience feel so positive for you compared to other times you've used AI?

User: It was the first time I had used AI for something of that nature, something more than just a tool to narrow down my research. I was able to care for my client in what felt like a more productive way and also felt a little less "on my own" while dealing with the issue.

AI: That feeling of being less "on my own" is really striking - it sounds like AI provided a kind of professional support in a situation where you had significant responsibility. 

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider in your work as a home health aide?

User: Well, until AI gets a body I don't feel particularly threatened.  Beyond that I also don't think AI is trustworthy enough to take over positions like mine. Its too easy to manipulate, even unintentionally, and its too ready to go along with what they user wants.

AI: That's a really practical perspective - recognizing both the physical limitations and the reliability issues. You mentioned AI being "too ready to go along with what the user wants" - that sounds like something you've observed firsthand.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself using it differently as the technology develops, or do you think your approach will stay fairly consistent?

User: I suppose one day I may find myself trusting it more, it is a tool that hopefully will improve as time goes one.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how you've developed that verification process to work with AI's limitations while still finding real value in it as a professional support tool.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I don't think so

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about using AI as a research starting point while maintaining that critical oversight, and how it can provide a sense of professional support in challenging situations, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how thoughtfully you've approached integrating this technology into such an important role. Take care!
