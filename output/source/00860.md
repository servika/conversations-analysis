# Dialog 00860

**Transcript ID:** work_0635

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Nope, go ahead I am ready to begin

AI: Perfect! Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use it quite a lot, I have a project management application that I use to coordinate tasks for the day, that is first. Then once I have those tasks I move over to VSCode where I do the majority of my work. I have the app open on my other monitor that I use for general questions. Then I have an agent within VSCode that I use for code specific tasks.

AI: That sounds like a really integrated setup across multiple tools. When you say you use the app on your other monitor for "general questions" - can you walk me through what those general questions typically look like? What prompts you to switch over to that screen during your workday?

User: I am programming, so I will ask about best practices for the specific task that i am going to accomplish, maybe data structures, or sometimes I will ask about the quirks of  the language I am using.

AI: That's really helpful context. I'm curious about the distinction you make between using the app on your other monitor versus the agent within VSCode. What drives your decision about which tool to use for different coding needs? When do you find yourself reaching for one versus the other?

User: The AI integrated into VSCode I will ask to look over the code that I have written or I will have it write small bits of code at a time that I can review, so I don't talk to it unless I am ready to integrate a new feature.

AI: That makes a lot of sense - so the VSCode agent is more for when you're ready to produce or review actual code, while the other monitor is for the thinking and planning phase. 

I'm curious about your preferences when working with AI. Are there certain programming tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: I think this really comes down to trust. I am using a language that AI struggles with so I cannot trust it to implement large features all at once. I have to be very granular about what I tell it to code, so if the task becomes so small that I could write it faster than having AI do it, then I will do it myself. Also if the task is really repetitive but clear, like formatting and compiler notes, I will have AI write that.

AI: That's a fascinating insight about trust being the deciding factor. The language AI struggles with - that must create some interesting dynamics in how you work together.

When you do use AI for those smaller, granular coding tasks, could you describe your typical interaction pattern? Are you more likely to go back and forth with it throughout implementing a feature, or do you tend to give it a specific small task and then take the output and move on independently?

User: I tell it to do something with VERY specific rules, it executes, I review it and if it made a mistake I will take the time to clearly explain how it messed up so that it won't make the same mistake in the future. Yes sometimes that means that I will be going back and forth with it for a while but I think its worth it if it forever gets it right in the future. Typically I get what I need from it and move on to the next feature. If I write the feature myself, I will ask if I wrote it in the most efficient way, as speed is really important to me.

AI: That's really interesting - you're essentially training it through those detailed corrections. It sounds like you're investing time upfront to improve future interactions.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that your approach aligns with how others around you are using these tools, or have you developed your own style?

User: This is my own style, I see AI as a permanent feature of the future so I am making sure that I know how to use it. It has increased my output significantly.

AI: That's a really forward-thinking perspective - treating it as a permanent fixture and optimizing for that reality. You mentioned it's increased your output significantly, which sounds positive.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Which do you want satisfied or frustrated?

AI: Let's start with whichever one comes to mind more easily for you - satisfied or frustrated?

User: Frustration happen constantly. This is why I have very little trust for it. Earlier today I had an idea for a small optimization that would require a small change in many places of the code, perfect for AI, but instead of doing that it wanted to create another large function to make the correction. So, it taking certain liberties when I don't ask for it really frustrate me. There was a time where when requesting a change to a specific function it would make the change and delete the rest of the code base, luckily that hasn't happened in a while.

AI: Wow, that sounds incredibly frustrating - especially the deleting code issue. It sounds like the AI taking liberties or making assumptions beyond what you explicitly asked for is a major source of friction.

When these frustrating moments happen, how do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, especially given that you see AI as a permanent feature?

User: Well as a programmer, I kind of want AI to take over. This means that I don't have spend time looking up syntax quibbles and other tedious parts of programming, it will just do it correctly (for the most part) If AI is better at its job that means that I am better at my job since I'm using it to do my work. As an analogy, if you ask me to dig a hole, before AI I was using a shovel, with AI - an excavator! The downside is I have to learn to drive an excavator, but once I get the hang of it holes will be a trivial task.

AI: That's a brilliant analogy - the excavator metaphor really captures that shift from tool to power multiplier. And it sounds like you're actively working on becoming a better "excavator operator" through those detailed corrections and specific instructions.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think you'll reach a point where that trust issue gets resolved, or do you see it as something you'll always need to manage?

User: That depends 100% on the AI. I am very granular and specific with it now, but I will sporadically test if it hand a little more complexity, or nuance and see how it fares. If it proves that it is able to handle it, then I am more willing to push those boundaries further.

AI: That's such a thoughtful approach - the sporadic testing to gradually expand those boundaries based on proven performance. 

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your excavator analogy and how you're treating this as a skill-building process for the future.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No I'm sure you guys know much more than I do and have secret tricks up your sleeve. I am really hoping that one day I can get it to the point where I can talk to it like a very attentive assistant.

AI: That vision of an attentive assistant sounds like exactly the kind of relationship you're working toward with all that detailed feedback and boundary testing.

Thank you again for your time and for sharing your experiences so openly. Your insights about trust-building, the balance between delegation and control, and that forward-thinking approach to skill development will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk through your workflow and share those specific examples - it gives us a much richer understanding of how these tools are actually being used day-to-day.
