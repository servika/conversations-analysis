# Dialog 00940

**Transcript ID:** work_0747

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: No questions. Lets go.

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I am a software developer in my day job, so AI influences everything I do at this point. It writes the code for my tickets. It writes my performance review, citing all the work I have done. It fluffs up the tickets in Jira to make them seem impressive, and it generates all sorts of spikes and reports and emails that are more detailed than my lazy self would be willing to otherwise do.

AI: That's a pretty comprehensive integration! It sounds like AI has become deeply embedded in multiple aspects of your workflow - from the actual coding to the administrative side of things.

When you say AI "writes the code for your tickets," can you tell me more about how that process typically works for you?

User: My company doesn't exactly allow AI to be used in that way, so a lot of the work is being copied into ChatGPT and then it gives me instructions on how to do the work. Alternatively, they let us use whatever IDEs we want, but block certain connections, so I can use Junie as they do not block Jetbrains AI. 

The process usually consists of me copying the ticket into the message box and then the bot either doing it or giving me instructions on how it is to be done and then writing tests to validate the work. I then add a few refinements of required and upload it.

AI: So you've found ways to work within the constraints your company has set up. It sounds like you're navigating between what's officially permitted and what actually helps you get your work done.

When you get instructions from the AI versus having it do the work directly, how different does that feel for you as you're working through the task?

User: The instructions are more tedious, as then I am just executing a list. I would prefer that the AI do the work directly, but with many web platforms, that simply is not possible yet. Or at least I would need to download beta extensions and tools that may be detected.

AI: That makes sense - there's definitely a difference between being the one making decisions versus following a step-by-step list someone else created.

You mentioned earlier that there are certain tasks you prefer to handle yourself, even when AI could help. Are there any aspects of your development work where you actively choose to do things manually rather than involve AI?

User: I do the validation and user acceptance testing myself to make sure it is aligned with my internal mental vision, which may or may not be what I actually communicated. I also tend to include architectural decisions in my tickets, so that is arguably work I am keeping for myself rather than outsourcing to the AI. The AI is the implementer more than the code strategist, although that is changing as the tools improve.

AI: That's a really interesting distinction - keeping the strategic architectural thinking and the validation piece for yourself while letting AI handle more of the implementation. 

When you're doing that validation and testing, what specifically are you looking for that you feel the AI might miss or not understand about your "internal mental vision"?

User: That is part of the problem. I know it when I see it, but lack the understanding to communicate it beforehand, as if I could consistently do that, I would not need to keep the user testing to myself. Mostly just a cohesive sense of organization and consistency. A common issue is that the button styles do not match with the rest of the codebase or it forgot to add validation checks to a form.

AI: That makes perfect sense - it's that intuitive feel for consistency and quality that's hard to articulate upfront but obvious when something's off.

When you're working with AI throughout a task like this, are you typically going back and forth with it - kind of collaborating step by step - or do you more often give it the full scope and then review the complete output afterward?

User: AI has gotten good enough that you can give it large chunks of work, often a full epic, and as long as the specifications are sufficiently detailed and it spawns sub-agents or at least breaks the task into individual steps so that the total thinking is not constrained, there is less of a reason for the collaborative back and forth. AI is getting better, so no need to do that. 

It does depend on the task though. If I just need a straightforward feature implemented and know what I want, I can provide the full scope. But sometimes I am not at that point yet and the collaboration is helpful.

AI: That's a helpful distinction - it really depends on how clear you are about what you want going in.

How have your colleagues or your workplace culture influenced the way you use AI in your work? You mentioned earlier that your company doesn't officially allow certain uses - how does that dynamic play out day to day?

User: The devs openly share features and tooling with each other. We completely hide it from management and our product people. Some are earlier adopters than others and that is causing the lagging adopters to seem unproductive and less capable, especially if they are using lesser tools that produce lower quality work.

AI: That's a fascinating dynamic - this underground knowledge sharing among developers while keeping it hidden from management and product folks.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I had a spike to write that was scoped at a week. I pasted the entire ticket into ChatGPT 5, uploaded our codebase, told it to use maximum reasoning, and it worked for 6 minutes and figured out every problem and use case perfectly. What Product thought would take a week took 10 minutes of prompt writing and resource sharing and 6 minutes of reasoning. The productivity boost is insane.

AI: That must have been an incredible moment - seeing a week's worth of work condensed into essentially 16 minutes. 

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, or does it factor into your decisions about what work to keep for yourself?

User: I don't maintain those skills as much, as they are kind of becoming obsolete. It is like cursive or speed typing. Those used to be measured skills by employers and now handwriting anything other than personal notes is unprofessional and speed typing is giving way to dictation and AI generation. 

Maintaining present skills that are declining in value and relevance (as lets face it, it costs a lot less to hire an AI over me) is a trap. The manual wheat harvester couldn't outcompete the combine by learning how to swing a scythe faster. He would lose, and lose badly. You have to learn to drive the combine. And managing AI is learning how to drive that combine.

AI: That's a really thoughtful analogy - the shift from being the harvester to operating the combine. You're clearly thinking strategically about adapting to these changes rather than trying to compete with the technology.

Looking ahead, how do you envision your relationship with AI at work evolving from here?

User: I think that I have to keep moving up the process hierarchy as AI takes the lower level work. 3 years ago, we manually typed every line of code we used at my job. I couldn't do that and produce even a 1/5th of what I do today. So I need to get better at ordering and managing the AI agents.

AI: That's all the questions I had prepared. You've shared some really thoughtful insights about your experience with AI at work. I particularly appreciated your perspective on adapting by moving up the process hierarchy rather than trying to compete with AI on its own terms - that combine harvester analogy really captured something important about how you're approaching this transition.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: One interesting bit of research is how much productivity companies are getting and how much workers are keeping for themselves. I didn't tell my employer that the 16 minute spike took 16 minutes. I kept the day to myself to give myself an extra long weekend. So getting ahead of the AI game means that at least until everyone else catches up, work can be quite relaxed.

AI: That's a really fascinating insight - there's this whole hidden layer of productivity gains that aren't necessarily flowing back to the employer immediately. It sounds like there's a temporary arbitrage opportunity for workers who figure out AI tools before management catches on or before it becomes universally adopted.

Thank you again for your time and for sharing your experiences so openly. Your insights about navigating the unofficial AI adoption, the strategic thinking about skill evolution, and especially that perspective on productivity distribution will be incredibly helpful for our research on human-AI interaction in professional contexts.
