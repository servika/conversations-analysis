# Dialog 00624

**Transcript ID:** work_0262

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: sounds good buddy

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: so I'm a data analyst at a big tech company, and I do quality auditing and analytics for a team of in-house data labelers. The quality is important because they're doing things like creating golden and benchmark datasets for various things. This was my first data analytics job (I was promoted internally from the job of labler actually) and so there was a fast learning curve and no real ramp-up, so I was using ChatGPT to help me learn how to do certain things in Excel, which is the main tool I'm using. It helped me figure out how to use a lot of relevant formulas, how to use pivot tables more effectively for dashboarding, and how to reshape data according to specific needs - in school I had only done these things very generally and never had to adapt to changing needs in a work environment. I never have it do any data analytics for me - I think this is a horrible idea tbh - but I use it to help me learn things that I can use on my own.

AI: That's really interesting that you draw that clear line between using AI to learn versus having it do the actual analytics work. 

Tell me more about why you think having AI do the data analytics directly would be a horrible idea.

User: A lot of data analytics, and definitely the stuff I'm doing right now, relies a lot on intuition and experience. I've done the data labeling job and I periodically fill in if someone is out, so I can intuit what the various points of confusion are for the labelers, either with guidelines or trouble navigating edge cases, and I can drill down on the root causes to recalibrate the labelers. They don't really care too much about their jobs frankly which is a separate issue, but I can at least identify the confusion points and connect that to the guidelines, and let it drive my recommendations to my boss or to the project managers. An AI would mostly just look at patterns and stop there, and since it was never a data labeler, it wouldn't be able to connect these quantified error cases with the actual thinking process a labeler would experience. I also think there is simply value in having a human who is able to have all these things in her head with a full and organic understanding of the workflow/pipeline. When you just copy and paste stuff into an AI and have it do all your work for you, you're literally cutting out a huge part of the experiential learning that allows you to be effective in your job.

AI: That's a fascinating perspective - the way you connect your lived experience as a former labeler to understanding the root causes behind the data patterns. 

When you're using AI to learn Excel techniques or formulas, how do you make sure you're actually absorbing that knowledge rather than just getting quick answers? What does that learning process look like for you?

User: mainly through repetition, which is how most people learn I guess. I ask it how to do something in a certain formula, it looks like total gobbledygook (excel formulas are atrociously onerous as someone used to python), it walks me through what the formula means, and then after a certain amount of repetition and thinking while I do it (as opposed to copying and pasting from a previous line in the spreadsheet and making slight alternations or whatever) I come to understand it. The AI chat history is there if I need a refresher, but really the idea is to just learn how to do it. I still use youtube tutorials and such for some things, but I generally find that for *simple* queries and explanations like this, ChatGPT has a pretty high accuracy and it's better than googling and wading through stack overflow nonsense.

AI: That makes sense - using it as a more efficient alternative to Stack Overflow for those straightforward "how do I do X" questions.

I'm curious about your preferences when working with AI. You mentioned you never have it do analytics work directly, but are there other work tasks you prefer to handle yourself, even though AI could potentially help with them?

User: I can't do a lot of things directly with ChatGPT or other AIs that are related to work - it's blocked on my work laptop actually and the company wants us to use their flagship AI and built a sort of imitation of ChatGPT to use internally with the proprietary model, but our AI is actually horrible and doesn't work well so I never use it. I understand and respect my company's desire to not have us use ChatGPT for anything involving actual internal data for obvious reasons, so I literally can't do things like feed it data and have it number crunch for me. So I don't really actually have the option to let AI handle a lot of that stuff because I can't use external models and our internal one sucks. But I really wouldn't in general even if I could for the reasons I explained before.

AI: That's really helpful context about the technical constraints you're working under. It sounds like even if you had access to better AI tools at work, you'd still choose to keep the actual analysis work in your own hands.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: well I'm not sure what you mean about delegating tasks. I'm using it on my personal computer usually when I use it for work, because like I said it's blocked on my work laptop, so I usually just approach it with stuff like "I have this data that's shaped like this, these are the columns and rows, and I want to reshape it so I can make a dual axis plot for blah blah, how do I do that" or I just tell it the type of thing I'm trying to calculate and ask what formula I can use, and it gives me the formula and explains it. For example an early one I had to learn was averageifs, which is a ridiculous looking clunky thing that made no sense, so would ask it to explain the parameters and it walked me through it in a very intuitive way, and now that's something I'm able to use daily with no issues. Sometimes it will also walk me through where to find certain features, like I was struggling to get my plots looking aesthetically pleasing and it helped me figure out where to hide the selector fields, how to move the data labels around, how to create custom features in the plots, etc. So I guess I use it more collaboratively, but it's really serving more of a role of like Excel Tutor and maybe a bit of an analytics tutor and not a coworker collaborating on my tasks.

AI: That's a great way to put it - "Excel Tutor" rather than coworker. It sounds like you're very intentional about maintaining that boundary.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do others on your team approach it similarly, or have you noticed different attitudes?

User: I'm the only data analyst on my team so I really have no idea what the other analysts in the company do. I don't think any of the labelers use our internal AI, or an external one, there's no reason to. My boss sometimes uses our internal one for things like rewriting/cleaning up things she's written or making suggestions for improvements, but I've found its performance is soooooo poor that I just don't use it for anything like that and I'm not sure it's served her well either tbh. A lot of us use the kind of administrative AI tools though, like we have a neat AI that was developed as a calendar assistant, so if I want to like book a 1:1 with my boss I can have it look at her calendar and just pick a time we're both free and book the call, which I love. But in terms of actual work tasks I think most of my team doesn't do that because there's no reason to. They wouldn't really influence me one way or the other though, I'm definitely someone who just does what I feel is best whenever possible and I would not be inclined to change my habits if I saw they were using it more.

AI: That calendar AI sounds really useful for the administrative side of things. You mentioned being pretty independent in your approach - that you do what feels best regardless of what others are doing.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: A couple of times I think I recall ChatGPT giving me out of date or confusing information about how to do some Excel tasks and I've had to just go to youtube and google to find my answer. I find that if an LLM misses some point and goes off down a different pathway based on a misunderstanding it's hard to redirect it, and it will just loop with inaccurate information. I've had extremely bad results in school with trying to get it to help me with programming - it's absolutely terrible at this because obviously it just treats code like text and is doing the same statistical operations to assemble code based on probability of one token appearing after the next just like with sentences - so I'm always cautious when asking it to go too deep with stuff. So I deliberately avoid things like that that I know will result in frustration. I've had generally good results because I know how to tailor my queries to its strong points and avoid the weak points

AI: That's a really thoughtful approach - being aware of both the strengths and limitations and tailoring your use accordingly. It sounds like you've developed a pretty good sense of when to trust it and when to look elsewhere.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: what do you mean?

AI: I'm thinking about the skills you're developing - like learning those Excel formulas and data analysis techniques. Some people worry that if they rely too much on AI for certain tasks, they might not develop or maintain those skills themselves. 

Do you ever think about that balance, or is that not really a concern for you given how you approach using AI?

User: oh, yeah no that's a real thing. I mean they're doing studies right now on programmers and school kids and they've found pretty irrefutable evidence that relying on AI for that stuff causes you to forget, or even worse in the case of kids, not develop those neural pathways at all. They've found that programmers who use it forget how to program, kids can't write essays anymore, I mean it's so messed up. I'm 41 so I grew up without any internet whatsoever, personal computers weren't common until I was in middle school, so I'm protective of that boundary like you said. At the moment I think there is more value in someone who has these skills and can augment them with AI like I have been doing - I can't stress how fast I had to learn and ramp up, I went from not being a data analyst to delivering end to end analytics on a weekly basis for multiple projects simultaneously in about 2 weeks, so being able to effectively use AI as a learning tool as well as my brain allowed me to do that. If I'd been floundering around on google and youtube and stack overflow I would have had worse results. My concern is in the future corporations are just going to keep following profit motives and keep outsourcing to AI even if the results are bad, because they will be very often. And then what do I do with all my stupid skills? That's my concern. And then of course there's the concern that that process continues to actual job replacement.

AI: That's a really compelling point about using AI as a learning accelerator rather than a replacement - especially given that intense two-week ramp-up you had to navigate.

Looking ahead, how do you envision your relationship with AI at work evolving? You mentioned concerns about corporations potentially outsourcing more to AI - how are you thinking about that?

User: as an aside, I never really thought before about how fast I had to ramp up into this job, reading that makes me a bit proud of myself lol. Anyway to your question, I don't think it will really evolve unless I'm explicitly directed to use AI in different ways. I'm a MASSIVE skeptic of offloading work to it and I object really strongly to that. I use it often in my personal life for all kinds of things like language learning (I'm studying italian), help with fitness goals and nutrition knowledge, etc, but with work I really strongly believe that the brain "muscle" needs to be excercised like any other, so I will probably just keep using it as a learning partner. In terms of continued outsourcing I have no idea, this is something I flat out panic about very often, because I feel like it's absolutely impossible to get a tech job now, and none of the companies seem to care about retaining and nurturing employees. Everyone gets laid off or is only hired short term on contract with no benefits. It's just such a decrease in the values of American work culture (this does not appear to be happening in other places to the same degree). I think the only thing I can do, and I'm lucky I look younger than I am because ageism is also a thing, is just emphasize how I can utilize AI to make myself a better worker, which is not a lie IMO.

AI: You should definitely feel proud of that ramp-up - that's genuinely impressive! And it sounds like your approach of using AI as a learning partner rather than a replacement has been key to making that work.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on the importance of maintaining that "brain muscle" and using AI as a learning accelerator rather than a crutch.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Just that I hope AI developers can keep in mind that creating tools that replace workers is going to be incredibly harmful to the economy and society at large - people need work for both monetary and psychological reasons. We will never live in some UBI-funded utopia where nobody needs jobs and everyone can just engage in endless leisure. We needs jobs, and we need more of them, not less. So I hope the developers will keep in mind that developing tools to augment work and teach is good, but developing tools designed to replace workers is objectively and unambiguously unethical and harmful, and I really hope we divert from the path we're on with that.

AI: Thank you for sharing that perspective - that's a really important point about the broader societal implications of how AI tools are developed and deployed.

Thank you again for your time and for sharing your experiences so openly. Your insights about using AI as a learning partner while maintaining critical thinking skills, and your broader concerns about the direction of AI development, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how thoughtful and honest you've been throughout this conversation.
