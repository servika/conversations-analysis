# Dialog 00530

**Transcript ID:** work_0120

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: I don't have any questions

AI: Perfect, let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I don't use AI regularly in my typical workday, but I do use it sometimes. If I come across a medical term,  phrase, or procedure, I will often run it through either ChatGPT or Claude to verify the information. This isn't information used for patient care, it is for the trauma registry. I would not rely solely on AI for this information, its more for purposes of double checking.

AI: That's interesting that you use it as a verification tool for the trauma registry rather than for direct patient care. 

Tell me more about what prompts you to double-check certain medical terms or procedures with AI - what makes you think "I should run this through Claude or ChatGPT"?

User: Trauma registry is often very subjective. There might be certain circumstances where I'm not sure if something should be labeled as 'none' or 'N/A'. AI has been useful in helping me choose which applies in that circumstance.

AI: That distinction between 'none' and 'N/A' sounds like it requires some nuanced judgment. 

Can you walk me through what that interaction with AI typically looks like when you're trying to make that determination? How do you frame the question to get useful guidance?

User: For example, there is a section where it asked if there was alcohol in the blood. There is an option to select 'N/A' or 'None'. If it is a 3 year old patient who wasn't tested, I wouldn't be sure which one to select. Most would think it would be 'N/A' because a 3 year old is not likely to be consuming alcohol. Another circumstance would be a pregnant patient. A pregnant patient should not be consuming alcohol, but there is no certainty without testing that they aren't. I would frame the question by asking, "I'm currently adding a 3 year old patient to the trauma registry for a fall. I'm not sure whether I should select 'N/A' or 'None' for the alcohol levels. Which option is more appropriate in this case?"

AI: That's a really clear example of how context matters in those decisions. 

When you get AI's response to questions like that, how do you typically evaluate whether the guidance makes sense? What do you do with that information once you have it?

User: If the guidance aligns with what I thought the answer should be, I would choose that answer. Again, this is largely subjective in many cases so there are times when there is no right or wrong answer. If the guidance seems off, I will reach out to colleagues to verify.

AI: It sounds like you're using AI as one input among several rather than the final authority. 

I'm curious about your preferences when working with AI. Are there certain tasks in your trauma registry work that you prefer to handle yourself, even though AI could potentially help with them?

User: There are too many nuances and subjectivity to rely on AI.

AI: Tell me more about those nuances - what specific aspects of the trauma registry work make you feel like you need to keep that human judgment in the process?

User: Human judgement is needed for the subjectivity. Trying to discern one physicians recommendation from the others, etc. leaves a lot of room for error on the AI's part.

AI: That makes sense - interpreting different physicians' recommendations sounds like it requires understanding the clinical context in ways that might be tricky for AI.

When you do use AI for those verification questions we talked about earlier, could you describe your typical interaction pattern? Are you more likely to have a back-and-forth conversation with it, or do you tend to ask a single question and move on?

User: Its usually just a single question then I move on.

AI: Got it - so it's more of a quick consultation than an ongoing collaboration.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do others on your team approach it similarly, or have you seen different attitudes?

User: No, no one on my team utilizes or understands AI.

AI: That's an interesting position to be in - being the only one on your team using AI. 

How does that affect your experience with it? Do you find yourself having to explain or justify your approach, or is it something you just do on your own?

User: Its something I do on my own. In addition, my coworkers are more senior and have a lot more experience so they are also less likely to need to ask those questions.

AI: That adds another layer - so you're not only the only one using AI, but you're also in a position where you're still building up that experience base that your more senior colleagues already have.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I feel more satisfied being able to confirm my selection with AI rather than needing to ask a coworker every time I need validation.

AI: That sense of being able to get validation independently sounds really valuable. 

Tell me more about what that means for you - how does it feel different to get that confirmation from AI versus having to ask a coworker?

User: I work remotely so I would have to message them the question which isn't a big deal, but it interrupts their work flow and I don't like interrupting others unless I really need to.

AI: That's a thoughtful consideration - wanting to be respectful of your colleagues' workflow. It sounds like AI gives you a way to work through some of those questions independently before deciding if you really need to reach out to someone.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Yes I consider it often.

AI: What goes through your mind when you think about that? How do you approach balancing using AI as a helpful tool while still developing your own expertise?

User: I try to stay knowledgeable in AI technology and capabilities. If and when it becomes part of my position, I will embrace AI and utilize my experiences and knowledge of AI to my advantage.

AI: That's a really forward-thinking approach - positioning yourself to leverage your AI experience as an asset rather than seeing it as a threat.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it expanding beyond these verification tasks, or do you think it will stay in this more limited role?

User: I think it will play a more limited role.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI as an independent verification tool while being mindful of not disrupting your colleagues' workflow.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about using AI as a verification tool in trauma registry work, especially in that remote work context, will be incredibly helpful for our research on human-AI interaction in professional settings.

I really appreciate how candidly you described the balance between getting independent validation while still maintaining appropriate skepticism about AI's limitations in nuanced medical contexts. Thank you!
