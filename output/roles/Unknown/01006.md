# Dialog 01006

**Transcript ID:** work_0845

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. Does that sound good? Do you have any questions before we begin?

User: Sounds great

AI: Perfect! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: In my work, I have to install and maintain various types of vendor provided software and specialized hardware (networking). LLMs are particularly useful for me when I can have them break down hundreds of pages of documentation across various versions and tell me the relevant steps or commands I need to proceed with my work. That's my primary use case - instead of spending 1-2 hours reading individual web pages, an LLM can do it in seconds and give me the answer. As an engineer, this is valuable in cases where it isn't relevant to me understanding how the product works. If I just need to know how this particular vendor formats commands, I don't care about learning it the traditional way. But for other things, I still need to know how the underlying systems work so that I can remain competent.

AI: That's a really clear example of how AI can streamline specific parts of your work. You mentioned that distinction between tasks where you don't need to learn the traditional way versus needing to understand underlying systems to remain competent.

Tell me more about how you decide which tasks fall into each category.

User: If I ask the LLM to solve a problem for me, and then I use that solution without understanding how it works, I'm not being a good engineer. We call that being a wizard - if the spell blows up in your face, you don't know what to do. I need to understand how my systems operate to act professionally with them. So that is the distinction. If I'm heading into a task where I am not confident with what is really happening underneath, I need to first ask the model how the system works, before asking for a solution. A more specific example might be - "How do BFD timers work on Cisco NXOS?" before asking "Write BFD config for my BGP peers"

AI: That's a fascinating distinction between being a "wizard" versus understanding the underlying mechanics. It sounds like you've developed a deliberate approach to maintain your engineering competence while leveraging AI's efficiency.

When you do use that two-step process - first asking how something works, then asking for the solution - how does that interaction typically unfold? Do you find yourself going back and forth with the AI, or is it more of a linear conversation?

User: Networking can be a very niche topic. I often find that I will keep a conversation going so that I keep all of the references under the same conversation name, but I still often have to abandon specific ideas or trains of thought that the LLM is going down. For example, with networking products, LLMs will often hallucinate commands or menu options that don't exist, or suggest troubleshooting options that I've either already done or aren't applicable. In that case, I will work on it solo for a bit, then come back with a more refined prompt or a slightly different pathway to take. The gap could span minutes or hours of work outside the conversation.

AI: That's really insightful - you're describing this dynamic where you and the AI are working together, but you're also stepping away to validate and refine your approach based on real-world constraints that the AI might miss.

When you come back to the conversation after working on it solo for those minutes or hours, what does that feel like? Are you approaching it differently than when you first started the conversation?

User: It can sometimes feel frustrating or overwhelming, but that isn't necessarily a symptom of the LLM interaction. Technology in general is very flawed and finnicky, which is why IT professionals have jobs in the first place. I think my approach is always that LLMs are another tool in the toolbox, so let's see what it can do with this idea or problem that I have. If it can't find anything, I still have to figure it out on my own, and that's okay.

AI: That's such a grounded perspective - treating LLMs as just another tool in your toolkit rather than expecting them to be a silver bullet. 

I'm curious about your workplace context. How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that others around you have similar approaches, or are there different attitudes toward AI use?

User: Other colleagues in my workplace definitely have different attitudes towards AI. Some see it as purely a marketing term, which is often a valid point. Many are frustrated when AI platforms are constantly forced on them, such as AI working groups or Microsoft products that pop up banners for AI integrations. I think that this hasn't influenced me too much, because I was a generative AI enthusiast before it became applicable to work, since I ran image generation on my personal machine. On the flip side, my workplace in general is actively promoting good AI use, offering locally ran LLMs, and creating spaces where colleagues can discuss AI use cases. The net effect of this is that I am not creating siloed AI implementations within my department, but rather working with the organization as a whole. This means adoption can be slower, but it is standardized and able to be used by everyone.

AI: It sounds like you've got this interesting balance - being personally enthusiastic about AI while also working within an organization that's taking a more deliberate, standardized approach. That contrast between individual enthusiasm and organizational pace is really interesting.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Yes, I had a particularly satisfying moment with a major LLM. I was stumped on a problem with a user who had slow SSH login times. Every time they tried to connect to a host, the login prompt would take a long time to appear. I eventually ran this by the LLM, who suggested, among other items, that the SSH server might be trying to run reverse DNS lookups on the SSH client IP address if it's openssh based. This actually ended up being the root problem, and allowed me to address the issue. I don't know how long or if I ever would have found this on my own. One of my colleagues even commented later that they were initially surprised I figured this out, after I let them in that the LLM helped me.

AI: That's a great example of AI helping you solve something that could have taken much longer to figure out independently. It sounds like your colleague's initial surprise turned into recognition that you'd found an effective solution path.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I think the idea of AI "taking over" has been overblown in recent times. My take is that people need to be comfortable supporting and integrating AI into workflows if they want to maintain their roles in their careers. With the current LLMs, there is no fundamental way that it could, for example, replace an entire network engineer. However, engineers who stay in touch with AI solutions will end up being more efficient and relevant in the workforce.

AI: That perspective on efficiency and relevance rather than replacement is really thoughtful. It sounds like you see AI as something that transforms how the work gets done rather than eliminating the need for human expertise.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: One thing I would like to see more of is secure RAG type solutions, where we can run local models that have access to all of our documentation and environment without fear of exposing anything or compromising security. Instead of logging into the wiki, finding the right article, finding the right place in the article, and interpreting it, I could ask a local LLM how to do a specific thing, and it would have a tailored response for the environment. If this was combined with an overall higher quality in LLMs, which it seems like we are gradually achieving, then even hardliners will begin using the tools, because they are undeniably helpful.

On the negative aspect, bad actors also have access to LLMs, so security solutions in the present and increasingly going forward need to have consideration for LLM assisted attacks, such as where each new attack can appear novel.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on the distinction between being a "wizard" versus maintaining engineering competence, and your vision for secure, localized AI solutions that could work within existing organizational constraints.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about balancing efficiency with technical understanding, navigating organizational AI adoption, and thinking strategically about security considerations will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candid you were about both the benefits and limitations you've encountered. Have a great rest of your day!
