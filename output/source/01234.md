# Dialog 01234

**Transcript ID:** science_0065

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: No, let's start

AI: Great! Let's dive in.

To start, I'd love to get a sense of your work. Could you walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: I am an astrophysicist studying accretion and outflows from compact objects. I use computer simulations to study astrophysical systems such as active galactic nuclei (AGN), X-ray binaries and protoplanetary discs.

A typical research project will involve 1) choosing a narrow scientific question to study such as understanding a specific astronomical phenomena in a specific type of astronomical system. I might be motivated to predict what a new telescope observation might yield or explain a recent observation 2) develop some new computational tool to simulate this phenomena using hydrodynamics simulations in C++ 3) analyze the simulation results in python 4) write up my results in a research paper and submit them to a peer review journal 5) go through the peer review process

AI: That's fascinating work! I can really see how computationally intensive and methodical that process must be - from the initial scientific question all the way through peer review.

Where in that process, if anywhere, have you experimented with using AI tools?

User: I've tried using AI for all of the steps. When researching ideas, to help search the literature for interesting systems or understand what other's have done before. When developing simulation code to help with implementing physics equations. When analyzing results to make pretty plots. When writing papers to quickly write first drafts of paragraphs or format data tables

AI: That's really comprehensive - it sounds like you've explored AI across your entire workflow. Let me focus on one of those areas you mentioned.

For the code development step - implementing physics equations in C++ - tell me about how you decided whether to use AI versus your traditional approach for that work.

User: My coding skills are not very good. AI helps make sure I am using the correct syntax. It's like a glorified google search but the output is specifically taylored to my situation

AI: That's a really practical perspective - using it as a more targeted search tool for coding syntax. 

Thinking about the parts of your research where you haven't used AI much, or where you've tried it but decided not to continue - what's kept you from using it there?

User: Two examples come to mind. AI is not very good for literature reviews. If I ask for example, "give me references for this claim in the literature" I've found the answers given are often incorrect or not very good.

AI is also very bad at searching through astronomical databases. For example, if I ask "give me a list of astronomical systems that have been observed by the Hubble space telescope with XYZ property" it will be unable to do so

AI: Those are really concrete examples - it sounds like AI struggles when you need accurate, verifiable information from specific databases or literature. 

When you've used AI for something like writing first drafts of paragraphs or making plots, how do you verify or validate what it produces?

User: For writing papers, I have AI write the paragraphs and I find relevant citations myself using NASA ADS and searching relevant papers for the citations older papers used.

When making plots, I'll test the plotting scripts with data that I know the answer for or think of extreme/limiting cases to compare to. I kinda treat AI outputs as something on of my students would bring me. I'm skeptical, and try to figure out if it makes sense.

AI: That's a great analogy - treating AI output like student work that needs your expert review. It sounds like you've developed a pretty systematic approach to validation.

We're about halfway through our conversation now. Let me ask you this: If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't handle well, what would that be and why?

User: Helping with literature reviews would be the most helpful. If AI could break down the main results of research papers and put them in context of other papers that would be super useful. If someone makes a scientific claim, if AI could reply papers XYZ broadly agree with this work but papers ABC found these differences that could be very helpful.

AI: That would be incredibly valuable - having AI that could synthesize findings across papers and highlight where there's consensus versus disagreement in the literature. It sounds like that kind of contextual analysis would save you enormous amounts of time.

Those are all my questions - your perspectives on how AI serves as a practical tool for syntax help and plot generation, but struggles with the accuracy needed for literature searches and database queries, were particularly insightful. 

Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: There is also the aspect of how to use AI in teaching. I currently don't teach but that use case i also very important.

AI: That's a really important point - the teaching dimension is something we didn't explore but could have major implications for how the next generation of scientists learns to work with these tools.

Thank you again for sharing your experiences so openly. Your insights about treating AI outputs with the same skepticism you'd apply to student work, and your clear articulation of where AI helps versus where it fails you, really help us understand the nuances of how AI fits into real scientific work. The literature review challenge you highlighted seems like such a crucial barrier to overcome.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
