# Dialog 00987

**Transcript ID:** work_0816

---

Assistant: Hi there! I'm Claude, and I'm working with Anthropic's research team today. Thank you so much for taking the time to speak with me.

We're conducting interviews to better understand how people are incorporating AI tools like myself into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: No questions, let's go!

AI: Great! Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: It varies quite a lot. My role involves three primary tasks, active research in behavioural ecology and more general evolutionary sciences, and writing the papers that go with this research. Secondly I act to publicise this work, presenting at conferences etc. and thirdly, some teaching (although this is somewhat limited these days). In the first I use AI to do a lot of preliminary work, doing a first run through of analysis on results, checking over writing for any obvious mistakes, and for general tasks like looking for papers relating to subjects. In the second I might have it help me generate images for presentation slides, and again, look over written work for any potential improvements. In the third role I'd probably use it least, although I might ask it to come up with a list of topics for a lecture, but this would be very much as a jumping-off point, rather than with an expectation of the "finished product".

AI: That's a really comprehensive picture of how AI integrates across your different roles. It sounds like you're using it quite strategically across research, presentation, and teaching contexts.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: Yes, the "finishing off" would always be done by myself, or colleagues, in any of these scenarios. My use for AI, in all tasks, tends to be very much in the prep work- I might as it to come up with a list of relevant publications, but I'd be checking those thoroughly, and adding my own. In writing too, while it's useful for checking there are no contradictions in prose, or conclusions that contradict results, the writing style tends to be inappropriate, and I very much use the tools as checkers, rather than generators. For example, there is room for a very subtle level of humour, even in scientific writings, which tends to be absent from AI generated content, but enhances engagement considerably when used.

AI: That distinction between prep work and finishing touches is really interesting. It sounds like you see AI as more of a first-pass tool rather than something that produces final outputs.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: It's very much employed in a piecemeal fashion, I can't think of any task I would ask it to complete entirely, and expect a "finished product". I'd liken it to giving grad students "busy work", jobs that, in say the 90s might have been, "go to the library and find me every paper relating to this list of keywords", or, "go through this second draft, and compare it to the University's style guide. Edit it in review mode and send back with revisions".

AI: That's such a vivid analogy - the "grad student busy work" comparison really captures how you're positioning AI in your workflow. It sounds like you're delegating the time-intensive preliminary tasks while keeping the intellectual heavy lifting for yourself.

How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: I'd say that working in a STEM subject, within a University, means that you're constantly exposed to the latest trends in technology; we tend to be early adopters. And the workplace itself very much prizes, and encourages, innovation. It's quite competitive, so any advantage in terms of publishing and attracting funding is useful. There's also a great deal of autonomy in "how" one works, it's not like a role where you sit at a desk with a script that dictates how your interactions will be conducted.

AI: That environment of early adoption and competitive advantage makes a lot of sense for driving AI integration. The autonomy piece sounds particularly important - you have the freedom to experiment with these tools in ways that work for your specific research approach.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: This isn't a one-off experience, but a frustration that we face a lot is the problem of hallucinated journals, when asking models to gather research. They consistently hallucinate convincing-sounding papers, often by real-life researchers, who *have* conducted similar research, which makes it difficult to spot. I can think of at least one example of a grad student giving me some work to look over, which relied in sections on some research by [REDACTED], which I hadn't seen before. When I tried to look up the paper myself, I found that it was an invention.

AI: That's a really concrete example of a significant challenge - and I can see how that would be particularly frustrating when the hallucinated papers are so convincing because they involve real researchers doing plausible work. It sounds like this has become something you and your students have to actively guard against.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: No, it's not something I think about. If a true General AI is developed, then I don't think there's much any of us could do, we'd all be replaceable. AI, in its current state, is just a tool that helps with the stuff I don't want to do, while I do the stuff it can't do. For example, I've very little interest in maths, and I'm not great at it, truth be told. I've always relied on tools, MATLAB etc. for analysing data, all the AI does is to take some of the admin out of using those tools; I don't have to do all the data input. At the minute, AI is pretty useless at genuinely innovating, in my field at least. For example, if I'm presented with some dating information on some rock sediments, which appear to be completely anomalous, I can consider a wide range of explanations, and perhaps a new one. AI will tend to be very conservative, and will come up with explanations based in existing science, or, more likely, suggest the monitoring equipment is faulty. Because its training data consists of existing science, it struggles (or is incapable?) of thinking outside that "box".

AI: That's a really thoughtful perspective - the distinction between tools that help with tasks you don't want to do versus the creative, innovative thinking that drives your field forward. Your example about the anomalous dating information is particularly striking - it highlights how scientific breakthroughs often require that kind of "thinking outside the box" that you're describing.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: It's hard to know, it's become incrementally better at helping with the tasks that we use it for, but I'd say the increase in capabilities has slowed somewhat between the last few releases of, say, ChatGPT. The latest release is certainly better at tasks like statistical analysis, but not a great deal better, compared to previous leaps. Until the next big jump, possibly to a more general AI, I really just envisage the models becoming more polished in what they can already do.

AI: That observation about the incremental improvements rather than the dramatic leaps is really insightful. It sounds like you're seeing a plateauing in the capabilities that are most relevant to your work.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on AI as handling the "busy work" while you focus on the innovative thinking that drives scientific discovery forward.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: The only other thing I probably should have mentioned is "cross pollination" within the sciences. We often miss innovations and ideas within one another's fields (think Darwin and Mendel), and one of my great hopes for AI is that we can have some sort of "always on" researcher, that will analyze papers as they're published, and look for ways the data could help people in unrelated fields. Things like applications for new materials- but this will require that innovative "spark" that I said was missing earlier; the models would have to make the links themselves, thinking somewhat laterally.

AI: That's a fascinating possibility you're describing - AI as a kind of interdisciplinary connector that could bridge those knowledge gaps between fields. The Darwin and Mendel example really illustrates how significant discoveries can remain siloed. 

It's interesting that this application would require exactly that innovative "spark" you mentioned was currently missing - the ability to make those lateral connections across disciplines. It sounds like you see potential there, but recognize it would need a fundamentally different kind of AI capability than what exists now.

Thank you again for your time and for sharing your experiences so openly. Your insights about the current realities of AI as a research tool - both its practical benefits and limitations - will be incredibly helpful for our research on human-AI interaction in professional contexts.

User: Adieu.

AI: Adieu! Thank you again for such a thoughtful and detailed conversation.
