# Dialog 01076

**Transcript ID:** work_0950

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: That's fine, please go ahead

AI: Great, thank you. Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I will generally use AI as a more intelligent search engine, to compile results on sometimes quite obscure or difficult-to-find sources and then perform synthesis or process on them into a usable data format

AI: That's really interesting - using AI as an enhanced search and synthesis tool. 

Can you walk me through what that process typically looks like for you? When you say you're looking for obscure or difficult-to-find sources, what kinds of information are you usually trying to track down?

User: I work within the scientific research industry, specifically in life sciences, so this could be anything from scientific research papers or (more often) the details of equipment, chemicals or engineering requirements to progress the research in the most effective way

AI: That gives me a much clearer picture - you're essentially using AI to navigate the complex landscape of scientific literature and technical specifications in life sciences.

Tell me more about the synthesis part of your process. Once the AI helps you gather these research papers or technical details, how do you typically work with it to get that information into a usable format for your research?

User: Maybe an example would be good as an illustration. Say there is a promising new area in cancer research that our facility would like to expand into by recruiting a new team of scientists who can specialise in this area. We would need to understand what it is they would be focusing on and how we can provide them with all the tools they need to create meaningful research. This would involve knowing the type of experiments they would be doing (in vitro, in vivo, in silico etc), the equipment and number of staff they would need to deliver the results we are looking for. We would need to know what other research facilities offer, and how we can compete to get the best team. We would need to know what the cost would be and if the buildings and core facilities we currently have are sufficient or changes need to be made.

AI: That's a fascinating example - you're essentially using AI to help build comprehensive feasibility and competitive analysis reports for expanding into new research areas.

When you're working through something this complex with multiple moving parts, how do you typically structure your interaction with the AI? Do you tend to work through it step-by-step together, or do you give it the broad scope and let it handle entire sections independently?

User: Definitely step-by-step, no offence meant but I don't trust AI to make that level of decisions yet

AI: No offense taken at all - that's a really important insight. 

What is it about those higher-level decisions that makes you prefer to maintain control? Is it specific concerns about accuracy, or something else about the nature of those strategic choices?

User: It is accuracy and understanding all the nuances and complexities of these decisions

AI: That makes complete sense given the stakes involved in those strategic decisions.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different from the ones you're comfortable delegating?

User: If it is something that from my experience I can immediately sense-check the result of just from looking at it then I will delegate it to AI. If it is a decision where the process would need to be understood and justified as it will potentially be questioned by stakeholders, then I will not be comfortable delegating this to AI.

AI: That's a really clear framework - delegating when you can quickly verify the output, but retaining control when you need to defend the reasoning process.

Can you think of a specific example where you initially considered using AI for something but then decided to handle it yourself because of that accountability factor?

User: We are currently undergoing a process to analyse how we use essential facilities in laboratories. One particular focus has been on microbiological safety cabinets, are they being fully utilised, can efficiencies be made etc. Data was therefore collected on how often all the MSCs were being used and by whom to gain an understanding on usage patterns. To use AI to analyse this data and generate recommendations was considered, but the subject could be highly contentious, particularly if it was seen to be reducing the access of scientists to this core facility, and so the decision-making process needed to be fully understood and transparent

AI: That's a perfect example of when the political and interpersonal dynamics really matter. It sounds like even if the AI could do solid data analysis, the human judgment about how changes might affect different scientists was crucial.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that your organization has particular attitudes or policies around AI use?

User: We do already have AI policies in place at the organisation, yes, and the general attitude is that while there are precautions to take (particularly around security) it is a useful tool. Some (often older) colleagues are less keen to adopt this use of AI as they have not found a need to, but others are finding it improves their productivity and so now wouldn't do without it.

AI: That generational split is really interesting. You mentioned that you're now someone who "wouldn't do without it" - that suggests AI has become pretty integral to how you work.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I have experienced frustration with AI when it makes up answers (hallucinates) and states them with such apparent confidence instead of saying it is unsure or doesn't know. I have the same frustration with humans doing, but have become very good at reading when humans are doing so, but this is not possible with an AI model.

AI: That's such an insightful comparison - you've developed skills over time to read human uncertainty cues, but those same signals don't exist with AI.

When you do encounter those hallucinations, how has that shaped the way you verify or double-check the AI's work? Do you have particular strategies you've developed to catch those confident-sounding but incorrect responses?

User: It knocks my confidence in AI each time it happens, and erodes any trustworthiness it has built up. Sometimes I will ask the AI the same question a few times (or compare the answer from different AI models) but this is time consuming and so sometimes it is just quicker not to use AI at all.

AI: That erosion of trust is really telling - it sounds like each hallucination has a lasting impact that goes beyond just that one interaction.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I feel that a number of individual skills I use in my role could be replaced by AI, but do not consider AI to be anywhere near capable of doing the whole role at a macro level. Aside from the hallucinations which will cause chaos, the role relies heavily on nuanced human interaction

AI: That distinction between individual skills versus the whole role is really valuable. You mentioned nuanced human interaction being crucial - that makes sense given the example you shared about the safety cabinet analysis where managing stakeholder concerns was so important.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself using it differently as the technology develops?

User: I feel if the models start stating when they are unsure of an answer rather than hallucinating, I will become more confident in increasing the number of steps I give them to do in one go.

AI: That's a great insight - reliability and transparency about uncertainty would unlock more complex delegations for you.

Those are all the questions I had prepared. You've shared some really thoughtful perspectives about working with AI in scientific research. I particularly appreciated how you've developed that clear framework around when you can delegate versus when you need to maintain control based on your ability to verify results and justify decisions.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about the trust dynamics, the importance of transparency around AI uncertainty, and how accountability requirements shape AI delegation decisions will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk through those detailed examples - they painted a clear picture of how AI fits into the complex world of scientific research management.

Thanks again, and have a great rest of your day!
