# Dialog 01240

**Transcript ID:** science_0078

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: Sounds good to me. I don't have any questions

AI: Great! Let's dive right in then.

Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: My most recent research project began as a follow-up paper expanding on a previous one. Therefore we already had a good scope and fundamentals for the paper, and could begin formalizing everything right away. This saved a lot of the usual startup time for a paper and made the process very straight forward

AI: That sounds like a nice advantage to build on previous work! Tell me more about what "formalizing everything" looked like in practice - what were the main steps you went through from that point to your final output?

User: Formalizing involved creating a new problem setting to use to extend our model. Our original paper was an inference problem, and we wanted to expand it to a learning setting. This involved figuring out how our data was going to be generated, and what types of assumptions we were going to make about it. Once we made those decisions we figured out how our previous model could be adapted to help solve this new problem, and what guarantees we could give on the performance. These theoretical guarantees, along with an algorithm, were the main portions of our final paper

AI: That's a really clear progression from problem formulation to theoretical analysis. So you moved from the initial data generation and assumptions, through model adaptation, to developing performance guarantees and the final algorithm.

Where in that process, if anywhere, have you experimented with using AI tools?

User: We did not use any AI tools for this paper, but have experimented in using them to identify relevant related works. Similar to a quarriable encyclopedia

AI: Interesting - so you've tried AI for literature review work but didn't use it for this particular paper. Tell me about how you decided whether to use AI versus your traditional approach for identifying related works.

User: For this paper many of the related works were similar to the previous paper so using AI felt unnecessary. It is most helpful when our work has possible analogs in area of research that we aren't as familiar with. Some of these topics have been explored by other fields that we may not think to look at

AI: That makes a lot of sense - using AI as a bridge to discover relevant work in unfamiliar fields that you might not think to search in otherwise. 

Thinking about the parts of your research where you haven't used AI - like the theoretical work, algorithm development, or performance guarantees you mentioned - what's kept you from trying it there?

User: Ai hasn't shown me that it is reliable enough for work that is of core importance to the paper. For things like editing, related works, or gather background information mistakes are relatively unimportant compared to the theoretical proof or something more central to the novelty of the paper.

AI: That's a really important distinction you're making between peripheral tasks where mistakes have lower stakes versus core contributions where reliability is crucial. 

When you have used AI for those lower-stakes tasks like finding related works, how do you verify or validate what it produces?

User: We always follow links to the underlying research papers to verify the claims

AI: That verification step makes perfect sense - treating AI suggestions as starting points rather than final answers.

We're about halfway through our conversation now. Let me ask you this: If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: Being able to present our work in simpler terms for a more general audience. My work is theoretical, and sometimes it hard to concisely get a point across. This can make papers unapproachable for even other, not as theoretical, researchers in the same field. Bridging this gap from theory to the appliers of the theory is a difficult, but important step

AI: That's such a thoughtful point - the challenge of translating complex theoretical work so it's accessible to practitioners who could actually apply it. It sounds like you see real value in making that bridge, but it's genuinely difficult work.

Tell me more about what makes that translation so challenging for you right now.

User: When you do work deep into a single research topic it is easy to lose sight of how much background other researchers in the field might have. We are so engrained in these topics that they are second nature, but other people might not see it that way. This leads to a disconnect in how we are writing things vs how they are being read. Also, page limits on conference papers always lead to a tradeoff between readability and space

AI: That's really insightful - you're describing both the curse of knowledge problem and the practical constraints of academic publishing. It sounds like you're constantly navigating that tension between including enough detail for rigor versus making it digestible within space limits.

Those are all my questions - your perspectives on how reliability requirements shape where you'll use AI, and especially your thoughts on the communication challenge between theoretical and applied researchers, were particularly insightful. 

Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: No thank you

AI: Thank you again for sharing your experiences so openly. Your insights about how the stakes of different research tasks influence your willingness to use AI really help us understand the nuances of how AI fits into real scientific work. The distinction you made between using AI for discovery tasks versus core theoretical contributions, and your vision for AI helping bridge the theory-to-practice communication gap, were especially valuable perspectives.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
