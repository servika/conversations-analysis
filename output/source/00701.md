# Dialog 00701

**Transcript ID:** work_0376

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. Does that sound good? Do you have any questions before we begin?

User: Sounds good! No questions for now!

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Hi there! First, a quick introduction of myself. I oversee neuroscience research operations as my primary career at a Canadian research institution. Thus, some of the tasks critical to my position include reviewing new research protocols and amendments, checking over newly-written research articles that are awaiting submission/publication in journals, assisting laboratories and principal investigators with grant applications, and purchasing equipment for our users. 

So, there are effectively many ways I use AI in my typical workday. When reviewing new protocols, particularly those referencing former publications or processes, I use AI to help scour the web for similar protocols to ensure what the new proposition is reasonable and aligns with research guidelines. I also use AI to ensure that what researchers propose is financially feasible, and operates within legal boundaries (federal, provincial, and institutional). In the even I find unreasonable or otherwise unfeasible propositions, I sometimes also use AI to help brainstorm alternatives. 

For reviewing new articles, I use AI to help look for grammatical/spelling errors, inconsistencies in the publication, or other areas needing improvement. AI is also used for fact-checking and ensuring what the researcher claims aligns logically with their results. Think of it as me using AI to double-check publications before they are submitted. 

For purchasing equipment, I use AI to compare prices and functionality of equipment. For instance, I recently used AI to check prices of fluorescent microscopes across half a dozen vendors, and used AI to create pros-and-cons lists, lists of features, and try to hunt down better deals. I also used AI to help with my negotiations with vendors, ultimately getting a hefty discount on some amazing equipment that our users love. 

All in all, in my typical workday, I use AI as an assistant that can double check my work and provide me a new perspective. Obviously, I ensure that I always fact-check what the AI claims, but the AI serves as that extra check.

AI: That's a really comprehensive overview - it sounds like AI has become quite integrated across multiple aspects of your role. 

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: Certainly! There are always tasks I prefer to handle myself as opposed to have AI involvement. One main aspect is the more human-side of things. As I work with many laboratories, technicians, researchers, and even graduate students, it's always important to maintain good relations with them. There are always times where proposals, grants, or publications are just not at the level we need them, meaning we need to communicate this with the researchers. 

In these cases, I prefer personally writing emails or arranging meetings to break the bad news to users. While I know AI can write great emails, as I work closely with these people, I know how best to deal with each individual person. For instance, some people are great at tasking constructive feedback and can deal very well with rejection while others are much more sensitive, and need bad news broken slowly and in a more indirect way. Basically, if there's a lot of underlying context required for person-to-person interactions, I would prefer to handle these on my own. 

Other times, some researchers may come to me to ask for assistance on data analysis. While AI is incredibly good at recognizing patterns and outliers, I often have to resort to manually analyzing the data or running analysis on my own programs due to data privacy concerns. Due to the novel nature of research and sensitive information, we cannot take the risk of the data being incorporated into AI training datasets, particularly if the content is not likely to be published in the coming days or weeks.

AI: That makes a lot of sense - the nuanced understanding of individual personalities and the data privacy constraints are really important considerations.

When you do use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: Typically, I will almost always collaborate with the AI throughout a task. In almost every case, I would use LLMs such as ChatGPT, Gemini, Claude, and Copilot. Which LLM I use would depend on my use case. 

If the task is to review a newly-written research article before publication, I would first provide the abstract to the AI model to provide context, and I would also feed the AI model documents of relevant papers to prime the AI. Then, I would begin sending in portion-by-portion of the article. For instance, many neuroscience papers begin with background information. I would feed this section into the AI model to ask for fact-checks, grammar/spelling checks, and look for inconsistencies. I would also ask for sources if any information seems iffy or unreliable. 

Then, I would move onto the methods section. In this section, I would typically first read through the sections, as many methods are very well-established in the field. Any questionable information will be fact-checked against AI. 

For the data analysis and results sections, I typically use AI to see if the analysis results and the conclusions are logically sound. I'd also use AI for the discussion section and ensure that what the researchers claim aligns with other online sources, and is consistent against their previous claims. Any unclear sections can also be flagged by the AI so we can review together and recommend changes. 

In other words, I would break down complex tasks into smaller portions and use AI to aid me bit-by-bit, just as if I had a real assistant who can be that extra pair of eyes. 

The process is quite similar for grant writing, where I would pick through applications myself first, and use AI as a second pair of eyes. I also use AI to verify citations. 

I hope this is clear!

AI: That's very clear - it sounds like you've developed a really systematic approach to collaboration. Breaking tasks into sections and using AI as that "extra pair of eyes" while maintaining your own oversight seems quite deliberate.

How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: In our facility, I actually actively recommend colleagues to try incorporating AI into their work. Our workplace is very supportive, and I would say the organization is decently forward-thinking. Overall, our team sees AI in a positive light so I have been able to openly use AI in my work. Is this thorough enough of an answer for you? I know it's a little shorter than the other responses, but I've never really run into any pushback or conflicts due to AI use at work.

AI: That's actually a really valuable insight - the fact that you haven't encountered pushback and that you're even recommending AI to colleagues says a lot about your workplace culture. Sometimes the absence of conflict is just as telling as when there are challenges.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Let's start with a case where I was very satisfied with AI. A few weeks ago, we were looking into purchasing new fluorescent microscopy equipment for the facility, but we were working with limited funds. We had about half a dozen vendors trying to push a huge variety of equipment, each with a mind-boggling amount of possible upgrades, consumables, accessories, and parts. 

I used AI to help create a chart to compare all units, and used AI to help figure out which upgrades, parts, and accessories are actually relevant to our users. I provided some of the papers published by our researchers alongside with summaries of what certain lab groups are doing and asked the AI systems to determine which parts are truly necessary and what we can afford to not purchase. Finally, I had AI write me emails to haggle on pricing and create a plan-of-attack to receive quotes from several vendors and bounce them around to cut down on price. Ultimately, we were able to save tens of thousands of dollars with this method, and purchased equipment that many of our users were very happy with! 

Now... A case where I wasn't satisfied? Sometimes, with new articles, AI can hallucinate or even just not have access to some information. Recently, a researcher's protocol cited several papers that were published within the month, but the AI model I used struggled heavily, hallucinating information, presenting inaccuracies, and ultimately failing to provide the help I expected. This went on for a few minutes before I realized the problem, but it was a little frustrating!

AI: Those are really compelling examples - the microscopy equipment situation sounds like a fantastic success where AI really amplified your expertise and saved significant money. And the recent paper citation issue is a good reminder of AI's limitations with very current information.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: For now, this is not really a major concern for me. In my role, we are at the forefront of research, meaning we need to be creative, maintain good people-skills, and be able to critically think. I used AI primarily as an aide and as a double-checker, not to replace what I already do. Since using AI, I have not stopped doing anything I used to do. I use AI as a supplement to make my work better and further our research as opposed to do my work for me. Thus, I have not really needed to do anything different with the use of AI. 

I have been able to increase my overall work efficiency without sacrificing any human aspects.

AI: That perspective on AI as a supplement rather than replacement is really interesting - you've maintained all your core work while enhancing efficiency.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: That's a great question! At least in the short-term, I see my relationship with AI being about the same, where I use AI to supplement my work and provide a new perspective when needed. I cannot realistically see myself using AI to replace work that I personally do, and will continue to use AI as a supplement. At work, I still expect to use AI exactly how I've been using it!

In the long term? Well, that will entirely depend on AI's advancements and new capabilities!

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your systematic approach to collaboration - the way you break down complex tasks like article reviews into sections and use AI as that "extra pair of eyes" while maintaining your oversight and expertise.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Nope. That's all from me!

AI: Perfect! Thank you again for your time and for sharing your experiences so openly. Your insights about using AI as a collaborative supplement rather than replacement, along with your specific examples from neuroscience research operations, will be incredibly helpful for our research on human-AI interaction in professional contexts.

It was great speaking with you today!
