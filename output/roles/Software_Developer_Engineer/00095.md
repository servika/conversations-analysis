# Dialog 00095

**Transcript ID:** work_0025

---

Assistant: Hi there! I'm Claude, and I'm here representing Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like myself into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Sounds good, I don't have any questions at this time.

AI: Perfect! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I work as a QA tester for software applications and I found that AI can be useful in generating test cases. Once testing goals are defined, the AI can help determine what types of tests should be executed to ensure areas are thoroughly tested. Some test runs can have upwards of 100 test cases and can take a good amount of time to create. With the help of AI this process can be done quicker, allowing more time to be spent on testing. In addition, AI can compile all of the testing results to generate a report and determine the health of each area. It can provide links to bug numbers that allow quick access to platforms like JIRA.

AI: That's really interesting - it sounds like AI is helping you with both the planning and reporting sides of your testing work. 

When you say AI helps generate test cases, can you walk me through what that process looks like? How do you typically interact with the AI to get the test cases you need?

User: You can integrate a 3rd party AI tool into JIRA as an add-on. From there you have the ability to create a test run based on predetermined stories, scenarios, or bugs that have already been created/logged in JIRA. Filters and search bars are available to improve searchability. Once you have included the necessary criteria you can then hit create and run and a test run will be generated.

AI: That's a really streamlined process. So the AI is essentially taking your existing JIRA items and automatically creating comprehensive test runs from them.

I'm curious about your preferences when working with AI for testing. Are there certain aspects of your QA work that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: The testing aspect is preferably handled by human testers because issues can sometimes be visual and the navigating of the application is better done by humans. AI primarily handles test management and reporting where it can handle large volumes of data at a time.

AI: That makes a lot of sense - you're drawing a clear line between the analytical data processing that AI excels at versus the visual inspection and user experience navigation that requires human judgment.

When you use AI for those test management and reporting tasks, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout the process, or do you tend to set it up and let it handle those tasks independently?

User: It is a collaboration. The contents of the tests and reports are determined by us, AI just does the heavy lifting by putting it all together. If we decide we need to revise anything, we can just simply adjust the criteria.

AI: That collaborative approach sounds really effective - you maintain control over the strategy and criteria while the AI handles the execution.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Has there been any particular encouragement, resistance, or shared practices around AI adoption?

User: Because test creation, management, and reporting is primarily the role of a Test Manager/Software Test Engineer, it feels that AI is making their job easier whereas the Test Associates (the ones who test software and find bugs) still do all the manual work. The plus side is that the Test Managers, with the help of AI, can work more efficiently and as a result be available to provide more support for the testers. The con is that Test Associates might feel like they do more work but for less pay than a Test Manager.

AI: That's a really insightful observation about how AI is affecting different roles within your team differently. It sounds like there's some tension around how the benefits and workload are distributed.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: AI is mostly used as a tool to make certain processes easier, so we rarely have AI use cases where it adds frustration because then we would simply not use it. We are not required to use AI if it makes things harder.

AI: That's a practical approach - using AI only when it genuinely improves your workflow rather than feeling forced to adopt it.

Since you mentioned the flexibility to choose when to use AI, how do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, especially given the differences you mentioned between Test Managers and Test Associates?

User: I think from a Test Manager perspective, although it makes test creation and reporting easier, it still requires thorough planning from a human to execute effectively. Test Managers might get a little rusty in creating test runs and reports from scratch but unless AI is capable of the planning itself I think that's the primary job/skill of the Test Manager and that appears to remain intact.

AI: That's a thoughtful perspective on how the core planning and strategic thinking skills remain essential even as the execution becomes more automated.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it expanding into other areas, or do you think it will stay focused on those test management and reporting functions?

User: I think it's possible that AI can get to a point where it can run, test, and report all on its own but only when it follows a predetermined workflow. I don't think it will ever be capable of testing a piece of software freely and thoroughly without guidance, but humans can.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI in QA testing. I particularly appreciated your perspective on how AI affects different roles within your team differently, and your observation about AI requiring human planning and guidance to be truly effective.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, I think we've covered everything.

AI: Perfect! Thank you again for your time and for sharing your experiences so openly. Your insights about the collaborative nature of AI in QA work, the different impacts on various team roles, and the importance of human judgment in testing will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!
