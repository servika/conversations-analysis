# Dialog 01222

**Transcript ID:** science_0045

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer here—we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: Hi Claude, sounds good. Ready when you are!

AI: Perfect! Let's dive in.

To start, I'd love to get a sense of your research work. Could you walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: One of my most recent projects was during my time as a researcher at the University of Tokyo, where I worked on the catalytic degradation of lignin. The idea was to study model compounds that mimic the ether linkages in lignin, and to understand how those bonds break under catalytic transfer hydrogenolysis using hot-compressed alcohols over a metallic catalyst.

Firstly, I worked with many lignin model compounds to reduce the overall complexity of the experiment and make it easier to identify breakage of specific linkages. In my case, I worked mostly with a tetramer (4,4'-Oxybis(phenoxybenzene)), containing 4 phenyl groups attached together with 3 ether bonds. I set out multiple experiments changing process conditions from the type and amount of catalyst, type of hydrogen donor, temperature, pressure, and residence time. The products were analysed using GC-FID, GC-MS, and NMR.

From there, I focused on quantifying yields, exploring possible reaction pathways, and using numerical methods to model kinetics. AI was very useful in this stage, it helped me in figuring out how to set up my conditions in Python for iterative calculations.

AI: That sounds like a fascinating project with the lignin degradation! I can hear that there were quite a few complex moving parts - from the experimental design with all those different variables to the analytical work and then the kinetics modeling.

You mentioned that AI was very useful in the kinetics modeling stage, specifically helping you set up conditions in Python for iterative calculations. Tell me more about that - what exactly did you use AI for in that part of the work?

User: Yeah, so in the kinetics stage I had to build a system o differential equations to represent all the possible reaction pathways and intermediates. In my case, I had around 30 rate equations, all interlinked, which made it really tricky to manage manually.

I used AI to help me set this up in Python. For example, I'd describe the reactions and rate laws, and AI would help me structure the system of ODE's and check the logic. It also helped in troubleshooting errors when I tried to scale the model up, like correct indexing and proper convergence of the iteration loops.

AI: That makes a lot of sense - 30 interlinked rate equations sounds incredibly complex to manage! It sounds like AI was really helpful as a kind of coding partner for that mathematical modeling work.

Thinking back through that whole project - from the initial experimental design with all those different catalysts and conditions, through the GC-FID and NMR analysis, to that final kinetics modeling - where in that process, if anywhere else, have you experimented with using AI tools?

User: Another big area where I used AI was literature reviews. Normally, digging through dozens of papers to find the relevant details is really time-consuming, and it's easy to get bogged down in stuff that isn't directly useful. With AI-assisted tools, I could ask targeted questions and quickly get summaries or context that helped me filter out the irrelevant papers.

Once I had a shortlist, I still went through the actual papers manually, I would rely on AI as the final words, but it meant I was starting from a much more focused set of sources. That saved me a huge amount of time in the early stages, since this project was extremely time limited.

In terms of experimental design, most of the equipment in the lab is old school, and written in Japanese, so AI didn't prove to be as useful in this case. I also didn't need AI much for GC analysis. This is knowledge you have to learn in the lab, and takes time to get used to.

AI: That's really interesting - it sounds like AI was particularly valuable for that literature review filtering process, helping you cut through the noise to find what was actually relevant. And I appreciate that distinction you made about still going through the papers manually rather than relying on AI as "the final word."

For that literature review work specifically, tell me about how you decided whether to use AI versus your traditional approach. What made you think to try AI there, and how did you weigh that decision?

User: I used AI for literature work mainly because of the time pressure, I needed to get a broad understanding quickly without reading irrelevant papers. I suppose I gave it a real go when I discovered some AI tools that are quite good at directly answering specific research questions. For example, I could ask: "What are the typical bond dissociation energies for β-O-4 versus 4-O-5 linkages in lignin?" and this would give me a list of peer reviewed published papers that have data on this question. I can then assess what process conditions led them to these values. It makes for a very fast starting framework.

AI: That's a great example - being able to ask that specific technical question and get pointed to relevant data and process conditions. It sounds like AI really excelled at helping you navigate that vast literature landscape efficiently.

We're about a third of the way through our conversation now. I'm curious about the flip side - thinking about the parts of your research where you haven't used AI, like you mentioned the experimental design with the Japanese equipment or the hands-on GC analysis. What's kept you from trying AI in those areas?

User: There are definitely parts of the work where AI hasn't been that useful. A lot of the equipment in the lab isn't well documented and known in terms of standardisation, so it really came down to physically learning the setup from other researchers. Same case with the GC-FID analysis. AI can help in understanding calibration theory or data processing, but the actual operation, including sample prep, loading columns, or maintaining the detector/column, is something you can only learn in the lab. It's also an area where mistakes can ruin days of work, so I wouldn't trust AI for any step-by-step lab instructions without cross-checking everything. The cost of error when using AI is too high.

AI: That's a really insightful point about the cost of error - when mistakes can ruin days of work, the stakes are just too high to rely on AI for those critical hands-on procedures. And I can see how that tacit knowledge from other researchers about equipment quirks and techniques is irreplaceable.

When you have used AI for things like the kinetics modeling and literature reviews, how do you verify or validate what it produces? What's your process for making sure the output is reliable?

User: Validation is very important to me. Whenever AI helped in structuring equations or writing code, I'd always test it against simpler systems first, like a single pathway or a dimer reaction where I already knew the expected trends. If the model produced sensible results in those controlled cases, then I'd feel more confident in scaling it up to the full 30+ reaction system.

For lit reviews, I never treat AI outputs as definitive. If it points me to a BDE or a catalytic pathway, I will check the reference and validate the claim. AI can be very useful in narrowing down the search, but it's up to you to check the source.

For me personally, AI is like an assistant for saving time, but I always cross-check everything, that's what makes me comfortable in using it.

AI: That validation approach sounds really thoughtful - using those simpler test cases to build confidence before scaling up, and treating AI as a time-saving assistant rather than an authoritative source. It seems like you've developed a good sense of where to leverage AI's strengths while maintaining scientific rigor.

If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: Maybe some way to integrate the analytical equipment with an AI assistant. A lot of time is spent either troubleshooting instruments or manually processing data from GC, NMR, FTIR, etc. If AI could do things like auto flag when a calibration curve looks off, or suggest optimal conditions based on the results in the current run, it would save a good deal of time. Outside of that, I'm pretty happy with how AI is growing.

AI: That sounds like it would be incredibly valuable - having AI integrated right into the analytical workflow to catch those calibration issues in real-time or optimize conditions on the fly. I can imagine that would eliminate a lot of the tedious troubleshooting and manual data processing that eats up research time.

Those are all my questions - your perspectives on using AI as a time-saving assistant while maintaining rigorous validation practices were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: I think that's everything

AI: Perfect! Thank you again for sharing your experiences so openly. Your insights about treating AI as a time-saving assistant rather than an authoritative source, and how the cost of error determines where you're willing to use it, really help us understand the nuances of how AI fits into real scientific work. 

Your approach to validation - testing on simpler systems first and always cross-checking sources - shows a really thoughtful integration of AI tools while maintaining scientific rigor. And that vision of AI-integrated analytical equipment sounds like it could be a real game-changer for lab efficiency.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
