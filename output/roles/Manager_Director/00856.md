# Dialog 00856

**Transcript ID:** work_0627

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: No questions. Let's get started.

AI: Perfect, let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: My company has AI interface that uses the LLM. I use it to organize meeting notes, reword emails, and review documents for suggested edits.

AI: That sounds like a pretty integrated setup with your company's AI interface. 

When you say you use it to organize meeting notes - can you walk me through what that actually looks like? What does the AI do with your notes versus what you handle yourself?

User: I will keep track of meeting notes as discussions progress. I then copy my version of notes into the interface and ask it to convert to a formatted meeting note to be shared over email. It does this well enough. But i always review it because it is prone to errors. Perhaps because my notes are not perfect.

AI: That's really interesting - so you're keeping the human judgment piece for quality control. 

Tell me more about those errors you catch during your review. What kinds of things does the AI typically get wrong or miss when it's formatting your notes?

User: Sometimes it changes the wording that adjust the meaning of what was said. Not always in a drastic way, but it could be more like saying something direct that was stated as a suggestion. Another example is that it confuses the vernacular or nomenclature of our products and services. For example, i put in an abbreviation "LMS" and it doesn't know what to do with it.

AI: That's a really concrete example - the AI missing your company's specific language and context. It sounds like those meaning shifts, even subtle ones, could be pretty important in a work setting.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: Yes. Email is a good example. When i use AI to write or edit them, it makes me sound like a robot instead of my personal brand/reputation being embedded in the language. It lacks virtually all character.

AI: That's such a good point about personal brand and character. It sounds like there's something important about your authentic voice that gets lost.

When you do use AI for emails - like for rewording - how do you decide which emails are worth that trade-off versus the ones where you need to preserve that personal touch?

User: When i am communicating with upper management, others who do not know me, or a large audience. It may be best to 'know the audience' and be more direct with my language. Thus, providing it in a systemic, easy and quick to read layout may be best. Which AI can provide.

AI: That makes a lot of sense - matching the communication style to your audience and context. So AI becomes useful when you want that more systematic, direct approach.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I do collaborate with it through out a task. Can you give me an example of what would be considered to 'complete tasks for it to handle independently?'. I do not think my AI at work can do this well.

AI: Good question - by complete tasks I mean something like "here's all the information, go write the entire report and send it" versus what you're describing, which sounds more collaborative.

It sounds like you're working with the AI step-by-step - like you give it your raw notes, it formats them, then you review and refine. Is that collaborative approach something you prefer, or is it more about the current limitations of your workplace AI?

User: Right, my current AI at work does not have the ability to send anything or create reports other than in markdown. I would use it to create a presentation in PPT if i could, but its current iteration does not allow that. I would of course need to review it for accuracy.

AI: So it's partly a limitation of what the tool can actually do right now. But even if it had those capabilities - like creating full PowerPoint presentations - you mentioned you'd still want to review for accuracy.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Are others using it similarly, or do you see different approaches around you?

User: Our company is pressing us to use it more often and show stats by user engagement. However, i am not aware of many of my colleagues using it. I would be the largest adopter of it, but still do not really use it all that often either.

AI: That's really interesting - there's a push from the company but not much actual adoption happening. 

What do you think is behind that gap? Is it that the tool isn't quite meeting people's needs, or are there other barriers keeping your colleagues from using it more?

User: Its current version does not really set up that much time. Coupled with being required to review it for accuracy, as it commonly makes errors, it is not valuable. I can envision a way where it could become very valuable, but it is far from that today.

AI: That makes complete sense - if you have to spend significant time reviewing and correcting, the time savings disappear. You mentioned you can envision it becoming very valuable though.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: A time it did make me very frustrated was giving me incorrect information on well known and established banking regulations. I was unable to get an answer to my specific question and ended up having to look it up myself outside of AI.

AI: That sounds really frustrating - especially when you're dealing with something as critical as banking regulations where accuracy is essential.

When the AI gave you that incorrect information, did you realize it was wrong right away, or did you have to discover that later when you looked it up yourself?

User: I asked a first question where it generated an answer, and then i had a follow up question and an element of their original answer changed. This led me to not trust either answer and required me to look it up myself and begged the question, why am I using AI at all if it cannot be trusted.

AI: That inconsistency would definitely shake your confidence - when the AI contradicts itself, it really undermines trust in the whole interaction.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I feel like it could become a substitute for a lot of what I do. I do consider it and try to see where/when my skills will be lapped by AI and be replaced.

AI: That's a pretty direct way of thinking about it - actively watching for when AI might surpass what you can do.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself adapting your role, or do you think the technology will need to improve significantly first?

User: I do expect my relationship with AI to grow at work. There is a lot of forces pushing us to use it and i do not see that stop. However, it does need to become more powerful in future releases

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how the inconsistency in responses - like with those banking regulations - really undermines trust in the whole system.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Nothing else. Thank you.

AI: Thank you so much for your time and for sharing your experiences so openly. Your insights about the gap between organizational pressure to adopt AI and the actual practical value you're seeing day-to-day will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate your candid perspective on both the current limitations and the potential you see ahead. Take care!
