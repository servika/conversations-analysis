# Dialog 01206

**Transcript ID:** science_0005

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: Sounds good!

AI: Perfect! Let's dive right in then.

I'd love to start by getting a sense of your work. Can you walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: I'm going to be somewhat vague here to protect my identity and my IP, but the overall goal of the project was post-processing of nanomaterial composites by dopant intercalation. The initial idea was driving material properties past the current state-of-the-art and ended with a mutivariable parameter space study of the experimental process to identify optimal processing conditions.

AI: That sounds like a fascinating project - working with nanomaterials and optimizing those processing conditions must involve quite a complex workflow.

Where in that process, if anywhere, have you experimented with using AI tools?

User: So my project spanned several years and only recently did I start integrating AI tools into my work. I did not use AI for DOE (design of experiments) or the literature review (although both would probably been quite useful). For the most part, I used AI to assist with coding: to provide example code snippets and to discuss alternative coding solutions to my data analysis. I also never gave an AI model my raw data and asked for analysis; rather, I proposed a generic coding problem and used AI to help me develop the code to solve my proposed problem (somewhat abstracting my own work out of the process).

AI: That's really interesting - you've been quite thoughtful about how you engage with AI, especially keeping your actual data separate from the process. 

For the coding assistance you mentioned, tell me about how you decided whether to use AI versus your traditional approach when you ran into those programming challenges.

User: Well my traditional approach was to Google my coding question and spend hours pouring through forum discussions and codebase documentation in order to figure out how to implement my coding needs. I figured it would be much smarter and more efficient to converse with a language model trained on this wealth of information; someone that had already aggregated and analyzed the various coding discussions throughout the web and could provide a quick recommendation from that experience.

AI: That makes a lot of sense - it sounds like you saw AI as a more efficient way to access that same pool of knowledge you were already tapping into.

We're about a third of the way through our conversation now. Thinking about the other parts of your research - like the DOE, literature review, or direct data analysis that you mentioned - what's kept you from trying AI there?

User: DOE and literature review - this was primarily because these components of the project were already complete by the time I started experimenting with AI tools. I could always go back and expand the background review at this point, but the project is mostly complete. Perhaps I will do so just to make sure I haven't missed any important citations. For direct data analysis, I think my job as a researcher is to be able to draw meaningful conclusions from my datasets. If I rely too heavily on someone else's thoughts on my data, I run the risk of failing to properly understand it myself. Having said that, I think AI is very useful for helping me write the tools to process my data, I just think the critical thinking should be done solely by me (or my coauthors).

AI: That's a really thoughtful distinction you're making - using AI to build the tools but keeping the critical thinking and interpretation in your own hands.

When you've used AI for that coding assistance, how do you verify or validate what it produces? What's your process for making sure the code suggestions actually work for your needs?

User: Well generally my code doesn't make high-level decisions on my behalf. It does very low level things: plotting, smoothing, averaging, baselining, integrating, etc. Occasionally I will use image analysis or other computer vision techniques. A lot of the setup to make a useful plot in, say, python is busywork. If I can have AI figure out how to handle the pandas dataframe for my dataset and organize it in a useful way, then I can spend more of my time analyzing the relationship between the data rather than wrestling with it to display it in a way that makes sense. I don't ever ask AI to write an entire codebase for me. It's usually a very specific request, like, how can I automate the plotting of data from this dataframe with line color determined by this column property and marker color determined by this column, etc. The majority of code is still written by me, with some sticking points eased-up by AI tools.

AI: That's a really clear picture of how you're using AI as more of a targeted assistant for specific technical hurdles rather than a wholesale solution. It sounds like you maintain a lot of control over the overall process.

If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: If I could wave a magic want and make AI finish my manuscript for me, then I would do that haha. I know AI *can* do this, so the magic wand would serve more to remove the ethical considerations for such a task. So the why is: because manuscript writing is hard and I don't enjoy it but also having an AI tool handle the actual scientific communication is ethically unacceptable.

AI: That's such an honest answer - and it really highlights the tension between what AI could potentially do versus what feels appropriate to use it for in scientific work.

We're near the end of our conversation now. Those are all my main questions, and your perspectives on maintaining that boundary between using AI as a tool versus having it do the actual scientific thinking have been particularly insightful. 

Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: I should say that I don't mean to downplay the capabilities of AI with my comments, but I think clear distinctions need to be made between using AI as a tool or resource and having AI replace all aspects of scientific research. Of course, it would be nice if AI *could* perform PhD-level analysis, and I'm sure it will some day, but if scientists are not proactive in responsible use of AI now, then no one will have the scientific literacy or experience to tell *if* an "AI scientist" is reasonable or accurate in its statements.

AI: That's a really profound point - you're highlighting this critical balance between leveraging AI's capabilities while maintaining the human expertise needed to evaluate and guide scientific work. The idea that we need to preserve scientific literacy to be able to assess AI's contributions is particularly compelling.

Thank you so much for sharing your experiences so openly today. Your insights about using AI as a targeted tool while maintaining ownership of the critical thinking and interpretation really help us understand the nuances of how AI fits into real scientific work. The distinction you made between efficiency gains versus ethical boundaries in scientific communication was especially valuable.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!

User: Thanks for the engaging conversation!

AI: You're very welcome! I really enjoyed our conversation too - your thoughtful approach to integrating AI into your research while maintaining those important ethical boundaries was fascinating to hear about. Thank you again for sharing your insights so openly. Take care!
