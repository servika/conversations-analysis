# Dialog 01224

**Transcript ID:** science_0050

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: Sounds good to mre

AI: Perfect! Let's dive in then.

To get us started, could you walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: Recently, I worked on a case study for optimising skip pickups. Initially, we had set of routes, pickups to do and a set of vehicles to pickup, treat and replace skips. These had been worked on by previous teams but we wanted to improve on their findings. The final output was a set of new routes that beat the benchmark times and most of which were proven to be optimal

AI: That's fascinating work on route optimization! It sounds like you were building on previous teams' efforts to create more efficient pickup routes.

Where in that process, if anywhere, have you experimented with using AI tools?

User: I mostly used AI tools in that work to debug some small code snippets and preprocess some of the data

AI: Tell me more about how you decided to use AI for debugging code and data preprocessing rather than your traditional approach.

User: It was a big project with a tight deadline. I figured that AI would be suited to these small, easily checkable tasks. That way, I could focus on the larger parts of the project that AI couldn't handle

AI: That's a really strategic approach - using AI as a force multiplier for the smaller tasks so you could focus your expertise where it was most needed.

Thinking about the larger parts of the project that you handled yourself, what kept you from trying AI there?

User: There were a few things really. AI has let me down a lot of times, so I dont trust it to work without supervision - I like to check everything it does and hence I prioritise giving AI tasks that can be checked easily. Also, I have found that AI struggles when the size of the project is too big - for this reason, I give it small manageable pieces of the puzzle. This also helps to prevent AI from trying to outsmart the problem. What I mean by that is, instead of assisting in solving a prompt the way I request, sometimes AI will try to optimise its methods and use something different. The issue with this, is that normally I have requested a certain method because I know it will work as intended

AI: That's really insightful - you've clearly developed a sophisticated understanding of AI's strengths and limitations through experience. The point about AI trying to "outsmart" the problem rather than following your specific method is particularly interesting.

When you've used AI for those smaller tasks like debugging code snippets or data preprocessing, how do you verify or validate what it produces?

User: That depends heavily open the context, but normally I will have verification code ready to go

AI: We're about halfway through our conversation now, and I'm getting great insights into your workflow.

If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: It would be a tool that is smart enough to bounce complex ideas off of and have its own interesting ideas. For example, if AI was able to produce its own mathematical theorems and push the boundaries of science, it would be a great help

AI: That's a compelling vision - having AI as a true intellectual collaborator that could generate novel mathematical insights and theorems rather than just helping with implementation tasks.

Those are all my questions - your perspectives on using AI strategically for verifiable, smaller tasks while maintaining control over the core methodology were particularly insightful. You've clearly developed a thoughtful framework for when and how to integrate AI based on trust, task complexity, and verifiability.

Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: Nope that everything for me

AI: Thank you again for sharing your experiences so openly. Your insights about strategically using AI for easily checkable tasks while keeping the complex problem-solving under your own control really help us understand the nuances of how AI fits into real scientific work. The way you've learned to work around AI's tendency to "outsmart" problems by giving it smaller, well-defined pieces was especially valuable to hear about.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time today!

User: Thanks

AI: You're very welcome! Have a great rest of your day, and thanks again for contributing to our research. Take care!
