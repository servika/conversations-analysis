# Dialog 01246

**Transcript ID:** science_0091

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: Yes, and no

AI: Great! Let's dive in then.

To start us off, could you walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: Well the most recent research project started life many years ago, with an application to the European Commission in 2012. The application process took 9 months, and it involved 12 academic partners. We established and ran 3 short, focussed clinical trials over 6 years. The output was collected over 18 months. The final goal was achieved, which was the approval for marketing authorization of a drug for a rare disease. The publication of papers and analysis of data occurred for several years after the completion of the project due to the amount of data collected

AI: That's fascinating - a project spanning over a decade from initial application to final outputs. That's quite a journey from EU application to drug approval.

When you mention the analysis of data that occurred over several years after project completion, tell me more about what that analysis process looked like for you day-to-day.

User: There were lots of different data sets with various patient groups. It was difficult understanding what statistical tests would really be most scientifically valid for the different data sets

AI: That sounds like a really complex challenge - trying to determine the right statistical approach for multiple datasets across different patient groups. 

Where in that analysis process, if anywhere, have you experimented with using AI tools to help with those decisions or the analysis itself?

User: When the decisions for these data were made, no we did not - at that stage, we didn't even think of that. Now, I use AI LLMs as a sense check. I will define a statistical approach, then i will check if AI thinks this is robust. I then check that answer with a different LLM

AI: That's really interesting - so you've developed this cross-checking approach with multiple LLMs. 

For that statistical validation process you described, tell me about how you decided to start using AI as that sense check rather than sticking with your traditional approach of consulting colleagues or statistical references.

User: Because the statistics colleagues are too few, and too busy. And they always say that we collected the wrong data. ALWAYS. Even if we asked them before the data were collected

AI: That's a very relatable frustration! It sounds like AI has become a more accessible alternative when human statistical expertise is either unavailable or... less than constructive.

When you use AI as that statistical sense check and then verify with a second LLM, how do you decide whether their recommendations are actually sound? What's your process for validating what they tell you?

User: Mainly, if they agreed with me, it must be correct, right? And if two agree with me, well it's much more robust

AI: Ha! I appreciate that honesty - there's something reassuring about getting that confirmation when you've already thought through an approach.

Thinking about the other parts of your research workflow - maybe the clinical trial design, data collection planning, or manuscript writing - what's kept you from trying AI tools in those areas?

User: I can't let go of too much control .....  I know AI make mistakes, if I have to check it anyway, maybe the planning and manuscript writing is just a bit too dangerous. OK, if it's designing a statistical approach I can accept that. It's actually quite useful because it drags out the statistical theory that you can check. In my experience, scientists know far too little about statistics. And they write about their data using unsound models, introducing noise into the literature with false positive and negative results.  I think it's actually really important to keep track of the things that you delivered from your reasoning and scientific know-how/experience. If you fool yourself that something an AI bot introduced and you've thought it came from your own intuition, I think this can become a feedback loop.

AI: That's a really thoughtful perspective - you've clearly thought deeply about where the boundaries should be. The point about maintaining awareness of what comes from your own reasoning versus AI input is particularly insightful.

You mentioned that scientists often know too little about statistics and introduce noise into the literature. If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't - while still maintaining that control you need - what would that be and why?

User: 3 things. 1 - Coming up with a novel twist on your ideas - what else could you test with your experimental set-up, what alternative hypothesis or additional ideas could be tested in the ame set of experiments. 2 - Statistical analysis, like I said. 3 - An alternative interpretation of the data as a sense check - what did I miss, why is that result that I thought would be positive actually negative - is that result really qualify as a positive result - that sort of thing. OK you could say that writing a manuscript, but then everyone's literature would start to look the same. Some sort of Admin assistant could also be helpful, but then I think you start to lose control of knowing the limits of your work boundaries. I don't want to accept all the applications from researchers around the world who wanted to do an internship, or let students and other staff book meetings with my AI assistant without my consent. In that case, I really need to do that myself.

AI: Those are really concrete and well-thought-out use cases - especially that idea of AI helping generate novel experimental angles from existing setups. That could be incredibly valuable for maximizing research efficiency.

We're about three-quarters through our conversation now. Your point about alternative data interpretation as a sense check is particularly interesting - that "what did I miss" perspective that could challenge your assumptions.

Those are all my main questions. Your perspectives on maintaining that balance between AI assistance and scientific control, and especially your insights about the statistical literacy problem in science, were particularly valuable. 

Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: I haven't approached the development of tools to measure the data itself. This could be potentially powerful. So some of the work involve immunohistochemistry, endless reams of qPCR data. The former is really tricky to quantify. You have a whole section on a slide and you look at one bit (or multiple fields, but not every single part)- is it transformed/activated/negative/similar or representative of the whole. Well you make a judgement and that's where you can get a judgement that disagrees with your colleagues, other professionals, because you all use a slightly different baseline of what you think is normal. So AI could transform that aspect of research too. But I suppose that's where I start to feel uncomfortable. I suddenly lost control ....

AI: That's a really profound point - immunohistochemistry interpretation is such a subjective area where even experts disagree on what constitutes "normal" or "positive." The potential for AI to standardize that interpretation is huge, but I can absolutely understand that discomfort about losing control over such a fundamental part of the analysis.

It sounds like there's this tension between the incredible potential benefits of AI standardization and your need to maintain scientific judgment and oversight.

Thank you so much for sharing your experiences so openly. Your insights about that balance between AI assistance and maintaining control - especially around statistical sense-checking versus more interpretive work like histochemistry - really help us understand the nuances of how AI fits into real scientific work. 

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out.

User: ok thanks

AI: You're very welcome! Thank you again for taking the time to share such thoughtful insights about your research work. Your perspectives were really valuable for our understanding of how AI integrates into scientific workflows. Have a great day!

User: Good night!

AI: Good night! Thanks again for the great conversation.
