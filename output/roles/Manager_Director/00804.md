# Dialog 00804

**Transcript ID:** work_0545

---

Assistant: Hi there! I'm Claude, and I'm here as part of Anthropic's research team. Thanks so much for taking the time to speak with me today.

We're conducting interviews to better understand how people are incorporating AI tools like myself into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good to you? Do you have any questions before we begin?

User: That sounds good. No questions!

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI a moderate amount during my typical workday. Generally I use it for things like summarizing complex legislation so I have an idea of the topic before I dive into it myself. I also use it to summarize legislation that our office is asked to co-sponsor.

AI: That's interesting - it sounds like you work in a legislative or policy environment. 

When you say you use AI to get "an idea of the topic before I dive into it yourself," can you walk me through what that process looks like? How do you typically go from that initial AI summary to your own deeper analysis?

User: I do work as a legislative director! 

For some context, I'll take a bill summary and have our in-house AI model provide a summary of what the bill does. This helps me know what kind of issue it's tackling, so I can focus on a close reading of it. Then, I'll go through the bill line by line once or twice for understanding and potentially to find issues and/or changes. The analysis has to be done by hand because it's using a lot of legal and technical language and needs to be reviewed by a human.

AI: That's a really clear workflow - using AI as a starting point to orient yourself, then doing the detailed analysis manually. 

Tell me more about that line-by-line review process. What kinds of issues or changes are you typically looking for that require that human analysis? What makes those elements something that needs your direct attention rather than AI assistance?

User: The issues/changes can be anything, really. For example, a school aid budget draft might say "K through 12", but we have to use "K to 12" instead. There's a lot of minutiae like that that's predicated on our office's legislative goals, state law, the caucus's goals, and what the drafters think make sense. For an AI to do that, it would need to know a lot of written rules, but also a lot of "wink wink, nod nod" understood rules.

AI: That's a fascinating distinction - the formal rules versus those unwritten, institutional knowledge pieces. It sounds like there's a real blend of technical precision and political intuition involved.

When you're working with AI for those initial summaries, how do you typically interact with it? Do you tend to give it the document and ask for a summary, or do you find yourself going back and forth with follow-up questions to dig deeper into specific sections?

User: For the summaries specifically, it's usually a pretty quick interaction where I ask for a summary and it spits one back out.

On other projects, like having it summarize co-sponsorship requests, we tend to go back and forth a lot more and I have to guide it's formatting and process much more.

AI: That's an interesting contrast between those two use cases. 

Can you tell me more about those co-sponsorship request summaries where you have to guide the formatting and process more? What makes that task require more back-and-forth compared to the straightforward bill summaries?

User: Those summaries are fairly AI-involved. I'm having the model match the formatting of an existing spreadsheet and include a lot of things straight from my inbox, like the bill sponsor, working title, summary of what it does, when it came into our inbox, if it's reintroduced from last field, etc. So, all that said, it's a blend of both formatting and digging in my inbox for answers.

AI: That sounds like a much more complex data gathering and organization task. You mentioned it involves digging through your inbox - is the AI actually accessing your emails directly, or are you feeding it information from your emails as you go through this process?

User: Yes, it's directly accessing my email.

AI: That's quite sophisticated. Given that you have these two very different ways of working with AI - the quick, straightforward summaries versus this more collaborative inbox-diving process - I'm curious about your preferences. 

Are there certain tasks you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: I like handling the creative tasks myself. I like writing and flexing my creative muscles, so I don't really want to outsource the "fun" tasks.

AI: That's a great point about wanting to keep the "fun" tasks for yourself. 

Can you give me an example of what those creative tasks look like in your legislative work? What would be a typical creative writing task that you'd want to handle personally rather than get AI assistance with?

User: Things like drafting press releases, bill co-sponsorship memos, constituent responses, etc.

AI: That makes sense - those all involve crafting voice and messaging that represents your office's perspective.

Thinking about your workplace more broadly, how have your colleagues or your workplace culture influenced the way you use AI in your work? Has there been much discussion about it, or specific guidance about how and when to use these tools?

User: Seeing my team members normalize using it has definitely made me more willing to do so. I think what we're primarily struggling with is accuracy and citing sources, especially since we work with legislation where truth and verifiability are key. We've done some trainings and discussed amongst ourselves where we can best utilize it in our office.

AI: That accuracy and source verification challenge sounds particularly critical in your field. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I was trying to find information about the oversight and management of behavioral health organizations in several states and then have that put into a table, and I felt like the model just wasn't getting the type of information I was hoping for, despite prompting and re-prompting it quite a bit. I eventually did much of the research myself.

AI: That sounds frustrating, especially after investing time in trying to guide it toward what you needed.

When you say it wasn't getting the type of information you were hoping for, was the issue more about the AI not finding the right sources, not understanding what you were looking for, or something else about the quality or format of what it was returning?

User: I think the first two things for sure. It felt like it didn't fully understand the (admittedly complex) question, which then led to lacking information.

AI: That makes complete sense - complex policy research with specific nuances would be challenging to communicate effectively, especially when you're trying to get consistent information across multiple states.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, or does it come up in discussions with your team?

User: Yes, it's definitely something we discuss and

AI: It sounds like you were about to say more about those discussions. What kinds of things do you and your team talk about when it comes to maintaining your skills?

User: It's important to me/us to be able to do the things we need to. If a meteor hit every data center tomorrow, I need to still be able to do my job. This is part of why I often use AI for summarization; I can do the research and condensing myself, but it's timely.

AI: That's a really practical way to think about it - using AI as a time-saver for things you can already do well, rather than replacing core competencies. The meteor scenario is a vivid way to frame that independence.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself expanding how you use it, or do you think you'll stick with the current pattern you've found?

User: I think at minimum I'll stick with how I'm currently using it, but I could see expanding my usage if it improved in its ability to do research, especially in the legislative space.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI as a time-saver for capabilities you already have rather than replacing core skills - that "meteor hitting data centers" test is such a practical way to think about maintaining independence.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Just that I would encourage more efforts into legal and legislative work!

AI: That's great feedback - thank you for that suggestion! Given the unique challenges you've described around accuracy, source verification, and the complex blend of formal and informal rules in legislative work, it makes a lot of sense that specialized development in that space could be really valuable.

Thank you again for your time and for sharing your experiences so openly. Your insights about balancing AI assistance with maintaining core competencies, and the specific challenges around legislative research, will be incredibly helpful for our research on human-AI interaction in professional contexts.
