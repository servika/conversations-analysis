# Dialog 01204

**Transcript ID:** science_0001

---

Assistant: Hi, thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: That sounds good to me and I have no questions, please continue!

AI: Great! Let's dive right in.

Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: The initial idea came about through discussion with an academic advisor. The field of research was not new to me, but the experimental techniques involved in the research were, so my advisor gave me ideas as to how this works and what I should be looking into. Once I had got to grips with the techniques involved, I started by creating basic theoretical models to confirm the validity of the techniques, and then added complexity from there. This is how I continued for the remainder of the project, adding complexity to my theoretical model until enough was there to be able to describe a physical phenomenon. At this point, I began testing and comparing theoretical models with observed data, which provided the main results for this research. Throughout this, regular meetings with my advisor helped to guide the research. Once the final results were collected, a final report was written. I am now currently editing and preparing this for publication.

AI: That's a really clear overview of your process - from learning new techniques to building theoretical models and validating against data. 

Where in that process, if anywhere, have you experimented with using AI tools?

User: I would say I used AI tools in multiple aspects of this process. Initially, I would use AI to check over emails I was writing to send to my advisor. These had to sound professional while getting my intended point across, and the tools provided by AI helped greatly with this. I would never ask AI to write emails for me. I would write an initial email with the information I wanted to convey, then ask an AI for suggestions of wording and grammar. As the project progressed, I would use AI tools to assist in coding of the models. Usually this would be in the form of debugging code or writing lines of code that are simple but lengthy for a human to do. My coding was a little rusty, so AI helped massively with getting me back into the coding mindset. The more comfortable I got with coding again, the less I used AI to help. However, if my code gave an error at any stage in this process, I would copy and paste this into an AI model looking for a fix. My final use with AI in my research was with peer reviewing my written report. I used AI models to look for: mistakes, synonyms, incorrect grammar, better explanations, etc.

AI: That's fascinating - you used AI across several different stages, from communication to coding to writing. You mentioned that as you got more comfortable with coding again, you used AI less for that task.

For the coding assistance specifically, tell me about how you decided whether to use AI versus your traditional approach when you encountered a problem.

User: I usually decided to use AI when it would solve a problem quicker than a traditional approach (ie checking stack overflow/github). In general this is the case for 90% of problems. In relation to where I said I used AI less when I got more comfortable with coding, I tended to encounter less problems, so I did not need to use AI as much. Also at this point, I needed to know my own code like the back of my hand so I could make small adjustments. Getting an AI to write this code would not be useful for me, as I would not understand it as well as if I had written it myself.

AI: That makes a lot of sense - the speed advantage for most problems, but then the need for deep understanding as your project progressed. 

Thinking about the parts of your research where you haven't used AI - like the theoretical model development or the data comparison analysis - what's kept you from trying it there?

User: I think the answer to this is similar to why I didn't get AI to write the more complex code; I needed a deep understanding of what was going on in order to progress. For me, simply reading something isn't enough to make information useful in my brain. I need to interact with researched ideas and play with them in order for me to be able to create links between big ideas in my head which can then be used for research. This relates to using AI because the "interacting and playing" with ideas part is complete by the AI model. You ask a question and the AI model does the hard work then gives you an answer that you simply just read. I need to spend the time looking for the information and trying to understand it from multiple sources to really understand and be able to use these ideas in my research.

AI: That's a really insightful distinction - the difference between reading an answer versus wrestling with ideas yourself to build those mental connections. It sounds like for you, that struggle is actually part of what makes the knowledge usable.

When you have used AI for things like debugging code or reviewing your writing, how do you verify or validate what it produces?

User: I verify what it produces by running the code to see if it produces an error or doesn't. If it doesn't produce an error, I go through the new code, line-by-line, to check if it is logical and if it is actually doing the thing I had originally intended.

AI: That's a very methodical approach - both the practical test and then the line-by-line logic check. We're about halfway through our conversation now.

If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: If we're using magic, I would like AI to take the ideas from my brain and write my entire report for me. This is my least favourite part of doing research, the time spent writing everything up at the end. This is more than simply asking the AI to write parts of my report (which is obviously already possible), I don't even want to be a part of it.

AI: Ha! I love the honesty there - you really want to completely bypass that writing phase. It sounds like the writing up is quite disconnected from the parts of research you find engaging.

Those are all my questions - your perspectives on needing that deep, hands-on understanding for the core research work, but wanting efficiency for the more peripheral tasks, were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: No I think that covers it all.

AI: Thank you again for sharing your experiences so openly. Your insights about the importance of that "wrestling with ideas" process for building deep understanding really help us understand the nuances of how AI fits into real scientific work - particularly how the cognitive process itself can be as valuable as the outcome. The distinction you made between tasks where you need that deep engagement versus ones where efficiency is the priority was especially illuminating.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time today!
