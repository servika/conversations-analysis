# Dialog 00953

**Transcript ID:** work_0768

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good to you? Do you have any questions before we begin?

User: sounds good

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Variety of tasks, including research, summarizing, collaboration on ideation, rewording text for emails/proposals/presentations. I'm hoping to explore more agentic and RAG functionality very soon.

AI: That's a nice range of applications. You mentioned research as one of the tasks - can you walk me through what that looks like for you? How do you typically approach research tasks when you're working with AI?

User: Generally it's for market analysis: competitor landscape, identifying niche content areas to produce content about, trying to identify opportunities. It starts with a client's business objective (increasing sales revenue is a common one), and we use what we learn in the discovery meeting with the client to focus the effort of the situation analysis, crafting deep research prompts with client- or project-specific deliverables.

AI: That sounds like a pretty strategic use of AI. When you're crafting these deep research prompts for your situation analysis, how much of that process do you handle yourself versus letting the AI take the lead? Are you building the research framework and then having AI execute it, or is it more collaborative throughout?

User: My typical approach is a sort of stream of consciousness mind dump of what I know about where we are in the process and where we want to be. Often I do this through audio interaction. I try to start  broad, as I talk through it, the conversation with the AI usually helps me funnel down to more salient focus. When I feel like there's enough context, I will often ask the AI to generate a research prompt for me, including some recommendations on where to focus the research. Sometimes I'll execute the prompt as is and see what I get back (seeing what's missing will help direct my focus). Other times, I do some prompt engineering, if I have something more specific in mind already.

AI: That's fascinating - the audio interaction piece really caught my attention. When you're doing that stream of consciousness mind dump through audio, how does that feel different from typing out your thoughts? Does it change the way you and the AI work together in those moments?

User: Yes. when I'm speaking, It tends to be faster because I'm not trying to word things the right way or spend time fixing typos. It's easier to just have my mind focus on the task/research. I sort of use the AI as a note-taker/summarizer. Someone to corral all my random thoughts, connecting them and helping me shape them into something cohesinve and actionable.

AI: That's a really interesting way to think about it - using AI as a note-taker to corral your random thoughts. When you're in that mode, does it feel more like you're talking to yourself and the AI just happens to be listening, or does it feel like you're actually having a conversation with the AI as you're working through your thinking?

User: A little bit of both. When I'm not using an AI where I've defined a role/style, I often get too much of the sycophantic preambles. Sometimes my rambling goes on for a while. Sometimes i pause for too long and the AI starts to interrupt. But even still, it's a different exercise to "think out loud" with someone who can't keep up with the randomness and doesn't take the conversation in their own way with their own ideas.

AI: That's a really vivid description - especially that point about how the AI can't keep up with the randomness or take the conversation in their own direction with their own ideas. That seems like it creates a particular kind of thinking space. 

Are there times when you actually want that interruption or pushback - where you wish the AI would challenge your thinking or take things in a different direction - or do you generally prefer that it stays in that note-taker role?

User: When I want pushback or feedback or I feel stuck, I'll ask for it. My go-to phrase is "what do you think?"

AI: That makes a lot of sense - you control when you want that shift from note-taker to collaborator. 

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: No, I don't think there are, really. I'm having trouble thinking of any examples. I generally try to have oversight over any output that anyone else will see. I like to make sure the AI is not going to embarrass me by missing something obvious, for instance. More and more, I'm trying to identify ways to train the models I work with to get to know my style.

AI: That's interesting - the oversight piece to avoid embarrassment makes sense. When you mention training the models to get to know your style, what does that look like in practice? Are you talking about prompt engineering, or something more involved?

User: mostly its things like the tone of my language.

AI: Can you tell me more about that? What aspects of your tone are you trying to get the AI to pick up on, and how do you go about teaching it those nuances?

User: I'm not sure how to put it into words. Some elements are word choice, my unique sense of humor, intuitively knowing when the client will need more specifics and when an overview is more appropriate. I've never really thought about how I can teach those nuances, because there aren't hard and fast rules to a lot of that. There are probably ways that I could take care of that on the front end, but I feel like I spend too much time crafting prompts as it is, and im cognizant about over-engineering (sort of in the realm or analysis paralysis).

AI: That makes perfect sense - those intuitive elements like knowing when a client needs specifics versus an overview are really hard to codify into rules. You mentioned feeling like you spend too much time crafting prompts already. How do you balance that? When do you decide a prompt is "good enough" versus continuing to refine it?

User: I never know when it is good enough. I think I mostly stop when my mind gets tired, or I feel like I'm not adding anything new. That's usually the point when I'll either send the prompt and see what I get, or ask the AI for some prompt optimization.

AI: That's really honest - the mental fatigue as a stopping point resonates. When you do ask the AI for prompt optimization at that point, how often does that actually help versus just adding another layer of complexity to the process?

User: Yeah, that's a good question. I guess I haven't really done enough of that kind of prompt opt to realize how much it's helping. I am just blindly trusting that whatever version the AI spits out will be automatically clearer and more helpful.

AI: That blind trust is an interesting dynamic. When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: Collaboration, for sure. At least at this point. I have not yet gotten to the point of asking for handling things independently, but I would like to. I think I described the typical interaction pattern earlier.

AI: You're right, you did describe that collaboration pattern earlier with the research process. What would need to change for you to feel comfortable delegating complete tasks independently? Is it a

User: sorry. there was more to that, but i hit enter too soon. Shall I finish, or do you want to move on

AI: Please finish your thought - I'd love to hear the rest of what you were going to say.

User: regarding typical interaction pattern: there are plenty of times when the "conversations" are short. More like a search query and a question about the results, or a request to reformat the results. But the true "conversations" tend to be collaborative.

AI: Got it, thank you for clarifying that distinction between the quick search-like interactions and the deeper conversations. 

Going back to what I was asking before - what would need to change for you to feel comfortable delegating complete tasks independently to AI? Is it a trust issue, a capability issue, or something else?

User: I think it's a knowledge gap issue on my part. There are times, I'm sure, when I don't realize that there's a way when I could delegate tasks more completely to AI. But back to that analysis paralysis thing, sometimes I feel like there may be too many ways to do it, so I rarely end up doing it. It seems like there needs to be more environmental set-up or connections to other models/services to be able to delegate more completely. Insofar as agentic, multi-modal tasks, or collecting the right documentation/access for effective RAG.

AI: That's a really insightful distinction - it's not about trusting the AI's capabilities, but about not knowing what's possible or feeling overwhelmed by the setup required. When you think about those environmental setups or connections that would enable more complete delegation, do you see that as something you'd want to tackle, or does the complexity make it feel not worth the effort right now?

User: I definitely have a desire to tackle it. But it feels very overwhelming, and I have had trouble setting aside the time for that long term objective/benefit in the midst of so many urgent priorities, especially addressing the needs of paying clients. I have made feeble attempts to have AI models help out with recommending a course of action, but mostly I have gotten enthusiastic generic advice, especially when it comes to multi-modal workflows.

AI: That tension between wanting to invest in better AI workflows but having client work take priority is really relatable. You mentioned getting "enthusiastic generic advice" when asking AI for help with this - that phrase really stuck out to me. Can you tell me more about what that looks like? What would actually be helpful instead?

User: the "enthusiastic" part is that sort of sycophantic style that I referenced before ("Sure! I can absolutely help you [achieve that goal]). Then then generic part is where it lacks the *actual* next steps and details needed to effectively begin to execute the plan. For instance, instead of identifying accurately identifying specific specialized models or services to help with a task component, it will suggest an octagonal peg for a round hole--something that seems like it might fit at first glance, but actually won't work, in the end.

AI: That octagonal peg analogy is perfect - something that seems close but doesn't actually solve the problem. It sounds like you need much more specificity about actual tools and services that work together, rather than general categories of solutions.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Are others around you experimenting with it too, or are you more of an early adopter in your environment?

User: I am definitely the early adopter in my immediate circle. We do work with some vendors here and there who seem like they are making good use of it for their company's specific needs.

AI: Being the early adopter can feel pretty isolating sometimes. When you're working with those vendors who seem to be making good use of AI for their needs, does that give you ideas for your own work, or does it mostly highlight how different your challenges are from theirs?

User: I see it a lot with the hiring process, or business systems and management processes. It's not really the same as figuring out how to connect all the pieces of a lead generation campaign, for instance .

AI: That makes sense - seeing AI being used for more standardized business processes doesn't necessarily translate to the creative, multi-step campaigns you're working on.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: There was one research project I was doing--one of my first attempts at a deep dive research topic--where the information I was getting back was just not helpful. It was either a shortcoming of the model, or lack of specificity in my prompt. Party of the research was to identify and evaluate the companies in a particular geography that were promoting a particular type of service, and (essentially) identify any opportunities for carving out any way of being unique. The result: an incomplete list of companies, very similar descriptions across each of them, and a list of recommendations that was incredibly far off from anything useful. I thought I spent a substantial/sufficient  amount of time engineering that prompt, but it felt like a waste of time, because I didn't really have anything worthwhile to show for my effort.

AI: That sounds incredibly frustrating - especially when you'd invested so much time in crafting that prompt. When you looked back at that experience, were you able to figure out what went wrong, or does it still feel like a mystery? Was it the geographic specificity, the service type identification, or something else that seemed to trip it up?

User: I don't know. Looking back, I think I wouldn't try to cram so many different aspects/topics into one prompt. I could have also been clearer about my expectations of verbosity. But I do feel strongly that the model I was using just couldn't accomplish what I was asking. I was particular ly surprised that the list of companies it provided wasn't even close to complete.

AI: That incomplete company list would be particularly concerning when you need comprehensive market research. It sounds like you learned to break down complex requests, but you're still left wondering about the model's fundamental limitations for certain types of research.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Can you rephrase that? are you talking about continuing education, keeping my job, somehting e;se/

AI: I'm asking about how you think about your own professional development - like, are there skills you make sure to keep practicing yourself even when AI could help, or ways you think about staying sharp in areas where AI is getting really capable? It could be about job security, or just about maintaining your own expertise and judgment.

User: I don't really think about it. As my career advances, I will be less and less responsible for many of the of things I'm responsible now. I'm interested in how AI skills can help me advance or transition in to new roles, though. I see AI as a tool that is only as good as the person who wields it.

AI: That's a really forward-thinking perspective - seeing AI as advancing your capabilities rather than threatening them. When you think about transitioning into new roles, what kinds of AI skills do you think will be most valuable for that next level?

User: Effective prompt engineering will always be a differentiator. But beyond that , it's the knowledge base. As AI continues to grow at lightning speed, maintaining a more complete understanding of how to harness the power of AI will be one of the most valuable skills.

AI: That makes a lot of sense - not just knowing how to prompt well, but understanding the broader landscape of AI capabilities and how to connect them effectively.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: Symbiotically, I suppose. AI will do more for me the more I learn about it. In addition to the functions of my job role, I look forward to integrating AI more into my own systems of personal and professional organization. Almost like getting my own personal assistant.

AI: That symbiotic relationship sounds like a nice way to think about it - both of you getting better together. The personal assistant angle is interesting too.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI as a note-taker to corral your random thoughts, and that honest reflection about the frustrations with incomplete research results.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: nope

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about the collaborative nature of AI work, the challenges with prompt engineering, and that progression from note-taker to potential personal assistant will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk through all of this with me today!
