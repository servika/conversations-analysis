# Dialog 00368

**Transcript ID:** work_0793

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Nope, that sounds good

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: it depends on what project im working on. I have a unique situation where a lot of the code I work on is government property and we have strict instructions at this time to not leak any code to existing 3rd party AI. This means I cant use it for bugfixing, refactoring, etc for any projects involving our existing codebase. That being said, any project I develop locally is fair game until its on the servers. So I use AI to help me launch new projects. I use it to build db schemas, code outlines, write a lot of the initial code, and get the project fairly close to a minimum viable project before its uploaded to our development servers. So I use it a lot for developing new tools and projects, but not for existing projects or old code bases

AI: That's a really interesting constraint you're working within. It sounds like you've found a way to maximize AI's value within those boundaries.

When you're using AI to launch these new projects - building schemas, writing initial code, getting to that MVP stage - can you walk me through what that process typically looks like? How do you and the AI work together during those early development phases?

User: The first thing I do is come up with the data structure and tables I need. I have a rough idea so I'll start by saying 'build me a table for x, it will work like x, make sure to include x, and include anything I might be missing. This often leads to a table layout I pretty much expect, but it will often add items ive missed, timestamping certain submissions, foreign keys I may have missed or might need down the road, etc. Thats always the first step.

AI: That's a smart approach - getting that foundation right from the start. It sounds like the AI is catching details you might overlook and thinking ahead about future needs.

Once you have that database structure sorted out, what happens next in your process? How do you move from having those tables to actually building out the application?

User: I'll always section out the project, for instance the latest project involved admins submitting a form that collects a lot of data. After the tables were created, The first thing I did was have it build the form, since it knows the data structure from the tables its usually pretty spot on with the form I'll need. I'll have it build both the front end and the submission process at once. After we have a base form I'll have it add in more robust error handling, as I've found it doesn't always account for everything that could go wrong. I'll ask it to make sure it has all the UI/UX aspects for error handling, invalid data types, etc. People make a lot of mistakes when filling out large forms with lots of data so I need a lot of checks to make sure all data is filled out correctly. Since we had a lot of people filling out a lot of data, it needed tons of checks to make sure everything was correct before going into the db.

AI: It sounds like you've developed a really systematic approach - building in layers and then going back to strengthen the error handling. 

You mentioned that the AI doesn't always account for everything that could go wrong initially. When you're asking it to add more robust error handling, how do you guide that process? Do you find yourself having to specify particular types of errors you want caught, or does it generally understand what you mean when you ask for more comprehensive checks?

User: Its usually pretty good, when I ask for more robust handling I mean a lot of the time it will send a blanket alert statement for issues when processing in the backend. I had it section out particular errors to give the user a more detailed explanation of the error (unless it was server related or something along those lines - that's instructed to be sent to the developer) In this case I really meant more messaging in the UI when a user types a number in a name field and stuff like that. Since we have so much data entry, people are eventually going to make mistakes and I needed the application to catch all human error possible before submission.

AI: That makes a lot of sense - you're essentially having the AI help you anticipate and handle the human factor in data entry. It sounds like you're being quite specific about distinguishing between user-facing errors versus developer-level issues.

I'm curious about your preferences when working with AI this way. Are there certain parts of this development process that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: I'm at a middle ground with AI right now. I genuinely enjoy writing code, but its hard to justify doing a lot of it myself when AI is now so efficient. Its only been the past year or so that I thought the models did a better job of writing than I did in 80-90% of cases. As far as which parts I do myself, not as much as I used to that's for sure. I do the initial planning and data structure, even though AI might write the actual SQL to generate the tables, and I still always go through the backend to make sure I understand how it actually works. As far as frontend/UI I pretty much entirely leave that up for AI to handle. I don't even go through it unless I see an issue. The main reason I go through the backend is to make sure I understand whats happening and why. Incase there are bugs in the future, I'm not left blindsided by an application whose process I'm unfamiliar with.

AI: That's a really thoughtful balance you've struck - leveraging AI's efficiency while maintaining your understanding of the core logic. It sounds like you're being strategic about where to invest your time and attention.

When you use AI for work in this way, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task - going back and forth - or do you tend to delegate complete sections for it to handle independently?

User: I think of it kind of like Legos. For example in my latest project after the form and data was built we needed other parts as well. Next we needed a PDF export of data, so I had AI do that, we implemented it, checked to make sure it worked, and moved on to adding notes to submissions. We built a note submission tool for users, made sure it worked, and moved on to CSV exports for other data types. Going back to the analogy of Legos. I have AI build a part I need, I go in and make sure it works, take a look at how the functions work, and if its all straight forward we move on to the next block.

AI: I really like that Legos analogy - building and testing discrete components before moving to the next piece. It sounds like a very methodical way to work together.

You mentioned this shift has really happened in the past year or so, where you felt the models became better than you at writing code in most cases. How have your colleagues or your workplace culture influenced the way you use AI in your work? Are others approaching it similarly, or are you navigating this pretty independently?

User: we are a small team, I have one co-worker who is absolutely obsessed with all things AI. He uses it for everything, even outside his job. He talks to it, gets advice from it, and constantly sings its praise. I have another co-worker who doesn't use it for anything other than an occasional quick script write or something quick and easy. Some co-worker would use it more if they could, but we still have to not use it within certain constraints that I mentioned earlier - existing codebases and whatnot. I've been using it more thanks to the AI obsessed co-worker, hes the one that really made me lean into it more, but I still have my reserves as I've encountered code safety issues before, so I still have to make sure I check every piece of backend infrastructure generated. This puts me in a weird spot because I would like to use it more, but I believe it still have some training to do before I 100% trust generated backend code. Its part of our job to be paranoid about code security and make sure we are 100% safe from vulnerabilities as our infrastructure can be a target at times

AI: That's really insightful - you're working in a security-sensitive environment where the stakes for code vulnerabilities are genuinely high. It sounds like you're in this middle ground between your AI-enthusiastic colleague and your more cautious one, but with the added layer of security scrutiny.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I remember being satisfied with the UI generated in a recent project with just one prompt. It was advanced, interactive, it looks great and I can say it genuinely looked better than anything I would come up with. I remember being really frustrated with I had to debug about 500 lines generated from AI recently and the problem was so obvious (a missing closing bracket somewhere deep in a nested JS script) but the AI for the life of it couldn't find it. Since it introduced the error, I felt annoyed I had to spend so long debugging AI code to find an error it created from working code. I finally found it and it was indeed just a missing bracket. I felt frustrated because I want AI to do the debugging while I write code, but it seems more and more every day that AI gets to do the fun part of writing code, and more and more I just become a debugger.

AI: That frustration really comes through - it's almost like you're getting pushed into the role of quality assurance for the AI's work, while it gets to do the creative part you actually enjoy. That missing bracket situation sounds particularly maddening.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, or does it just naturally happen through the debugging and review work you're already doing?

User: I maintain my skills by always making sure I know exactly what's happening in any application I use AI to write. This can happen through debugging, or simply reviewing the backend infrastructure. I am still the project manager, the data structure engineer, and AI builds the application around my specific parameters. If I don't understand what the code does that I've generated, I've essentially outsourced myself to AI.

AI: That's a really clear philosophy - staying as the architect and making sure you understand every piece that gets built. It sounds like you've found a way to leverage AI without losing your essential role in the process.

Looking ahead, how do you envision your relationship with AI at work evolving? Where do you see this heading for you personally?

User: I see it continuing down the path its already going. It will generate more and more code, while I take on more of a project lead role. I think this will lead to a huge increase in efficiency.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on that balance between leveraging AI's efficiency while maintaining your understanding of the backend - and that Legos analogy for how you build applications piece by piece.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about working within security constraints, that evolution from enjoying coding to becoming more of a project architect, and how you navigate the debugging challenges - all of that will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk through your process with me today.
