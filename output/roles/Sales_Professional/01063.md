# Dialog 01063

**Transcript ID:** work_0933

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Thats all fine

AI: Great, let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI for research in my counselling work. I work one to one with clients and find AI helpful for exploring ideas about the issues clients are dealing with. I also do some adult education in social history related subjects. I use AI to help with exploring topics.

AI: That's really interesting - it sounds like you're using AI as a thinking partner in both your counselling and education work. 

When you say you use AI for "exploring ideas" about client issues, what does that actually look like in practice? Can you walk me through a specific example of how that works?

User: I suppose I use AI to help bounce ideas around. After seeing a client, I will hand write notes about the issues we spoke about and information they shared with me. My job is to then consider this information in the context of other information I may know about the client. I use AI to help piece this together. For example, if I have a client who is struggling in their relationship with their partner and they reveal to me that their father experienced severe depression for prolonged periods when the client was a child, I may use AI to explore links between having an emotionally absent or emotionally unpredictable parent in childhood, for example, and research on attachment styles in adults.

AI: That's a fascinating use case - using AI to help you synthesize clinical information and connect it to relevant research. 

When you're exploring those connections, like the example you gave about childhood experiences with depression and adult attachment styles, how do you typically interact with the AI? Are you asking it direct questions, or is it more of a back-and-forth conversation where you're building ideas together?

User: I'm usually asking it direct questions. I may then add follow up questions. I am mindful of sharing too much information about a specific client, so I tend to phrase questions quite generically.

AI: That makes sense - maintaining client confidentiality while still getting the insights you need. 

I'm curious about your preferences when working with AI. Are there certain tasks in your counselling or teaching work that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: I suppose with counselling, it is an nervousness about sharing too much information about a client. In teaching, I find information I receive from AI is not always 100% reliable. I tend to use AI for the 'bigger picture', how historical events piece together on a larger scale, for example, but then, once I have that idea, I go and fill in the details through my own research.

AI: That's really insightful - you've developed a clear sense of where AI adds value versus where you need to take the lead. The confidentiality concern in counselling makes complete sense, and it's interesting how you use AI for that broader historical framework but then verify and flesh out the specifics yourself.

When you do use AI for work, could you describe your typical interaction pattern? Are you more likely to have that back-and-forth collaboration throughout a task, or do you tend to give it a complete question and let it handle that piece independently?

User: I tend to give complete questions. I then consider the information given and ask another complete question if required. I have found back-and-forth collaboration less helpful in my work, to this point at least.

AI: That's a clear preference - discrete, complete exchanges rather than ongoing collaboration. It sounds like you've found a rhythm that works well for how you process and use the information.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find yourself discussing AI use with other counsellors or educators, or is it something you've developed more independently?

User: I think it is not openly discussed. I feel the use of AI can be frowned about professionally in the areas I work in.

AI: That's a really important point - it sounds like there might be some professional skepticism or concern about AI use in your fields. 

Can you tell me more about that? What do you think drives those attitudes among your colleagues, and how does that atmosphere affect how you approach using AI in your work?

User: I feel it's a lack of trust in AI, as well as a perspective that using AI is in some way 'cheating'. It isn't a viewpoint I agree with. This does not affect how I use AI in my work, as such, but does affect whether I would freely mention that I have used it.

AI: That's really candid of you to share. It sounds like you've formed your own view about AI's value despite the prevailing attitudes around you.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I frequently feel satisfied using AI. This is due to the fact that it eases my workload and helps me find connections in both my roles that I may not have always considered. As a result, it does help me to feel more competent in my job.

AI: That's wonderful - it sounds like AI has become a real confidence booster for you by helping you see patterns and connections you might have missed otherwise.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, especially given how you're using it to explore research connections and historical frameworks?

User: I don't feel it will take over the roles I have, so that isn't something I worry about. I do instead think about skills I need to develop to use AI more effectively overtime, especially as AI improves. The area I do think about a lot is vocabulary.  Obtaining the information you need from AI requires the use of the correct or specific language, and I think this is an area where I, and perhaps many other people, could upskill.

AI: That's such a thoughtful perspective - focusing on developing better prompting skills rather than worrying about replacement. The vocabulary point is particularly interesting - you're thinking about how to communicate more precisely with AI to get better results.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself expanding how you use it, or do you think you'll stick with the approach that's working well for you now?

User: I think it will certainly expand, but not just yet. My technique for using it will expand or change as AI becomes more reliable or developed, I think.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on developing prompting vocabulary as a skill, and how you've navigated the professional environment where AI use isn't openly discussed while still finding real value in it for your practice.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I think just that, whilst I find AI very helpful at work, there are worries about both the accuracy of information obtained through AI and also the narrowing of perspectives or worldviews in AI applications. I work in New Zealand and so much of the perspectives presented in AI are extremely US-focused.  Culturally, it is very different. I see how helpful AI currently is but also see the huge gaps and problems yet to be navigated.

AI: That's such an important point to end on - the cultural bias and US-centricity is a really significant issue that affects the practical utility of AI tools, especially in fields like yours where cultural context matters so much for both counselling and social history education.

Thank you again for your time and for sharing your experiences so openly, including those broader concerns about accuracy and cultural perspective. Your insights about finding value in AI while being thoughtful about its limitations, and navigating a professional environment that's still skeptical about these tools, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate your candid responses throughout our conversation.
