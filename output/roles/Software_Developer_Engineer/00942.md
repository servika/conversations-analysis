# Dialog 00942

**Transcript ID:** work_0750

---

Assistant: Hi there! I'm Claude, and I'm working with Anthropic's research team today. Thank you so much for taking the time to speak with me.

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

The insights we gather will be used to improve our understanding of AI's role in work environments, and anything you share won't be personally attributed to you.

Does that sound good to you? Do you have any questions before we begin?

User: Sounds good. Let's start

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I do mainly programming/development. I use AI a lot in terms of crafting code changes before I PR them. I basically use it in my IDE, either VS Code or Visual Studio.

AI: That's interesting - you're using AI right in your development environment. When you say you use it for crafting code changes before PRing them, what does that process typically look like for you?

User: I break my work down into small steps. I'll either ask the AI to suggest the next step, or ask it review a change that I have just made. I don't ask it to do large tasks, only small ones. I occasionally ask it to explain unfamiliar terms or use to it explore alternatives approaches.

AI: That sounds like a very methodical approach. When you're deciding between asking the AI to suggest the next step versus reviewing a change you've already made, what influences that choice for you?

User: If I know the code will be tedious to write e.g. a detailed SQL query, I'll ask the AI to do it. If it involves adding important functions that I know I want written in certain way, I'll write those first.

AI: That makes sense - there's clearly some thought going into what you handle versus what you delegate. Tell me more about those "important functions that you know you want written in a certain way." What makes those different for you?

User: I usually have a clear idea about modular design. I don't want the AI introducing a different way of doing things. It often produces code design that I don't like. It is much better given single functions rather than free reign to add lots of functions. I really concentrate on keeping it in check. I often have to add sentences things like "ONLY ADDRESS THIS SPECIFIC CODE. DO NOT WRITE ANY EXTRA CODE". I find that AI can be actually quite detrimental if it starts making too many changes.

AI: That's really insightful - it sounds like maintaining control over the architecture and design is crucial for you. When you say the AI can be "quite detrimental" if it makes too many changes, can you walk me through what that looks like when it happens?

User: It usually happens when I haven't been saving my work between code changes. I might be happy with say 4, 5 or 6 changes but maybe I haven't been saving at each step. The AI can suddenly ruin the code completely and I have to go back to the start again. I have had limited success with 'go back one step' button. If I feel the code is getting dangerous, I git save each step before requesting the next change from the AI. I must look into the 'back' button in more detail but at the moment I don't trust it. So my worst nightmare is, I have been coding with the AI for say 2 hours but have neglected to save each step with git, and the AI ruins my code. It is not very good at going back if you ask it.

AI: That sounds like a really frustrating experience - losing hours of work because the AI went off track. You mentioned you've developed this practice of git saving at each step when you feel the code is getting "dangerous." How do you recognize when that moment is approaching?

User: Well I should do it every time. But realistically, I start git saving once there has been a certain amount of change. It's a feeling really that creeps up on me, like "Oh no, I had bitter git save this in case the AI wrecks my code".

AI: That "Oh no" feeling is really telling - it sounds like there's this underlying tension even when things are going well. When you do use AI for those smaller, more contained tasks like the SQL queries you mentioned, how does that experience feel different for you?

User: It's fantastic when I break down the changes into small manageable steps. The AI is excellent at this. It gets exponentially worse the larger the codebase. Say I have code that a team of 2-3 people would take 3-4 months to refactor and I point the AI at it out of interest, and give it the final requirement, the code changes it comes up with are worse than useless.

AI: That's a striking contrast - "fantastic" for small steps versus "worse than useless" for large codebases. When you say the AI is excellent at small manageable steps, what is it about that experience that makes it work so well for you?

User: It's usually because I know roughly what should happen. The AI just does it quicker and I can check it.

AI: So you maintain that oversight and validation role. That makes me curious - are there certain types of tasks you prefer to handle yourself completely, even though AI could potentially help with them?

User: Not really. I usually always get the AI to check my code if I have written completely on my own. If I get a thumbs-up that's great, and if I get a suggestion for a slight improvement, that's even better.

AI: Interesting - so you're comfortable having AI review everything you write. When you get that "thumbs-up" or suggestion for improvement, how do those different responses affect how you feel about your work?

User: It feels like pair-programming. I did pair-programming for real, for about a year. It was the best work experience of my career. Working with an AI in my IDE is a bit like that.

AI: That's a beautiful comparison - it sounds like you've found a way to recreate that collaborative dynamic you valued so much. How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: Not much now. A year or so ago, it was all a bit new. So people would be testing it and getting it to do more and more outrageous things. It was almost like we were experimenting with a funny thing. Now people just use it as a tool. Some devs will say to other devs that they use it too much. But that's about it.

AI: That evolution is fascinating - from experimentation to just being a tool. When you say some devs tell others they "use it too much," what does that conversation typically look like?

User: During code review. Some people can tell that the code was AI manufactured and the developer didn't fully understand it.

AI: That's a really specific concern - being able to detect when someone didn't fully understand the AI-generated code. Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I have already explained. When I am several hours into coding, haven't externally saved my work, and the AI completely ruins my code. I hate it then. I just say to myself "ALWAYS git save your steps because you never know what it's going to do next".

AI: I can hear how much that sticks with you. On the flip side, can you think of a time when using AI made you feel particularly satisfied?

User: Not really. It's good for stuff where I'm not necessarily expert. I'm a C#/Python/C++ programmer, so if it helps be do a bit of JavaScript, which I understand in principle but not expertly, that produces a good feeling.

AI: That's an interesting distinction - using AI for languages you understand in principle but aren't expert in. How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Kind of. I have been programming for 25+ years, so my basic knowledge is very good. I think AI is actually much better for somebody like me because I have a deep understanding of systems. Even if I use AI to write code in a language  that I'm not expert in, I can ask it a series of questions and understand what is happening. I fear for youngsters who haven't spent 20+ years pouring over lines of code for hours to find one tiny bug. I think they will have to worry about this more than me.

AI: That's a thoughtful perspective - your deep foundation giving you the ability to interrogate and understand what the AI produces. Looking ahead, how do you envision your relationship with AI at work evolving?

User: I honestly don't know. I am happy using it in my IDE at the moment. But I am open to being educated to keep abreast of the latest changes.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experience with AI in development work. I particularly appreciated your comparison to pair programming and how you've developed strategies to maintain control over your codebase while still leveraging AI effectively.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: People should be trained in the use of a 'back' button , me included. In fact, I'm going to go off and research this now. Surely Copilot in VS Code should have a simple 'back' button where you can cleanly go back to the previous step before you sent the last request. It's just that I have had problems trusting this.

AI: That's a really valuable point - the importance of reliable version control within the AI coding tools themselves. The fact that you don't trust the back button even though it exists speaks to how crucial that safety net is for developers working with AI.

Thank you again for your time and for sharing your experiences so openly. Your insights about the evolution from experimentation to tool usage, the importance of maintaining architectural control, and especially your perspective on how experience level affects AI interaction will be incredibly helpful for our research on human-AI interaction in professional contexts.

User: Do I just close this browser window now?

AI: Yes, you can go ahead and close the browser window - we're all done with the interview. Thank you again for participating and sharing such detailed insights about your development work with AI. Your feedback will be really valuable for our research.

Have a great rest of your day, and good luck exploring that back button functionality!
