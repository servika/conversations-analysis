# Dialog 01040

**Transcript ID:** work_0896

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: No questions, let's begin.

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I am a freelance software engineer that works on a wide variety of projects for clients. I primarily use AI for coding and coding-adjacent tasks; this would include Copilot's in-editor autocomplete, Claude Code for agentic development workflows, and ChatGPT to answer questions (as a replacement for Stack Overflow). When I'm actively working on a client project, I typically use each of these tools several times a day, at least.

AI: That's fascinating - you're using multiple AI tools throughout your development process. 

When you say you use Claude Code for agentic development workflows, can you walk me through what that looks like in practice? What does a typical interaction with Claude Code involve?

User: I'll usually hand off a small, well-scoped task to Claude to handle. Something like building a specific component or setting up a placeholder page. I typically have a CLAUDE.md file set up in my project to guide the agent toward following my preferred style; one of my biggest annoyances for AI-generated code is having it be so off-style that I can't integrate it without significant manual work. That's also why I tend to lean toward only assigning well-scoped tasks; the less ambiguity, the less likely the agent is to produce an outcome I'm not happy with.

When I've decided on a task, I'll type out the prompt directly into the Claude Code app. This prompt will usually include context on why something is being built and important details on what needs to be implemented. If something isn't essential, I'll try to leave it out and lean on the CLAUDE.md setup to hopefully guide things in the direction I want it to go. I try to follow the advice to "talk to an agent like they're a junior developer" and particularly try to keep the mindset of mentoring a junior, which usually means focusing on providing the context they would need to know how to do this task again in the future. I find that giving them what a human junior developer would need to learn and grow also lends itself well to helping agents produce higher quality results.

AI: That's a really thoughtful approach - treating it like mentoring a junior developer. I'm struck by how deliberately you're managing the balance between guidance and autonomy.

Tell me more about that CLAUDE.md file. What specific style preferences or guidelines do you include in there, and how did you figure out what worked best for getting the results you wanted?

User: I'm pretty rigorous about how I structure my projects, and I've had a bad experience with agents following different organizations patterns. I try to specify specific directory structures (particularly for component organization), some logic around where to place things (ie. "sub-components only used a single page should be co-located with that page; general components go in `src/components`"), and patterns for how to define types (ie. "always use the `React.FC` generic for prop types").

As far as getting the results I want, it's an iterative process. When I notice something in an output that annoys me enough to fix it manually, I'll also try to add it to CLAUDE.md to try to avoid the issue in the future. This is a pretty slow process, though, as I don't use agents full-time; I imagine the CLAUDE.md file would come together more quickly if I were using the tool more.

AI: That iterative refinement process makes a lot of sense - learning from the friction points to prevent them next time.

I'm curious about your decision-making process when you're facing a task. Are there certain types of coding tasks you prefer to handle yourself, even though AI could potentially help with them? What makes you think "I'll do this one myself" versus "I'll hand this to Claude"?

User: It usually comes down to time spent prompting vs. coding. Because I provide so much context, my prompts tend to be 2-3 paragraphs in length. So, if I can fix it myself faster than writing the prompt, I'll just do it.

There are times when I know how to fix something, but also know the fix will be tedious and require me to make a fair number of changes or changes across many files. In that case, it's faster for me to write the prompt than make a bunch of tedious changes.

AI: That's a really practical calculation - the prompting overhead versus the coding time. 

When you do hand off those tedious, multi-file tasks to Claude, how do you typically work through that process? Do you find yourself collaborating back and forth with it as it works, or do you more often give it the full context upfront and let it handle the task completely?

User: As a general rule, I try to get the agent to complete a task in entirety. My first step is almost always to create a new branch to work from to make it easy to both review changes and revert them if necessary. I know Claude provides diffs, but I find it easier to use VSCode's diff viewer on the actual code.

I'll send off the prompt with the intent of the agent completing it in a single go but, depending on the difficulty of the task, I'll usually have to point out a few issues that need correction and let the agent handle that. I try not to touch "in progress" agent-written code, but I will occasionally make small corrections and point out what I did in the next prompt.

AI: That workflow with the dedicated branch and VSCode's diff viewer sounds really efficient. 

How have your colleagues or clients influenced the way you use AI in your work? Do you find yourself adjusting your AI usage based on the team you're working with or client expectations?

User: I don't think I have specific examples of how I've been affected by teams or clients, but I do feel the pressure of having to integrate AI as much as possible just to keep up. The interesting thing about this pressure is that it's more explicit pressure (ie. interviewers asking how I use AI to make my workflow more efficient) than implicit. That is, the tools I've naturally integrated into my workflow because they seemed interesting (ie. Github Copilot's autocomplete) have been sufficient to keep up with deadlines without needing to make a conscious effort to expand my AI usage.

AI: That's a really interesting distinction - between the explicit pressure to demonstrate AI integration versus what actually helps you get work done efficiently. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I don't think I've ever had any particularly stand-out experiences in either direction. There are small positive instances, like when Copilot suggests a large chunk of code that exactly what I need. There are also negative instances where an agent produces multiple files that produce a working product but are poorly organized and hard to follow; but they're always expected and prepared for, so I don't consider it to be a very notably negative experience.

I think this might be a good thing, though. Just like I don't really put that much thought into my editor, the fact that I don't really think about the AI tools despite using them every day seems like they're doing a good job of just doing their job.

AI: That's a really thoughtful observation - that seamless integration might actually be a sign of success rather than something missing from the experience.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I've actually spent a lot less time practicing things like writing code by hand and have shifted more to focusing on learning how to use AI more effectively. I consider it inevitable that AI is going to be better than writing code than me (and it already is in many ways), so I'm spending my time and effort to learn higher-level concepts like architecture where AI still struggles and trying to get better at using agents to do what they're going to be doing anyway in the future.

So to answer the question, I focus on learning new skills based around an AI-driven future.

AI: That's a really strategic way to think about skill development - focusing on the higher-level architecture work where you still add unique value.

Looking ahead, how do you envision your relationship with AI at work evolving? Where do you see this all heading for you as a freelance developer?

User: I see myself transitioning to more of an "engineering manager" role where my job mostly consists of setting strategy and orchestrating multiple agents to do the actual building. Most of the work will likely be verifying outputs more than actually doing the work myself.

AI: That vision of transitioning to more of an orchestration and verification role is really compelling.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on focusing skill development toward an AI-driven future rather than trying to compete with AI in areas it's already excelling.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I think that's all, thanks!

AI: Perfect! Thank you so much for your time and for sharing your experiences so openly. Your insights about the practical decision-making around when to use AI, the iterative process of refining your workflow, and especially your strategic approach to skill development will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk me through your process today. Have a great rest of your day!
