# Dialog 01018

**Transcript ID:** work_0863

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers – we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Yes it sounds good and no I don't have any questions

AI: Perfect! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: It's best to think of my two jobs - one in early childhood education and one in business editorial. 

1. In ECE I use it to brainstorm ideas of things to do with students (crafts, stories, etc) and sometimes I also use it to discuss ideas of best ways to deal with certain situations. 

1. In editorial I use it comprehensively - I will have it research recent articles about companies and give me a summary of what they've been doing, with links; I will give it information and interviews and get it to write articles for me, which I then edit. I would say I use it as a junior writer/editor

AI: That's really interesting how you use AI differently across your two roles. 

Tell me more about how you use AI as that "junior writer/editor" in your editorial work. What does that collaboration look like day-to-day?

User: I will have an assignment, say, to write an 800-word article based on an interview with a Managing Director of a company. I will collect background information, attach the interview, attach the background information, attach a set of writing/editorial rules and attach a couple of sample articles so the AI can see style. I then usually have to go through several versions with the AI while we work to get it to a point where I can simply run through and edit

AI: That sounds like a pretty iterative process. When you say you go through several versions, what typically needs to be adjusted between those rounds? What are you usually working on together to get it right?

User: Here is a list of things I almost invariably have to get it to fix, and often it's because the AI is not following my rules: 

1. Redundancy, or pre-quoting – Here is a real example of part of a conversation with AI during this process: "This is another bad redundancy. But I don't want you to remove the first paragraph - the article is getting too short now. Just make it much better. Look at the original interview. The interview was quite comprehensive so there is no reason for you to repeat things like this:
Digital discovery has become the third-leading influence on fragrance purchasing decisions among younger consumers, fundamentally changing how brands approach product launches and consumer engagement in travel retail. "Social media is playing an increasingly important role in the fragrance discovery process; it is now the third-leading source of influence on fragrance purchasing decisions among younger consumers," Engell states."
1. What I call "high school essay" type writing – Eg. "This strategy is evident in the decision to open a new store in Doha"
2.  Boring/lazy intros: "In the dynamic world of travel retail ..." 

Most of these I already state in my list of rules (which came about because of recognizing issues while working with AI -- would you like to see them? Let me know if you want me to attach them)

I also find a big issue is when I get the AI to correct one part, it neglects to look at the rest of the article. So, for example, it will remove a redundancy in one section but in its rewrite it will create a new redundancy, because it looks only at that one section.

AI: I'd love to see those rules you've developed - it sounds like they came from real experience working through these patterns.

It's fascinating that you've noticed the AI seems to focus narrowly on the section you're asking it to fix rather than keeping the whole article in mind. How do you work around that tendency when you're in those revision rounds?

User: [REDACTED]

Please find my list of rules attached. In answer to the question above, before even reading the rewriet I ask it if it's read the whole article when rewriting, and tell it to do so to check for other redundancies. ***OFTEN ***redundancies remain even when the AI is telling me it's removed them. 

I do experience other issues, too, which I'll tell you about in the next message so as not to confuse you.

AI: Thanks for sharing those rules - I can see how they evolved from patterns you kept encountering! The emphasis with all those exclamation marks really shows your frustration with the repetitive nature of these issues.

It's particularly striking that even when you explicitly ask the AI to check the whole article and it tells you it's removed redundancies, they often still remain. That must be quite frustrating in your workflow.

You mentioned there are other issues too - what else do you run into?

User: List of other issues I encounter:

1. not getting the correct word count
2. taking parts of the articles I specifically said were for style only and not to refer to them, but referring to them
3. Losing track as the conversation progresses. I've learned to copy the entire conversation and start a new one so I don't have to start all over again but I get a fresh AI
4. In the case of you, Claude, a big frustration is that I'll have to use tons of turns because you're not following my rules and then suddenly the conversation is too long, which seems especially unfair. 
5. Making things up, especially when I ask for image captions. I ask the AI to create a caption using the article (let's say a good caption would be "QDF has noticed sales to have improved in its new Chanel store since the refurbishment", the AI will say something like "A shopper looks at the new merchandise in QDF's Chanel store", so it makes up what might be in the image. 
6. This is one of the worst things it does, is make up quotes. If it's a quote it has to be a quote! It will completely paraphrase a section into a quote that is not real, or -- this is one of the worst things it's done -- it made up a whole internal method for a business to deal with a certain issue.

AI: Those are some really significant issues, especially the made-up quotes and business methods - that goes beyond just style problems into accuracy territory. That must create real trust concerns when you're working on professional content.

The conversation length limitation you mentioned with Claude is particularly interesting - it sounds like you're essentially being penalized for the AI not following your instructions in the first place.

When you encounter these more serious accuracy issues like fabricated quotes, how do you catch them? Do you have to fact-check everything against your source materials?

User: Yes I do. When I first began working with AI I thought it would save me time and it doesn't really. Sometimes it actually takes longer. In the end the collaboration between AI and me usually creates a better final article, but sometimes it seems like far too much effort for the end result

AI: That's a really honest assessment - it sounds like the relationship with AI in your editorial work is quite complex. You're getting a better end result, but at a significant time cost and with constant vigilance required.

I'm curious about the contrast with your early childhood education work. When you're brainstorming activities or discussing how to handle situations with students, do you run into similar reliability issues, or does that feel different to work with?

User: It is different. The best is when I'm looking for craft or game ideas, though I often need to remind it that I do not have unlimited resources. It can also offer some decent suggestions for dealing with children or other issues. Stories are another matter. It doesn't have the right tone for stories. It sounds like an alien who's studied humans but doesn't really understand them, which I guess it is

AI: That's such a vivid description - "an alien who's studied humans but doesn't really understand them." That really captures something about the disconnect in storytelling.

It sounds like in your ECE work, you're more accepting of those limitations and work around them, whereas in editorial you need much higher accuracy and reliability. When you think about those two different uses, are there certain types of tasks you've decided you prefer to just handle yourself rather than involving AI at all?

User: It isn't so much that I decide to do a specific task without AI, it's more that when I keep trying to get it to help me in a certain way and it's not getting it, I just say forget it

AI: That makes sense - it's more about reaching a breaking point with the back-and-forth rather than pre-deciding what to keep to yourself.

When you do hit that "forget it" moment and take over completely, how does that feel? Are you relieved to just handle it yourself, or frustrated that the collaboration didn't work out?

User: Sometimes I feel frustrated that I've spent so much time trying to get AI to work when I could have done it myself in 1/10th the time

AI: That frustration is really understandable - especially when you're working under deadlines or trying to be efficient.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do others in your editorial role have similar experiences, or are you navigating this pretty much on your own?

User: I do it on my own. I think I have a better understanding of how to use AI in a collaborative way that works well whereas most people just expect AI to do the work and get disappointed

AI: That's an interesting perspective - that you've developed more of a collaborative approach while others might be expecting more of a "do it for me" relationship.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: For satisfaction, I can say I'm normally more satisfied now that I have worked with AI so much that I have a better understanding of its weaknesses, what I have to look out for, the instructions I have to give etc. And I use two different AIs (I've tried others, but these are the best) -- Claude and ChatGPT. Each has certain strengths and weaknesses and I work to the strengths of each. 

As for frustration, it happens all the time. As one example (which has now improved with ChatGPT 5), I put in the rules and the requests/memory several times not to use emojis or lines in answers because I have to take them all out, which is super irritating, but it constantly went back to using them. That's been super frustrating. But I always experience frustrations, such as when Claude tells me in version 12 that it has gone through and definitely removed all redundancies and I go through and find more.

AI: It sounds like you've really developed expertise in managing these different AI tools and their quirks. The fact that you've mapped out which AI works better for which tasks shows how much you've learned through trial and error.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, or does it not really concern you given how much hands-on work you still need to do?

User: For me, unless I'm doing creative writing, which AI totally sucks at, I'm happy to not do the actual writing. My strength has always been editing, and I teach editing to writers. So for me this relationship is fine. As I say to writers: Even the greatest writers of all time need an editor, and that is certainly the case with AI.

AI: That's such a clear way to think about it - positioning yourself as the editor that even AI needs. It really aligns with your strengths and experience.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think you'll keep refining this collaborative approach, or do you see it changing in other ways?

User: That's difficult to say. AI is evolving, as you are well aware. I could see in future I will use it to help me in other ways as well, as it has more to offer. For simple writing/editing, I can see using it the same as I do now but I wish it was better at paying attention

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on positioning yourself as the editor that AI needs, and how you've developed such detailed rules and workflows based on recognizing specific patterns in AI behavior.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I think we've probably covered it as far as these tasks go, anyway!

AI: Perfect! Thank you so much for your time and for sharing your experiences so openly. Your insights about developing that collaborative editing relationship, the specific challenges you've encountered, and how you've adapted your approach over time will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candid you were about both the benefits and frustrations - that kind of honest perspective is exactly what helps us understand how these tools are actually being used in the real world.

Thanks again for participating in this interview!

User: I just thought of something else -- often when I have AI researching for me I will give it a time limit -- eg, search for all articles for Avolta on these particular sites but only recent news, from May 2025, and often I'll end up receiving articles or information from articles from 2022, 2023 ... I've even received older ones than that, from 2017, 2018 .... obviously not at all relevant!! This is why I always ask for sources, so I can check, but often even after I say "this article you gave me is 5 years old! I want from May 2025 forward ONLY!" the AI will still give me old information.

AI: That's a really important point! That kind of time boundary issue must be especially problematic in your editorial work where you need current information about companies. It sounds like even when you explicitly call out that the sources are too old, the AI continues to pull from outdated material.

That must add another layer of fact-checking to your workflow - not just verifying accuracy, but also verifying recency. Do you find this happens more with certain types of searches, or is it pretty consistent across different research requests?

User: Well, that's usually the type of request I will have that I need specific times for, so no. Before I learned how bad it is at this, I would sometimes lose 2-3 hours of work before I realized it was irrelevant. As with everything else, I'm more careful now.

AI: Wow, losing 2-3 hours of work before realizing the information was outdated - that's a significant cost. It really highlights how these accuracy issues aren't just minor inconveniences but can have real impact on your productivity and deadlines.

It sounds like across all these different issues - the redundancies, the outdated research, the fabricated quotes - you've had to develop this whole layer of verification and double-checking that you probably didn't anticipate when you first started using AI tools.

Thank you for adding that example - it's exactly the kind of real-world impact that's valuable for us to understand.

User: Ok NP! All the best to whoever reads this :)

AI: Thank you so much! That's very kind of you. Your insights have been incredibly valuable, and I'm sure the research team will find your experiences really enlightening. 

All the best to you too, and thanks again for taking the time to share such detailed and honest perspectives about working with AI!
