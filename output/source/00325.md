# Dialog 00325

**Transcript ID:** work_0656

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Sounds good! ready to go

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Sure. I'm an academic librarian, so my interactions with AI tends to fall into two categories: using it for my own work and supporting our users with their questions/usage of AI tools. In my own work, I often use AI tools to help with my writing. For example, I will often give an AI info that I need to send in an email or similar and ask it to craft a professional message incorporating that content. I also conduct research in my work (I'm a faculty member, so it's a part of my job responsibilities), so I will use AI to help brainstorm ideas and especially for outlining. That's hands down my least favorite part of writing, so having access to AI to help collate my thoughts and put it all together is super helpful. I don't tend to use it for the actual writing--a lot of academic journals are won't allow that for publishing--but it's helpful for the planning stages especially. On the other end of the spectrum, I field a lot of questions for our users about AI, so I'm constantly staying up to date on new tools and their possible uses to I can help our patrons. I teach classes on info literacy, so I'm incorporating education on AI literacy in those sessions. Basically, trying to teach users how to use the tools and apply a critical lens on the outputs, just like any other source of information.

AI: That's really interesting - you have this dual perspective as both a user and an educator around AI tools. 

You mentioned that you don't use AI for the actual writing in your research because of journal policies, but you do use it for brainstorming and outlining. I'm curious about your preferences when working with AI. Are there other tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: At this point, I haven't used an AI for data analysis. I think I'm a little hesitant because I'm not 100% sure of the capabilities of the various models, and what would be a good fit to help with that. So while I suspect that there are AI tools that could help streamline this process, I haven't actually explored or used them. I guess I feel like, well I'd have to double check all the outputs anyway, so just do it without AI. But I do think this is an area that might change for me going forward as I get more experience with different types of AI tools

AI: That makes a lot of sense - that feeling of needing to double-check everything anyway. It sounds like trust and familiarity with the tool's capabilities play a big role in your decision-making.

When you do use AI for work - like with the email drafting or outlining - could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: Definitely a collaborative process. One thing that I tell my students and that I've absolutely found in my own work is that you get out of the AI what you put in--so giving specific details, clear expectations for what should be included, etc. For example, I helped plan a research day at my university, and I used AI to help draft the call for proposals and some of the emails sent out to panelists. Developing the CFP especially required some back and forth--e.g. the first version wasn't really hitting the mark as it missed some key details and was too short. So there was some back and forth where I needed to give more instruction and suggest some revisions

AI: That back-and-forth process you describe sounds really iterative - almost like working with a colleague who needs more context to get it right.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Has the academic library setting shaped your approach in any particular ways?

User: Yes exactly--that's how I describe it to my students as well. As far as the culture, I would say it definitely shapes how I use AI. My colleagues and I are really trying to take the lead on campus as we view AI literacy as an extension of the info literacy work we are already doing. I think because of that, and because we have a group of people who are invested in learning and teaching about AI, I've been more empowered to explore different tools and integrate them into my work. I'm pretty open to exploring different aspects of AI, but also I'm probably more likely to apply a critical and skeptical lens on AI tool. But I'm doing that across the board, right? Just because research gets published in a journal doesn't necessarily make it *good quality* research. So I tend to take the same view with AI--just because a AI can generate content, doesn't necessarily make it good or useful. So basically, I think the culture makes me more open to exploration and more critical/skeptical simultaneously

AI: That's a really thoughtful balance - being open to exploration while maintaining that critical evaluation lens you'd apply to any information source.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: That's a really good question--I think one of the things I've struggled with is when trying to use it for research specifically. Sometimes (way too often, to be honest), AI chatbots will just make up citations or provide way too generic information. This is common when I'm in the initial stages of brainstorming or outlining, and sometimes even when I've given it really specific instructions for output and level of detail. That' gets really frustrating

AI: That frustration with fabricated citations and overly generic responses really comes through - especially when you've been specific with your instructions. It sounds like it can derail that collaborative process you described earlier.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: That's interesting--I think one of the areas where I have been thinking about this in terms of my library work is with creating search strings for databases. Some of the AI tools are really good at creating a pretty solid Boolean search string. So I think about how to continue advancing my own search skills, but also like--can I work on the next step of the search, refining from the AI suggestions, etc. It's an interesting area for sure

AI: That's a really practical example - building on what AI generates rather than starting from scratch. It sounds like you're thinking about it as skill evolution rather than replacement.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I definitely see it becoming more integrated in my work. You can already see with various subscription databases adding AI tools to their products (like JSTOR's AI research tool), and our campus is discussing possible larger scale licensing for AI tools. I can see it playing a role in some of the research areas I support--like I support evidence synthesis/systematic reviews, and there's a lot of conversation in that space about how to add AI as a partner/collaborator on complex reviews and what that would look like. In my own research as well I'm starting to see a shift in how some journals are handling AI, so I can see some changes on the horizon as well. On the whole, I think AI's presence is only going to grow. Like I said before, I personally view AI literacy and information literacy on a spectrum, so even as tools grow and advance and potentially take over some aspects of library work, I still see librarians/library workers has having a key role in the education aspect. How to use the tools, how to apply a critical lens, how to be ethical and responsible etc. I'm excited to see what comes out over the next few years!

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on viewing AI literacy as an extension of information literacy - that connection really highlights how librarians are uniquely positioned to help people navigate these tools critically.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: no that's all. Thanks

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about balancing exploration with critical evaluation, and how AI literacy fits into the broader information literacy mission, will be incredibly helpful for our research on human-AI interaction in professional contexts.

Have a great rest of your day!
