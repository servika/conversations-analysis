# Dialog 00984

**Transcript ID:** work_0812

---

Assistant: Hi! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. Does that sound good? Do you have any questions before we begin?

User: I'm ready

AI: Great! Let's start with something broad to get us going.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I would say the task I most use AI for is planning out and ideating about the software feature I'm implementing that day. Typically using the plan mode in Claude Code to draft a project spec document and go from there. I also use Ai for general data manipulation and transformation tasks, like translating a bunch of data from a txt file to a JSON format so I can use it in a program. I will also use it to do deep research on various science related topics, but its not always the best at summarizing concisely the concepts and information that I'm specifically looking for; like how does electrolysis work.

AI: That's really helpful - it sounds like you're using AI across quite a range of tasks, from planning to data work to research. 

I'm curious about those planning sessions with Claude Code. When you're drafting that project spec document, can you walk me through what that process actually looks like for you?

User: So I basically prompt Claude Code to think about and design the specific software dev tasks breakdown to implement the desired feature I'm working on. I will try and get as fine grained as possible about what I want the feature to do, the specific tech stack and the style of code I want. I will let CC run and then review the plan it generates. I typically have to manually correct things in the plan document or tell CC where it went too far with its planned tasks, which it often does.

AI: That's interesting that you often have to pull Claude Code back when it goes too far with the planned tasks. 

Tell me more about that - what does it look like when it goes too far? What kinds of corrections do you find yourself making most often?

User: It often starts veering off track of the main focus that I prompted it for. I find myself telling CC to remove certain line items and sometimes whole sections from the plan because they're just not directly and immediately relevant to the feature I'm implementing. The suggestions are good technically but its bloat for my specific focus of that day.

AI: That makes a lot of sense - it sounds like there's a tension between Claude Code's thoroughness and your need to stay focused on immediate priorities.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: Tasks where I need very fine precise creative details to be made are when I fully take over. I've found AI pretty much fails when it comes to creativity in novel spaces.

AI: That's a really clear distinction. When you say "very fine precise creative details" and "creativity in novel spaces" - can you give me a specific example of when you've hit that boundary where you knew you needed to take full control?

User: When I was developing the UX for a property management ticketing system I knew that I had to specifically design the order of pages and user forms displayed to the user to make the experience not horrendous to use.

AI: That's a great example - sounds like you recognized the user experience design required understanding nuances that AI might miss.

When you do use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I will typically delegate a task and monitor it initially to make sure it can handle the task how I want it to. Then when I am working on something I know AI can't handle on its own I then co-drive with it to solve the problem or achieve the task.

AI: Interesting - so you have these two distinct modes: delegation with monitoring, and then co-driving when needed.

When you're in that "co-driving" mode, what does that collaboration actually look like in practice? How do you divide up the work between you and the AI?

User: The way I divide up the work really depends on the task. Typically, if hard problem solving thinking is required I will think about it and solve myself while also giving a prompt to the AI to see if it comes up with a helpful insight or angle that I miss. I'm almost always giving it the busy work, like writing a bunch of scaffold code or something.

AI: That's a really clear division - you handle the hard problem-solving while AI takes care of the scaffolding and busy work, plus serves as a second perspective for insights you might miss.

How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: Not much at all. I was very early on integrating AI in how I work, back in Claude 3.5 days, and so I was actually the one to take the lead with my coworkers and got them to start incorporating AI into their workflows.

AI: That's fascinating that you were the early adopter who led the way for your team. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: There was a time I was developing a GUI that was using a specific library for GUIs in Python and at some point i ran into an issue where the AI's suggestions just stopped working. After some digging I discovered that the AI had been using as reference the C++ documentation for the library instead of Python. Frustrated that I wasted days of dev because of that

AI: That sounds incredibly frustrating - wasting days because the AI was referencing the wrong language documentation without you realizing it. That's the kind of mistake that could really shake your trust.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I know AI will take over and completely exceed my ability in any and every space possible. There is nothing to consider because it is futile.

AI: That's a pretty definitive perspective - you see it as inevitable rather than something to strategize around.

Given that view, how do you think about your role or value as you continue working with AI? What keeps you engaged in the work you're doing?

User: I know my value will continue to trend to 0, as will everyone else's, and so I must gather enough wealth before then. What keeps me engaged is that I know it is not here yet, that I am still valuable and that I have a chance to win before AI takes over everything

AI: That's a really striking way to frame it - as a race against time to build wealth before AI capability surpasses human value entirely.

Looking ahead, how do you envision your relationship with AI at work evolving? What do you think that transition period looks like for you personally?

User: I think AI will continue to take over the lower levels of abstraction work increasing and I will spend more time just driving the higher order vision for what tasks the AI does and how it completes them

AI: So you see yourself moving into more of a director role, setting the vision and guiding AI execution rather than doing the implementation work yourself.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on being an early adopter who led your team's AI integration, and your very direct view on how this technology will reshape work entirely.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Thank you again for your time and for sharing your experiences so openly. Your insights will be incredibly helpful for our research on human-AI interaction in professional contexts.

It was particularly valuable to hear about your early adoption journey, the specific ways you've learned to collaborate versus delegate with AI tools, and your candid perspective on the long-term implications. Your experience as someone who's been integrating AI since the Claude 3.5 days gives us a really important view into how these relationships evolve over time.

I appreciate you taking the time to speak with me today!
