# Dialog 01036

**Transcript ID:** work_0891

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: How will the research be used and will it be available in a study publically released by Anthropic?

AI: That's a great question, and I appreciate you asking for those details upfront.

To be completely transparent with you, I should clarify something important: I'm actually Claude, Anthropic's AI assistant, conducting this interview as part of a research exercise. While this is a real conversation that could provide valuable insights about human-AI interaction, I don't have specific information about how this particular research will be used or whether it will be part of a public study release.

What I can tell you is that this interview is designed to better understand how people integrate AI tools into their work, but for details about publication plans or specific research outcomes, you'd want to check directly with Anthropic through their official channels.

Given this context, are you still interested in having this conversation about your experiences with AI at work? I'm genuinely curious to hear your perspectives, even within this slightly different framing.

User: Yes, lets begin

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI search engines on a daily basis for work and personal related content. I generally avoid putting in any work related information though and try to keep my searches general. I find AI search tools to be easy to work with. For work specific tasks, my work has Microsoft copilot with the enterprise data protection turned on on my work laptop. I will use this and paste in the problem I am solving and code snippets. Copilot lets me use GPT 5 right now, which I find sufficient, but the app seems to significantly degrade when you get a long context. Its hard to use. My work also has a in house AI web app but its GPT4 based (like the one from years ago) and it is basically useless in my opinion. Sometimes I will just use my personal computer with AI subscriptions i own that are better than the work ones to gain insight into a problem, but never put in specific work details.

AI: That's really interesting - you've developed quite a thoughtful approach to navigating different AI tools across different contexts.

Tell me more about what makes the long context degradation in Copilot particularly hard to use. What happens when you're working on something and it starts to break down?

User: In the copilot app, once you get maybe 5 messages out, you start the see the entire app become unresponsive. Code snippets will not load or load forever, and eventually the app may give you an error screen 'reload app' at which point it will take you to a fresh conversation. You can go back to the old conversation and continue but eventually it becomes so slow that its just better to start fresh. The app overall gives errors and becomes unresponsive and slow with large contexts. It is frustrating.

AI: That sounds incredibly frustrating, especially when you're deep into solving a problem and suddenly lose that conversational flow.

When you hit those performance issues and have to start fresh, how do you handle picking up where you left off? Do you find yourself changing how you approach problems because of these limitations?

User: Not necessarily. I find performance degradation to be something I do consider when usin AI. context management is a key skill I have found after using lots of AI tools. I generally still obtain a lot of inforamtion from that conversation and then will just create a new one where I can start the new conversation with much more valuable context for solving the problem. that context of which i learned in the previous conversation. So sometimes a problem could take me several conversations before I actaully have solved the problem or gotten close

AI: That's fascinating - you've essentially developed context management as a strategic skill. It sounds like you're treating these multiple conversations almost like chapters in solving a larger problem.

Can you walk me through what that looks like in practice? When you start that fresh conversation, how do you distill what you learned from the previous one into that more valuable starting context?

User: I may start with the problem and in the first conversation 'waste' some of the context gathering intial insights and understanding details more. Maybe i will ask for some packages i should use or the strategy. Then eventually the perforamcne degrades and i carry that into the next convo. So now I would say, using x strategy (gained from first convo) do my task. Then maybe it will give me some code and then I say, wait i need anothe requirement here its missing. Third convo, now heres this code, add this requirement. Each time though this process is frustrating and not fun. It eventually is faster and better than me researching through documentation or google, but the app becomes unresponsive and I have to go back and summarize the key points from the ocnvo to the next convo

AI: That really paints a clear picture - you're essentially becoming a human context manager, distilling and carrying forward the essential insights across these fragmented conversations. The fact that it's still faster than traditional research despite the frustration says a lot.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: I still prefer to document and write comments for code myself. I dislike reading AI generated comments or docuemnetation. I dont want my work to seem like AI generated, and its better if i can docuement the code as i then know whats its doing. Sometimes i ay just take the AI generated comments and then chagne them to be a little more human list usually by removing perfect grammar/captialization or removing words

AI: That's a really thoughtful distinction you're making - wanting to maintain that human authenticity in your documentation while still leveraging AI for the problem-solving parts.

When you mentioned making those comments "more human-like" by adjusting grammar or removing words, what drives that choice? Is it more about personal preference, or are you thinking about how others might perceive the work?

User: +{}|-

AI: I'm not sure I caught that - it looks like there might have been a typing issue. Could you share what you were thinking about regarding making comments more human-like? I'm curious about what drives that choice for you.

User: Sorry i was cleaning my keyboard. It is about perception more than anything. In a personal project, i often will keep comments that clearly were written by AI. For example, if I noticed in my coworkers code these type of comments, I would assume he's using AI to write his code. My company still doesn't really talk much about AI so it just would raise qeustions in my head. For me, when i see human like comments and documentation with really good code, I think wow this is a good programmer versus wow this guy just used ai copy and paste. It shows thoughtfulness and that they may have used ai but went through and docuemented it themselves

AI: That makes complete sense - you're navigating both the technical benefits and the workplace perception aspects. It sounds like there's still quite a bit of ambiguity around AI use at your company.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: collaborate throughout a task, most of my tasks are too complicated to let it handle independently. Maybe if my compnay allowed agents or AI IDEs that could work, but I do it all myself aside from getting code from copilot

AI: So you're really maintaining control of the overall problem-solving process while using AI as more of a collaborative coding partner. 

Given that your company doesn't talk much about AI yet, how have your colleagues or workplace culture influenced the way you use AI? Do you get a sense of what others are doing, or are you mostly figuring this out on your own?

User: No I figure this out completely on my own. I have heard from someone else that copilot is allowed, adn my boss has told me before to just use the in house AI tool (using GPT4) but I dont talk about it with anyone. I want to take credit for my work, not AI tools. After all, I am the one utilizing the tooling.

AI: That perspective makes a lot of sense - you're viewing yourself as the strategist and problem-solver who's skillfully using AI as one tool among many.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: AI and CSS frustrates me. I don't like CSS and was trying to get css working with some legacy code I was working on. Just something somewhat basic like centering a table and making it scrollable past a certain vw of the screen. AI had a lot of trouble and eventually the code is full of CSS and eventually i got it working but ahve to go back and remove all the unneeded css.

AI: That CSS situation sounds like a perfect example of AI being almost too helpful - throwing everything at the problem when you just needed a targeted solution.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I consider AI to be one of my key skills at this point in time. I find that there are areas where AI really struggles (newer frameworks and code for example). I am a fast learner and adaptable so I believe im laregly okay in the long run. I also generally perceive that software quality seems to be going down as AI is adopted more, currently AI is not good enough and software quality frustrates me at times. But that also could be the faster rate of development

AI: That's a really insightful observation about software quality potentially declining as AI adoption increases. The tension between speed and quality is fascinating.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it changing as the tools improve or as your workplace becomes more open about AI use?

User: Yes i believe that as time goes by, current AI technology will change how my work is done. It just takes time. New technology or advancements could come out as well. I'm not sure about waht that means. Less engineers? Or greater efficieny? The entire department would have to undergo significant changes in terms of release times and deployemnt

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on developing context management as a strategic skill and how you navigate the perception aspects of AI use while still leveraging its benefits.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No that is it

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about context management, navigating workplace perceptions, and the practical realities of working with current AI tools will be incredibly helpful for understanding human-AI interaction in professional contexts.

It's been really valuable to hear how you've developed your own strategies for working effectively with AI while maintaining quality and authenticity in your work. Thanks for participating in this conversation!
