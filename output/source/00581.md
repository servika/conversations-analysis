# Dialog 00581

**Transcript ID:** work_0205

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Sounds good, let's begin

AI: Great! Let's start with something broad to get us going.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I mostly use AI for researching and understanding different topics. Whenever I need to understand a complex task i have a conversation with some AI model

AI: That's interesting - using AI as a conversational partner for understanding complex topics. 

Can you walk me through what one of those conversations typically looks like? What happens when you encounter something complex that you need to figure out?

User: I start a chat asking the specific question. Most of the times they will be niche questions, e.g. How do Dropwizard commands vs tasks compare for backfilling data? After an initial response, I usually ask follow up questions to dig deeper into the details.

AI: That makes sense - starting with a specific technical question and then drilling down. 

When you're having these back-and-forth conversations to dig deeper, what determines when you feel like you have enough information? How do you know when that conversation has served its purpose?

User: It's when I understand the topic enough that I can finish the task and I'm able to "deduce" answers from the information given by the chat, but not explicitly stated.
If this doesn't happen, it's when the model starts repeating itself again and again, I know that it can't help me

AI: That's a really insightful way to gauge when you've hit the limits - when you can start making your own deductions versus when the AI starts cycling through the same information.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: AI can summarise messages, email threads etc, I prefer to read the text myself. It's like reading the summary of a book vs the actual book. You get more from reading the whole thing and understanding subtle details.
Another use-case is generating classes of code. I do collaborate with AI when writing code, but I think that when asking AI to generate entire classes of code, it will often miss the mark, although the code will work, it might not be the most maintainable one, as well as being not consistent with older code in the project.

AI: That's a great analogy about reading the summary versus the actual book. You're highlighting something important about nuance and context.

You mentioned collaborating with AI when writing code, but not having it generate entire classes. Can you describe what that collaboration looks like in practice? How do you work together on coding tasks?

User: As an example, if I work on a ticket to enrich some object with more details by using HTTP calls etc, I will think of a solution, ask AI how it would do it, compare solutions and debate about which one is the optimal one. When the code design is decided, I will start writing code, but use auto completion at the line/functions. I'll then ask the AI to review the code (not just the functional code, but tests etc, similar to a pull/merge request).

AI: That's a fascinating collaborative approach - almost like having AI as a coding partner who you bounce ideas off of and then get a code review from. 

When you're debating solutions with AI and comparing approaches, what usually tips the scales for you in deciding which solution to go with? Is it typically your original idea, the AI's suggestion, or something that emerges from that back-and-forth?

User: A lot of the times my idea and the AI's idea are the same. Especially for lower complexity & lower domain knowledge problems.
Whenever we don't have the same idea, I will usually propose my solution, and ask about the differences between them, trying to understand what advantages and disadvantages each one has.

AI: That convergence on simpler problems is interesting - it suggests you and the AI are often thinking along similar lines for more straightforward tasks.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that your team has particular approaches or attitudes toward AI that shape how you use it?

User: Everyone is happy to use AI, since it can help automate more mundane tasks, and also help us do our job better. My team has the same attitude towards AI as me, it's a great tool for learning and researching. It still isn't ready for work on big complex projects, but it's helpful either way.

AI: It sounds like there's a shared understanding on your team about AI's current capabilities and limitations. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: One time that made me feel particularly satisfied with using AI was when a subtle bug was introduced to a version change in Confluent Kafka that broke the parallel consumer at runtime. It was something that AI identified really quickly and made me feel really amazed of the whole situation.
One time that AI made me feel frustrated was when I was trying to fix a Renovate - Gitlab Registry integration. It kept saying the same stuff over and over, even if it didn't work.

AI: Those are two really telling examples - AI catching that subtle Kafka bug that would have been hard to spot versus getting stuck in a loop with the Renovate-Gitlab issue. 

In that frustrating situation where AI kept repeating the same unhelpful information, what did you end up doing? How did you eventually solve the Renovate-Gitlab problem?

User: Well, I knew what the problem was, but I wasn't able to find a satisfiable solution. So, I googled around and asked principal engineers about their opinions. In the end they helped me reach a good solution.

AI: That's a perfect example of knowing when to shift strategies - recognizing AI's limitations and turning to human expertise and traditional search methods.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: It's something a little scary. I try to focus on the big picture - architectural structures, infrastructure, deployment, CI/CD. As well as focusing on less technical sides of my job - client meetings, gathering requirements, product knowledge etc

AI: That strategic shift toward higher-level thinking and interpersonal skills makes a lot of sense. You're positioning yourself in areas that require human judgment and relationship-building.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: Colleagues. We work together, since it's normal to accept change

AI: That's a really nice way to put it - colleagues who work together, with change being part of the natural evolution.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI as a debate partner when designing solutions, and how you've strategically focused on big-picture skills.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Thank you, nothing else to discuss

AI: Perfect! Thank you again for your time and for sharing your experiences so openly. Your insights about the collaborative approach to coding, knowing when to step away from AI when it hits its limits, and focusing on higher-level skills have been incredibly helpful for our research on human-AI interaction in professional contexts.

Have a great rest of your day!
