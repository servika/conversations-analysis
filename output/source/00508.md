# Dialog 00508

**Transcript ID:** work_0090

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Yes, no questions.

AI: Perfect, let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I mostly use it for coding tasks, more specifically in explaining/researching code in a larger context, rather than creating code. I also use it for general questions. in 80% of the time, the questions are related to coding. The rest of the time I use it for general questions, maybe about business topics that I require during coding(example: finance).

AI: That's interesting that you focus more on explanation and research rather than code generation. 

Can you walk me through what a typical coding session looks like when you're using AI for explanation or research? What prompts you to turn to AI during that process?

User: Okay, let's say I have a task that requires research before, as I usually work in a large codebase. I usually first need to get the idea of the context, before making any code changes. I usually use "Agent"/"Ask" in Cursor to do this, my first prompt would generally be something simple, like this: "Explain X piece of code from this file(attached A- file) and find if there are any other references in this part of the codebase(attached B - folder)."

AI: That gives me a clear picture of how you start. So you're using AI to map out the landscape before you make changes.

Once you get that initial explanation and find those references, what happens next in your workflow? How do you typically build on that first response?

User: This depends on the nature of the task and if the first response clarifies the bigger picture. It rarely does though, so I usually ask about 2-3 turns of follow-up questions, such as "How does X happen? Why did you say that Y does this?"

AI: So it sounds like you're having a back-and-forth conversation to drill down into the details. 

Tell me more about those moments when the first response doesn't clarify the bigger picture. What's usually missing or unclear that leads you to those follow-up questions?

User: Sometimes I feel like the arguments are not present or are rather weak. I feel like it has not captured the entire picture

AI: That's a really insightful observation about the arguments feeling weak or incomplete. 

When you say it hasn't captured the entire picture, can you give me an example of what you're looking for that's typically missing? What would make you feel confident that AI has truly grasped the full context?

User: I do not have a concrete example, but I sometimes know that there is something missing(given that I also know the codebase). I think that I would need more detailed explanation to be confident that the AI is not hallucinating sometimes.

AI: That makes sense - you have that intuitive feeling when something's off because of your familiarity with the codebase.

I'm curious about your preferences when working with AI. Are there certain coding tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: If the task is a one-liner or something I am already 100% confident I can do myself, I usually skip AI unless something else shows up.

AI: So you're being strategic about when to engage AI based on your confidence level.

When you do use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I never delegate entire tasks to AI. I probably use AI for like 30% of the task.

AI: That's interesting - so you're keeping most of the work in your own hands. 

What drives that 30/70 split for you? What determines which parts of the task you bring AI into versus the parts you handle entirely yourself?

User: The context in which I am working is the main reason for this split, as the implications are rather severe if something messes up. I've seen it hallucinate when trying to write the actual code, more than when I use it for explanation.

AI: That makes a lot of sense - the stakes matter, and you've noticed different reliability patterns between explanation versus code generation.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that your team has particular approaches or attitudes toward AI?

User: My team is positive on AI, but they encountered the same issues as myself. I would say they are using it pretty similar to me, but they are generally happy about it, since it saves time for some time-consuming tasks(explanation and research mostly)

AI: It sounds like your team has found a collective sweet spot with AI for research and explanation tasks.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Yes, I spent a few hours trying to understand a system, some event-driven stuff. Then I used AI and it made it clear for me in a few minutes. I felt really satisfied by the use of AI in this case.

AI: That's a great example of AI really delivering value - turning hours into minutes for understanding complex systems.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I do not think that AI is something that "would take over", but rather something that I can use to be more efficient. I do not think that AI will take over completely(in the next period of time).

AI: That's an interesting perspective - viewing AI more as an efficiency tool than a replacement.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself using it differently as the technology improves or as you get more experience with it?

User: I feel like I will continue to use AI at work and seems like it gets better continuously. I would probably use it more if it gets better at writing code.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI as an efficiency tool rather than a replacement, and how you've found that sweet spot of using it for research and explanation while keeping the critical coding work in your own hands.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Nope, that's it.

AI: Perfect! Thank you again for your time and for sharing your experiences so openly. Your insights about how you and your team strategically use AI for research and explanation tasks, while maintaining control over the critical code implementation, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk me through your workflow and share those specific examples. Have a great rest of your day!
