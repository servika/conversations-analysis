# Dialog 00537

**Transcript ID:** work_0131

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Nothing at this time, let's begin

AI: Perfect, let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI mainly for two broad topics - helping with code, and crafting perfect written reports and plans. To the former, that can be new code, most often existing code I am cleaning up - typically my questions will revolve around "How can I make this more efficient in terms of X" where X might be to reduce CPU or memory requirements, improve response times, that sort of thing. The latter, where I mentioned written reports - again, usually I'll draft something and ask for the language to be softened, adopt a specific tone or just generally tidied up.

AI: That's really helpful context. You mentioned you typically draft things first and then ask AI to help refine them - both with code cleanup and with written reports. 

What draws you to that approach of starting with your own work first rather than having AI create something from scratch?

User: Good question, honestly I like to feel like I am "in charge" and the one actually adding the value. I know what I want to do and how to achieve it, but the fine-tuning can be time consuming and onerous - and I am constantly busy in my day job, so rather than just defer totally to AI, I'll have a turn myself. I will say that on rare occasions, if I cannot solve a business problem, I will ask for something from scratch!

AI: That sense of being "in charge" and adding the core value yourself is really interesting. It sounds like there's a clear line in your mind between the creative or strategic work you want to handle versus the refinement tasks.

When you mentioned those rare occasions where you can't solve a business problem and ask for something from scratch - can you tell me more about what makes those situations different? What pushes you over that line to fully delegate?

User: Specifically, if I'm trying to make a start on something and don't know where to begin, how to approach the task, that kind of thing. Like if I have to write a report to achieve Task X, and I don't know where to start on that, I will go from scratch with AI - making sure I ask for explanations so I can learn and ask questions along the way. In terms of the technical aspect, if it's something I've never seen or done before, I might go in from scratch and establish the best way of achieving the task. For example,  I want to get X result, should I use a recursive CTE, can you write one for me. Does that make it clear?

AI: Absolutely, that makes perfect sense. So it sounds like when you're in unfamiliar territory - whether that's not knowing how to structure a particular type of report or encountering a technical approach you haven't used before - that's when you're comfortable starting from scratch with AI and using it as more of a teacher.

When you do work with AI in that teaching mode, asking for explanations and questions along the way, how does that interaction typically unfold? Are you going back and forth a lot, or do you tend to get what you need in just a few exchanges?

User: I suppose it depends. I'd say most of the time it is a back and forth, I'm happy to ask clarifying questions or drill into points that I don't understand or intial responses from AI haven't been super clear on.

AI: That back-and-forth dynamic sounds like a pretty collaborative process when you're in learning mode. 

I'm curious about your colleagues and workplace - how have they influenced the way you use AI in your work? Are others using it similarly, or have you noticed different approaches around you?

User: Another great question, so my organisation is big on AI right now - we even have our own "AI Lab". I think a lot of employees outside the technology team think of AI in the context of chatbots \ LLMs and forget there is a vast (untapped, for us) machine learning side to it. That is being actively explored by top management \ board level. My immediate colleagues use AI as I do really, perhaps even more so - I take it for granted, for example, that my Teams license gives me a Copilot meeting summary with little effort, and I know others use those summaries to better effect than I do.

AI: That's fascinating - it sounds like you're in an environment that's actively embracing AI at multiple levels. You mentioned that you "take for granted" features like Copilot meeting summaries, while others use them more effectively than you do.

Can you tell me more about that? What does "using them to better effect" look like compared to how you currently use those summaries?

User: Specifically, using those to create plans, communications and even incorporating text into reports. I will use the summaries for my own purposes such as tracking projects, assigned tasks and progress, as well as follow-ups with my team. I don't embed those summaries into other pieces of work. Perhaps I should!

AI: That's a really interesting distinction - using the summaries for your own tracking and follow-ups versus incorporating them into other work products. It sounds like you see potential there but haven't made that leap yet.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I've not felt frustrated with AI for a while now, honestly. Perhaps a year ago I would get crazy outputs that blended Python syntax with SQL when I'm asking for a trigger, or assume certain tools are used when I'm talking about high-level ETL or ELT (I think one response would have been great if we were using Snowflake.....we weren't and don't!). I am mostly satisfied if I'm honest - the most recent specific example I can give was where I fed in kind of a 'factsheet' of infrastructure and data, and asked for a documented migration plan I could distribute to a technical level. The output was incredible - I changed nothing and the plan it produced was very good indeed (I checked it over meticulously)

AI: That migration plan example sounds like a really positive experience - especially that you felt confident enough in the output to use it unchanged after your thorough review. That seems like a significant level of trust.

You mentioned the improvements over the past year, moving from those frustrating mixed-syntax responses to outputs you can rely on. How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: AI is here to stay. I don't see that changing. I also see my employer, and any potential future employer, embracing it similarly. So it's on me to keep my skills sharp and current, and to learn new things - new ways of working with AI being among them. I'm not the smartest guy in the room by any means, so I don't mean I'm going to go and become an AI \ ML Engineer. I mean things like proper prompt engineering, adding value in my role by being an effective leader, planner, mentor and coach - all the while using AI as kind of a trusted advisor if you like. I hope I've answered that in the right way

AI: You absolutely have - that's a really thoughtful perspective. The idea of positioning yourself as an effective leader and mentor while using AI as a "trusted advisor" shows a clear vision for how you see the partnership evolving.

Looking ahead, how do you envision your relationship with AI at work continuing to develop from here? Do you see it changing in any particular ways?

User: I think I will probably come to rely on AI more and more for lower-level tasks, I don't have anything automated yet but I envisage absolutely this will come. Basic checks and remediation steps could - and I personally feel, should - be handled autonomously. So I envisage the "trusted advisor" relationship will continue, with additional duties as trust builds.

AI: That progression from trusted advisor to handling autonomous tasks as trust builds is a really compelling vision. It sounds like you're thinking about a gradual expansion of AI's role based on proven reliability.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on maintaining that sense of being "in charge" while still leveraging AI effectively, and your vision of the evolving partnership.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, I think that's everything

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about that balance between maintaining control and leveraging AI as a trusted advisor, along with your thoughts on how the relationship evolves with trust, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk through your approach with us today.
