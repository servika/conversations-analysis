# Dialog 00589

**Transcript ID:** work_0214

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: sounds good, let's go!

AI: Great! Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I am frequently called on to review and improve processes and procedures; lately I have been using AI to assist in drafting any kind of template, or generally use re-useable documents that would need to be filled out specifically for certain situations.

AI: That's really interesting - using AI to create those foundational documents that can be adapted for different situations. 

Tell me more about that process. When you're working on these templates or reusable documents, what does that actually look like day-to-day?

User: I generally use a backwards design approach; considering how the product will physically need to appear when it is complete and filled.

AI: That backwards design approach sounds thoughtful - starting with the end result and working your way back. 

Can you walk me through a specific example? Maybe describe a recent template or document you worked on with AI and how you approached that process from the final product back to the beginning?

User: an example that comes to mind; I was recently working with a client who had concerns about a harassing email that a party had sent to one of their employees. After the discussion, we determined that the client needed a written "escalation protocol" to assist employees with figuring out what to do when faced with such situations in the future. In this instance, I used AI to draft a model protocol, which would then be inserted into their existing employee handbook, and also printed out as a physical copy for quick review in employee's individual offices/desks

AI: That's a really concrete example - thank you. So you had this harassment situation that revealed a gap in their procedures, and you needed to create something that would work both in their handbook and as a standalone reference.

When you asked AI to draft that escalation protocol, how much guidance did you give it upfront about what you wanted? Did you provide specific details about the situation, or keep it more general?

User: very rarely does I need to give it specific details, however after I have a first-round draft, I generally put that back into the AI to TEST it with specific details from hypotheticals to make sure it correctly inputs/formats information, as well as to make sure it is an appropriate length and appropriately readable for the audience intended

AI: That's a really smart testing approach - using hypothetical scenarios to stress-test the draft. 

What happens when you run those tests? Do you typically find gaps or issues that need adjusting, or does the initial draft usually hold up pretty well against those specific scenarios?

User: In my experience the draft generally holds up, but sometimes the AI misunderstands the task and tries to rewrite or suggest modifications to the draft WITHOUT such a prompt, when all I want to see is how the final product would look visually completely filled out.

AI: Ah, that's fascinating - so the AI sometimes takes initiative when you just want it to demonstrate the template in action, not redesign it.

When that happens and the AI starts suggesting modifications instead of just filling out the template, how do you handle that? Do you have ways to redirect it back to what you actually need?

User: I've found that the AI does respond well when given direct feedback coupled with a direct instruction for correction. Example:  "No, the purpose of this task was not to modify the form, but to fill in the form with existing information. Redo the task based on this specific feedback, and do not retain any changes YOU made to the form."

AI: That's a very clear correction strategy - being explicit about what the task was versus what it did instead.

I'm curious about your preferences when working with AI. Are there certain tasks in this process improvement work you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different?

User: Anything where there needs to be a specific citation or a direct quote from a law or policy I prefer to put into the document myself. I do not trust AI in its current state to provide accurate legal citations in any capacity.

AI: That makes complete sense - legal citations need to be absolutely precise. 

What is it about those citations and direct quotes that makes you feel you need to handle them personally? Is it concerns about accuracy, or something else about how AI approaches that type of information?

User: a concern about complete and total accuracy, as well as I want to be able to truthfully say--potentially under oath--that I did my due diligence and manually researched and added the relevant legal citations.

AI: That's a really important distinction - the professional and potentially legal accountability you have for the accuracy of those citations.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I'm not sure I understand the distinction. Can you give me examples of each?

AI: Absolutely - let me clarify with examples.

Collaborating throughout might look like: you draft an outline, AI helps expand section 2, you review and revise it, then AI helps with section 3 based on your feedback, and you go back and forth like that.

Delegating completely might be: you give AI all the requirements upfront and say "create this entire escalation protocol," then you review the finished product.

Does one of those sound more like how you typically work with AI?

User: Ah, I see, thank you for the clarification. I actually have used both for the same task before. For instance, I will open up one tab and have the AI give me a full model policy (e.g. total delegation), but I will also use a different tab to repeat the same task but with the granularity of the collaborative approach. I then frequently check the second tab against the first to make sure I am not missing anything major, as well as to see if there is any good language or framing I can re-use in the collaborative model.

AI: That's really clever - using both approaches as a check against each other. So you're essentially getting two different perspectives on the same task and then cross-referencing them.

When you compare those two versions, what kinds of differences do you typically notice between the fully delegated version and the collaborative one?

User: The fully delegated version is generally extremely basic, and also seems likely to confuse or not distinguish between legally important terms of art (e.g. "regulation" vs "guidance"). It is also much more time consuming to use as a standalone 'drafter' in my experience because any revisions or suggestions require it to completely regenerate, whereas in the collaborative version I can go section by section and fine tune OR zoom out and change the whole document if I have changed my mind. HOWEVER, I have noticed that the collaborative approach may invoke memory issues in the model if I make too many revisions or alterations (like it may forget the name of a particular office that I initially provided in the prompt)

AI: That's a really insightful comparison - the trade-offs between comprehensiveness and control. The memory issue you mentioned with the collaborative approach is particularly interesting.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do people talk about it openly, or is it more something you've figured out on your own?

User: More something I've figured out on my own. There are some real stigma in the legal/compliance profession when talking about AI usage, especially when it involves clients and/or PIP.

AI: That stigma makes sense given the high stakes and professional responsibilities in legal work. 

Can you tell me more about that? What kinds of concerns or reactions have you encountered when AI comes up in your professional circles?

User: Broadly, there is simultaneously a disbelief that AI usage actually can improve work quality or efficiency and a belief that only "coders" will know how to handle AI properly

AI: That's a really interesting tension - both dismissing its value while also seeing it as too technical for most people to use effectively.

Given that environment, how do you navigate using AI in your work? Do you keep it quiet, or have you found ways to demonstrate its value to colleagues?

User: generally I keep it quiet, except whereas the nature of the project requires higher level approval. I don't have the opinion that anyone else needs to know whether a TEMPLATE was manually drafted or AI drafted, when only the output actually matters.

AI: That's a pragmatic approach - focusing on the output quality rather than the process. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I am always impressed when I ask the AI to create a fictional case study, and it actually produces something that is genuinely impressively creative. Especially if it creates a complex situation I had not considered before

AI: That sounds really valuable - getting those complex scenarios you hadn't thought of yourself. 

What makes those fictional case studies particularly impressive to you? Is it the creativity, the complexity, or something else about how AI approaches creating those scenarios?

User: It is the specific precision of the complexity, such as creating a situation in which the fictional main character is impacted by medical issues, that are factually correct and play into the fact-pattern in a very thoughtful way (like needing to take breaks during a 'mock' interview)

AI: That level of nuanced detail is really impressive - weaving together medical accuracy with procedural realism in a way that creates authentic complexity.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Based on my work, I am less and less concerned about an AI "takeover" and more worried about an AI usage skills gap

AI: That's a really interesting perspective - shifting from AI replacing people to people not developing the right AI skills. 

Tell me more about what you mean by an AI usage skills gap. What kinds of skills do you think people need to develop to work effectively with AI?

User: I think a lot of professionals are either going to use AI really sloppily, or not at all, ESPECIALLY if they feel they are already "adequately trained." I find it both laughable and worrying the amount of college professors with ZERO AI expertise who believe they can detect AI usage.

AI: That's a sharp observation - the overconfidence in being able to detect AI use without really understanding how it works. 

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself using it differently as the technology changes or as your workplace culture potentially shifts?

User: Not sure, really except for the fact that I am personally and academically interested in AI, I could go for months at a time without being required to even touch on the topic, however I actively look for ways to work AI into my process so that I gain experience and understanding. Many times this doesn't even save me time, but I still think it is valuable.

AI: That's really thoughtful - actively seeking out AI integration for the learning experience even when it's not necessarily more efficient. The long-term skill building over short-term time savings.

Those are all the questions I had prepared. You've shared some really insightful perspectives about your experience with AI at work. I particularly appreciated your dual-tab approach for cross-checking different AI interaction styles, and your point about the skills gap being more concerning than replacement.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: nope, thanks!

AI: Perfect! Thank you so much for your time and for sharing your experiences so openly. Your insights about the practical realities of using AI in legal and compliance work - from the citation concerns to the workplace stigma to that clever dual-approach method - will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk through all of this with me today!
