# Dialog 00028

**Transcript ID:** science_0000

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today - I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: Sounds good. No questions.

AI: Perfect! Let's dive right in then.

I'd love to start by getting a sense of your research process. Could you walk me through a recent research project you've worked on - what did that process look like from the initial idea all the way to the final output?

User: Yes, I did research on the effectiveness of an intervention program on the 6 month mortality rate of elderly patients. The process included: working with the medical team to define and track the intervention, examine medical history for propensity for mortality, control/test splitting, and outcome evaluation.

AI: That sounds like a really comprehensive study. I can see there were multiple stages there - from working with the medical team initially, through the data analysis, to evaluating the outcomes.

Where in that process, if anywhere, have you experimented with using AI tools?

User: Yes, AI tools were used mainly for propensity for mortality evaluation to narrow the target population and for data evaluation.

AI: Tell me more about how you decided to use AI for those specific parts - the mortality evaluation and data evaluation - versus using your traditional approaches for those tasks.

User: Machine learning was used to generate a singular propensity score, whereas traditional approaches used by the medical team was ranking based on the number of risk factors the patient had. AI was also used to help isolate correlated features.

AI: That's really interesting - so you moved from a more straightforward count-based ranking to a machine learning approach that could generate a more nuanced propensity score.

When you made that decision to use AI for generating the propensity scores instead of the traditional risk factor counting method, what drove that choice? What made you think the AI approach would be better for this particular aspect of your study?

User: It was likely driven by AI hype to satisfy the company investors

AI: That's a really honest answer - thank you for sharing that. It sounds like there were external pressures beyond just the scientific merits that influenced the decision.

Given that the choice was partly driven by investor expectations, how did you actually experience working with the AI approach compared to what you might have expected? Did it end up being more helpful, less helpful, or about what you anticipated for those tasks?

User: It was helpful to have a singular metric to segment the population, opposed to the previous count-based ranking of potentially unequal factors.

AI: That makes sense - having that single metric would definitely make the segmentation more straightforward and potentially more accurate than assuming all risk factors carry equal weight.

Thinking about the other parts of your research process - like working with the medical team to define the intervention, the control/test splitting, or other aspects - what's kept you from trying AI tools there?

User: Keeping the medical team engaged in the project at a level where they felt their medical expertise was directly contributing to the project.

AI: That's a really thoughtful consideration - maintaining that sense of ownership and direct contribution from the medical team. It sounds like there's a balance you're trying to strike between leveraging AI capabilities and preserving the human expertise that's so critical to the project.

When you did use AI for the propensity scoring and feature correlation work, how did you go about verifying or validating what the AI was producing? How did you make sure those results were reliable for your study?

User: We back-tested on historical member data

AI: That's a solid validation approach. 

We're about halfway through our conversation now. Let me ask you this: if you could wave a magic wand and have AI help with one aspect of your research work that it currently doesn't - whether in this project or your research more broadly - what would that be and why?

User: A tool for model transparency that can be easily understood by the medical team and also allows for the operations team to monitor for model drift.

AI: That's a really compelling need - essentially bridging that gap between the technical AI capabilities and the practical needs of both the medical experts who need to understand and trust the model, and the operations folks who need to maintain it over time.

Those are all my main questions. Your perspective on balancing AI adoption with keeping medical teams engaged, and this need for better transparency tools, were particularly insightful. 

Is there anything else about using AI in your research work that we haven't touched on that you think would be important for us to understand?

User: No

AI: Perfect. Thank you again for sharing your experiences so openly. Your insights about navigating the tension between investor expectations and scientific needs, as well as the importance of keeping medical teams feeling valued in their contributions, really help us understand the nuances of how AI fits into real scientific work. 

That point about needing better model transparency tools that can serve both medical and operations teams is especially valuable - it highlights how AI integration isn't just a technical challenge but really a human collaboration challenge.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
