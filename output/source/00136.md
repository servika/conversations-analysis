# Dialog 00136

**Transcript ID:** work_0150

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers – we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: I think I'm all set.

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: So I'm a high school English teacher. I'm in this interesting position where there is honestly some tension—I'm simultaneously trying to find ways to embrace AI in my own profession (lesson planning, grading, brainstorming, etc.), trying to teach my students to use AI responsibly and with care, AND limit their usage of AI in their own work. It's a balance that is difficult to maintain because things seem to be progressing so rapidly at the institutional and technological levels.

AI: That sounds like a really complex position to navigate. You're juggling multiple roles with AI - as a user, as an educator teaching responsible use, and as someone who needs to set boundaries around student work.

Tell me more about that tension you mentioned. What does that feel like day-to-day when you're trying to balance those different needs?

User: One particular class I teach is a composition class. One of the objectives of the class is to help students develop their style and voice as writers. As AI becomes more ubiquitous and my students become more savvy, I find them increasingly turning to AI to complete writing assignments—writing assignments that are meant to develop their rhetorical skills, their voice, and their style. Feeding a writing prompt into ChatGPT undermines the very purpose of the course. So I find myself spending more time utilizing AI-detecting software, more time checking edit and version histories of documents, and more time scrutinizing students' writing for AI usage. There are moments when I go into an assignment expecting most students to have used AI in some capacity—that is troublesome to me.

AI: That sounds incredibly challenging - you're essentially having to become a detective while also trying to be an educator. 

When you find yourself in those moments where you're expecting most students to have used AI, what goes through your mind? How does that expectation affect how you approach grading or interacting with their work?

User: I struggle, honestly. At times, there is a sense of resignation; a feeling that I cannot battle something so profoundly massive. I understand the merits of AI—I use it in my own work (pretty limitedly, I'd say)—but knowing they are often using it to complete work more effortlessly is frustrating, especially knowing that many students won't know the struggle of what it takes to produce a good narrative, or a good argument, or a good synthesis. I don't like being inherently suspicious of my students because I know the vast majority are hard working and studious. I feel, though, like I am battling expedience.

AI: That sense of battling expedience really resonates - you're trying to preserve something valuable about the learning process itself, not just the end result.

You mentioned you use AI in your own work, but in a limited way. Can you walk me through what that looks like? How do you decide when it's appropriate for you to use versus when you avoid it?

User: When I say limited, I mean maybe once or twice a month. I will occasionally ask an AI assistant to format a syllabus or identify awkward language in a document. I have used AI maybe a couple of times to help organize feedback on assignments. And perhaps once have I actually used a lesson plan suggested by AI. That has been the extent of it. Honestly, I make a conscious effort to avoid AI usage in my professional day-to-day life.

AI: That's a really intentional approach - using it sparingly for specific formatting or organizational tasks. 

What drives that conscious effort to avoid AI in your day-to-day work? Is it connected to the same concerns you have about your students' use, or are there other factors at play?

User: It does connect somewhat to to concerns I have about my students using AI—I would feel like a bit of a hypocrite if I used AI extensively. I also just feel like I trust myself better than any AI platform. I'm sure some of what a model could produce might be helpful, but I've been teaching a while and I think I'm good at what I do. So I'd rather think of AI as an absolute last resort.

AI: That makes a lot of sense - there's both the integrity piece and the professional confidence in your own expertise.

When you do use it for those occasional tasks like formatting or organizing feedback, how would you describe your interaction style? Are you working back and forth with the AI, or do you tend to give it a task and let it handle it completely?

User: Oh, I definitely go back and forth. I tend to approach using AI as a drafting tool. I will ask the AI to modify prose, or audience, or reconsider word count. Those sorts of things. Again, I trust myself more than anything else so I'd be uncomfortable letting the AI handle a job completely.

AI: That collaborative approach sounds very deliberate - treating it more like a drafting partner than handing over complete control.

How have your colleagues or your school's administration influenced the way you think about using AI in your work? Is there a shared culture or policy around it, or are teachers pretty much figuring it out individually?

User: I am lucky to work on a course team that shares values. We have developed a course policy that prohibits use of AI and treats it as academic dishonesty (classified as a sort of plagiarism in our handbook). Again, the intention here is to allow students to engage in the writing process and develop voice and style. We don't intend to condemn or wholesale dismiss the enterprise of AI. We honestly spend a good deal of time talking about AI, its merits and usefulness in the classroom and beyond. This also means we are constantly reflecting upon how to handle any infractions and student use. No policy is written in stone.

AI: It sounds like having that aligned course team makes a significant difference in how you navigate these challenges.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: This is something separate from the course I've been talking about but I did use AI several months ago to help develop a seminar-style course I am teaching based on the television show, Severance. I turned to AI to help develop some social experiments that could be adapted for a specific classroom setting. The AI came up with several ideas that, while not wholly effective on their own, became incredibly engaging and novel with some tinkering. Turning to AI in this instance helped supplement the knowledge I already had and really served as a brainstorming tool.

AI: That's a fascinating example - using AI as a creative brainstorming partner for something as unique as a Severance-based seminar. It sounds like that interaction felt different from your usual hesitancy around AI.

What made that particular use feel right to you, compared to situations where you might avoid using it?

User: Well, I had been a fan of the show, but some of the underlying principles and philosophies that the show was based upon were things not terribly familiar to me. In this case, I needed the AI to help fill in some gaps for me. The difference with this situation, I suppose, is that I felt less expert in the domain I was attempting to lesson plan for.

AI: That's a really insightful distinction - using AI when you're working outside your core expertise versus in areas where you feel confident.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: That's a good question and one I honestly haven't given much thought to. I do my best to keep abreast of what AI is capable of but I'm not concerned about AI taking over anything that pertains to my work…at least, not yet. I think so much of what I do necessitates human interaction and feedback.

AI: That confidence in the human elements of your work is interesting, especially given how much you're grappling with AI's impact on your students' learning process.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself maintaining this limited, careful approach, or do you think things might shift?

User: I'm going to be cautiously optimistic about AI in the classroom. I want to assume benevolence both of my students and of the technology. To that end, I don't see a near future where I am going to be using AI to grade the bulk of my students' work or provide feedback or even lesson plan. I see myself using those things as sparingly as a currently do. I do think that I will need to work harder to understand my students' relationships with AI, though. I may be able to limit the ways they use AI in my classroom but they will be constantly faced with this technology in other areas of their lives and I think I may need to respond to those ways more and more, even in my classroom.

AI: That thoughtful balance between maintaining your teaching principles while staying responsive to your students' evolving relationship with AI really comes through.

Those are all the questions I had prepared. You've shared some really insightful perspectives about navigating AI as an educator - I particularly appreciated how you've thought through the distinction between using AI in areas where you feel expert versus where you're filling knowledge gaps.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Nope. This was interesting! Thank you.

AI: Thank you so much for your time and for sharing your experiences so openly. Your insights about the complexities of being an educator in the age of AI - juggling your own careful use while teaching responsible practices and maintaining academic integrity - will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how thoughtfully you've approached these challenges, and I hope the conversation was useful for you to reflect on as well. Take care!
