# Dialog 00969

**Transcript ID:** work_0791

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: No, there are no questions, let's get started!

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: There are very few tasks that we utilise AI for. We have utilised AI for service development purposes, namely for creative tasks; we've used AI to help generate suggestions for therapeutic activities recently.

AI: That's interesting - you mentioned using AI for creative tasks and generating therapeutic activity suggestions. Can you tell me more about what that process looks like when you're developing these suggestions?

User: So we would ask AI for suggestions for potential activities, typically after we've begun drafting a timetable, to help us generate strong suggestions for therapeutics on site. These suggestions are modified for our service, and integrated into our timetable.

AI: That sounds like a practical application. When you say the suggestions are "modified for your service" - what does that modification process typically involve? Are you adapting them for specific client needs or organizational requirements?

User: Typically for organisational requirements, some suggestions will be unfeasible as our site lacks the required equipment, or personnel. We might extract some elements of an activity and make it more appropriate, to make it more practical to implement.

AI: I see - so there's quite a bit of adaptation work on your end to make the AI suggestions actually workable. When you're going through that process of extracting elements and making activities more practical, how much of the original AI suggestion typically remains versus how much becomes your own adaptation?

User: Depends on the suggestion! Some activities can be directly implemented, for others we take the core themes and think about how they could work with the equipment that we have. So the essence of the suggestion is implemented, but a toned down version of the activity may be rolled out.

AI: That makes sense - it sounds like you're using AI more as a starting point for inspiration rather than getting final, ready-to-use solutions. I'm curious about your preferences when working with AI. Are there certain tasks in your therapeutic work that you prefer to handle yourself, even though AI could potentially help with them?

User: Suggestions for anything person centred (i.e. referring to work for a single service user), or to do with risk assessments, I would not use AI for, as the cost for utilising information that could result in harm/risk to the individual is so high if the suggestion is poor.

AI: That's a really important distinction you're making about risk levels. When you think about those person-centered tasks and risk assessments that you handle yourself, what is it about your human judgment that feels essential in those situations that AI couldn't replicate?

User: Knowledge of the individual service user and risks (primarily on our site), due to the day-to-day experience of working with our patients in that context. A suggestion that may seem mundane may pose serious safeguarding risks if rolled out.

AI: That contextual knowledge and real-world experience with your specific patients and environment sounds crucial. When you are using AI for those general therapeutic activity suggestions, could you describe your typical interaction pattern? Are you more likely to have a back-and-forth conversation with the AI to refine ideas, or do you tend to ask for suggestions and then work with them independently?

User: It can be a bit iterative. After requesting an initial round of suggestions, I can include more information regarding either our service user demographic, our service, or redirect the model onto some activities may be more appropriate, if the round of suggestions misses the mark

AI: That iterative approach sounds useful for getting more targeted suggestions. How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that others in your organization have similar approaches, or are there different perspectives on where AI fits in?

User: There is relatively minimal use of AI across the service, and the functions for which AI could be useful fall largely into the domain of the management team only. There's definitely a preference for traditional methods, and no real shared incentive to begin using more AI.

AI: That's a really interesting dynamic - having limited adoption across the service with most potential applications sitting with management. Can you share a time when using AI for those therapeutic activity suggestions made you feel particularly satisfied or frustrated? What was happening in that situation?

User: It can be frustrating when the model provides clearly impractical options (like suggesting high intensity exercise), or a series of suggestions that are highly similar (such as several variants of class based, art therapy groups). Some nuanced, more detailed examples can be very useful, and get us thinking about how we can be innovative with the resources available on site.

AI: Those detailed, nuanced examples that spark innovation sound really valuable. When you get those good suggestions that help you think creatively about your available resources, what makes those stand out from the more generic or impractical ones?

User: They tend to be less akin to generic suggestions that you would find in the top results of a Google search, and incorporate functional and novel suggestions about how therapeutic activities can be offered using different, often more specific measures.

AI: That makes sense - you're looking for suggestions that go beyond what you'd easily find elsewhere and offer specific, functional approaches. How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider in your therapeutic work?

User: Sorry, what do you mean by areas where AI could take over? Are these areas that may be automated in future?

AI: Yes, exactly - I'm asking about areas where AI might become more capable of handling tasks that you currently do yourself. For instance, as AI gets better at understanding therapeutic approaches or generating more sophisticated activity suggestions, do you think about how to keep developing your own expertise in those areas?

User: Yes, I think there's a huge reflective area to the roll-out of such programs. Even if AI suggests a very useful system, you're always going to have to learn from the experience of implementing a program. There will always be lessons to be learnt from what went well, or did not go well when you're bringing therapeutics to a clinical population. They may not respond well, then you have to identify this and tweak what you are providing them.

AI: That's a really thoughtful point about the implementation and learning cycle being irreplaceable. Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it staying in that creative suggestion role, or expanding into other areas?

User: I could definitely see AI assisting with other routine, more systematic areas of site management. Like with data input, governance documentation and so on

AI: That makes sense - expanding into more administrative and systematic tasks. 

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on the importance of contextual knowledge with individual patients and how that creates clear boundaries around where AI fits versus where human expertise remains essential.

Before we wrap up, is there anything else about your experience with AI in your therapeutic work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, there's not.

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about the careful balance between using AI for creative inspiration while maintaining essential human judgment for person-centered care will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!

User: Thank you.

AI: You're very welcome! Have a great rest of your day.
