# Dialog 00070

**Transcript ID:** science_0079

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: Go ahead

AI: Great! Let's dive right in.

To start, I'd love to get a sense of your research background. Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: As a researcher, my process starts with taking new ideas that are discussed on social media (especially regarding AI). One research project ive worked on for a few years, and is not nearly finished, is how humans quantize complex topics into levels of abstraction, such as high level overviews, mid-level analogies, and lower-level details, and testing individuals with quizzes to measure cognitive load.
It usually starts with a hypothesis, then the research phase begins, where LLMs are used to locate sources and research papers on the topic.
Next, the hypothesis is refined into a smaller idea that can be measured through testing.
Finally, a basic quiz is designed, and there is a section at the end to measure how it made them feel, or if it made them stressed.

AI: That's a fascinating area of research - the way humans process information at different levels of abstraction sounds really complex to study. 

You mentioned that LLMs are part of your research phase to locate sources and papers. Tell me more about how you use them for that - what does that process actually look like when you sit down to research?

User: It usually starts with a few example prompts that are centered around the hypothesis, and I try to measure the most realistic ideas against the hardest to prove. From there, I will design a prompt that fits the questions I would like to ask and usually spend time modifying it and sending it until I get my desired result. I frequently use chain of thought prompts that I come up with before starting a conversation, such as follow-up questions or asking the model to rank the trustworthiness of articles.

AI: That's really interesting - it sounds like you've developed quite a systematic approach with the chain of thought prompts and trustworthiness rankings. 

When you're in that process of refining your prompts and getting results back from the LLM, how do you decide whether to use AI versus going directly to traditional database searches or other research methods you might have used before?

User: When I first started being a researcher, I used databases that my college offered to find relevant articles. The database search was often more time-consuming than using Google Scholar because it was keyword dependent. When ChatGPT got access to searching the internet, I immediately adopted it because it could provide links based on entire paragraphs describing my hypothesis or research ideas, instead of relying on keywords.

AI: That shift from keyword-based searching to being able to describe your hypothesis in full paragraphs sounds like a real game-changer for efficiency. 

Thinking about the other parts of your research process - the hypothesis refinement, quiz design, or analyzing how participants felt about the cognitive load - what's kept you from trying AI in those areas, or have you experimented there too?

User: I have not used LLMs to design my quizzes, but I have occasionally used them to brainstorm because the questions I ask are short and direct, and I find that LLMs quickly become wordy or fail to distill complex ideas into short questions. The writing quality is not good enough, but sI could see how it can get better. I am not sure how to implement AI into asking the participants about their cognitive load, but I just now imagined creating an LLM-inspired questionnaire that is more interactive than my pre-written questions being useful in the future.

AI: That's a really perceptive observation about the wordiness issue - it sounds like you've hit on something important about where AI currently falls short for your specific needs.

When you do use LLMs for research and finding sources, how do you go about verifying or validating what they produce? You mentioned asking them to rank trustworthiness of articles - tell me more about your process there.

User: I do not usually use the text excerpts that LLMs give summarizing the articles, and instead I create a list of sources in a notepad that I will later read through, and if there is an article that I might use, I will independently verify the source, such as its authors or if it was done at a university. I currently see LLM's as a type of search engine for finding articles that produce a higher rate of relevant articles compared to using Google Scholar. I do notice that the models will frequently find links that are not at all on topic, or have titles that sound like they could be relevant, but after reading, are not.

AI: That's a smart approach - using LLMs essentially as a more sophisticated search engine while maintaining your own verification standards. The issue you mention about titles sounding relevant but not actually being on topic when you read them is really telling.

We're about halfway through our conversation now. If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't handle well, what would that be and why?

User: I wish that it wouldn't decide to be completely dismissive of early-stage ideas, or express as much criticism about novel idea's even if I later decide they are unrealistic. I will sometimes need to modify prompts to tell the model to treat my questions as theoretical because it will often cite psychology studies or ethical concerns, when the questions being asked in my research are harmless and more speculative than factual.

AI: That's really insightful - it sounds like the AI's tendency to be overly cautious or critical can actually stifle the kind of exploratory thinking that's so important in early research stages. The fact that you have to specifically tell it to treat things as theoretical just to get it to engage with your ideas sounds frustrating.

Those are all my questions - your perspectives on using AI as a sophisticated search tool while maintaining rigorous verification standards, and especially your point about AI being too dismissive of novel ideas in early research phases, were particularly insightful. 

Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: I believe one of the most helpful advancements LLMs could use for my research is maintaining the level of insight and intelligence it has through prompts 2-4, because I have noticed that I frequently must restart conversations, or edit the second prompt, because it is noticeably dumber and less focused the more prompts I use.

AI: That's a really valuable insight - the degradation in quality over longer conversations is something that could significantly impact research workflows where you need sustained, deep engagement with complex ideas.

Thank you so much for sharing your experiences so openly today. Your insights about using AI as an enhanced search engine while maintaining your own verification standards, the challenges with AI being overly cautious about novel ideas, and especially that observation about conversation quality degrading over time - these really help us understand the nuances of how AI fits into real scientific work.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
