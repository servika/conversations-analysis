# Dialog 01241

**Transcript ID:** science_0081

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: Sounds good to me!

AI: Great! Let's dive in then. 

To start, I'd love to get a sense of your work. Could you walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: As an example, part of a recent project I worked on involved an aquatic drone that was meant to help detect and monitor invasive species in fresh bodies of water. Since the drone would be connected to university research and contain important data, the team needed to make sure they knew what kind of signals were being transmitted via each of the wires - This is where I came in. They had a mystery wire in the controller and had no idea what its purpose was or its signal. 

From here, I do a preliminary search to gather loose information about whatever malfunction/problem/etc. the device is experiencing, and generally end up reading a lot of User Manuals. Then I come in and mess around with stuff, in this case I brought in a grounded oscilloscope initially to see if I could get a read. After messing around in the lab for awhile running diagnostics, it's then back to searching, but at this point the topic usually requires a thorough literature review. Then the diagnostic/literature review cycle repeats until ultimately (hopefully) a resolution is reached. This is often in the form of a "fix" or in this case, by resolving the frequency of the wire's signal. Does that answer your question?

AI: That's a really helpful example - I can see how that diagnostic process involves a lot of iterative cycles between hands-on testing and research. The mystery wire investigation sounds like detective work!

Where in that process, if anywhere, have you experimented with using AI tools?

User: While my research/work tends to involve a lot of lab-based tasks, a good amount of my work is conducting literature reviews. The initial stage of gathering the manuals I need is easy, feeding AI the manual and telling me to pick out any part of it that involves specific *concepts*, not just words or phrases, is something I've tried and continue to try. AI does...okay at this. One thing AI can be really great at in this stage is scouring web forums, like reddit, for posts that are related to very specific topics - its recognition for "similar concepts" vs "similar words or phrasing" can really help narrow down some tidbits from other's peoples' totally separate problems to piece together the solution to the very unique problems I deal with.  I also use it to help me gather sources to review, particularly scientific papers - however, this is kind of a crapshoot most of the time.

AI: That's really interesting - it sounds like you've found AI helpful for that conceptual pattern matching, especially in forums where people might describe similar issues in completely different ways. 

Tell me more about why gathering scientific papers with AI is "kind of a crapshoot" - what happens when you try to use it for that?

User: AI adores hallucinating the relationships in sources between Author and Title. Particularly, it really likes to take real scientist's names and attribute papers to them either in their field, or adjacent fields, that *do not exist. *Not that the paper was written by someone else, but that it never existed at all. Typically, the title is very very close or similar to the title of another paper they wrote, or a combination of a few titles they wrote with some added flair to make it seem like it's relevant to the topic you're asking for sources on. It will make the reference citations look very very real as well and it will hyperlink them, sometimes to a different paper than titles (since the original doesn't exist) or the link is broken to begin with.

AI: That's a really specific and concerning pattern you've identified - the way AI creates these almost-real papers by mixing and matching real authors with plausible-sounding titles. That must be frustrating when you're trying to do serious research.

For the mystery wire project you mentioned, when you decided whether to use AI versus your traditional approach for different parts of that process, what factors influenced those decisions?

User: I wanted to add on my last response, apologies: The reason I still continue to use AI for literature reviews though, is that while it is alarmingly faking real scientists' names with non-existent papers, it usually does lead me to a scientist/scientists that are in the field and work-in or are adjacent to my topic. 

The factors that influence when I use AI for research are: How much time will this take? And, how utterly mundane is this task? For instance, my time was much better spent sitting in the lab with my hands actually on the oscilloscope, taking apart the controller, and running multitudes of other diagnostics, vs. if I spent hours combing through manuals or figuring out the exact right phrasing, search after search, to pinpoint the exact type of data I need to find.

AI: That makes a lot of sense - you're essentially using AI as a time-saving filter for the tedious parts while keeping the hands-on diagnostic work for yourself. And I appreciate that follow-up about the literature reviews - it's fascinating that even with the hallucination problem, AI still points you toward relevant researchers in the field.

Thinking about the parts of your research where you haven't used AI - like that hands-on oscilloscope work you mentioned - what's kept you from trying it there?

User: Well, I don't trust the AI to be thorough. While I may use it to help me with manual summaries, for instance, I still go back and skim the table of contents if there is one, and skim seemingly relevant areas to make sure it didn't miss anything - because it does, all the time. It gets a lot of things, and summarizes them pretty well, but it misses enough (sometimes 50/50) too frequently. So, when it comes to the idea of asking it to say, automate a series of *delicate* tests, I'd worry that period placed at the wrong spot while formatting a bulleted list I asked it to make "earlier" will become an issue.

AI: That's a really insightful distinction - the difference between tasks where you can double-check AI's work versus tasks where a small error could have significant consequences. It sounds like with delicate lab equipment, there's no room for that "50/50" reliability rate.

We're about a third of the way through our conversation now. When you have used AI for those manual summaries or forum searches, how do you verify or validate what it produces?

User: Manual extraction and summaries are a little annoying. I usually run them through a few different models to help fish out points any of them might have missed. Then I very quickly do a loose ctrl+f and search for related keywords I can think of - I don't ask the AI to produce a list of this for me because it always includes way too many extra things for whatever reason, making it harder to sift through. I skim around, and as for the accuracy of the summaries themselves, I only check the ones that look like they might be relevant, because at that point I am going to go back to the manual and closely go through that section. This ultimately still cuts down on a lot of time being able to have the AI do part of the work. Forum searches are easy; the AI never seems to fail to produce a link that goes to the correct conversation it references.

AI: That's a smart verification system - using multiple models to catch what each other might miss, then doing your own targeted keyword searches. It's interesting that forum search links seem much more reliable than those scientific paper citations you mentioned earlier.

If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: I think the forum searches are so accurate because search engines often include a "snippet" that's relevant to your search on the results page, because of how deeply they scour a lot of forums. It's easy access information with a specific link for a specific quote (often) right above it - is my guess why this is accurate. God, if I could trust AI to be able to search scientific papers for relevant and related and related topics, not just a workaround to look up scientists in their fields, it would be a game-changer. The amount of time it would save me...everything in our lab would be fixed in a year, and I'd get to spend more time on my core projects, or even doing science by fixing everything instead of scouring through hundreds of papers a month! I'd love to spend more time doing actual scientific investigations into my core projects

AI: That makes perfect sense - the forum accuracy likely comes from that structured snippet data, while academic databases are much more complex. Your frustration really comes through about spending so much time on literature searches instead of actual scientific investigation.

We're nearing the end of our conversation now. Those are all my main questions - your perspectives on using AI as a time-saving filter while maintaining hands-on control over critical work were particularly insightful. 

Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: Not off the top of my head, though I spend a lot of time using AI in my research work, for personal tasks/planning, and general day-to-day questions, and would love to provide more insight in the future if needed!

AI: That's wonderful to hear! Thank you so much for sharing your experiences so openly today. Your insights about how you navigate AI's reliability issues - using it strategically for time-consuming tasks while maintaining direct control over critical lab work - really help us understand the nuances of how AI fits into real scientific workflows. 

Your point about AI's potential to free up time for actual scientific investigation rather than endless literature searches particularly resonated with me. The way you've developed workarounds for AI's limitations, like using multiple models and doing targeted verification, shows a really thoughtful approach to AI integration.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thank you again for your time and perspectives!
