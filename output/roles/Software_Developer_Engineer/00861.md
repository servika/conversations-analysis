# Dialog 00861

**Transcript ID:** work_0636

---

Assistant: Hi! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: No, let's get into it

AI: Great! Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I tend to use AI mostly for the more mundane aspects of my job - drafting emails, blocking out reports - that type of thing. Nothing too high stakes and I very rarely just copy and paste. I'm usually using it as a first draft that I'll go on to rewrite. In addition to this, if there's a topic I need to research I'll ask the AI model to point me in the right direction to get me started.

I also find it quite useful when it comes to working through problems that I'm stuck on - I believe it's called rubber duck debugging? Being able to talk through a problem with a 'person' often leads me to solving my own problems.

The chat window is pretty much open all day, and I'll pop in and chat whenever needed, like an interactive google.

AI: That's really interesting how you describe it as an "interactive Google" that's open all day. 

When you mention using AI for drafting emails and reports as a first draft that you rewrite - what drives that decision to always rewrite rather than use the output directly? What are you looking to change or improve in that rewriting process?

User: It's not necessarily that I feel the need to change or improve the writing produced, it's more that the writing isn't 'me'. It doesn't sound like something I'd produce and is often either hot or cold when it comes to formality. It's either too professional or too friendly. Rather than going back and forwards trying to strike the right balance, I find it easier to just take the bulk of what is provided and tailor it myself

AI: That makes a lot of sense - it sounds like you're using AI to handle the structural work, but you need to add your own voice to make it authentic.

I'm curious about your preferences when working with AI. You mentioned you use it for more mundane tasks, but are there certain tasks you prefer to handle yourself entirely, even though AI could help with them? What makes those tasks different for you?

User: For larger blocks of code or more complex data analysis I'll usually choose to handle myself entirely. I might break the problem down into some chunks that I'll throw at the AI, but generally I find it serves me better to do those myself

AI: Interesting - so you'll break down complex coding or analysis into chunks for AI, but keep the overall architecture to yourself.

When you do use AI for work, could you describe your typical interaction pattern with those tasks you do delegate? Are you more likely to have a back-and-forth collaboration throughout the task, or do you tend to give it something to handle and then work with whatever it produces?

User: Very rarely will it be a one and done type of interaction - It tends to be a different style of back and forth though based on what I'm working on. For example, with the writing drafts, I'll go back and forth tweaking paragraphs or making sure it touches on certain points. That collaboration is a like a lot of different revisions and the draft will go through a number of versions before I'm happy with it.

When it comes to coding, that back and forth is usually like a Q&A vibe, as I attempt to understand the solution to the problem. So that could look like me asking the model how a certain print statement works, or to show me an example of a one line for loop. I would then go in further and ask it to break down elements of the solution or I'd ask it a question to reinforce my own understanding.

If I don't understand the code, how can I explain it to my superiors, or even trust that the model has generated the correct code? This feeds into my answer to the previous question, it's why I choose to mostly handle complex code myself.

AI: That's a really insightful distinction - using AI as a revision partner for writing versus as a tutor for coding concepts. Your point about needing to understand code well enough to explain it to superiors really highlights the accountability aspect.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that the environment you're in shapes how you approach these tools?

User: I'll be honest, it's not really discussed in the environment and any chat with colleagues about AI is mostly 'how crazy is it that it can do this' type of vibe. I'm not sure if this is because it's seen by some as cheating?

AI: That's really telling - the lack of open discussion despite people clearly being curious about AI's capabilities. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I don't necessarily think that I could name a time when I've ever felt satisfied by using AI, I think there's an element of when the AI does it's job well, that's the bare minimum I'd expect and so there's not a lot of room there for it to go above and beyond.

I've been left unsatisfied a number of times though, either when drafting an email and I ask it to rewrite the first paragraph but keep the second as is, and then it changes everything. Or when I ask it for help coding something and it produces code that doesn't work. These contribute to me overall not 100% trusting the output of any AI model, which if I'm being honest, is probably the healthier outlook to have.

AI: That's a really honest perspective - treating AI competence as baseline rather than impressive, and those trust issues from inconsistent outputs definitely seem like they've shaped your cautious approach.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I think as AI capabilities progress anyone would be forgiven for questioning their job security. I do believe that there will always be some need for human oversight and so for that reason I don't believe AI will truly 'take over'.

AI makes mistakes, it hallucinates, I think because of all that it in the long run it'll only ever be used as a tool to handle the more mundane parts of jobs - i.e writing unit tests, writing json. Stuff that is difficult to get wrong and easy enough to check over.

I'm thankful I've already got my foot in the door as I do believe AI is a lot harder on the junior positions. As you get more senior the reliability drops off.

AI: That's a thoughtful take on how AI's limitations actually create boundaries around where it's useful. Your point about it being harder on junior positions is particularly interesting.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself using it differently as the technology develops, or do you think your current approach will mostly stay the same?

User: It's hard to say as we don't know how the capabilities of AI models will evolve - look at where we were only a year ago vs today. I think I've reached a point where I've struck a good balance with my usage - I'm not reliant on it to do my job, but it does make it a little less tedious at times.

The area I can see my usage increasing is using it as a learning tool, especially as it gets more reliable.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on treating AI competence as a baseline expectation rather than something impressive, and how that healthy skepticism shapes your approach to maintaining oversight.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, that's everything. Thank you

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about finding that balance between useful delegation and maintaining control, especially around trust and accountability, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candid you were about both the benefits and limitations you've experienced. Have a great rest of your day!
