# Dialog 00732

**Transcript ID:** work_0422

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: No, fire away

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use it for creating rough drafts of web content and brainstorming, sometimes helping write scripts in python or I get help with excel

AI: That's a nice range of tasks. When you say you use it for creating rough drafts of web content, can you walk me through what that process typically looks like for you?

User: I give it some content about our business that's already on our website, say a snippet of text, then I provide some background context about the business, then I ask it to "create an seo friendly article for a webpage specifically about this topic."

AI: That sounds like a pretty structured approach. When you get that SEO-friendly article back from AI, what do you typically do with it next? Do you use it as-is, or does it become more of a starting point for you?

User: I check it for consistency, since it doesn't KNOW our business, it may assume some things

AI: That makes sense. When you're checking for consistency and those assumptions, how do you usually find that process? Is it pretty straightforward to catch those issues, or do you sometimes find things that slip through?

User: It's usually pretty easy to spot, if it mentions a service our business doesn't perform, or assumes our location

AI: Got it. I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: I write code myself if I can, unless its taking too long for me to figure something out or I know AI could give me a good starting point for a complex problem. I write my own emails and i would rarely want ai help, unless it was a lengthy important email that I wanted feedback on.

AI: That's interesting - it sounds like there's something about those tasks that feels important for you to maintain control over. What is it about writing code yourself or handling your own emails that makes you want to keep that personal touch?

User: The models I use can make jumps and assumptions when I ask them about code. They don't really understand what I'm working towards and the structure of my code so far, even copilot integrated with VS Code recently hallucinated error lines when I explicitly told it what line the error was on. Because there is no "understanding" I make sure to analyze the code myself and make sure it fits. For emails, I want to give my thoughts and feelings, not a guess from a computer.

AI: That's a really thoughtful distinction - the importance of having that full context and understanding versus letting AI fill in gaps it can't actually see. 

When you do use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I tend to strategically collaborate, usually only on a segment of a project. I find its ability to follow me through a lengthy reasoning and creation process is lacking. It will often start to shift away from previous context, which becomes very frustrating. I try to keep it on a timer, if I can't get any help from it in a few prompts, probably time to think more about it myself or hit up stack overflow.

AI: That "timer" approach is really smart - sounds like you've learned to recognize when diminishing returns kick in. You mentioned it gets frustrating when AI starts to shift away from previous context during longer processes. Can you tell me more about what that looks like when it happens?

User: let's say I am making a grid based game. Early on in the process, I told Ai that I convert all pixel values to grid values when handling mouse clicks, player movement etc... but several turns later, when I ask for help with a function that checks the position of an item on my grid, it gives me a function that uses pixel coordinates.

AI: That's a perfect example - it's like it forgot a fundamental design decision you made early on. That would definitely be frustrating when you're trying to build on established logic.

How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: Not much, Its used by some others in the office for similar tasks

AI: So it sounds like AI use is pretty normalized in your workplace, but people are mostly figuring out their own approaches. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: One time it claimed that a fundamental mathematical theory was wrong when i was giving it a proof to check. It was trying to say something like that the set of integers wasn't closed under multiplication... My most satisfying moments have come from it helping me flesh out ideas or build a starting point for bringing that idea to life.

AI: Wow, that's quite a mistake - claiming integers aren't closed under multiplication is pretty fundamental! That must have been jarring to see it get something so basic wrong.

On the flip side, when you talk about it helping you flesh out ideas or build starting points, what makes those moments feel particularly satisfying to you?

User: I felt validated and like there was a clear path to follow

AI: That feeling of validation and having a clear path forward sounds really valuable. 

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I don't think AI can take over anything. I used to think that, but now I believe all these stories about "we replaced our workers with ai" are really just "we needed to fire people but we don't want investors to see this as a bad thing so we will claim it was because of us being so cool and adopting ai." I really don't believe any big company claims about ai. If it can't catch an error in 100 lines of code, how can it understand or work with thousands? The security risks are never ending and the simple fact that the models are built on language, not world models, logic or understanding, will always be a problem. Essentially any time anyone uses an ai, they are rolling the dice, and rolling the dice at enterprise scale could be disasterous.

AI: That's a really grounded perspective based on your direct experience with the technology's limitations. You've clearly seen firsthand how those fundamental issues with language models can create real problems.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself continuing with this strategic, limited approach, or do you think your usage might change?

User: I think I will continue this way for now, and hope for systems with a better method of "understanding" not just my immediate prompt, but the context of my work.

AI: That makes a lot of sense - you're looking for something that can maintain that broader contextual awareness throughout a project rather than losing the thread.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on the difference between language-based responses and true understanding, and how that shapes the way you strategically collaborate with AI.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I think AI is great as an interactive notebook or thought mirror, but I don't see how we can let it take on serious customer facing tasks, or even backend work. Humans are currently too good at understanding context and edge cases. Thank you for your time.

AI: Thank you so much for sharing that insight - the idea of AI as an "interactive notebook or thought mirror" really captures something important about its current strengths while acknowledging those critical limitations around context and edge cases.

And thank you for your time and for sharing your experiences so openly. Your insights about the practical realities of working with AI, especially around maintaining that strategic collaboration while recognizing the technology's fundamental constraints, will be incredibly helpful for our research on human-AI interaction in professional contexts.

Have a great rest of your day!
