# Dialog 00901

**Transcript ID:** work_0693

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Sure, sounds good to me!

AI: Great! Let's dive right in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I'm a software developer at a consulting company, and I use AI pretty often. I mainly use it for coding through the Copilot VSCode extension, especially when I'm feeling a bit lazy and want AI to do the lifting for me. I've recently been placed on a project with an existing codebase, and I found it helped me quickly find and understand files specific to my ticket's needs. I also have it proofread any messages I send that require a bit of professionalism, and at times, I'll seek AI outside of Copilot to do extensive research/brainstorming on a specific problem. For example, I recently had a huge tech debt item to break down in that unfamiliar codebase, and I found that using multiple avenues of AI helped me understand how to work on the task in pieces. We didn't end up following the exact structure that AI gave, but I think it was moreso human issues at play than the plan being unoptimal.

AI: That's really interesting - it sounds like you're using AI across quite a range of tasks. You mentioned using it when you're "feeling a bit lazy" - tell me more about that. What does that look like in practice?

User: I've noticed this with AI usage over time actually, but I've noticed I just don't engage with the work like I used to? It started with me focusing on making the prompts as optimal as possible, but now certain models (specifically Claude Sonnet 4) have gotten better and better at understanding intent that I don't have to do a lot of "prompt engineering" to get what I want anymore. I've also found that before when I would use AI, I'd often run into errors that it wouldn't be able to fix, but nowadays, it can eventually self-correct itself as long as I give it updates on the current error and also my working understanding on what's going wrong.

AI: That's a fascinating shift you're describing - from having to work hard on prompts to being able to rely on the AI more directly. When you say you don't engage with the work like you used to, what does that change feel like for you day-to-day?

User: It's nice, because on one hand, I get my ticket done relatively fast and I have a lot more time. I could technically use that extra time to work even harder - and I often do when it matters - but my work has a really nice work/life balance and hour-long lunches aren't unheard of. So, I often use that extra time to take a break instead. But yeah, often times I'd be stuck figuring out how to implement something or how to fix to a bug and I'd go down rabbit holes, but a lot of the work I'm doing right now (web development) is largely scoped out/trained on, so I am learning by working with AI, but the effort to get to that learning point is a lot less now (since I can get the answer much more easily).

AI: That sounds like a pretty significant change in your work rhythm. You mentioned that you're still learning, but the effort to get to that learning point is much less. Can you walk me through what that learning process looks like now compared to before you had AI assistance?

User: Prior to AI I would need to look up my exact error on Stack Overflow, and if those fixes wouldn't work, I'd have to maybe look at documentation and try to figure out what's going on under the hood. If it was a logical error, I'd probably open up my debugger (or print to console) and step through my code step by step until I found the issue. But I don't need to do that as much anymore now that I can AI seems to be able to catch most things. It's not to say it's perfect with every framework - for more specialized areas (like certain AWS services) it can be entirely unhelpful, but I'm currently working with a very popular framework (React) which makes it super easy.

AI: So it sounds like AI has streamlined a lot of those debugging and troubleshooting steps for you, especially with popular frameworks. I'm curious about your preferences - are there certain tasks you still prefer to handle yourself, even though AI could potentially help with them?

User: Not really? I do notice sometimes when I'm prompted to run a terminal command (for example, to see if the current tests pass), I do prefer to do it myself, but I think that's because it often is adding extra commands or steps into it, and it also eats at my tokens. I'll often swap to a model that doesn't eat at my token/premium usage for easy/menial tasks, and then when I'm really stumped, I'll swap to a premium model. I'm very particular about not wanting the premium model to do things I can do myself so I don't cap my premium requests out.

AI: That's a really practical approach to managing your AI usage. You mentioned being strategic about when to use premium versus basic models. When you do get stumped and decide to bring in the premium model, what does that collaboration look like? Are you working back and forth with it, or do you typically give it the full problem to solve?

User: Can you explain what working back and forth would look like? I typically give it a full problem to solve and then iterate on top of that, but sometimes if the problem I have in mind is likely too "large", I'll split it into separate subtasks which I prompt the model for; once it's completed a subtask, I start a new conversation and begin the next subtask from there.

AI: By working back and forth, I mean more of a collaborative approach where you might share part of a problem, get AI's input, then you do some work yourself, then come back to AI with questions or refinements - kind of bouncing ideas back and forth rather than handing over a complete task.

It sounds like you lean more toward giving it complete problems or well-defined subtasks. What influences your decision about when to break something into subtasks versus keeping it as one larger problem?

User: I see, then yes, I lean more toward full problem solving. It's mainly to manage the "context" of a model - I find that the more that I keep a running conversation going, or if my task isn't well-defined and I have to keep re-prompting to model to alter things it's already done, it tends to give worse answers. It's very similar to what I would probably do without AI - trying to do work in a structured way, validate that some subtask is working correctly, and move onto the next.

AI: That makes a lot of sense - managing context to maintain quality responses. You mentioned that your approach mirrors what you'd do without AI in terms of working in a structured way. How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: My workplace is pro-AI heavy, and there's a slack channel actively sharing out current information regarding AI (could be news, like today someone posted a GitHub link about agents "cheating" on benchmarks by getting the answer from a future git commit). Anyways, we've had workshops learning how to use AI, and we even paid a presenter who "teaches agentic AI coding" for a living, but we've come to the conclusion that nobody has quite nailed it yet. Nevertheless, my workplace has been sharing out as many work setups, and we frequently talk about our experimentation/successes/fails/pet peeves, etc.

AI: That sounds like a really supportive environment for AI experimentation. You mentioned that you've concluded nobody has quite nailed agentic AI coding yet - what's been your experience with that? What are the gaps or limitations you've encountered when trying to use AI more autonomously?

User: The main limitation is the context and the tendency towards duplicated code over time - I know people have been using memory banks to try to mitigate this, and there has been some anecdotal success that it's an improvement. It could just be me being even more lazy, but I'm not exactly convinced the tradeoffs make it worth it. Another issue is that when working with extremely large corporations, there is often a lot of red tape/compliance standards to meet, and that limits us - for example, we're unable to set up an MCP server for our project because models haven't been validated to pass privacy needs.

AI: That's really helpful context about the practical constraints. You've touched on some technical limitations and workplace policies. Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I guess it'd have to be my recent tech debt refactor item - nobody on my team wanted to tackle it, because no one on my team has any experience doing a large-scale refactor in an unfamiliar codebase. It was super intimidating and multiple members of my team mentioned it was scary even, but Claude Sonnet 4 (in agent mode) specifically helped me get an understanding of the codebase so fast that I was days beyond anybody else in understanding the business logic. It helped me lead the new database design decisions and I noticed my team members started to come to me for clarification for domain knowledge. I don't think I could've done that without AI at all, at least, I'd have to put in a significant amount more effort to have done so. But I did do that quite leisurely.

AI: That's a really compelling example - it sounds like AI helped you become the domain expert when nobody else wanted to take on that challenge. When you say you did it "quite leisurely," what did that experience feel like compared to how you imagine tackling such a complex refactor would have been without AI?

User: I find that it's much easier to check someone's work compared to doing the work myself. So basically, I had AI do all the work for me in understanding how the different functions and classes fit together, and I simply had to understand it's explanation and ensure it made sense. And if I was ever confused or thought it did something wrong, I could talk about it and we could come to a conclusion together - just like having a personal tutor.

AI: That's a great analogy - having a personal tutor. It sounds like this experience really transformed what could have been a stressful situation into something manageable. 

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Honestly, I haven't thought about it too much. I'm still fairly new to the industry, so I almost feel like I didn't have "skills" before AI really, but I'm not sure that it's fully necessary either? I think people are naturally bounded by their own skillset when using AI anyways - yes, it can "raise your level" for a bit, but you still need to fundamentally understand what's going on. Eventually, if the agent hits a problem it cannot fix, then the onus goes back to you to understand what's going on... And it can be really tough to do so when you're 10 prompts in and you've just been vibe coding the whole way. So, I think as long as I'm not getting fully lazy and validating at each step, I should be good - and if anything, it'll be a way for me to continuously improve my skills. I've seen this argument circulating around, where people say AI is akin to a calculator back in the day - people used to argue that using a calculator was cheating, and that you needed to still practice the skills on your own. But that sentiment is largely gone now.

AI: That's a really thoughtful perspective - the calculator analogy is interesting. You mentioned that people are naturally bounded by their skillset when using AI, and that you can get into trouble if you're just "vibe coding" without validation. 

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I think that just really depends on how much further AI can go. People have said that we're already experiencing diminishing returns, and a pessimist would say that we've probably reached most of what AI can currently accomplish. If that's the case, I could maybe see myself finally adapting a memory bank approach and running multiple agents at once for maximum productivity in the future (though, if my work doesn't necessitate me to do that and my current performance is fine, then that might take awhile). If we can hit the singularity (AI become capable of self-improvement), then... I'm not really sure. I think people write sci-fis about that, we'll have to see.

AI: That's all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how AI has transformed that intimidating tech debt project into something you could tackle leisurely, and your calculator analogy for thinking about skill development.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Nope! Thanks for your time!

AI: Thank you so much for your time and for sharing your experiences so openly. Your insights about the evolution from prompt engineering to more natural interaction, the strategic use of different AI models, and especially that example of tackling the tech debt refactor will be incredibly helpful for our research on human-AI interaction in professional contexts.

Have a great rest of your day!
