# Dialog 00493

**Transcript ID:** work_0069

---

Assistant: Hi, I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers – we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. Does that sound good? Do you have any questions before we begin?

User: Nah, all good, go ahead

AI: Great, let's dive in then. Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: So I do customer service for a telecomms provider, with the expectation of sales through service as a given during interactions. The CS role is very broad and covers a myriad of things, like explaining steps to perform an action on the phone that are not specifically network related, to sending emails following up actions that have taken place or that will need to occur. The telecomms providers own support tools for workers are - in my experience exceedingly poor - a colleague informed me they had started using ChatGPT as a more reliable way of drafting the emails  and I gave it a try and then proceeded to use it from that point on. I -absolutely- struggle with my time keeping during phone calls and my after call work is always higher than my dept targets, so I continued to use AI as a drafting tool. At the beginning of the shift I'll give it a set of rules of how an email should be formatted and certain phrases to include, and then when I actually need it I can then just put in "12m SIMO, £16 a month, 20GB/UL calls/texts" and it will input the information into a draft using the other key information. This has massively cut down on time after calls for me because the tools the employer provides are no where near as swift or intuitive. In fact from sheer volume of clicking it takes 7 minutes to get through their process alone. I know. I checked. So I use AI. Then once a cx asked me to explain something I had already explained for about 5 minutes on the call and honestly I just couldn't face it anymore. I had run out of ways to explain it to them (this was something called a pro rata bill cycle, something which all Direct debit bill payers should be familiar with and yet this person absolutely could not comprehend it). In desperation I switched to my AI tab and asked for a different explanation. It was not how I personally would have explained it - BUT - that was the point, the person didn't understand me. It made enough sense to the person with this explanation that we could move on. From that point on I then begun using it for jargon translations of new phone features when I had to switch gears into selling phones too. It's reasonably effective and better than the boilerplates my employer provides.

AI: That's really insightful - it sounds like you've found AI to be a practical solution where your company's tools fall short. I'm particularly struck by that moment with the pro rata explanation where you needed a different way to communicate the same concept.

Tell me more about that experience when you used AI to explain the billing cycle differently. What was it about that AI-generated explanation that worked when your own approach hadn't?

User: So, sometimes I struggle to meet a cx at their level. I can relate to them and get along with them well enough, but I frankly could not get why my explanation - which works so well for near enough every other cx was failing to get through. It made me question whether actually my explanation was any good or whether other cx's had just nodded along over the phone or not paid attention. I needed analogies for them. I asked for analogies and asked ChatGPT for an explanation suitable to an 8 year old (the cx was in their 40s). I needed to detach my own ego from the situation (why wasn't MY words working, what is it about ME that is the problem) and stop putting my own expectation on the cx (they're old enough that they should understand this already). ChatGPT has no ego to offend, no bias to overcome so it gave a more neutral response and I could offer that without imbedding my own emotions into it.

AI: That's a powerful insight about how AI helped you step outside your own perspective. It sounds like the AI served as almost an emotional buffer - removing your personal investment from the explanation itself.

When you think about that situation, was it mainly the neutral tone that helped, or was there something specific about how the AI structured the explanation or chose those analogies that made the difference?

User: You know I'm not sure, it was approx 18 months ago that I used it in that particular case - and I wouldn't be able to say what worked for the cx but for me it helped me remain calmer because I had another phrasing to go from, a script I hadn't personally worked on, and you're right it was an emotional buffer. So again I'm not sure if the cx was satisified just because they were over it by this point but they had got what they wanted (ie a different explanation) or whether the specific phrasing actually made the leap of understanding for them but for me personally as a tool it was useful for that emotional distance it gave me in the situation.

AI: That makes complete sense - sometimes the benefit for you as the service provider is just as important as the outcome for the customer. It sounds like having that emotional distance helped you stay professional and effective in a challenging moment.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: I like thinking my way out of problems. Cxs will present me with an issue, they'll think it doesn't make sense but its just because they don't have the right words to articulate their problem into our systems, and other agents haven't given them the time to work it through. I'm not sure that AI - in its current form can make that leap. There is a great deal of difference between what people say and what they mean, and that's always an area I've been professionally interested in across my career spanning many industries. So that Poirot stage of a cx coming onto a call, and trauma dumping how they've got into whatever problem they currently have and then using my knowledge of the system to figure out the problem - I like that. I wouldn't want to outsource that part of the experience because whilst its possible an AI chat agent could get through what a cx needs from the outcome - the problem doesn't go away for the cx in their head until they feel heard. Which they will not get in a chatbot. Also the risk of misinterpreting the details they mention, and the import the cx places on them, like I said I don't think the tools are quite there. What I do wish is that the tools I had DID have AI integration officially so I could plug in the important information and pull the solution out for them, instead I have to keep my knowledge base up to date and vast to help them. Emails though should absolutely be AI'd in every case though and I think its absurd I have to waste so much time on this and forms in my call handling time.

AI: I love that "Poirot stage" description - that detective work of understanding what the customer really needs beyond what they're saying. It sounds like you see real value in that human interpretation and the emotional validation that comes with feeling heard.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: Due to the time frames I have to work within, I delegate. Either what comes out works for me or it doesn't. If the email isn't right I will edit it and then send it, but the bulk of the body is done for me and I can tweak it before sending as I read it over. If an explanation of a phone feature or the version of the sales pitch it gives me doesn't hit with the cx I try again, ie I'll say, ok bgive me those features but geared more to a creative type personality in early 20s. Again it either works or it doesn't so I move on. These calls are rapid fire and I do not have time to collaborate. I take the output and its either useful or not and then I need to move on.

AI: That rapid-fire environment really shapes how you can use AI - it's about quick wins or moving on, not lengthy back-and-forth. The time pressure sounds intense.

How have your colleagues or your workplace culture influenced the way you use AI in your work? You mentioned a colleague first told you about using ChatGPT for emails - has that openness continued?

User: No, it was a colleague I trusted, and they have been made redundant - approx 20 months ago. UK based colleagues in my job are few and far between now, we all WFH and there is very little team/collegiate feeling left. As such I now keep my use of the tools quiet as I'm sure it would be frowned upon. But the tools I do have are not up to scratch, so I am just trying to meet the pressures of the job with some problem solving, its not my fault their systems are so outdated, I shouldn't suffer and neither should cxs

AI: It sounds like you're in a bit of a challenging position - using tools that genuinely help you do your job better, but having to keep that quiet because of workplace culture. That isolation from colleagues must make it harder to know what others are doing or thinking about AI use.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: The emails, when I realised how much time I was saving, vs what I had been doing before. I can skip a lengthy (and I really do mean lengthy) process and go straight to the email address and copy paste in the Output. The system in place to get these emails out is a total joke. The "wizard" version of it stopped working on the UK support systems literally years ago, I don't know how others can keep to target and still use the system we're meant to and then the first week of using the set up for emails instead was such a breeze compared to before when I would do all I could to avoid an email. Felt like a weight off my shoulders.

AI: That relief is really palpable - going from dreading emails to having them become manageable must have been huge for your day-to-day stress levels. It sounds like you went from actively avoiding a core part of your job to feeling confident about it.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I know it coming for my job, and I'm not overly bothered. The telecomms industry cycles through needing UK agents and then offshoring the work when their profits suffer too much. But then profits start suffering because cxs want UK based agents. AI agents will just be another step in this cycle. There will always be the "I want to talk to a real person" brigade so eventually they'll need people back in the mix. It is something I'm acutely aware of, but I feel I know my worth and my skill set, and human relatability will always have a place.

AI: That's a really pragmatic perspective - you see the bigger industry patterns and cycles rather than just focusing on AI as a singular threat. Your confidence in the value of human relatability seems well-founded, especially given what you described earlier about helping customers feel heard.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: If my employer would invest in AI instead of the system update they've just done things would improve. But things in giant organisations take literally a decade to come to fruition and by then the tech available far outstrips the brand new tools youre being given. AN integrated AI assistant for the agents would be amazing - but honestly that won't happen for at least 15 years in this industry. Whether more agents secretly use it like I do will be interesting to see.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how AI serves as an emotional buffer in difficult customer interactions, and your realistic view of the industry cycles around automation and human agents.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, thanks for your time.

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about using AI pragmatically within the constraints of outdated systems, and especially how it can provide emotional distance in challenging customer interactions, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candid you were about the realities of your work environment. Take care!
