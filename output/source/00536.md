# Dialog 00536

**Transcript ID:** work_0129

---

Assistant: Hello! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good to you? Do you have any questions before we begin?

User: Sounds good, no questions.

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: In my current position as an OR RN, I rarely use AI. I would say the only time I have used AI in my workplace has been for things like helping to draft an email or asking a question that would take some time for me to research myself. For example, two or more medications that may interact with something to be given during surgery or other similar questions.

AI: That's really interesting - it sounds like you're using AI more as a research assistant for specific clinical questions. 

When you mentioned using it to check medication interactions, can you tell me more about that? What does that process look like for you - are you pulling out your phone during a case, or is this something you're doing during prep time?

User: Prep time is more hands on for me. Making sure equipment and supplies are ready and prepared in the OR room. As the OR is a fast-paced environment, I am reading over a patient's chart just prior to speaking with them. This is when I will pull out my phone to ask a question. I may pull out my phone during a case if the surgeon asks a question I don't know the answer to, and I will google the question.

AI: So you're using AI during those quick moments when you're reviewing charts or when a surgeon asks something on the spot. 

I'm curious - when you do reach for AI versus Google in those situations, what drives that choice? Is there something specific that makes you think "I'll ask AI this" versus "I'll Google this"?

User: I think Google is just more of a habit for me at this point. I also don't fully trust AI, so I like to know where my information is coming from sometimes so I can make sure its from valid sources.

AI: That makes a lot of sense, especially in a clinical setting where accuracy is so critical. 

You mentioned not fully trusting AI - can you tell me more about what that looks like for you? What would need to change for you to feel more confident using it for work-related questions?

User: I think if there was a clinical specific AI model that only pulled information from peer-reviewed journals, well documented research, clinical texts, etc. that I would be more likely to use it for clinical questions and be able to trust it. I know from working with AI that it still hallucinates things so that is worrisome when in a clinical setting. I also know that it uses a wide variety of sources for information, including Wikipedia, which is not always accurate.

AI: That's a really thoughtful perspective - the idea of a clinically-focused AI with verified sources makes a lot of sense for your field.

Since you mentioned you've worked with AI and are aware of its limitations like hallucinations, I'm curious about the non-clinical tasks you mentioned, like drafting emails. How do you approach using AI for those types of work tasks differently than the clinical questions?

User: Well, punctuation and grammar are not life or death, so it's easier for me to rely on it and feel okay if AI is wrong. So, I can ask AI to draft an email stating certain things and then quickly look it over prior to sending.

AI: That's a really clear way of thinking about it - the stakes are so different between clinical questions and email drafts.

When you do use AI for those lower-stakes tasks like emails, do you find yourself collaborating with it back and forth - like asking it to revise or adjust the tone - or do you typically just take what it gives you and edit it yourself?

User: I usually just take what it gives and edit what I need to myself.

AI: That makes sense - sounds like you're treating it more as a starting point than a collaborative partner for those tasks.

I'm curious about your workplace culture - have you noticed other nurses or colleagues in the OR using AI tools? And if so, how has that influenced how you think about using it yourself?

User: I don't know of anyone else who uses AI in my workplace.

AI: Interesting - so you're kind of navigating this on your own without much peer influence.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Well, like I said before, the OR is a very fast-paced environment. I remember a time not too long ago, that I asked a clinical question (I don't remember what it was, sorry). It was not understanding what I was asking, which was frustrating. It could have been the way I was wording it due to being in a hurry or just not understanding.

AI: That sounds really frustrating, especially when you're under time pressure and need a quick answer.

When that happened - when AI wasn't understanding your question - what did you end up doing? Did you try rewording it, or did you just move on to Google or another resource?

User: I asked a peer and asked Google.

AI: That makes complete sense - when time is critical, you need reliable answers fast.

How do you think about maintaining your clinical knowledge and skills in areas where AI could potentially help? Is this something you actively consider, or does it not really factor into your thinking given how you currently use it?

User: I have not thought about using it in that way. Usually just as a check to make sure I remember something correctly or I have asked for steps in a clinical skill that I haven't done in awhile.

AI: That's helpful to understand - using it more as a backup to verify what you already know or refresh skills you don't use regularly.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think you'll use it more, less, or differently as the technology develops?

User: I am hoping to use it more. I would love for our documentation to be able to utilize it. One of the most time consuming parts of nursing is the documentation, and to be able to utilize AI to take some of that load would be amazing. I think it would be helpful to be able to take a picture of the OR room, equipment, or patient and have AI fill in the documentation with patient positioning and interventions, equipment used and settings, etc. At my previous job, we used the ROSA robot for total knee replacements where it took measurements and gave precise cuts that were patient specific. I am hoping for things like that to make it into the routine everyday part of my job to improve patient care.

AI: That vision of AI helping with documentation and equipment recognition sounds incredibly practical - I can imagine how much time that could save you and your colleagues.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work, especially around the trust considerations in clinical settings and your vision for more specialized healthcare AI tools.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I don't think so. Thank you.

AI: Thank you so much for your time and for sharing your experiences so openly. Your insights about the balance between AI's potential benefits and the critical need for reliability in healthcare settings have been incredibly valuable for our research on human-AI interaction in professional contexts.

I really appreciated hearing about your practical approach to using AI - how you think about appropriate use cases based on stakes, and your thoughtful vision for how AI could transform documentation and patient care in the future.

Thanks again for participating in this interview!
