# Dialog 01035

**Transcript ID:** work_0890

---

Assistant: Hi, I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. Does that sound good? Do you have any questions before we begin?

User: Sounds good. I don't have any more questions before we begin.

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Using AI is an essential part of my typical workday. I am a software engineer at a robotics start-up. I use AI to write and fix code. Around 70% of the time using AI is for debugging errors in large projects. This has helped me save a significant amount of time.

AI: That's really interesting - debugging sounds like it's become a major use case for you. When you say you use AI for debugging errors in large projects, can you walk me through what that actually looks like? How do you typically approach it?

User: Since we develop software for robots, almost all of my coding is done in a ROS2 framework. A typical example of using AI for debugging would be if someone presses a button on a controller for the robot to perform an action, but the robot does not respond. I would describe the scenario context to AI, and then get AI to explore the code base and track the flow of data to identify potential places for problems.

AI: That's a fascinating process - having AI trace through the data flow to find where things might be breaking down. When you're working through a debugging session like that, how do you typically interact with the AI? Are you going back and forth with it as you explore different possibilities, or do you tend to give it all the context upfront and let it work through the problem more independently?

User: Usually, I would have to go back and forth multiple times. For us, AI rarely ever get things right the first time, but almost always goes in the correct direction for solving problems. Usually, AI would make some fix or add some debugging statements, and then I run the code, and then copy and paste the debugging statements, and also describe whether the problem is solved and how the system now behaves if a new problem arises.

AI: That iterative process sounds really valuable - the AI pointing you in the right direction even when it doesn't nail the exact solution immediately. When you're in those back-and-forth debugging sessions, how do you decide what information to share with the AI at each step? Do you find yourself developing strategies for communicating effectively with it about your robotics codebase?

User: Yes there are good strategies for what to share with AI so it doesn't get overwhelmed but it still has the essential information. I would make sure that the AI has access to the code, terminal output from running the script of concern, physical descriptions of hardware behavior (for example, if robot joint motor moved). If we are developing ROS2 software, a ros2 topic echo terminal output in addition to the ROS2 node's terminal output is often very helpful to the AI. However, sometimes we also have to make sure to not feed any unnecessary information that could confuse the AI, such as a debug print from another part of the code that says something like "Systems ready".

AI: That's a really thoughtful approach to information curation - giving the AI what it needs while filtering out the noise. It sounds like you've developed quite a refined process for this collaboration.

I'm curious about your preferences when working with AI. Are there certain tasks in your robotics work that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: Design of high level architecture of our robots' software systems is 100% done manually instead of AI, eventhough AI could be helpful sometimes.
We also usually prefer any system integration task to be done by ourselves rather than AI. A good example is a UDP messaging protocol for sending commands and receiving feedback between a remote operator PC and the robot, which is 100% written by ourselves, to ensure that all team members working on different software packages are on the same page for things that cross over.

AI: That makes a lot of sense - keeping the foundational architecture and integration points under human control for consistency across the team. When you think about those high-level architecture decisions and system integration work, what is it about those tasks that makes you feel they need that human touch rather than AI assistance?

User: AI does not have access to all of our background information. Ultimately, we know what we want from a high level perspective, and it is difficult to tell that entire context to AI.

AI: That's a really insightful point about context and institutional knowledge. It sounds like there's a lot of accumulated understanding about your specific robotics system and goals that would be challenging to convey to AI.

When you are using AI for those debugging tasks we talked about earlier, can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: There was a time when AI made me very frustrated. In a ROS2 package that translates ROS2 topics into CAN messages to controlling a series of motors, we had a problem when outgoing CAN frames contained only zeroes no matter what was publishes on the ROS2 topic. AI repeatly pointed to our configuration file that sets motor maximum speeds as the culprit, even though we set these values from the motor vendor's documentation. Only after manual inspection did we find that the problem stemmed from big-endian / little-endian formatting issues.

AI: That must have been incredibly frustrating - especially when the AI kept pointing you toward the configuration file when the real issue was something completely different. When you were going through that experience with the endianness problem, what was it like to keep getting steered in the wrong direction? How did you eventually decide to step back and do the manual inspection that found the real issue?

User: Getting steered in the wrong direction was frustrating because it can often lead to loss of correct / good values for variables. While every programmer will always make lots of back-ups, it is simply impossible and impractical to back up every thing at all times. For example, when AI overwrote values in our configuration files, we had to re-set those values by looking for them in the vendor's documentation again. We decided to step back and do the manual inspection when AI spent a long time thinking and could not come up with any different solution.

AI: That's a really important insight about the practical costs of AI getting things wrong - it's not just the time lost, but potentially losing working configurations that you then have to recreate. 

How have your colleagues or your workplace culture at the robotics startup influenced the way you use AI in your work? Do you find that your team has developed shared approaches or guidelines around AI use?

User: Yes our team has shared approaches to AI use. I was the first software engineer in the start-up, so I set some rules and guidance for others to follow after they joined. This makes our work streamlined because if we have problems with other's work, we know how to continue their AI conversations to fix their problems.

AI: That's really smart - creating consistency so team members can actually pick up where others left off in AI conversations. What kinds of rules and guidance did you establish? I'm curious about the specific practices that make it possible for someone to continue another person's AI debugging session.

User: We have rules on when to start a new conversation with and when to continue an existing conversation. On all our projects, the conversations with AI are generally like this:
1. Software package creation from a set of instructions written in a txt file (which is preserved), and then followed by build problem fix, until the package can fully build with no errors
2. Error 1 that happens during execution 
3. Error 2 that happens during execution
4. Upgrade to package in functionality / compatibility
5. More errors

And the pattern repeats. We would look through the history of conversation topic labels to see if the problem existed before or not. Sometimes continuing a conversation from an error that has happened before is very helpful because AI's memory in that conversation can accelerate the iteration of fix and run.

AI: That's a brilliant system - structuring the conversations by distinct phases and maintaining that conversation history as a searchable resource. It sounds like you've essentially created a knowledge base through your AI interaction patterns.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it changing as the technology develops or as your robotics projects become more complex?

User: I don't think our relationship with AI at work will change much. AI will always be a good helper but we will always use our own judgement in many high level and difficult areas.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how you've developed systematic approaches to AI collaboration and the way you've structured conversations to create institutional knowledge for your team.

Before we wrap up, is there anything else about your experience with AI in your robotics work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, that's all

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about debugging workflows, the challenges with context and institutional knowledge, and especially how you've developed team practices around AI collaboration will be incredibly helpful for our research on human-AI interaction in professional contexts.

It's been really valuable to hear about the practical realities of AI use in robotics development - both the successes and the frustrations. Thanks again for participating in this interview!
