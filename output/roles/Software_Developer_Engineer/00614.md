# Dialog 00614

**Transcript ID:** work_0248

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good to you? Do you have any questions before we begin?

User: Sounds great! No questions yet.

AI: Perfect! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Typically, I'll use AI in my workday as somewhat of a colleague. For example, if I am about to go about some task to find out how some particular variables are changing with time, and whether or this could be attributed to by anything in particular (perhaps the weather, changing trends or adjacent internal decisions), I'll usually give AI a high-ish level of my plan, to see if there are any clear holes in my logic. The tasks that I use AI for are usually just taking messy tabular data and asking AI to check over it and present it nicely, before doing some more thorough checks later on. I have been using it as more of a sounding board lately, however.

AI: That's really interesting - you describe using AI as both a colleague and a sounding board. 

Can you tell me more about what it's like when you use AI to check for holes in your logic? What does that interaction typically look like?

User: Sure! Well, admittedly it's often with tasks or ideas that haven't been thought about enough to present them with my colleagues - i.e., usually just high level ideas. For example, if I am looking to come up with some new variable which may be interesting, but isn't readily available, and I'd like to attempt to derive this variable, I'd quickly discuss my thoughts with AI. If there are obvious gaps, then it saves me time from thinking about it further!

AI: That makes a lot of sense - using AI as a first filter before investing more time or bringing ideas to colleagues. 

When AI does identify those obvious gaps in your early thinking, how do you typically respond? Do you work through the gaps together with AI, or do you take that feedback and work on it independently?

User: Even if my ideas aren't fully thought out yet, I'll still try to pick holes in the AI's logic, even if obvious holes don't exist - it seems easy for AI to be over-confident, and with a little push-back, there can be some self-critism with the AI's logic. Whether or not I work through the gaps together with the AI does really depend on the size of the gaps. If there are massive roadblocks that renders my idea impossible, then I will not work through the gaps with the AI. However, when there are gaps that don't pose such a challenge, I will still try to pick holes in the AI's logic, but if the reasoning seems solid, then I'll work on it independently, yes.

AI: That's a fascinating approach - actively challenging AI's reasoning even when it seems sound. 

Tell me more about that process of picking holes in AI's logic. What have you learned about AI's tendencies toward overconfidence, and how has that shaped the way you interact with it?

User: Well it comes in two forms. The first is where there actually are obvious holes in the AI's logic, then I'll attempt to correct the AI's logic by asking further questions about each point. But if there continues to be clear holes in the logic, I'm more likely to end the conversation. The second is where there aren't obvious holes in the AI's logic (to me) - in this case, I'll usually attempt to challenge the points that the AI made (with little or no reasoning), just to see if it is confident in the ideas or to explain the ideas in more detail, and I'll further ask for sources regardless.

Overconfidence is the main driver of my hesitation to rely too heavily on AI. It seems as though once one idea is presented, the AI will usually go about the conversation in such a way to back up this idea (even if it's not quite right). Hence, when there are holes in the logic, the AI can come across so confident and convincing, when actually I'd like it to be self-critical and cynical to its own logic. This has shaped the way that I interact with AI, as I will usually ask it explicitly to find holes in its own logic, as I'm always cynical about things the AI says from the get-go. This might even be sending the entire conversation into new chats, to get a 'third' opinion.

AI: That's really insightful - you've developed quite a sophisticated approach to working with AI. The idea of starting new chats to get a "third opinion" is particularly clever.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different from the ones you're comfortable delegating?

User: Yes, I like to handle regular analysis tasks without AI - I could simply send a list of objectives and the data to the AI and likely end up with the same result. However, touching back on my hesitation when using AI - I don't necessarily like to do this, as it usually requires a thorough check regardless. This differs from the messy tabular data tasks that I ask AI to do (mentioned earlier), as the consequences of being incorrect in the analysis are much more severe. Additionally, when it comes to running code, I tend to shy away from any assistance (although I'm aware that this likely hinders me). The reason I do this, however, is that although I use Python and SQL day-to-day, there is a sense of self-satisfaction when I can create my own code, rather than strictly relying on assistance.

AI: That distinction you're making is really compelling - between tasks where errors have severe consequences versus those where they don't, and also that sense of self-satisfaction from coding independently.

Can you share a specific example of a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Yeah, although it was a while ago now. I was struggling to find out how to integrate a custom pack of definitions and wrappers into a pipeline, in order to impute and transform independently within each fold of cross-validation. I couldn't find out how to do this at that particular time, and I seeked help with AI, who told me to change mutliple definitions within the custom pack in order to get to work. I remember spending hours on this, but it never got me anywhere, and I think the actual issue was that I had an outdated version of sklearn. This meant that I spent so much time trying to figure out how to do this, and the actual reason was something trivial.

AI: That sounds incredibly frustrating - spending hours on what turned out to be a version compatibility issue. 

When you reflect on that experience, what did it teach you about how you approach asking AI for help with technical problems? Has it changed how you frame your questions or the context you provide?

User: Well it certainly made me extra hesitant with seeking help surrounding code. I generally will not ask for assistance with large procedures like this anymore. Additionally, when the AI responds by telling me that I should change multiple definitions, I'll usually not continue the conversation, or instead ask if there is a simpler way forward - but it is quite rare that I'll ask for help with code nowadays. In terms of how I frame my questions differently now, I will usually ask for a high-level way to do something in Python (if need be), and figure it out without getting into editing the underlying code.

AI: That makes complete sense - you've shifted toward asking for high-level approaches rather than specific implementation details. 

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that your approach aligns with or differs from how others around you are using it?

User: I wouldn't say my colleagues or workplace culture has influenced the way that I use AI at all. I feel as though I'm quite confident in my approach, and I do feel more efficient compared to my colleagues in receiving a satisfiable output.

AI: That confidence in your approach is really striking - it sounds like you've developed your own methodology independent of workplace influences.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I'm always trying to skill up and improve, so I'm hoping that I manage to stay ahead of the curve, and this doesn't happen. It is great, in a way, as it allows me to stay on my toes and continue learning, rather than just being stagnant in my ability/knowledge.

AI: That's a really positive way to frame it - using AI as motivation to keep pushing yourself forward rather than becoming complacent.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think your current approach will change, or do you see it continuing along the same lines?

User: I do think it will continue along the same lines, since I don't think I'll ever be confident in an output from an AI. Even if some AI was said to give fully accurate information 100% of the time, it still deserves a check, and I wouldn't be able to use the output without checking it myself.

AI: That's such a consistent thread through everything you've shared - that fundamental approach of always verifying, regardless of how advanced AI becomes.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your sophisticated approach to challenging AI's logic and getting multiple "opinions" through fresh conversations.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: That's all I had. Thank you! :)

AI: Thank you so much for your time and for sharing your experiences so openly! Your insights about developing that skeptical but strategic approach to AI - from actively challenging its logic to using it as a sounding board while maintaining your independence - will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candid you were about both the benefits and the pitfalls you've encountered. Have a great rest of your day!
