# Dialog 00775

**Transcript ID:** work_0497

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Sounds good, let's begin

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: AI for me mostly acts as the librarian of the internet. I use it primarily to gather information about topics / resources, or to act as a tutor to teach me new concepts. Occasionally I'll get it to write code for me as well

AI: That's a really interesting way to think about it - AI as the librarian of the internet. I like that framing.

When you say you use it to gather information about topics and resources, can you walk me through what that typically looks like? What's a recent example of when you've done this?

User: I work in IT Support, so quite often I'll embark on a new journey and want to find the "go to" solution for something. As an example, I recently wanted to set up a cloud hosted server for a cheap price, just to set up some automation for myself. I used AI to give me an overview of what options are available, what is most commonly used, and what the public consensus is for each of these options.

AI: That's a really practical use case. So you're using AI to get that landscape view of your options before diving deeper.

Tell me more about that cloud server research - once AI gave you that overview of the options and public consensus, what did you do next? Did you continue working with AI throughout that process, or did you take that information and go handle the rest yourself?

User: I take care of most of the rest of the process myself - Once I'm given a direction by the AI and no longer need to navigate the 'noise' of the internet, I don't need much more guidance. In this case, I asked it some specific questions when I ran into roadblocks with setting up an EC2 instance, but I find AI struggles with navigating platform specific workflows like AWS EC2 (which, to be fair, is always changing and kind of poorly documented)

AI: That makes a lot of sense - using AI to cut through the noise and get oriented, then taking the reins yourself once you have direction.

You mentioned that AI struggles with those platform-specific workflows that are constantly changing. Are there other types of tasks where you've found AI less helpful, or where you deliberately choose to handle things yourself even though AI could potentially assist?

User: AI tends to be good at very high level, or very low level. Most easily explained with programming: If I provide it with a context for an application I want to build, it's very good at producing a high-level plan for the technology stack, classes, libraries, and general responsibilities. Similarly, if I ask it to implement a single function and give it the full context, it will probably do that well. 

it struggles in the middle, where I've got a half-built application; some of it works, some of it doesn't. Some of it needs to be re-factored, and progressing from this point is no longer linear. 
AI struggles with this kind of problem solving, and often causes more frustration than anything. I think this is a combination of lack of context, but also lack of ability for the AI to just say "i don't know" or ask questions to get more context.

AI: That's a really insightful observation about AI working well at the extremes but struggling in that messy middle ground. The point about AI not saying "I don't know" or asking clarifying questions is particularly interesting.

When you hit those situations where you have a half-built application that needs troubleshooting or refactoring, how do you typically approach that work? Do you find yourself missing having a collaborator who could ask those clarifying questions, or do you prefer working through those complex problems solo?

User: I mostly work through those problems solo. Again, I'll use AI only to answer very specific questions, or to do some research for me that might lead me to the answer im looking for.

AI: That pattern is really clear - you seem to have developed a pretty specific way of working with AI where you maintain control of the overall problem-solving process.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that others in your IT support role approach AI differently, or is there any organizational guidance around how to use these tools?

User: Honestly, most people I've spoken with have very little understanding of LLMs under-the-hood, and give AI models too much precedence because they sound so *convincing*. 
In my -limited- experience, I often find that colleagues try to get AI to do meaningful work for them ("write this knowledge base article..", "write a full powershell script that does...") which either produces slop, or again causes them frustration because it doesn't work first try.

AI: That's a really telling observation about how AI's convincing tone can be misleading. It sounds like you've developed a more calibrated sense of what AI is actually good at versus what it sounds like it can do.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: There have been times where using Claude Code was genuinely satisfying. There are rare moments where it feels like I am speaking with a colleague and an equal, and we're both trying to solve a problem together through discussion and trial and error. This natural flow of discussion and the terminal interface - as opposed to the web chat room - makes the AI feel more natural, and fits into my existing workflow more easily.

AI: That's fascinating - it sounds like Claude Code created a different kind of interaction experience for you. The fact that it felt like speaking with a colleague and equal is really striking.

What specifically about that terminal interface and natural flow of discussion made it feel more collaborative compared to your typical AI interactions? What was different about those moments that made the partnership feel more genuine?

User: Largely the difference in context. With Claude Code, I can say "investigate this function" and it will gather its own context, because it has access to the files. 

On the contrary, the web chat version requires that I provide all the context and ask *very* specific questions. 

There's also a more personal note. Running a program in my own terminal makes it feel more like it is 'mine'. Web browsers have become just a place for advertisements, so i don't feel as kindly towards them.

AI: That's really insightful - the ability for AI to gather its own context changes the whole dynamic of the interaction. And I appreciate that personal observation about the terminal feeling more "yours" compared to web browsers.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, or does it factor into how you decide what to delegate versus what to handle yourself?

User: I can't say I'm worried. I don't feel that AI - or specifically LLMs - will improve significantly from where they are now, and they're definitely not ready to take entire jobs like my own. 

In the case that they *do* improve to be expert level and completely independent engineers, for example, I would just see this as an opportunity to build my own software / business completely solo. 

I'm fine with either direction

AI: That's a really balanced perspective - not worried, but ready to adapt either way. It sounds like you see potential improvements in AI as opening up new opportunities rather than closing them off.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think you'll continue with this current approach of using it as your "internet librarian," or do you see that changing as the tools develop?

User: As far as producing meaningful work, I only see value in programming, personally. 
Otherwise, AI will remain a librarian for me or a source of brainstorming / tutoring.

AI: That's all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on AI working well at the extremes but struggling in that messy middle ground, and how the terminal interface in Claude Code created a more collaborative feeling.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?
