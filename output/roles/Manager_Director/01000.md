# Dialog 01000

**Transcript ID:** work_0830

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Glad to be here, this is a really interesting idea, AI interviewing! I could see this concept being useful in the future speaking of it, maybe in hiring processes or intakes, who knows. No questions at the moment and I'm ready to begin.

AI: That's a fascinating observation about the potential applications! You're already thinking about how AI could transform various interaction patterns.

Let's dive in then. Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Yeah sure. So I am a writing/communication tutor at a college and I use AI tools (mostly GPT due to students preference and familiarity) in consultation with the students I meet with. There really isn't a predictable pattern to my use of it because the content of the appointments and what the students are looking for changes so much from appointment to appointment. But off the top of my head there's a few use cases that stick out to me, especially in my use over the last semester. So one such use is when foreign language students come to me with various english language mechanics problems, they could be struggling with pronunciation of certain letter combinations, or having problems using certain word types or identifying them, so I find AI really useful to quickly ask for example exercises which I can do with them, or to quickly generate relevant content. Like there's this one student from South Korea and she always says the 's' sound too much like SHHH in words like design. So I would just ask GPT to give me examples words with a similar phonetic S just like design has, and seeing if they trip her up and we can practice with them. A second major use case is showing people how to use it, because a lot of people are confused about or scared to get in trouble using it or they don't want to admit they use it, so a lot of times I will just run certain requests for the students and show them how it can really speed up the creation of a paper for instance. Like for getting research sources, I find it speeds up the process hugely! Instead of browsing around online manually or through the school database and chewing up 3 hours you can just think about what points you want to prove first, and then get GPT to find you sources which help you prove those points, and you can also specify what source types to look for. So in this sense I open up people's minds to taking valuable shortcuts in their academics with it, without going overboard. A third major use case would be for exam study, like towards the midterms and exams people come to me super stressed about their tests and they don't know what to do with all the content jamming and the limited time frames for studying, so I show them how you can GPT to create practice tests and questions easily for them by uploading the course notes and telling to make them for you. This is another major helpful shortcut I've encouraged students to take. Those are 3 major use cases I would say, and there's something else I should mention. I'm not actually 'allowed' to be using it with the students, but the desire for the tools is huge, and the questions and amount of data to pore through in the course content is ridiculous so it becomes a game of leveling the playing field for the students in my view. The college is so strict on AI, they say were not even allowed to use 'Grammarly' but you hear talk of all the students using it anyway, they tell me directly they use it, so it's ridiculous to expect otherwise or to pretend these tools aren't there. In this sense, I feel like the post-secondary community is being a bit stubborn, or it's just too much to regulate, so it's interesting to observe and be in the middle of it.

AI: That's really rich detail about your experience - thank you for being so open about the complexities you're navigating. It sounds like you're in a fascinating position where you see both the institutional resistance and the student demand firsthand.

I'm curious about your preferences when working with AI. You mentioned these different use cases, but are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: Yes indeed! Feeling lucky to observe this firsthand, but these complexities are probably pretty far reaching across industries now that I think about it. And to answer the question I do really try to ensure that people are still expressing their own unique ideas at the core of whatever they're working on. Like let's say there's an assignment on the renaissance in a history class or something and the students have to write a paper. While it would be really easy to just feed the instructions to the AI and say give me 7 good ideas for a paper that meets the instructions, I don't think that's the approach we should be taking, like it should be helping us express what we are genuinely inspired to express. So when it comes to technical examples, or studying content, or monotonous 'boring' tasks like meticulous research, I feel more at ease showing shortcuts to the students. But when they are struggling with core aspects of the assignment, or struggling to understand what the assignment is actually asking of them, I ensure to ask them critical questions firsthand and get them using their critical thinking for the core/central aspects of the assignment. Like for the renaissance paper example, sometimes people would be too hard on themselves or put too much pressure to write something which they think is expected, but I ask simple prying questions, like 'what stands out to you about the renaissance?', or 'do you know what the renaissance is?' to start and get them thinking about what they want to express simply. Then we can grow out from there and use all these tools for the complexities. If they take such shortcuts in their own workspace that's their choice, but I make sure not to encourage that in my tutoring space. From personal experience, I've taken such shortcuts when struggling with due dates or feeling burnout so no judgment from me, but I won't actively encourage that level of use as someone who represents the college. And I think it's still vitally important that we flex our critical thinking muscles, and in doing so, there's actually a whole lot more value we can extract out of these tools, because if you're inspired about the core ideas then you can see much more clearly all these extensions of your ideas which are possible through the AI tools, and feel better about your work.

AI: That's a thoughtful distinction you're making between supporting the technical work versus preserving the intellectual core. It sounds like you've developed a philosophy around maintaining that human spark while leveraging AI's capabilities.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: Yes, exactly. So when it comes to my interaction pattern I'm much more likely to collaborate with it, since the appointments have a relatively small amount of time (usually only an hour), there's a flow I have to maintain in order to get to as many of the tutee's questions as possible and more thoroughly address their concerns. And it's always something which is complementary to the ongoing discussion, like I just draw their attention to the tool or tell them what I'm doing, and then show them the results and we work on it together if it's an exercise or discuss the results if it's a task for an assignment. So in that way it's very much collaborative, as both me and the student are looking at it as we go. And the tutorial aspect of it as well is very collaborative, because in the cases where students are having confusions or confidence issues in using the AI tools, I just show them some tricks with it like a walkthrough. So both me and the student in all use cases I can think of are very much active and watching the tool work and interacting with it as we go, not really delegating stuff to it.

AI: That collaborative approach really makes sense given the tutoring context - you're essentially teaching both the subject matter and the tool use simultaneously.

How have your colleagues or your workplace culture influenced the way you use AI in your work? You mentioned the institutional restrictions, but I'm curious about the more informal dynamics too.

User: So in terms of my colleagues at the same level as me who are also fellow students and tutors, we all are well aware of how prevalent AI tools are and we all make active use of them frequently as far as I can tell. But the college itself and the managerial staff are opposed to it in terms of the actual policies, as the policies for tutoring state that we are not allowed to use any 'AI' tools, even going so far as discouraging Grammarly because it uses 'AI'. I tried searching for the exact policy statement, but I can't find it. That being said, I don't observe much practical opposition to it, like active opposition from the managerial staff, but they also don't observe appointments firsthand, they only hear them in the background. But it seems as if most college staff are resigned to the fact that AI is going to be playing a large part in education moving forward, whether we accept it or not. I've especially observed this in my study field, software, where the professors are much more keen to these technologies, but across most fields it's getting harder to discern whether AI has been used. But these policies have definitely informed how I approach sharing knowledge about AI use, because I make sure to do it quietly and carefully, and if students are getting too confused or excited about it, I back off and divert back to 'traditional' so as not to make a scene. Like sometimes the shortcuts blow student's minds a bit, and since we're not allowed to share info about or encourage AI use officially it can put me in a bad position. So it's always as if I'm sharing secrets which is a bit annoying. This is just in terms of the in-person appointments, which are in a pretty quiet and open environment anyway, so it's usually fine. But in terms of the online appointments we share with students through video call I can be much more liberal there in the information I share about AI use. And like I mentioned earlier, I still actively try to encourage academic integrity in the sense that I encourage students to start from their own creative ideas and branch out from there. I am a bit confused what you mean by 'informal dynamics' though, did I cover it okay here?

AI: Yes, you covered it well - that tension between the formal policies and the practical reality sounds like it creates this interesting underground dynamic where you're sharing "secrets" as you put it. The contrast between in-person and online appointments is particularly telling.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: So I met with this one international nursing student who was facing some tight schedules before the exam and made an appointment with me for study tips. I am also allowed to give general guidance on preparing for tests and such things. And due to the amount of content she was facing and the time to the exam and her stress levels I recommended using AI to create custom tests based on the slides. She found this useful, but what was really awesome is when she asked about how we could handle the diagrams (for example the diagram of an animal cell). Like she was having confusions over how she could reliably remember them or coming up with a way of easily testing herself on the many diagrams because they didn't say which one would be on the exam and there was quite a few. So I showed her that you could also use GPT for image manipulation, like saying 'Remove the labels from this diagram, just paint over the labels with white but keep the pointer sticks. Do not change the color of the cell.'. That way she could have blank diagrams without labels which could be printed and which she can test her knowledge on. She was not aware of the image manipulation capabilities and was pretty impressed! And you could say, well isn't it just as easy to paint white covers over the labels in a paint editor yourself? Perhaps, but when you have 20 diagrams and you can simply upload them and tell the model to do the same for all the diagrams, then it becomes a super time saver! I would say that showing these image capabilities to someone who didn't know about them and was impressed, and also the time this potentially saved her made this a satisfying experience.

AI: That's a wonderful example - it really shows how AI can solve practical problems that might seem small but add up to significant time savings. The image manipulation for study materials is such a creative application.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Through the lens of my current day job, I don't consider it that much because I only see myself doing this and working at the college while I'm actively a student there. And that would only be a few years at the max, and I don't practically see AI replacing face-to-face tutors any time soon. And I don't think students will want to go without the guidance of fellow students who are in the same boat as them, I mean that I don't think peer tutoring would be replaced any time soon so I don't really 'actively consider' it. But I will say that I do consider the implications in my field of study, software, as AI models are becoming increasingly capable of writing software or acting as autonomous agents. So in this sense, I want to develop strong skills of guiding AIs towards beneficial results aligned with project goals, and I actively practice this through my work. But in terms of replacing work, from a high level I actually think it's a good thing, like a lot of monotonous or repetitive stuff could be further automated or made more efficient just the same as the computing revolution. And I want to become much stronger in general design principles and integrity of solutions so that I can effectively tell whether AI is doing a good job. The potentials are scary/exciting sometimes, but basically though, I think good ole critical thinking and our integrity of purpose will be valuable tools for navigating possible AI phase-ins.

AI: That's a thoughtful perspective - focusing on developing skills to guide AI effectively rather than competing with it, and maintaining that critical evaluation ability. Your experience in tutoring seems like excellent practice for those AI collaboration skills.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: Well I see it maintaining as it's been for the most part. I don't really see it evolving a great deal. But I will say there is the possibility of new use cases emerging as more tutoring appointments come my way. Most of the use cases previously mentioned have just been generated by the demand of the students and the questions they ask. Just like a few years back if someone asked me a question I didn't know and I wanted to give them an answer I would google it. But now with AI it's like we have an interactive google that better understands what you're asking and with which you can modify your requests, and do more complex requests. So in this sense, I do see it evolving if new questions come my way in the number of potential use cases, but I don't really see my frequency of use increasing, it will most likely stay the same. These uses I have mentioned don't happen every appointment, but sometimes AI can come in handy. And due to the systemic resistance in education towards the tools, at least for the time being, I won't be actively looking to evolve my use of it, instead just letting it unfold naturally as it has so far. It's moreso just the pressure of requests from students, the availability of these tools, and the student's openness to using them that sometimes unveil cool new use cases. But I won't be actively pushing to use it directly with the students more, I think that would be more dependent on changes in policy and acceptance with mine and other educational institutions, and that might be far off still.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on maintaining that balance between leveraging AI's capabilities while preserving the human creative core - and how you're navigating those institutional tensions while responding to genuine student need.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I think that's it from me, it's been a very interesting AI interview and I enjoyed sharing my experiences!

AI: Thank you again for your time and for sharing your experiences so openly. Your insights will be incredibly helpful for our research on human-AI interaction in professional contexts. The way you've navigated the complexities of institutional policies while genuinely helping students is really fascinating, and your thoughtful approach to maintaining academic integrity while leveraging AI's capabilities offers valuable perspective.

It's been a pleasure speaking with you - and you're right, this AI interview format is quite interesting! Take care.
