# Dialog 00891

**Transcript ID:** work_0680

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: sounds great, let's go.

AI: Perfect! Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: As a Complex Care Case Manager, I use AI multiple times throughout my workday. I'm responsible for in excess of 30 support workers, and so AI helps me to automate a lot of my HR admin workload. For example, I use AI to help me write my appraisal and clinical supervision reports. I also use AI a lot for writing emails, as this saves me a lot of time throughout the working day.

AI: That sounds like AI is handling quite a bit of your administrative workload. When you're using AI for something like writing appraisal reports or emails, how do you typically work with it? Do you give it specific information and let it draft everything, or do you work back and forth with it more collaboratively?

User: I initially give the AI an overview of what I want to achieve. So, for example: "write an email to my care workers which informs them that the cut-off for this month's payroll is [REDACTED]. Advise them that if their hours aren't logged on the XYZ platform by 23:59, they won't be processed in time, and will be paid in [REDACTED] instead. Advise them to contact Jane Doe in Payroll for any pay related queries". Then, I'll wait for the response and check it over. If I want amendments, such as to the tone or to remove certain aspects of the response, I'll collaborate with the AI until I get my desired output.

AI: That's a really clear process. I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: Working in healthcare, I'm very conscious of service user confidentiality. therefore, I don't use AI to write any care plans - this feels too invasive.

AI: That makes complete sense given the sensitive nature of that information. Beyond the confidentiality concerns with care plans, are there other tasks where you choose to handle things yourself even when AI might be able to help? What drives those decisions for you?

User: When looking at my staff's training data, I prefer to do this myself rather than using AI. This is because I don't have 100% faith that the AI will provide the right insights and conclusions based on the training data. This is imperative, as non-compliance with training in the healthcare industry is non-negotiable - this could lead to regulatory issues, and could result in my company having its CQC registration revoked. Therefore, I prefer to analyse training data myself.

AI: That's really insightful - it sounds like you've developed clear boundaries around where AI fits based on both confidentiality and the level of risk involved. 

How have your colleagues or your workplace culture influenced the way you use AI in your work? Are others in your organization using it similarly, or have you noticed different approaches?

User: It's a bit of a mixed bag. What i've noticed is that the younger members of the team are more willing and engaged with adopting AI usage within their workdays. In comparison, the older members of the team are more reluctant and have reservations and concerns about adopting AI technology - the big concern seems to be that they're worried "AI will take their jobs". At a company level, our directors are very keen for us to adopt AI in our working days, to the point they're developing their own LLM.

AI: That's fascinating that leadership is investing in developing their own LLM while you're seeing such different adoption patterns across age groups. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I felt really satisfied about my AI usage when I was tasked with writing a bid for a palliative care package. The caveat was that this package needed to be implementable quickly, due to the health status of the service user. Bid writing usually takes several hours, but using AI meant I could submit the bid much quicker than usual, and my company went on to be awarded the package. I was very careful about service user confidentiality - i.e. I didn't use the service user's name, just initials.

AI: That's a powerful example of AI helping you respond quickly in a time-sensitive situation while still maintaining your ethical boundaries around confidentiality. 

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: AI can never replace the human interaction required by my role. Part of my role entails visiting service users in person, to conduct both care plan reviews and spot checks of staff performance and compliance. Whilst AI may eventually take over a lot of my admin tasks, e.g. staff appraisals, I'm not at all concerned about my role as a whole, as it simply cannot be adopted by AI.

AI: That's a really grounded perspective on how AI complements rather than replaces the core human elements of your work. 

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself using it differently in the future?

User: Honestly, at this time I can't see my AI usage changing much over the next year or so. More long term, I'd really like to see an AI-powered care planning system - care plan writing is very time consuming, so a dedicated platform which can handle the admin side of this, whilst guaranteeing service user privacy and confidentiality, would be a game changer.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how you've developed clear boundaries based on confidentiality requirements and risk levels - that distinction between administrative tasks and direct care responsibilities really stood out.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I have nothing further to add at this time - thank you.

AI: Thank you so much for your time and for sharing your experiences so openly. Your insights about navigating AI adoption in healthcare - especially how you balance efficiency gains with confidentiality requirements and risk management - will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!
