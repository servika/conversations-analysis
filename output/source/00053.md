# Dialog 00053

**Transcript ID:** science_0038

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: sure

AI: Great! Let's dive in then.

To start, could you walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: I was recently looking at medical/research applications of endosymbiote theory. Initially I was interested in finding the current state of the field, and running a literature review. The final output was proposals and ideas for future research.

AI: That sounds fascinating - endosymbiote theory has such interesting implications for medicine. 

Tell me more about how you actually went about conducting that literature review and developing those research proposals. What were the specific steps you took?

User: I started with regular sources like google scholar and other methods of searching for many papers at once, I have a few different tools. I also tried using AI to help with this.

AI: Interesting that you brought AI into your literature review process. 

Where else in that project - from the literature review through to developing those research proposals - did you experiment with using AI tools?

User: I tried like I said but there are many errors and hallucinations, links to fake papers. Real authors mentioned but no actual papers by them on the specific topic existed. I also used AI to help with editing, changing my tone, looking for weaknesses in my argument. But again it not very good and cant be trusted.

AI: It sounds like you ran into some real challenges with reliability, especially with those fake papers and non-existent citations. 

For the editing and argument analysis part that you mentioned - tell me about how you decided whether to use AI versus your traditional approach for that work.

User: I try to use AI to simplify complex tasks, or tasks that take a long time and are pretty annoying and repetitive. So for example I'll ask for it to find all papers referenced in a PDF by an author, or all mentions of something. I also try to use it help me fine tune or broaden my searches. Sometimes my keywords are too restrictive and I end up missing a great source that my colleague was able to find.

AI: That makes a lot of sense - using it for those time-consuming, repetitive tasks. It sounds like you've found some practical applications despite the reliability issues.

Thinking about the parts of your research where you haven't used AI - like maybe certain aspects of developing those research proposals or other parts of your analysis - what's kept you from trying it there?

User: It simply can't be trusted. Too many mistakes happen. The knowledge base I guess is not up to date, dangerous ideas are proposed and often there is no consideration of real world like constraints, budgets, existing infrastructure at my lab,

AI: Those are really significant concerns - the combination of outdated knowledge, unrealistic suggestions, and potentially dangerous ideas would definitely make me hesitant too.

When you have used AI for those tasks you mentioned - like finding references in PDFs or broadening your search terms - how do you verify or validate what it produces?

User: I have to literally verify every single line myself. I try to get it to output it in an easier to understand format like so i can click a link or run a title in a database and make sure the paper exists before trying to find the journal through [REDACTED]

AI: So you're essentially doing double the work - having AI generate results and then manually checking everything line by line. That's quite a verification burden.

We're about halfway through our conversation now. Let me ask you this: If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't - or do it in a way that actually worked reliably - what would that be and why?

User: I use it all the time, I wish it would be more accurate. If I could wave a wand... I guess the biggest thing for me personally would be having some way of verifying that its actually doing what it says it doing, or some kind of confirmation tool. Sometimes ill send a paper and reference it in my prompt, and the ai does not read or open the file, it instead finds the wrong paper online and makes an  incorrect conclusion about it. The first few times I didn't understand, I had to ask it to show me the steps and what paper it was using

AI: That's a really insightful example - the AI finding a different paper online instead of using the one you actually provided, and you not realizing it initially. That kind of silent substitution could really undermine your work without you knowing.

Those are all my questions - your perspectives on the verification challenges and the need for transparency in AI's actual processes were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: I don't think the claims about context windows, and thinking are accurate. I sometimes send prompts that rely on only a few pages of  paper/file and it says i hit the limit for the chat.

AI: That's a really important point about the disconnect between what's claimed about context capabilities versus what you're actually experiencing in practice. Those technical limitations clearly have real impacts on how useful AI can be for research tasks.

Thank you again for sharing your experiences so openly. Your insights about the verification burden you face - having to check every single line - and that example of AI silently using the wrong paper really help us understand the nuances of how AI fits into real scientific work. The gap between promised capabilities and actual performance seems to be a major theme in your experience.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Your perspective as someone actively trying to integrate AI into research workflows has been incredibly valuable.

User: how would i follow up

AI: That's a great question, and I realize I should clarify - as an AI conducting this interview, I don't actually have a direct way for you to follow up with me personally or with Anthropic's research team through me.

If you did want to share additional thoughts about AI in research or provide feedback about this conversation, you could use the general feedback mechanisms available through Anthropic's website or support channels. But I should be transparent that I can't facilitate a direct follow-up connection.

Thank you again for taking the time to share such detailed and honest insights about your research experience. Your feedback about verification challenges, context limitations, and the gap between AI capabilities and claims has been really valuable.
