# Dialog 01083

**Transcript ID:** work_0963

---

Assistant: Hi there, I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. Does that sound good? Do you have any questions before we begin?

User: I have no questions, thanks. You're welcome to begin.

AI: Great, thank you. Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I am an adjunct educator and I primarily focus on standardized test prep (strategy and specific topics) with both classes and individual students. I don't use AI often, typically only when I'm stuck making practice for my students from scratch or I've run out of pre-made practice. Usually, I'll use the material I already have and ask AI for similar scenarios/words/ideas to save myself the time and effort of brainstorming. I do the same on occasion (1-4 times a year) when I need to write up report cards for a class of students and need a, more or less, similar framework for each report--I ask AI to come up with a framework report where I can fill in blanks with student-specific details or I might ask it to reword certain phrases I feel I've overused in previous reports.

AI: That's really helpful context. It sounds like you're quite selective about when you bring AI into your work - using it more as a creative jumpstart when you hit certain roadblocks.

When you say you use AI for "similar scenarios, words, or ideas" for practice materials, can you walk me through what that process typically looks like? How do you go from being stuck to getting what you need from AI?

User: Sure. A common example for me usually came from using College Board's online SAT question bank. If a student had already seen all the questions there but wanted very similar or exactly the same format for their practice, I might feed AI the question and ask it to change details. In the real of writing questions, I often needed new or more difficult vocabulary replacements to challenge students. In math, I might have the AI replace numbers in a word problem (changing unit, etc.) or use the same numbers, but with different context to make the problem appear new (changing a question about a projectile launched in an upward parabola to the negative alternative, rewording it to be about a person diving into a pool and resurfacing).

AI: That's a fascinating approach - you're essentially using AI as a content variation tool to keep the educational structure intact while refreshing the surface details. 

When you're working with AI this way, are you typically giving it the original question and then going back and forth to refine what it gives you, or do you usually get what you need in that first response? What does that interaction look like?

User: If I can avoid it, I don't give the AI much context. This is easier for the reading/writing questions, since I just happen to find these easier to brainstorm on my own and often just have one or two pieces left I can't immediately come up with, like adding one more synonym for an answer choice. However, I do tend to get quite specific on rerolling the answers because I don't give the AI context to begin with. For example, I might ask for a "more difficult" synonym for a word like "conceal." Sometimes, AI models would just give common synonyms ("cover," "obscure," etc.) so I might need to request a specific letter length, ask for a specific education level (e.g. college-level) or even qualify that the word could be uncommon or archaic in order to get an answer that I was happy with. Because I knew what I was looking for, I felt it was easier for me to do this and rule out words that didn't fit the context than to try and feed the model the question and go through the same process anyway. I'm not confident that the question's context would make finding the answer I wanted any simpler.

AI: That's really interesting - you've developed a strategy of keeping your requests minimal and then using very specific follow-up criteria rather than front-loading context. It sounds like you've found that approach more efficient.

I'm curious about your preferences when working with AI. You mentioned you don't use it often and seem quite intentional about when you do. Are there certain tasks in your work that you prefer to handle yourself, even though AI could potentially help with them?

User: Absolutely. I rely on it very minimally, almost out of principle. These days, students seem more and more reliant on AI to do classwork/homework, and I try to be an exemplar in not doing so. Often, it's obvious or easy to weed out when students have used AI to aid in their work without putting in any of their own effort. I do a lot of report writing, such as class or study session summaries that are sent our to students and their families. If anyone that reads them is attentive enough, I'm sure they'd be able to tell if I used AI to help too much. Despite that I have been teaching the same lessons and skills with students having the same struggles and pitfalls, I do often write my reports myself when I know it would likely be much less time consuming or less effortful to keep a catalogue of summaries ready to go or to use and AI tool to fill in some blanks for me.

AI: That's a really thoughtful approach - modeling the behavior you want to see from your students. It sounds like there's an authenticity element that's important to you, both in terms of your professional integrity and how your work comes across to families.

When you do choose to use AI - like for those practice materials or the occasional report framework - what drives that decision? What makes those particular moments feel different from the report writing you prefer to do yourself?

User: I often only turn to AI after failing to quickly do the task on my own. If I notice I have been struggling to come up with an idea and have, in a sense, wasted an amount of time in doing so, I'll turn to AI. This is also true when I knew I didn't have the capacity to be very creative (often for creating and editing vocabulary-based work).

AI: That makes a lot of sense - AI becomes your backup when your own creative process hits a wall or when you're just not feeling mentally sharp enough for that kind of work.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I have found that it's less helpful to me when working in an English-speaking environment, as it just doesn't hold up to the complexity I required for brainstorming with particularly creative or college-level vocabulary. There have been times where I had taken an easy multiple choice question (a sentence with a blank was provided, each answer choice was a word, only one of which would accurately complete the sentence in a logical way) and used AI to find difficult synonyms for the answer choices already provided. I found myself rewording my requests and getting nowhere after ten minutes (too long to get a couple of synonyms from a bot, in my opinion) and started clicking through online dictionaries instead in order to find suitable synonyms. Obviously, it was a bit annoying that I knew it was a task AI should be able to complete without much issue since it wasn't very complex.

AI: That frustration is really understandable - especially when you know the task should be straightforward but the tool keeps missing what you need. It sounds like in that case, traditional resources ended up being more reliable.

On the flip side, have there been moments when using AI felt particularly satisfying or worked well for you?

User: Yes. As I mentioned before, in English-speaking environments, AI hasn't been up to par for me. However, I used to also teach ESL/TEFL for elementary-middle school students. I also had to write reports for each student every semester, which could be up to 100 to write at once. Naturally, it's a bit difficult to hit a unique word limit on students' abilities when they're either 8 years old or just learning the alphabet or both. AI was extremely helpful in taking certain statements and rewording them in a way that wasn't too complex (non-native speaking staff/parents could read easily) without being too repetitive or curt. This was especially helpful in my school's specific environment, where parents often shared information between each other, and they would know if you had copied and pasted certain statements from one student to another.

AI: That sounds like such a perfect use case - AI helping you navigate that delicate balance of keeping language accessible while avoiding repetition across so many reports. And with parents comparing notes, that authenticity piece was really crucial.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think your current selective approach will stay the same, or might it change?

User: I may be looking into pivoting career paths (more toward admin/assistant work) rather than teaching, which would likely change things a little. I imagine, in that case, I might rely on AI a bit more for brainstorming--likely with a higher use for starting business emails and continued content creation. I don't envision the change in use frequency being too great, though, as I still find myself a little annoyed when I notice text in professional spaces that was obviously written by AI. I also just have a prideful piece (a held value, as you stated earlier) about myself that would rather be able to definitively state any ideas or work submitted is my own. I expect that AI usage would be relegated to tasks I find extremely boring to draft or when I fail to brainstorm on my own after giving myself some time to try.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on modeling authentic work for your students and how your approach shifts based on the complexity and context of what you're trying to accomplish.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, thank you.

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about maintaining authenticity while selectively using AI as a creative backup, and how context really matters for when these tools are most helpful, will be incredibly valuable for our research on human-AI interaction in professional contexts.

Have a great rest of your day!
