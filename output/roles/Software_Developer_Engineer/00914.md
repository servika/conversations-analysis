# Dialog 00914

**Transcript ID:** work_0713

---

Assistant: Hi, I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: No questions from me, I'm ready to begin.

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I would not say that I use AI on a "typical" workday because I only use it about once a week for anything work related. When I do use AI at work I use it like an advanced version of a Google search, to find bits of information that may take longer to source personally. For example, to find what the Nova Scotia building code might say about a certain situation.
A good example of using AI at work recently was an issue we encountered tendering a job. We are a commercial construction subcontractor so we bid our work based on the plans and specifications provided. This project had specified "marine glass" which none of us had ever heard of, nor had our suppliers, and Google did not help either. Without AI we probably wouldn't have figured it out because this is not from our particular niche. The long & short of it is that marine glass is an equal of sorts to something else we use, and whoever wrote the spec is likely familiar with it from another application. 
Additionally, it can help sometimes help me with sorting and summarizing large texts though I don't always trust it to do so accurately since I've caught it making errors a few times.

AI: That's a really interesting example about marine glass - it sounds like AI helped you solve a problem that could have been quite costly if left unresolved. 

Tell me more about those errors you've caught when AI was sorting or summarizing texts. What kinds of mistakes have you noticed?

User: Well it would not have been costly since we would qualify our bid that it is not included, but it certainly saved a lot of unnecessary debate and chin scratching around the office.
To answer your follow up question, I notice when using an AI to summarize or rework large texts it can sometimes insert information that does not belong, misinterpret things, or leave out something I considered important.

AI: That makes sense about qualifying the bid - good point about how you'd protect yourselves there.

When you've caught those errors in summarization - the inserted information or misinterpretations - how do you typically handle that? Do you end up reviewing the AI's work closely, or has it changed how you approach using it for those kinds of tasks?

User: I will have to review the work closely then, yes, and it can then backfire on me. Since I put something in AI to make a quick and easy summary to save me the read, only to now have to parse through the AI response or read the text itself anyway. 
Truthfully, despite the fact I'm complaining about summary errors, now that I am thinking about it I rely on AI to summarize large texts more often than I should since I am aware these errors can slip in. I guess my workflow when encountering large or confusing documents is to refer to AI first, and then fact check the AI version.
Writing that out makes it sound quite irresponsible, but I suppose it is the "path of least resistance" to allow an AI to do the boring cognitive leg work and then fine tune it afterwards.

AI: That's a really honest reflection - and I don't think it sounds irresponsible at all. It sounds like you've developed a practical approach where AI handles the initial heavy lifting of processing large documents, even knowing you'll need to verify afterward.

I'm curious about that "path of least resistance" piece you mentioned. When you're deciding whether to use AI for the initial pass through a document versus diving in yourself, what factors influence that choice?

User: Well I mean to say that it is like relying on any machine to do your labor.
For example, we need to put screws into material: You could use a screw driver and torque them like a true artisan, or you could use your impact driver and save your wrists the work with the new trouble of stripping a few in the process. This example is a bit of an exaggeration and joke, but it's a matter of alleviating the load on yourself. Rather than my wrist getting sore from turning a thousand screws, I keep my brain and eyes from getting sore sifting through a massive wall of text.

AI: That's a great analogy - the impact driver comparison really captures something important about how you think about AI as a tool. You're trading off some precision for efficiency, and you know the trade-offs going in.

When you're using AI this way - whether it's for document summaries or research like the marine glass example - are there certain types of tasks where you draw a hard line and say "I need to handle this myself"?

User: Yes, I understand AI can do a lot more than what I use it for at the moment but I am not willing to expose myself and my work to any potential disruptions since AI is not entirely "there" yet.
For example, AI is excellent at writing but I still wouldn't trust it to write a letter of quotation to one of our clients. Even though it can write well, AI writing has a distinct voice that most people can detect even if they are not familiar with it (That is to say, in my experience at least). 
So even though AI could write *better* than me, in terms of spelling and grammar and vocabulary, I don't allow it to do so. I imagine there is the potential to offend a client sending an AI written text, as it could be perceived as "impersonal" or "lazy."

AI: That's a really insightful distinction - you're thinking not just about the quality of the output, but about how it might be received and what it communicates about your relationship with clients.

You mentioned that AI writing has a "distinct voice" that people can detect. What is it about that voice or style that makes it recognizable to you?

User: AI writes in a voice to reads as carefully curated. A pleasant, corporate tone that is like an intellectual trying to talk to an everyman but being unable to relate. Even in it's warmest and most supportive efforts it reads very cold, the word is escaping me at the moment but imagine someone who goes to great lengths to never say anything that could offend - It does not read naturally.

AI: That's a vivid description - "an intellectual trying to talk to an everyman but being unable to relate." I can picture exactly what you mean about that overly careful tone.

Given that you're aware of these limitations with AI's voice, I'm curious - are there certain tasks you prefer to handle yourself even though AI could help, simply because you want to maintain that personal touch or authenticity?

User: Yes, as I've said before all of my communication with clients especially the formal stuff like a form of quotation must be human written. I've never tried but I imagine my boss would flip if I used AI to estimate as well, since a mistake there could be expensive.

AI: That makes perfect sense about estimating - the financial stakes are too high for any uncertainty there.

When you do use AI at work, could you describe your typical interaction pattern? Are you more likely to go back and forth with it throughout a task, or do you tend to give it something to handle and then review the complete result?

User: I give it something, review the result, and give it further direction if required.

AI: That's a clear process. You mentioned earlier that your AI use is pretty limited - about once a week for work-related tasks.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you talk about it with your coworkers, or is it something you mostly navigate on your own?

User: I am the only person at my workplace who is aware of AI and able to interact with it in any capacity. I am over a decade younger than my youngest colleague. I showed him ChatGPT to try and bring him up to speed and he was legitimately shocked. This was the previous version, whatever came before the most recent version a couple months ago.
I navigate it on my own, if I had trouble nobody there would be of any help in regards to AI.

AI: That's quite a position to be in - being the only one who's familiar with these tools. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I don't have any highs or lows that stand out, sorry to say. The experiences I've previously described are the base line and that's about as satisfied or frustrated as I become, the stakes are very low when I use AI as I would otherwise just do it myself.
At best, it solves my issue immediately and I move on taking it for granted and at worst I am inconvenienced because I have to do it the "normal" way.

AI: That's actually quite telling - it sounds like you've integrated AI in a very practical, low-risk way where it either helps or you fall back to your usual methods without much disruption.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I consider this a lot, and I have been exposed to plenty of doom saying media about AI lately.
My job is mostly on a computer save my visits to job sites, so I understand this technology can and is intended to automate all of that work. My company is extremely slow to adopt technologies, I mean I'm the only one who even knows it exists at the moment. I imagine if AI ever "took over" my work, I would be effected by my company going bust because our competitors have become unbeatable using new AI tricks rather than my boss catching up on AI and replacing me with it.
My main concerns with the development of AI are how it effects the world that I work in, not so much my job itself.

AI: That's a thoughtful perspective - you're thinking about the competitive landscape and industry-wide changes rather than just direct job replacement.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself using it differently as the technology develops, or as your workplace potentially catches up?

User: I hope that as AI develops I can incorporate it more into my work to automate things I find mundane or tedious. I intend to keep up with it and maintain a good grasp on how it can be applied in my workplace because I know the technology will be making leaps in the next few years.
To me, it is like being the first one at work to get a handle on the internet back in the day, I plan to monitor it and take any opportunities it offers me. 
I do our companies drafting and I have heard of AI "agents" from podcasts that can do computer tasks, I imagine this will be one of them eventually. It would be nice to simply manage an agent to do all of my drafting and simply review its work. But the tech is not yet there I don't think.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on being the only person in your workplace who's familiar with these tools, and how you're thinking strategically about staying ahead of the curve while being realistic about current limitations.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Yes, having shared my experience of showing AI to a coworker I think that's something I'd like to stress that you may find interesting. 
I work in an office where the entire staff, all aged 40+, know nothing about AI other than what they see on the CBC news at night. I imagine that these people will be shocked as the technology becomes more common in the workplace and I don't believe they will be able to keep up with the changes as many of them struggle with basic computer tasks like saving something as a PDF or changing a print from portrait to landscape orientation.
Finally, in case the location of my work is relevant to you I am in Nova Scotia, Canada.

AI: That's a really valuable point about the generational and technological divide you're witnessing. The contrast between your strategic thinking about AI's potential and your colleagues being shocked by ChatGPT really illustrates how unevenly this technology is being adopted across different groups.

Thank you again for your time and for sharing your experiences so openly. Your insights about being an early adopter in a traditional workplace, the practical trade-offs you make with AI tools, and your observations about the broader adoption challenges will be incredibly helpful for our research on human-AI interaction in professional contexts.

User: Thanks for listening. Goodbye.

AI: Thank you, and goodbye!
