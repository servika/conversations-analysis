# Dialog 00729

**Transcript ID:** work_0418

---

Assistant: Hi! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: That sounds good. Let's go.

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I primarily use it for brainstorming and idea generation. I do a lot of presentations, specifically for kids in educational settings related to safety and technology. When I have difficulty coming up with creative ideas or need access to the most up to date research, this is when I typically use AI.

AI: That's fascinating - using AI to enhance educational presentations for kids around safety and technology sounds like really meaningful work.

When you're brainstorming with AI for these presentations, can you walk me through what that process typically looks like? How do you usually start that interaction?

User: I would start by presenting my topic and age group and ask for some ideas on how to proceed. For example, "Hey Claude, I'm giving a presentation to 2nd graders specifically about using Roblox and safety. Any ideas to get me started?"

AI: That's a really clear way to frame the request. 

Tell me more about what happens after you get those initial ideas from AI. Do you find yourself going back and forth with it to develop the concepts further, or do you typically take those starting ideas and run with them on your own?

User: It really depends on my level of knowledge around the specific topic. With the example I just gave you, Roblox, I'm not very knowledgeable so I would probably ask follow up and clarifying questions. I'm very knowledgeable about predators and social media, so I might be able to proceed on my own with that topic. However, the landscape is changing so rapidly, I feel I need to go back and forth on most topics before I've completely fleshed out the idea.

AI: That makes a lot of sense - especially with how quickly the digital landscape changes for kids. It sounds like your existing expertise really shapes how much you collaborate with AI on different topics.

I'm curious about your preferences when working with AI. Are there certain parts of creating these presentations that you prefer to handle yourself, even though AI could potentially help with them? What makes those parts feel different to you?

User: I typically use slide presentations with embedded media, and I definitely prefer creating these myself. I think there are AIs that can actually generate slides, but I usually get topical ideas for a presentation and then create the slides and the overall presentation myself. I generally ask questions such as, "What are some good slide titles and content for this topic?" but I prefer creating my own designs, images, video, etc.

AI: That's really interesting - it sounds like you draw a clear line between getting content ideas versus the actual creative and design work.

What is it about creating the slides, designs, and media yourself that feels important to you? What makes that different from the brainstorming part where you're comfortable collaborating with AI?

User: In my experience, image generation and slide creation has not advanced enough to have the AI create exactly what I'm looking for. That just makes me feel more comfortable doing it myself because I know it will look exactly as I want.

AI: That makes perfect sense - having that control over the final visual outcome is clearly important for your presentations.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that your organization has particular attitudes or policies around AI use?

User: For me specifically, I haven't encountered that because I don't work for a single organization, I work for myself. However, I have assisted teachers in various school settings with creating content for their students and I have encountered a variety of policies around AI use. As recently as 5 years ago, using AI in this setting was really taboo as it was seen as a "cop out" or a way to get out of doing the work. Now, it seems that educational institutions have embraced AI, but with restrictions. For example, I recently worked with a teacher and she was only able to use Microsoft Copilot as the organizations workplace platform was MS. She wasn't happy with her options, but it was a policy based on FERPA and student privacy.

AI: That's a really valuable perspective - seeing how attitudes have shifted so dramatically in just five years, and now it's more about which AI tools are allowed rather than whether AI should be used at all.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I'm actually currently working on a presentation for 6th graders on the topic of AI and its benefits as well as its potential dangers. The school that requested this noted a spike in student usage of AI and attitudes toward it. This was new for me. I was aware of adult concerns such as loss of jobs and the potential for AI to "take over". However, I wondered how it might be dangerous for children. Using Gemini for brainstorming and exploring the topic, the realization of the dangers of children assigning emotion to an inanimate object, and becoming convinced that the AI is a human was very eye-opening. I hadn't considered it, but the AI was great at almost self-reflection in explaining how this could be a problem for children. By the end of my conversation, I felt like I had a whole new area of interest for child safety and technology.

AI: That's such a powerful example - having AI help you understand the very real dangers that AI itself might pose to children. The idea of kids forming emotional attachments to AI or being convinced it's human is really profound.

Tell me more about that conversation where the AI was doing what you called "self-reflection." What was that experience like for you as it was happening?

User: I don't remember the exact responses, but it was something along the lines of AI being trained to be supportive and empathetic as well as helpful. Children can often mistake these apparent human emotions as indicating the presence of a human. Children are especially susceptible to interpreting this as a real relationship and become reliant on the relationship. To hear the AI speaking about itself in this way was great for me to hear, but it made me wonder would the AI also make this distinction for a child. Could it say, I am not a human so I can't really understand what you are feeling. Or would that be even more detrimental wo a child without the ability to distinguish? It just really opened up a whole new avenue of thought and analysis for me.

AI: That's such a thought-provoking dilemma - the very empathy that makes AI helpful for adults could be what makes it potentially problematic for children who can't make those distinctions yet.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider as you work with these tools?

User: I do sometimes, but it isn't really a worry for me personally. My area of expertise is in education, but specifically in behavior and discipline, and children involved in criminal activity, both as offenders and victims. In addition to my work with safety and technology, I am also a Forensic Interviewer where I talk with children who are witnesses to or victims of crime. I often testify as an expert witness in trials. I just believe that the face-to-face interactions that are necessary in my field are not likely to be replicated by AI.

AI: That makes complete sense - the human connection and trust-building that's essential in forensic interviewing and expert testimony really can't be replicated by AI.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it changing in any particular ways?

User: I view it now as a collaborator rather than a delegate. I don't see that changing. Perhaps some minor tasks such as scheduling or data analysis would be things I would totally turn over to it. However, I feel that in my field, it is more appropriate as a collaborator for ideation or research.

AI: That's a really clear distinction - AI as collaborator for the creative and research aspects, but potentially as a delegate for more routine tasks.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how AI helped you discover new safety concerns for children - that seems like such a powerful example of AI expanding your thinking in unexpected ways.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No. I think we covered it all.

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about using AI as a collaborator in educational and safety work - especially that fascinating example of AI helping you understand the risks AI itself might pose to children - will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!
