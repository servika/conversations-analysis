# Dialog 01052

**Transcript ID:** work_0915

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: No let's begin

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI extensively in my work day. I will often use AI to synthesize data, summarize data into presentations and I use AI to rewrite narrative and emails

AI: That's helpful context - it sounds like AI plays a significant role across different types of communication and analysis work for you.

When you mention synthesizing data, can you walk me through what that actually looks like in practice? What kind of data are you working with and how does the AI help you process it?

User: I have two sets of data that I use frequently. The first set is demographic data usually around 1500 people that we need the data analyzed for. The second set is student performance data and could be several columns long. The point of each data set is to figure out student success in coursework compared against potential identifiable demographics

AI: That's really interesting - you're looking at educational outcomes through a demographic lens. 

When you're working with these datasets to understand student success patterns, how do you typically approach that work with AI? Do you find yourself uploading the raw data and asking for analysis, or do you break it down into smaller pieces first?

User: We find that uploading raw data rarely gets a complete answer - AI generally has problems analyzing very large data sets. As a result we break it down into smaller sets.

AI: That's a practical insight about working within AI's limitations. 

When you break down these datasets into smaller sets, how do you decide what those pieces should be? Are you chunking by certain demographics, by course types, or something else entirely?

User: we generally break it down into programmatic area first which tends to spread out the data across 8 groups.

AI: Got it - so you're organizing by program areas to create more manageable chunks for analysis.

Once you get the AI's analysis back on those 8 different program groups, what do you typically do next? Are you synthesizing those results yourself, or do you bring the AI back in to help connect the patterns across all the groups?

User: The first step is to see if there are any major outliers in the data. Then we take prior data and ask AI to create some narrative around trends (usually a three - five year period). If the narrative makes sense we will ask AI to summarize across all programs.

AI: That's a thoughtful process - checking for outliers first, then building historical context before looking at the bigger picture.

I'm curious about that moment when you're evaluating whether the AI's narrative about trends "makes sense." What are you looking for there? How do you decide if the story the AI is telling about your data rings true?

User: So for example if the data set turns in a student population of 200 in  with a pass rate of 97% - that is probably not related to student effort - and is likely the product of either easy to pass tests or cheating.

AI: That makes perfect sense - you're using your domain expertise to reality-check what the AI produces against what you know is actually possible or likely.

I'm curious about your preferences when working with AI. Are there certain tasks in this whole process - from the data breakdown to the final analysis - that you prefer to handle yourself, even though AI could potentially help with them?

User: Sure there are bits that AI could help with - however sometimes if a task would take longer for me to enter into AI and recheck I usually will do it myself

AI: That's a really practical consideration - the overhead of prompting and verification sometimes outweighs the benefit.

Can you give me an example of one of those tasks where you've found it's just faster to do it yourself rather than go through that back-and-forth with AI?

User: Sure checking on student attendance from the prior day takes less than 5 to 10 minutes to analyze who attended and who did not from the time that I download the report to completion. It would take at least double that to do the same thing in AI

AI: That's a great concrete example - the simple pattern recognition tasks where you already have an efficient workflow.

When you are using AI for the more complex work like the data analysis and trend narratives, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout the process, going back and forth, or do you tend to give it a complete task and let it handle it independently?

User: In order to make sure that we do not miss - or that the AI doesn't time out (this happens a lot with big files) I check in frequently and collaborate

AI: That timeout issue with large files sounds frustrating to work around.

When you say you "check in frequently and collaborate," what does that interaction typically look like? Are you asking it to pause and show you interim results, or are you more guiding its approach as it works through the analysis?

User: Right I always have AI give samples, stop let me review then provide more detailed response. I find it easier to correct mistakes if AI produces smaller sample sizes first

AI: That's a smart iterative approach - catching issues early with samples before committing to the full analysis.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Are others at your institution using similar approaches, or are you more of an early adopter?

User: No higher education is largely split on the issue of AI use. Many, especially in senior positions are absolutely against AI

AI: That's an interesting dynamic to navigate - being in an environment where leadership is resistant to AI use.

How does that institutional skepticism affect how you actually use AI in your day-to-day work? Do you find yourself being more cautious about when or how you use it, or does it not really change your approach?

User: for data analysis it's for my eyes only so it does not matter, however for narrative I am very cautious with my AI use and final product

AI: That distinction makes a lot of sense - using it privately for analysis versus being careful with outputs that others will see.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Frustrated is fairly easy - we had a simple task we were doing - take an assembled list of names and titles. Find the associated school they worked with and add the webpage address, phone and school address. The AI would do a block of 10 names, and then would punt. If it went beyond 10 names the AI started to fabricate heavily the information.

AI: That's a really telling example of AI's limitations - it sounds like it hit some kind of processing threshold and then started making things up rather than admitting it couldn't handle the volume.

On the flip side, can you think of a time when using AI made you feel particularly satisfied with the results? What made that experience work well?

User: Yes - we used AI to really help develop some curriculum mapping that took hours of work and did it within a few minutes.

AI: That sounds like a significant time saver - hours down to minutes is quite a difference.

What made that curriculum mapping task work so well with AI compared to something like the contact information task that frustrated you? Was it the type of work itself, or something about how you approached it?

User: That is what made the contact information really frustrating, it was a simpler task than curriculum mapping (which technically is harder)

AI: That's fascinating - so it wasn't about the complexity of the task itself, but something else about how AI handles different types of work.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, especially given the resistance in your institution?

User: AI would not necessarily impact my role but it would impact the roles of people who report to me (likely eliminating them or reducing to part time)

AI: That's a significant consideration - AI potentially affecting your team structure and the people you manage.

How do you navigate that reality? Are you thinking about how to help your team adapt, or is it something you're still trying to figure out?

User: AI is still not reliable enough to adequately plan to eliminate positions, but the long term impact is likely lower tuition for students to attend colleges (less staff means a smaller budget etc)

AI: That's an interesting broader perspective - connecting AI adoption to institutional economics and ultimately student costs.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself using it more extensively, or staying roughly at your current level of integration?

User: No my intention is to vastly increase my AI use - Chat5 is already well ahead of where o3 was. Hopefully AI will continue to evolve to where I can use it for much larger tasks

AI: That's interesting - it sounds like you're seeing real improvements in capability that make you optimistic about expanding your usage.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how AI's reliability varies so much depending on the type of task - that curriculum mapping success versus the contact information frustrations really highlighted how unpredictable it can be.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Perfect. Thank you again for your time and for sharing your experiences so openly. Your insights about working with large datasets, navigating institutional resistance, and the unpredictable nature of AI reliability will be incredibly helpful for our research on human-AI interaction in professional contexts.

Have a great rest of your day!
