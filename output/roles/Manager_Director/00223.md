# Dialog 00223

**Transcript ID:** work_0402

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Sounds good, no questions at this time.

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: We use AI to read through responses to prompts in educational assessments before having those responses scored by humans.

AI: That's interesting - so AI serves as a preliminary screening step before human scoring. Tell me more about that process. What does the AI do when it reads through those assessment responses?

User: Depending on the assessment project, AI will sort out unscorable responses and/or actually do some or all of the scoring.

AI: So the AI's role varies by project - sometimes it's filtering out responses that can't be scored, and other times it's actually doing the scoring itself. 

When the AI does the actual scoring, how does that work alongside the human scorers? Are humans still reviewing those AI-scored responses, or does the AI handle certain types completely on its own?

User: Again, this depends on the specific project. Sometimes AI will score certain criteria and humans will score other criteria. Sometimes AI will score all criteria, then humans will also score it, and any disagreements between the two are reviewed by a scoring director.

AI: That's a really sophisticated workflow - it sounds like you have different collaboration models depending on the assessment needs. 

When there are disagreements between the AI scoring and human scoring that go to the scoring director, what kinds of patterns do you notice? Are there particular types of responses or criteria where the AI and humans tend to disagree more often?

User: I have noticed in assessments for English Writing, that many disagreements come from the length of the response. AI often credits writing that isn't necessarily relevant to the prompt and may not credit a shorter response that gets straight to the relevant ideas.

AI: That's a fascinating insight - so the AI seems to associate length with quality in writing assessments, even when shorter responses might actually be more focused and relevant to what's being asked.

When you encounter these patterns, how does that affect your confidence in using AI for different types of assessment tasks? Do you find yourself adjusting how you set up the AI scoring or which criteria you're more likely to have AI handle versus humans?

User: It doesn't happen often, so we tend to be pretty confident with it. I am able to make recommendations to my superiors, but I don't make the final decisions on AI set up. We are not at the point, however, where we want to eliminate the comparison with human scoring. Additionally, our clients (often state or federal) make the final decisions on how much AI we can incorporate into the scoring of their project.

AI: That makes sense - there are multiple layers of decision-making involved, from your recommendations up through your organization and ultimately to the government clients who set the parameters.

I'm curious about your day-to-day experience with this. When you're working with these AI-human scoring comparisons and making recommendations to your superiors, what does that work feel like for you? Are you more in an analytical role, or do you find yourself troubleshooting, or something else entirely?

User: Definitely analytical. I look for the patterns and am often correcting the human scorers.

AI: So you're spotting patterns in both the AI and human scoring, but it sounds like you're frequently finding that the human scorers are the ones who need correction rather than the AI. 

What kinds of patterns do you typically see with the human scorers that require correction? And how does it feel to be in that position of having to correct human judgment when AI is often getting it right?

User: Since it is one AI program versus a group of scorers, there are always a few scorers who need guidance. I don't correct them in a way that says, AI scored this accurately and you didn't. I point out what they missed within the score and how it fits into the rubric in an effort to improve their scoring. I also utilize this type of feedback when there is a disagreement with another human scorer, not just AI.

AI: That's a thoughtful approach - you're focusing on helping scorers understand the rubric better rather than positioning it as AI versus human accuracy. 

Are there certain tasks in your analytical work that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks feel like something you want to keep doing personally?

User: The reports at the end of certain projects are often tedious, but we continue to do them manually as they require examples of where scorers had difficulty and ideas that could help the director the next time the project is scored.

AI: So those end-of-project reports require a kind of contextual understanding and forward-thinking that you feel needs the human touch - identifying not just what went wrong, but why it went wrong and how to prevent it next time.

When you're working on those reports, are you more collaborating with AI throughout the process, or do you tend to complete the entire report independently and then maybe have AI help with specific pieces?

User: I complete the reports independently.  Also, I hit the Return button before I finished my previous comment. I wanted to add that as we score, (on certain projects), we train as a group and talk as a group; sometimes coming to a consensus on how to credit or not credit something, as a group. AI would not seem to fit into this design.

AI: That's really insightful - so there's this collaborative human element where you're building consensus as a group, discussing edge cases, and collectively interpreting the rubric. That kind of real-time group decision-making and nuanced discussion sounds like something quite different from how AI operates.

How have your colleagues or your workplace culture influenced the way you approach using AI in this scoring work? Are people generally comfortable with it, or do you notice different attitudes toward the AI integration?

User: As always, it varies by project, but mostly we have welcomed AI's help. Our corporate heads are always trying to save money, so tasks that AI can accurately perform much more quickly than humans are preferred.

AI: So there's this practical reality where AI helps with efficiency and cost-savings that leadership values, and it sounds like your team has generally adapted well to that.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I can only think of one time where I was a supervisor on a project rather than a director, and the director did not tell me that AI had already scored all of the responses, and I was second-scoring many of them. Rather than providing coaching feedback, as I do when I am a director, the director just told me she agreed with the AI instead of me, and it was not helpful. That was more of an issue with the director than the AI, I believe.

AI: That sounds really frustrating - being put in a position where you're doing work without the full context, and then having your scoring dismissed without the kind of constructive feedback that helps you improve. It seems like the AI wasn't the problem, but rather how the information about AI's role was communicated and how disagreements were handled.

How do you think about maintaining your skills in areas where AI could potentially take over more tasks? Is this something you actively consider as these tools become more capable?

User: I believe my responsibilities will be replaced by AI at some point. Many projects have already moved from humans providing the first and second scores to humans only providing second scores. Once human scoring is no longer required, there will be no need for me to train them.

AI: That's a very matter-of-fact way of looking at a significant potential change. It sounds like you're already seeing the progression - first AI takes over initial scoring, then potentially second scoring, and eventually the training role itself might not be needed.

Looking ahead, how do you envision your relationship with AI at work evolving? Are you thinking about how your role might shift, or are there other areas where you see yourself working with these tools?

User: Between the increased role of AI and the elimination of funding for education, I am looking to find new work. We had a significant decrease in available projects this year due to cancelled government contracts, and I am unsure what my future holds.

AI: That paints a clear picture of how multiple forces - both AI advancement and funding cuts - are reshaping your field. It sounds like you're navigating some real uncertainty right now.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how AI handles length versus relevance in writing assessments, and your nuanced view of the collaboration between AI and human judgment in scoring.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Nothing comes to mind.

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about the evolving role of AI in educational assessment - from the technical details about scoring disagreements to the broader workplace implications - will be incredibly helpful for our research on human-AI interaction in professional contexts.

I wish you the best as you navigate the changes in your field. Take care!
