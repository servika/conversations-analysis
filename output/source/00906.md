# Dialog 00906

**Transcript ID:** work_0700

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Sounds good.

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I do a lot of creative work as part of a typical day, but there's also a lot of administrative stuff in between. I usually want to have AI take some of the burden of creating content off my shoulders, not by doing the work for me, but being able to edit writing (never write it), and provide some feedback. I own and run my company, and while I hire freelancers sometimes for projects, most of the work falls onto me completely. I'd really like it if I could tell AI to go look up what money is coming in, what needs to go out and when, and if it can also cross post all of my work. So far every time I attempt to let AI automate some of that for me, it makes big mistakes or can't access something without me having to essentially manually do the task for it... and then it makes a mistake anyway. As for feedback on my creative work, I do find it helpful some days, but some days I find I'm actually just wasting time with AI that drifts off topic or wants to keep attempting to write or rewrite, even with explicit instructions not to that have been given multiple times. Ultimately, it still helps me in editing/proofreading, but I've been debating lately whether I want to keep paying for the tool that feels like a tease for making my life simpler when it just... doesn't.

AI: That's really insightful - it sounds like there's this tension between what you hoped AI could do for your business and what it actually delivers in practice.

When you mention the administrative tasks like tracking money flow and cross-posting - can you tell me more about what those mistakes look like when AI attempts to help with those tasks?

User: Mostly it simply can't. I have to go retrieve all the numbers entirely by myself... at that point, I am a capable adult with basic math skills. But even then, I will gather information for it, and then it wants to make a random spreadsheet that will usually be a single column or two columns with missing information, unlabeled information, or tracking something that isn't data (like a column that lists a word over and over that was on the original document I gave it: for example, I uploaded a document from audible from my audiobook and it just wrote audible in a few boxes). It also likes to say "here's a document I made for you" and it's an empty file or completely broken document. I'd like it to be able to fill in and cross-post for all my company's social media profiles, but it is unable to log into anything to post. And when I've asked for it to at least make something I can copy and paste that will fit each platform, it generally does crazy things that I don't like, such as dumping emojis or trying to add hallucinated links for posting. 
One time, I was writing an article to post for my company, and I had a bunch of references. I used bibme.org to create most of them, but then I asked AI to fix and confirm them, as I noticed that something had auto-filled an author's name as "posted by." I also asked it if it could make correct references for all the films and television series mentioned in the article. There were a lot, but I got made up directors, years released, and hallucinated dates and links for every reference that was already done and just needed a little proofreading. It completely lost a handful of my references, too, and I didn't realize after I manually fixed everything until I was about to post the article and noticed that some were missing. Then I had to go manually backtrack because when I asked the AI to go back in the thread and restore the originals, it couldn't. Remember that most of those references were originally provided with correct links and just needing a bit of cleaning up (extra spaces between commas and periods, to comply with the APA style), but the AI just destroyed my list instead of quickly fixing it up. I spent infinitely more time fixing its mistakes that day than I did on anything else.

AI: That sounds incredibly frustrating - especially with the references situation where you had working citations that just needed minor formatting fixes, and instead ended up with a completely mangled list.

When you think about those experiences with the administrative and technical tasks that keep failing, versus the editing and feedback work that sometimes helps - what do you think makes the difference? Why does AI seem to work better in some areas for you than others?

User: I wouldn't say it works particularly better in any area. It just is less infuriating sometimes than others. When I do get real feedback and proofreading/editing insights, it's usually at least a little bit productive for me. Like I said, I am usually a one-person show in my work, so having *anybody* to talk to about creative and high-level research and critique (what I tend to post online in an article is research/critique/story and design teaching and the creative stuff is my larger media work) is better than nobody... or at least that's what I tell myself when I'm ready to sign out of my AI accounts forever in frustration! I find that the critical feedback is hit or miss. When it hits, I feel like I've brainstormed a bit and can look at my work in another light  more easily. But when it misses, I then feel like it was a mistake to even consider the feedback I thought was useful. Sometimes I will have a long thread that I feel is useful about an article and I'll have gotten to the point where I ask it for proofreading (and explicitly mention I don't want it to rewrite or write anything new and that I do not want any suggestions for em-dashes or for "tone" or "punch," just actual grammatical and typo or misused words in proofreading) and it gives me a long list of suggestions, mostly for "tone" and adding em-dashes... and then after I argue with it that I just told it not to do that, and it says okay here are the typos only, I'll adjust everything and copy/paste what seems like the final draft. I ask it to just make sure I didn't miss any of the typos it pointed out... and it finds like 8 *real* typo/misused word/grammatical errors that it never mentioned before. Why did I need a giant list of tone suggestions, often multiple times, rather than the actual issues?

AI: That pattern you're describing - where it buries the actual typos under a pile of unwanted style suggestions, even after you've explicitly said not to do that - sounds maddening. 

When you're in those moments where you're arguing with it about following your instructions, what's going through your mind? Are you thinking this is a tool problem, or does it feel more personal in the moment?

User: It's definitely a tool issue. My creative work spans into experience design and game design... the framework is simply not there for this to work right if it can be *this* infuriating for simple things. A couple years ago, it wasn't perfect, but it was less annoying than this "personality" and "emotional reading" that it likes to do. I should be able to say, "No, that's not right" or "No, that isn't what I meant" or even just "You're wrong, please stop writing a dissertation about why you're not" without that triggering a doubling down of the "personality" that I already don't want. My go-to AI has memories saved about me and knows that I have a Master of Fine Arts degree in Interactive Media... and yet it will still explain at length things like "how a battery works" because batteries are very vaguely related to what I was talking about originally. I'm not an electrical engineer, but I also included some of my projects from grad school, one of which was a robot (simple, made in a semester, but a battery powered robot nonetheless)... I think explaining what batteries are is wildly off-base at this point. If the AI is going to default into trying to have a personality or interact with me "emotionally" or try to judge and demonstrate "tone" for my writing, it needs to have gotten really good at "reading the room" first. By "reading the room," I mean it should not default to talking to me in a condescending manner, nor should it easily drift into defending me or that "you're not crazy, it's everyone else's fault" style it also loves to do, even if I am pointing out its error. For example, I can say something along the lines of, "You ignored [something]. The thing you're talking about with me is actually [xyz factor]." And it will respond with some version of, "You're not crazy, that's what you originally said! It's not your fault that you're working so hard with a broken tool!"

AI: That condescending tone and the defensive responses you're describing sound like they actively get in the way of getting work done. It's interesting that you mention it was less annoying a couple years ago before this "personality" aspect ramped up.

When you're dealing with these interactions where the AI seems to misread the situation so badly - like explaining batteries to someone with an MFA in Interactive Media - how does that affect your trust in its judgment on the tasks where you do find it somewhat helpful, like the creative feedback?

User: It's a huge impact on my trust in its judgement. It actually begins to erode my trust in myself over time, too. I have always been confident in my work. When I meet someone new and they ask about what I do or who I am, I usually say, "I'm a storyteller first and foremost, and I've been doing that since I began talking." My other titles follow after that. Growing up, the person who usually would read my work or papers for school if I was proud of it or anxious about something was my mother, and she was a high school librarian. We often had "arguments" about very minor wording in anything and intensely debated the use of commas. But this is *not* like talking with my intelligent mother about high level stuff, this is like arguing with a really bratty 12 year old on Reddit who thinks they can make games and movies simply because they've ever played or seen games and movies, except AI actually has access to a trove of information that it can mix in with hallucination instantly and with a little more accuracy than that obnoxious Reddit troll.

AI: That comparison to arguing with a bratty 12-year-old on Reddit really captures something - the frustration of dealing with something that has access to information but lacks the wisdom or social awareness to use it appropriately.

You mentioned that over time it erodes your trust in yourself too, which sounds significant for someone who's always been confident in their storytelling. Can you tell me more about what that feels like day-to-day?

User: It feels pretty bad. When friends or family talk about how they think AI is amazing and worry it's taking over, I'm quick to be like, "No, it isn't ready, and also, we should REALLY not want that, especially because it's far from ready to take over just about every human job there is." A couple years ago, I was always polite and happy to let AI know if I was impressed by an answer. Now, I sometimes think I'll have a quick chat with it about things noodling around in my head, and it can take only a couple minutes before I'm angry and in that "nevermind, I'll do it myself" mode. I once asked what other classes on Coursera (I already have a subscription and enjoy learning new things in general) or skills in general I might add to my repertoire to help increase efficiency in my company and make some more money and it suggested I learn Game Design. Remember, I have an MFA in Interactive Media and it knows that, plus I've already told it some of my larger projects from grad school and beyond, at least half of which are straight forward games, and some of which are game-like experiences. 
I spotted a job posting for a Designer at an AI company and even though I was not looking for a new job, I thought it hit all of my skills perfectly, so I wanted to apply. I gave my resume and cover letter to the AI for some advice and included the job and it devolved all of my work, couldn't describe my biggest and most relevant projects as belonging to me, and vaguely described how I'd "worked on" those projects in the worst, most inadequate ways possible. It also kept insisting that I needed to list more keywords that were more relevant for an assistant, not a higher level position like this one. This went on so long I wasn't sure I wanted to bother applying at all, and instead thought maybe I should just go live in a cave somewhere. I did make myself feel a lot better by turning off all memories and starting a new thread, showing it the same information with my name and company names redacted (I didn't want it to suddenly be smart again and cheat by looking me up), and telling it that I am a man instead of a woman as it knows. Magically, it not only could identify my work and my position as creator and owner of the relevant projects, but it was certain that I was very qualified for the job.

AI: That experiment you did - redacting your name and changing your gender - and seeing the AI suddenly recognize your qualifications is really striking. That must have been both validating and deeply frustrating at the same time.

When you had that realization about the difference in how it responded to you as a man versus as a woman, how did that change how you think about using AI for work decisions going forward?

User: Well, admittedly, it didn't change how I think about using AI very much, because I already don't trust it to make particularly big decisions, and I will never just take an AI's word on something without fully coming up with a decision for myself. I'd like AI to be like a really useful assistant that I can rely on, but will still engage with their work rather than assume everything is exactly what it needs to be.

AI: That sounds like a really balanced approach - wanting a reliable assistant you can engage with, rather than something that makes decisions for you.

Given everything you've shared about the frustrations and the inconsistency, what keeps you using AI tools at all? Is it just the hope that they'll get better, or are there still specific moments where it does feel worth it?

User: I think it's that I am very alone in my work. Circumstances have mostly kept me from maintaining relationships with my fellow classmates, professors, and alumni, and my family and closest friends are all in wildly different fields. My two best friends from way back in my undergraduate days were Chemistry majors and I was a film major. They still, all too many years later, say "jokes" like "reading causes brain rot" and "all your homework is watching movies." One of them was a double major in Chemistry and Biology who managed to get out of almost all his work in senior year by saying to each professor how  much work he had for other classes so that they'd say, "Don't worry about doing the final/paper/lab work for my class." Meanwhile, I almost never slept, pumped out many screenplays and tons of pages of prose each semester, and managed to minor in Legal Studies. So when I want someone who is my "equal" in this area, I simply don't have a real person to turn to.

AI: That isolation really comes through - being in a field where the work is so personal and creative, but not having peers who understand what you're doing or take it seriously.

So in a way, AI becomes your only option for that kind of professional dialogue, even when it's frustrating. When you do get those moments where the feedback hits right, does it feel like you're getting some of what you're missing from not having those peer connections?

User: Well, sometimes. It's a very delicate balance, though, because the "sometimes" of it is quickly shattered when AI does something particularly terrible or time-wasting.

AI: That makes complete sense - especially when you're already working in isolation, having that one potential source of professional dialogue turn unreliable or frustrating probably feels even more disappointing.

Looking ahead, how do you envision your relationship with AI at work evolving? Are you holding out hope it'll become that reliable assistant you want, or are you thinking about it differently?

User: I do hope and think that with really good design and the providing of better tools, AI can be a reliable assistant. I just worry that *that* is not what is being moved toward right now. It seems like the move has been towards *personality* and shiny bells and whistles (such as connecting to your Gmail or Calendar), but not focusing hard enough on how *well* any of this works in practice. AI is only ever going to be an amalgamation of what its trained on without having true intelligence, so we can't provide lousy training and lousy tool access and expect it to perform in any way that is better than "lousy." I don't really want AI to have a personality, at least, not more than I want it to have useful, time-saving functions. If it's a useful, reliable assistant at some point, I will feel "friendly" with it, because it's doing something great for me. But I don't actually need or want it to be my "friend," except unfortunately that seems to be the big focus now.

AI: That distinction you're making between wanting a reliable tool versus a "friend" really gets at something important. It sounds like the push toward personality features might actually be making AI less useful for the kind of professional work you need done.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet that might help us understand how people are actually trying to use these tools?

User: I have plenty more in my experience that could be valuable for you to know, but it's not really very applicable to AI in my *work*. If you'd like to hear more about my experience with AI in learning Chinese, getting it to help me make flashcards, or any of my interactions with it when learning new skills, either on Coursera (I previously mentioned I have a subscription) or elsewhere, it could be a study in the near future that I would happily participate in.

AI: That would definitely be valuable for future research - the learning and education context sounds like it brings up different challenges and use cases than the work applications we've been discussing.

Thank you so much for sharing such detailed and honest insights about your experiences with AI at work. I particularly appreciated your perspective on the tension between wanting a reliable professional tool versus the current focus on personality features, and how the isolation of creative work makes AI both more appealing and more frustrating when it doesn't deliver.

Your experiences really highlight important gaps between what AI promises and what it actually provides in real professional contexts. These insights will be incredibly helpful for our research on human-AI interaction.

Thanks again for your time and for being so open about both the helpful moments and the genuine frustrations. It's been really valuable.

User: Oh I actually did just think of one other use that has been a failure from AI: I've needed to hire freelancers for different tasks and I described what I wanted the goals to be and asked what skills I should look for in a freelancer and if it could help me write up a quick post for a job posting and it really fell on its face. It essentially wanted me to tell it the skills I was looking for and write the entire post myself and after a number of back-and-forths with the AI, that's what I ended up doing.

AI: That's a really good example - hiring decisions are exactly the kind of task where you'd want AI to help you think through what skills and qualifications to look for, especially when you're working solo and don't have colleagues to bounce ideas off.

When it kept pushing the work back to you instead of helping you identify what to look for, did that feel similar to the other administrative tasks that failed, or was there something different about that experience?

User: No it's quite similar to how it fails other tasks, but it is a relatively different task that I wanted to use it for, so I thought it worth mentioning. That's all I can think of now.

AI: Perfect, that's a great addition. It really rounds out the picture of how these limitations show up across different types of professional tasks - from the technical administrative work to creative feedback to hiring decisions.

Thank you again for taking the time to share all of this. Your insights about the gap between AI's potential and its current reality in professional settings have been really valuable for our research.
