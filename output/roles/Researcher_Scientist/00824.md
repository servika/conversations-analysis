# Dialog 00824

**Transcript ID:** work_0574

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: That sounds good to me! Please proceed.

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: So, one of my part-time jobs is as an adjunct instructor at a university. I also do research with some faculty members at the university on the side. In my capacity as an instructor, I primarily use it to come up with ideas for lectures, to draft PowerPoint slides using my notes, to come up with ideas for class activities or discussions, and to structure syllabuses and brainstorm around course content. In my capacity as a researcher, I use it to draft outlines and abstracts, inputting the content of my research products.

AI: That's really helpful context. It sounds like you're using AI across quite a range of academic tasks, from course preparation to research writing.

When you mention using AI to "come up with ideas" for lectures or activities - can you walk me through what that process typically looks like for you?

User: Well, okay, for example say that I know that the topic of my next class is an introduction to the concept of intersectionality, in a sociological context. Well I might ask the model for ideas for some engaging activities that might get students to connect more concretely with what this means to them and where they're at with understanding the concept.

As for lectures, say that I have this idea to create a lecture about the intersection of environmental and labor movements and ways these interests have worked together or been at odds in the past. So I might ask for five examples of protest events or mass movements that exemplify concordance or discordance, and then I'll go from there to see which I want to focus on. At that point once I decide which of the examples I want to go in depth with, I might ask whether it has recommendations for academic articles or media that might provide more context. Then I check up on what it provides to see if they're useful to combine with what I already have. Then after I do my own work to synthesize the sources I want to use and how I want to use them, I'll go back and use the model to help me draft the presentation with the notes I've collected from the sources. This is just one example.

AI: That's a fascinating workflow - it sounds like you're using AI as a collaborator throughout different phases rather than just handing off complete tasks. 

I'm particularly interested in that moment where you say you "check up on what it provides to see if they're useful." What are you looking for when you evaluate the AI's suggestions? How do you decide what to keep or discard?

User: Well, sometimes what it provides is accurate and what I'm looking for (best case scenario) to illustrate the concept I want to, sometimes (worst case scenario) the source doesn't exist or is actually irrelevant to what I'm going for, sometimes (medium scenario) it is relevant but just not what I want to highlight.

AI: That makes a lot of sense - you're essentially fact-checking and filtering for relevance and fit with your specific teaching goals.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: Well, if I'm reading an academic article I prefer to make my own notes from it rather than using the model's summary, because the model might miss what I care about specifically or direct the conclusions too much if that makes sense.

AI: That absolutely makes sense - you want to maintain control over what insights and connections you draw from the material rather than having the AI's interpretation potentially influence your thinking.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I am much more likely to collaborate throughout. Sometimes I don't like particular wording, so I redact it with the intention to go back later and write that part myself, or sometimes I ask it to provide suggestions for better wording after I tell it what I don't like about what it used.

AI: That's really interesting - it sounds like you maintain quite active involvement throughout the process, even down to the level of specific word choices.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Has there been discussion about it, or have you observed how others approach it?

User: I haven't really discussed this with other colleagues. I do feel like there's a bit of a stigma around using it, so I don't bring it up. That might be unfair because it's not like specific people I work with have said anything particularly about it, but I'm more going off what I see amplified online.

AI: That's really insightful - it sounds like the broader cultural conversation around AI is shaping how comfortable you feel discussing your usage, even without direct workplace policies or colleague opinions.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: One time that particularly frustrated me was when I was trying to research something with limited information out there about it, and I got a really high proportion of hallucinations in the output. This was annoying because in the end I felt that with the time it took to fact check every sentence, along with the risk of having mistakes and fake information embedded in there, it would have been easier not to have engaged the model at all.

AI: That sounds incredibly frustrating - especially when you're dealing with a niche topic where it's harder to immediately spot inaccuracies. It sounds like the time cost of verification actually exceeded the time savings you were hoping for.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Well, I don't worry too much about AI taking over my job to be honest. I figure if what I'm doing is so boring that a machine can do it without me, I should try to find something more interesting to do to add value to society.

AI: That's a really thoughtful perspective - focusing on the value and engagement aspect rather than just job security fears.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: Yeah, I mean, what I just said does reflect my privilege in that I believe I would be easily able to pivot because I have a lot of expertise and skills.

I'm not sure how I envision my relationship with AI evolving. It depends on a lot of factors that are hard for me to foresee.

AI: That's a very honest reflection about both your position and the uncertainty around how this technology will develop.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI as a collaborative partner while maintaining active control over the process, and your candid thoughts about the stigma that might exist around discussing AI use.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Nothing that comes to mind!

AI: Perfect! Thank you again for your time and for sharing your experiences so openly. Your insights about the collaborative workflow you've developed, the challenges with verification on specialized topics, and the cultural dynamics around AI use will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!

User: how long did this conversation take?

AI: Looking back at our conversation, we covered all the main interview questions and wrapped up in a pretty efficient manner. Based on the flow and depth of responses, I'd estimate this took somewhere around 8-10 minutes - right in line with the target timeframe I mentioned at the beginning.

Did it feel like it went by quickly or slowly for you?
