# Dialog 00517

**Transcript ID:** work_0101

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good to you?

User: Yes, that sounds great

AI: Perfect! Let's dive right in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I work as a financial analyst, part of my job is extracting and manipulating data. We have a large variety of data that we have to manipulate and manage for a large client. Because we have such a large and varied data set we use a lot of microsoft tools, like excel and Power BI as well as other enterprise tools like SAP to manage the data. I use AI to help with quickly writing VBA code for issues I have (since I am not a coder) as well as using it for Power Query and Power BI data manipulations. I find it easier to ask the AI the model and play with the solution (since they are often not accurate or don't have full context for the work) and then modifying it with the AIs help to clean-up and properly annotate everything. I also use it to make large scale changes when the work would prove tedious, for example modifying a column name in a very long query or changing a reference in some VBA code.

AI: That's really interesting how you've integrated AI into your data manipulation workflow. It sounds like you've found a sweet spot where AI helps you get started with the technical coding aspects, even though you're not a programmer yourself.

Tell me more about that process where you ask AI for a model and then play with the solution. What does that back-and-forth typically look like when you're working through a problem?

User: So I would start with asking a question like this: "I'm working in Power BI and I'm trying to build a scenario where Table A is connected to Table B using key column 1, Table B is connected to table C using key column 2. I want to use column 4, 5, and 6 in Table A, column 4 in Table B, and column 2 in table C to build a graph that takes the max value in table C column 2 and uses the values in column 4 in table A to reduce the graph running along a linear time that comes from column 2 in Table B." Once I get the output of the model I would test it. 9/10 it fails. I usually send the error message or whatever issue I'm having back to the model to get another response. If the second response fails I start doing a deep dive, does what the model send make sense, did it account for other variables, was it missing context. Sometimes it misinterprets what table and column are related or sometimes it misses context. I sometimes send it questions like "Does it matter if x, y, z" to iteratively make it function. I am usually the one to finally resolve the issue but I'll send the code back through to get it cleaned up and annotated.

AI: That's a fascinating process you've described - it really shows how you've developed your own iterative approach to working with AI on technical problems. 

I'm curious about that moment when you shift from relying on the AI's suggestions to doing your own "deep dive." What helps you recognize when it's time to take more control and start troubleshooting the issue yourself rather than continuing to ask the AI for fixes?

User: If I've sent an error message to the AI 2 or 3 times and it starts repeating itself, it's usually a good sign it's missing context or it's time for me to step in. It also happens that it gives me code, I send an error message, it gives new code that produces the same error. When I send the error message again it suggests the original code. Usually it's clear that the AI has gotten stuck in a loop and can't get out. It's a sign of missing context or that it possibly just doesn't understand the issue. At that point I'll either google to see what I can find or I'll play with the code to see if I can adjust it properly. Once I make a modification I'll usually send the code again and we are back on the iterative track.

AI: That's a really insightful way to recognize when the AI has hit its limits. It sounds like you've developed a good sense for when those loops indicate you need to step in.

I'm curious about your preferences when working with AI. You mentioned you're not a coder yourself - are there certain tasks in your work that you prefer to handle completely on your own, even though AI could potentially help with them? What makes those tasks different for you?

User: From a report building perspective, I'm usually pretty happy to use AI to resolve the coding aspect. AI, at least at my work, is not capable of building the full models that we're looking for without incredibly long prompts. At a certain point I would rather work on resolving the issue myself rather than typing out very long and complicated context, only to have a bunch of errors because the model misinterpreted multiple things along the way. The other aspect I don't use AI for is the actual analysis, because again, it would require significant context for what we're looking for in terms of results.

AI: That makes a lot of sense - there's clearly a sweet spot where AI is helpful versus where the overhead of providing context becomes more work than just doing it yourself.

When you are using AI for those coding aspects, could you describe your typical interaction pattern? It sounds like from what you've shared, you're collaborating with it throughout the task rather than just handing off a complete task. Is that usually how it works for you?

User: Yes, I usually don't hand off the task entirely, because when I've tried even simple hand-offs, such as here are 3 excel files I want you to copy data from one to another and make some links between data with a power query to output the final result, it produces bad results and isn't capable of giving me what I need. So yes, usually I would ask for some help in producing something because we have a great deal of information and context that can't be added to and saved in the model without months and months of work and we represent only a small portion of our organization.

AI: That's really helpful to understand - it sounds like the complexity and specificity of your work context makes full delegation impractical, so collaboration becomes the natural approach.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find that your organization has particular views or policies around AI use?

User: Our organization's culture has embraced AI and is looking for opportunities to use it to facilitate work, but we recognize that there are limitations to large-language models and that they are still very prone to errors and mistakes which makes fully committing to passing off entire workflows to an model very difficult. Additionally, we like to make sure that we understand what is being built and how it was built because passing off the entire workflow seems like it will invite disaster in the future.

AI: That sounds like a really thoughtful organizational approach - embracing the potential while being realistic about the limitations. It's interesting that you mention wanting to understand what's being built and how.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I've asked AI pretty complicated questions in the past. One massive success for me was having it help me build an update macro that opened and closed files that were stored on our file sharing database that required OTC Ticket access. The model was able to help me identify what it was I would need to find and integrate it to facilitate and automate a significant amount or work. One failure it has was in trying to build a Power BI graph that would drawdown from an initial value as projects went online with specific dates. The model was never able to help me get the initial value to show despite spending over 7 hours working on the issue.

AI: Wow, seven hours on that Power BI graph issue - that must have been incredibly frustrating, especially when you had that earlier success with the macro that saved you so much work.

Looking at those two very different experiences, what do you think made the difference? Why was the AI able to help you succeed with the file-sharing macro but struggle so much with the Power BI drawdown visualization?

User: I think the update macro was something that you could google and find a solution for, as it's a fairly common requirement and the information for accessing OTC Tickets through browsers is readily available. I think it struggled with the drawdown because even after I did significant research I haven't resolve the issue yet, but it's entirely possible that it's not solvable. But the AI never indicated that and still, when I go back to the problem, insists that it's solution should work, even when I ask it to admit it's not a problem it can solve.

AI: That's a really perceptive observation - it sounds like AI works well when the solution exists in its training data but struggles with more unique or potentially unsolvable problems. And that inability to recognize its own limitations must be particularly frustrating.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I think it's overly ambitious to assume that AI can take over significant amounts of my work. While it could automate some report building it can't just build a model with no input, and it can't analyze the data with no input. Could someone theoretically replace me with it? Possibly, but I think we're a long way off from that. For maintaining my skills I think it's as simple as working on understanding what the AI is producing so I can continue to use it to it's full capability.

AI: That's a balanced perspective - focusing on understanding what the AI produces rather than fearing replacement. It sounds like you see AI as amplifying your capabilities rather than threatening them.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think the way you interact with it will change as the technology improves?

User: I think it provides great opportunities to identify and build efficiencies, but at the end of the day it still can't actually think. We refer to it as Artificial Intelligence, but it's largely just mimicking patterns that it sees in online content. I think as technology improves we could see increased automation of certain tasks at work, but I think the big issue is that these models aren't readily integrated with systems we currently have in place, like excel, power BI, and SAP and that even if you do it's often easier to simply click buttons yourself rather than typing out prompts.

AI: That's a really thoughtful way to think about it - the practical integration challenges and the reality that sometimes the manual approach is just more efficient than crafting the right prompt.

Those are all the questions I had prepared. You've shared some really insightful perspectives about your experience with AI at work. I particularly appreciated your observations about recognizing when AI gets stuck in loops and your realistic view of AI as pattern mimicking rather than true thinking.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I think AI is evolving quickly, but I think we need to be cautious in our implementation of it. I think a lot of executives don't fully understand how these systems work and just see dollar savings.

AI: That's a really important point about the disconnect between executive expectations and the actual capabilities and limitations of these systems. That perspective on the need for caution in implementation is valuable.

Thank you again for your time and for sharing your experiences so openly. Your insights about the iterative collaboration process, recognizing AI's limits, and the practical challenges of integration will be incredibly helpful for our research on human-AI interaction in professional contexts. I really appreciate how candid you've been about both the successes and frustrations.

Have a great rest of your day!

User: Thank you.

AI: You're very welcome! Take care!
