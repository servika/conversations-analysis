# Dialog 00971

**Transcript ID:** work_0795

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: Sounds good, I have no questions.

AI: Perfect! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I mainly use it for patient communication. As a part of my job I answer all patient concerns/questions on every company format -- email, text, and the app chats. Topics can range from basic home exercise program questions to more complex physiology based questions, and while I often know what information I want to share, I use AI to help me formulate my thoughts, word things better, make my tone more professional, and come up with better explanations/metaphors when applicable. I also use it when doing patient outreach (I.e. contacting no-shows, missed appointments, etc...). More recently the company has been attempting to incorporate AI in our home exercise program creation, using it to create customized plans and instructions.

AI: That's really interesting - it sounds like AI is helping you communicate more effectively with patients across multiple channels. 

When you mention using AI to help formulate your thoughts and improve your tone, what does that process typically look like? Do you draft something first and then ask AI to refine it, or do you start by explaining the situation to AI?

User: I do both -- it really just depends on the situation. If I already know what I want to say and just want it to sound better, then I'll tell the AI something like:

"Make this sound better. It should be polite, respectful, and professional. I want the patient to feel like I am helping them, but also understand that to get this resolved they need to talk to billing, not me:
Hi [REDACTED],
Unfortunately I can't see your billing details. As far as your insurance information goes, it looks accurate to me. Typically in these situations the fastest way to get to a resolution is to get an insurance rep on the phone and then call in to our billing department and do a three way call. Otherwise, you can contact our billing department directly for clarification. I have included their information below."

Usually this type of prompt I'm pretty happy with the output, and may just make a few tweaks after copying/pasting it over.

However, if I don't know exactly what I want to say (it's a more difficult explanation/question) and I need to organize my thoughts, I'll send a prompt like:

"I have a patient asking me about whether or not they should be icing. Create a response that covers the following information: they don't have to ice, but they can. IF they ice they should only do so AFTER their exercises, and they MUST ice with the joint in an open position. So, in this case, since it's their shoulder, they should ice the shoulder in a position where they have good posture (the shoulder blade can sit down and back, and ideally in their shoulder "robber" exercise position). They shouldn't ice it for more than 10 minutes, and if they wish to ice it multiple times they should wait at least 5 minutes between. Explain that the reason for this positioning has to do with the fact that you literally have gelatin in your body (same stuff in Jello) and that when we ice it, it solidifies in that position -- so if you "solidify" it in that open joint position that's ideal and good for it. If there's a better analogy you can include use that, but it should be appropriate for an adult male in his 30s."

Usually this type of prompt will take a few tweaks after the initial prompt (based on what I like or don't like about the output).

AI: That's a fascinating glimpse into your workflow. I can see how you're using AI as both a polishing tool and a thinking partner depending on the complexity of the situation.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: When it comes to writing/patient communication I 100% prefer AI to handle it. When it comes to utilizing AI in the creation of patient programs I do prefer to handle it myself since it's less overall work for me. I know that sounds counter-intuitive, but here's what I've noticed with the more recent company implementations of utilizing it in patient program creations:
1. It doesn't always take into account company policies, and so I often have to fix things. For example, a company policy is never to recommend heat to a patient unless the patient has adhesive capsulitis. Generally speaking, most sources you find will recommend heat in various cases (like prior to working out), and so the AI will automatically output the more scientific/medical/general information rather than amending that information to reflect company policy. This creates more work for me because I have to fix these issues and it takes longer than if I'd just done it myself.
2. It often assumes diagnoses and makes a big deal if I try to change the recommended exercises. For example, at my job when the patient initially creates an appointment they have to select what area of the body they are coming in for (e.x. foot, calf, low back, shoulder, etc...). There are a handful of times per week where the person comes in for a totally different issue (due to various reasons) and I am unable to change the body part, so I either have to re-do the program from the assumed diagnosis, or I have to create a totally new program by hand. So, for example, let's say Susan originally was going to come in for her back, but then she sprained her ankle, so she's seen for that instead. Since her program is listed as "back", the AI has automatically created a program with basic back exercises, prescriptions, and advice (e.x. pelvic tilts, bridges, clamshells, etc). Since this has nothing to do with her actual appointment, I then have to either fight with the AI to completely change out the program (to relevant ankle exercises) or I have to create a new program by hand (which is usually what I end up doing).

AI: That's a really insightful example of how AI can sometimes create more friction rather than efficiency when it's not aligned with specific workflows or policies. It sounds like the communication tasks work well because you maintain control over the process, but the program creation tool assumes too much without giving you the flexibility you need.

When you use AI for work, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to delegate complete tasks for it to handle independently?

User: I'm more likely to collaborate with it throughout a task. Since I mainly use it for patient communication I usually open up either my company dashboard (to view emails/texts) or go to the company app login (to view app chats) and scan through the new messages (could just be that day's messages, or it could be up to three days prior, just depending on how busy we are and if I had time to look at them the previous day). Any that are simple to answer and that I don't need help with, I will go ahead and complete (e.x. a parent requesting a note for school is easy since the notes are automatically generated and I literally just attach it to the email and send it). All others I will go through one by one and collaborate with the AI until I achieve and send a message I'm happy with.

AI: That workflow makes a lot of sense - you're essentially triaging the messages and using AI as a collaborative partner for the ones that need more thoughtful responses.

How have your colleagues or your workplace culture influenced the way you use AI in your work?

User: The way our company is set up I (as a CRS) work directly with a specific licensed chiropractor or physical therapist. In other words, each chiropractor/physical therapist hired by the company works out of a single clinic location, and they have a single dedicated CRS. We focus on the patients, and any insurance/billing issues, referrals/new patient appointments are outsourced to our company call center. I work with a licensed chiropractor, let's call him Dr. Snow. Dr. Snow describes himself as "technologically challenged", hates using the app, and really would rather not be bothered with technology at all (he's in his late 30s by the way). So while our company HQ sends emails and things encouraging us to utilize technology (including AI) as much as possible to make things more efficient and better track patient outcomes (which they incentivize by providing commissions based on this), Dr. Snow is not a fan. Since Dr. Snow is my "every day" I'm certainly less influenced to use it because of his personal preferences. If I didn't enjoy using it so much for my patient communication, I likely wouldn't use it at all, despite company HQ encouragement, just because of Dr. Snow.

AI: That's a really interesting dynamic - you have company headquarters pushing AI adoption while your direct working partner is resistant to technology. It sounds like you've found your own middle ground by using it for tasks you genuinely find helpful, despite the mixed signals around you.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Sure. There is a certain exercise for the shoulders/upper thoracic area that there isn't a good video for, but Dr. Snow uses all the time. Before trying to implement AI in program creation, I'd go in by hand, add the closest video, and then write a whole monologue describing in detail what the patient needed to do differently than the video. While this took some time, it was certainly less frustrating than when the company implemented AI in our program creation and it created its own detailed description of the exercise (of exactly what the video showed) and I now have to go in and create a separate note that basically says "ignore everything that is written and do this:". I also had to amend the monologue because there's only so many characters available for that section, so I now I have to explain to the patient what they're going to see on the app, what to pay attention to, and hope they remember it correctly.

AI: That's a perfect example of how AI can actually complicate things when it's not designed with your specific workflow in mind. It sounds like the AI created a solution that technically worked but ignored the nuanced way you and Dr. Snow actually practice.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: No, I don't actively consider this, because AI can't replace everything I do. AI can't socialize/create a relationship with Dr. Snow the way I do, and Dr. Snow is so particular about his exercises are done that an AI couldn't provide the hands-on patient correction I provide (e.x. even if it could visually see the patient, it can't provide tactile feedback, it can't demonstrate as effectively, etc...). As far as communication skills, I certainly do learn a lot from watching how it crafts my responses, but it wouldn't hurt my feelings if AI took over (there are plenty of other ways in which I can practice my communication skills).

AI: That's a really grounded perspective - recognizing that the human elements of relationship-building and hands-on patient care remain uniquely yours, while being open to learning from AI in areas where it can help.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I'd love for it to get to a point where it drafts an automatic response to emails/text/app chats based on prior history and understanding of company policies. Then I could just look over these and approve them, or adjust them if necessary, and it would make things super easy. If the AI could evolve to the point that it could incorporate all of the nuances of the way Dr. Snow and I operate for patient HEPs, that would certainly decrease our workload as well, but based on how things are going I don't see this happening for quite some time (as opposed to the automatic response thing, which I feel like could realistically happen).

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how AI works well when you maintain control and collaboration, but creates friction when it makes too many assumptions without understanding your specific workflow and policies.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, not that I can think of.

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about the balance between AI efficiency and workflow compatibility, and how workplace dynamics influence adoption, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candidly you described both the successes and frustrations - that kind of honest feedback is exactly what helps us understand how these tools actually work in real-world settings.

Have a great rest of your day!
