# Dialog 01242

**Transcript ID:** science_0082

---

Assistant: Hi, thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your research work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: That sounds good to me! I have no questions before we begin.

AI: Perfect! Let's dive right in then.

Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: A recent project I've worked on involved preclinical in vitro testing for cancer drug development. The cancer of interest is characterized by a specific aberrant fusion protein that drives oncogenesis. We want to target that fusion protein with a PROTAC drug. Our collaborator used their drug discovery ML model to perform in silico screening of a library of millions of compounds for their ability to bind to the fusion protein (and therefore serve as the ligand for building the PROTAC). A select few hits were synthesized and sent to us for in vitro validation. My work was to perform this binding validation via reporter assays and SPR experiments. A few of these hits showed promising activity, and the top hit was redesigned by our medicinal chemist for hypothetical improved binding and medicinal safety. Several of these proposed structural edits are being synthesized for repeat validation studies. The future steps would broadly be to use this ligand to build a PROTAC, test it in vivo, and if the results warrant so then it could move to the clinical testing phase.

AI: That's a fascinating project - thank you for walking me through that comprehensive workflow from computational screening all the way through to potential clinical applications.

Where in that process, if anywhere, have you experimented with using AI tools?

User: When designing my experiments, I sometimes used ChatGPT to double-check my mathematical calculations for very simple questions (e.g., dilutions). However, it was often wrong so my usage is minimal due to lack of trust. My coworker also experienced it hallucinating scientific citations.

Sometimes if I'm slightly unsure about something (such as being paranoid that I made an error in my math or a minor tangential fact) I will still use AI to quickly double-check, and if it agrees I take this as reassurance. If it doesn't, I will investigate further but not take the AI answer as an authority. This is the extent to which I use it.

AI: That's really helpful - you've identified a clear pattern in how you approach AI as a verification tool rather than an authoritative source.

For those mathematical calculations and double-checking tasks, tell me about how you decided whether to use AI versus your traditional approach of maybe using a calculator, asking a colleague, or looking something up yourself.

User: Well I always use a calculator to begin with, and I do my own research to reference multiple external protocols in the event I'm planning a novel procedure. I use AI to double-check my work on those days when I'm a bit tired/etc. and I want to make sure I'm not, say, off by a factor of 1000 accidentally (e.g., when my stock solutions are written in micromolar vs. nanomolar), or that I didn't forget to include a condition/control, etc.

My coworkers are all very busy and this isn't an appropriate situation to ask them to double-check my calculations. So I would say that as it stands, I don't substitute AI in for the calculator/research, but perhaps it somewhat substitutes for asking a colleague to lend a second pair of eyes. I mainly think of it as a supplemental tool in its own category.

There was a time when the AI was wrong and my work was actually correct, and this wasted time because I *did* go ask someone else to verify that.

AI: That makes a lot of sense - you're using it as a supplemental "second pair of eyes" when colleagues aren't available, but with healthy skepticism about its reliability.

Thinking about the parts of your research where you haven't used AI - like the actual experimental design for the SPR experiments, data analysis from your reporter assays, or interpreting your binding validation results - what's kept you from trying it there?

User: Due to the aforementioned accuracy/factuality problems I've witnessed firsthand from AI, it's not reliable enough yet to use for more complex problems like tailored experimental design or mathematically advanced data analysis. For example, I do all my data analysis using GraphPad Prism and by the time I'm done, I'm confident in my work. The problem with using AI here is that firstly, it's not trustworthy for the advanced math or conceptual understanding of the experimental context, so if I used it, I would have to double-check everything it did at which point I may as well have done it myself to begin with. This doesn't save time. Even if it were trustworthy, it doesn't integrate with my lab software tools such as GraphPad. For me to use AI for data analysis, it would have to either have integration with my software or replace its functionality altogether (e.g., the AI could handle finely controlled graph generation, organizing and storing my raw data, etc.).

However, I would use AI (if it were reliable enough) to research which formulas to apply in certain scenarios (for example, doing a novel drug combination experiment in which I need advice about applying Bliss and Loewe synergy analysis), or get its input about generating experimental design with sources cited.

AI: That's a really insightful breakdown - you're highlighting both the reliability barrier and the practical integration challenges with your existing tools and workflows.

We're about halfway through our conversation now. When you have used AI for those mathematical double-checks, how do you verify or validate what it produces, especially given that you mentioned it was wrong at least once?

User: Since I use it to double-check my preexisting work for the math equivalent of typos, I already know conceptually how to solve the problem and when the AI shows its work, I can usually see where it went wrong. It's often obvious stuff like confusing moles for molarity.

I recall once having a conversation with ChatGPT that amounted to ChatGPT claiming that it could not solve a dilution problem without knowing the molecular weight of DNA. It did not need this info, and when I asked it if it couldn't just answer the question via basic cross multiplication, it agreed and then solved the problem. So the AI could itself acknowledge its own error, but only when specifically prompted.

If I couldn't validate something the AI is saying via my own external research/knowledge then I would not put faith into the AI's explanation. I've also experienced it be very wrong about non-science topics.

AI: That's a perfect example - the DNA dilution issue really illustrates how AI can get confused about what information is actually necessary for a problem.

If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: Literature review, definitely! Combing through papers and keeping track of info from multiple sources can take a ton of time. If AI could be relied on to cite sources accurately, this would be a dream. For example, I'd love to be able to feed the AI a batch of scientific papers, ask it to scrape them all for data related to a specific compound, and then summarize that info for me in a tabled list with citations.

AI: That's such a compelling use case - being able to synthesize information across multiple papers and organize it systematically would clearly be a huge time-saver for your work.

Those are all my questions - your perspectives on using AI as a supplemental verification tool while maintaining healthy skepticism about its reliability were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: Thank you, and no, I have no other comments. Since many situations involve clearly correct/incorrect answers, I am very optimistic that AI can be trained over time to become quite accurate and powerful as a scientific research tool.

AI: Thank you again for sharing your experiences so openly. Your insights about the current trust barriers and the potential you see for literature synthesis really help us understand the nuances of how AI fits into real scientific work. The way you described using AI as a "supplemental tool in its own category" - not replacing your primary methods but serving as an additional verification step when colleagues aren't available - gives us valuable perspective on how scientists are thoughtfully integrating these tools.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Your contribution to our understanding of human-AI interaction in scientific contexts is greatly appreciated!
