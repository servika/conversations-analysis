# Dialog 00805

**Transcript ID:** work_0547

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Nope, I'm ready.

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I work as an IT tech in a braille factory. I'm the only "computer guy" at the company, so I end up more than just IT work. I'll typically do software dev for internal applications, mostly stuff to help visually impaired employees on the factory floor work with not-very-accessible machines better.

AI: That sounds like really meaningful work, helping make technology more accessible. 

When you're doing that software development or other IT tasks, how specifically does AI come into play? What kinds of things do you find yourself turning to AI tools for?

User: I'll typically use it for boiler plate code and for generating class and method structures when I'm first starting out a new project. Using an AI model really helps when I know what it is I want my program to do, but I do not yet know exactly how I'll be implementing the functionality.

AI: That's a really interesting way to use AI - almost like having it help you set up the scaffolding before you build out the specific functionality. 

Can you walk me through what that process looks like? When you have an idea for what you want the program to do, how do you typically interact with the AI to get that initial structure in place?

User: Of course. For example, I recently had to create some C# bindings to the LibLouis library, the de-facto standard C library for translating digital braille text to english and vice versa. I started by asking the AI which functions within LibLouis would be required for my application, and then asked it to produce a method signatures for each C# wrapper method around the LibLouis C functions. Then, once it did that, I asked the AI to make a super basic GUI using WPF for me so that I can test how the wrappers worked. From there, I took over the reigns and used the AI a little less.

AI: That's a fascinating example - you essentially used AI as a guide to navigate an unfamiliar library and then to quickly prototype a testing interface. 

You mentioned that you "took over the reigns and used the AI a little less" once you had that foundation. What makes you shift away from using AI at that point in the process? What's different about the work you prefer to handle yourself?

User: I find that once I start defining the overall structure of my application and fleshing it out, I use the AI less because I want to be very familiar with my own codebase as it becomes more complex. There have been times where I over use an AI when writing a relatively complex application, and even though the application works and the code is fine, I spend for more time trying to understand my own codebase when I want to make changes, since I kinda passed off some of the responsibility to the AI.

AI: That's a really insightful observation about maintaining ownership of your codebase. It sounds like there's a balance you've learned to strike between leveraging AI's help and ensuring you understand what you've built.

Can you tell me more about one of those times when you felt you over-used AI? What was it about that experience that made you realize you needed to pull back?

User: I remember once I entrusted the AI to code up a fairly complex fuzzy-string searching algorithm to aid LibLouis in the translation of english to a non-standard braille spec. I wanted to make a change to the algorithm to not only search for combinations of characters, but formatting of the characters within the document, because formatting is extremely important in braille text. I found that I really struggled to understand what the AI-generated algorithm was doing, so I ended up just starting over and writing the algorithm myself. When I had finished, I compared my algorithm to the AI's, and it was actually very similar. I spent more time re-writing the algorithm to actually understand what it did than I saved using the AI model  to generate it for me.

AI: That's a really telling experience - essentially the time saved upfront got eaten up later when you needed to modify something you didn't fully understand.

When you think about that situation now, was there something different you could have done in your interaction with the AI that might have helped you understand the algorithm better as it was being created? Or do you think some types of complex logic just need to be written by hand to truly grasp them?

User: I definitely think some types of complex logic are very hard for even the best of programmers to wrap their heads around without trying it out for themselves. However, what I maybe could have done was written the algorithm myself to begin with, then asked the model to improve upon it, or add the formatting recognition feature I wanted. That way, since I already understand how the algorithm works, it might've been easier for me to understand what the AI is changing/improving upon in my algorithm.

AI: That's a really smart approach - using AI more as a collaborator to refine something you already understand rather than asking it to create complex logic from scratch.

When you use AI for work, how do your colleagues or your workplace culture influence the way you approach it? Since you mentioned you're the only "computer guy" there, I'm curious if that affects how openly you can use these tools or discuss them.

User: Oh, to be honest, save for maybe one or two people out of about 100 at the factory, no one really understands what it is that I do. They just know that I get their computers and machines to work when they break and that I occasionally make some software that helps them. Thus, there is really no discussion or pressure regarding my use of AI models. I kinda just use them when they seem applicable, which is less often than not.

AI: That's interesting - you have complete autonomy in how you use AI since others don't really understand the technical aspects of your work.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation that created that feeling?

User: I think I was most satisfied with AI when trying to build a mobile port for one of the in-house web applications we have at the factory. I ended up using React-Expo-Typescript to program the application, since it was already programmed in typescript as a web-app. I found that I could very easily compartmentalize each individual feature of the application and simply ask the model to add GUI features consecutively until most of the application was GUI complete. Each time an individual feature was added, it definitely needed some manual tweaking to get it just right, but it was close enough that it saved me a bunch of time and effort.

AI: That sounds like a really effective use case - breaking down a larger project into discrete GUI components and having AI handle each piece. It sounds like you found a sweet spot where the AI output was close enough to be genuinely helpful but you still maintained control over the final implementation.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, especially given how useful it's been for things like generating boilerplate code and GUI components?

User: To be completely honest, I currently find it hard to believe that AI could take over areas in my field that I would genuinely care about. The AI was great at developing an GUI for my application, but that was an in-house application where the GUI really didn't need to look all that great, especially considering half of the people using it in the factory are blind. I don't believe the AI would be able to create an enterprise-grade application on par with that of an actual UX designer. Furthermore, I only let the AI touch the GUI of my application, not the business logic, because it performed nowhere near as well programming the business logic. Until a major paradigm shift occurs with AI, I simply see it as a global averaging machine; it can pump out great code that any average person can produce, not great code that exceeds the average.

AI: That's a really nuanced perspective - seeing AI as capable of producing "average" quality work rather than exceeding human expertise, especially in specialized contexts like yours.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself continuing to use it in much the same way, or do you think your approach might change as the technology develops?

User: I mean, sure, as AI advances, it will get better at producing code for complex problems that already exist, but I don't think it will be able to push the boundary for complex code that doesn't yet exist. Thus what is considered "average code" will expand. As AI gets better, I'll just use it the same way I currently do.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on maintaining ownership of your codebase and your view of AI as a "global averaging machine" that's great for established patterns but not for pushing boundaries.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Nope, I think that's it for me.

AI: Perfect! Thank you again for your time and for sharing your experiences so openly. Your insights about finding that balance between leveraging AI's help and maintaining deep understanding of your own code will be incredibly helpful for our research on human-AI interaction in professional contexts.

It's been really valuable to hear from someone working in such a specialized field with unique accessibility considerations. Thanks again, and have a great rest of your day!
