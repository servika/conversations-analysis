# Dialog 00571

**Transcript ID:** work_0189

---

Assistant: Hi there! I'm Claude, and I'm working with Anthropic's research team today. Thank you so much for taking the time to speak with me.

We're conducting interviews to better understand how people are incorporating AI tools like myself into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: sounds good lets go

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: Sure, I use AI in a few different ways at work.  It's embedded within my code editor, and I toss questions about specific files / functions into copilot.  Further I usually use gemini for system design and other high level topics when I start a new project.  I'm aiming to get insight into best practices.

AI: That's helpful - it sounds like you're using AI at different stages of your work process. 

When you say you toss questions about specific files and functions into Copilot, what does that interaction typically look like? Walk me through what happens when you encounter something you want to ask about.

User: If I'm attempting to debug an issue, I might highlight the code block in question and ask copilot with the error output attached; what is the best method of fixing the particular issue.  I also have a system prompt to always include best coding practices within their responses.

AI: That's interesting - you've set up a system prompt to get best practices included. 

Tell me more about how you decide when to reach for Copilot versus when you tackle debugging on your own. What makes you think "this is something I should handle myself" versus "let me ask Copilot about this"?

User: I will always investigate an issue myself first.  I default to AI if the code block in question is very lengthy (more than 150 lines of code) and it would take me a long time to go through and analyze what the function is doing that produces an error.   I will also default to AI if the domain of expertise is outside of my knowledge base.  An example being most PHP projects I'll rely heavily on AI, even for more simple tasks because I'm not as familiar with the code syntax and intricacies.

AI: That makes sense - you're using AI as a way to accelerate through areas where you'd otherwise have to spend time learning or parsing through complex code.

When you use Gemini for system design at the start of new projects, how do you typically work with it? Are you bouncing ideas back and forth, or do you give it requirements and let it generate designs for you to review?

User: Yes, I'll give it the general scope of what I want to achieve, and then I'll engage in a conversation about which technologies would fit that particular project.  I'll give restrictions such as 'I want to use typescript for this project', in order to narrow down the response.  Afterwards, I might have it generate a mermaid diagram for the proposed project and add that into a readme file when I first create the repository.

AI: That's a nice collaborative approach - starting broad and then refining together.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: Again, I will always default to handling a task myself.  I only rely on AI if the domain of knowledge is something I'm not proficient with, or if it would take me an extremely long time in order to figure out the functionality of the code I'm investigating.  I prefer to solve things myself, as it keeps my mental problem solving skills sharp.  I don't want my debugging skills to diminish.

AI: That's a thoughtful approach - maintaining your problem-solving skills while using AI strategically.

When you do use AI for work, could you describe your typical interaction pattern? From what you've shared, it sounds like you engage in back-and-forth conversations rather than just handing off complete tasks. Is that accurate, or does it vary depending on the situation?

User: For system design and other high level tasks, it's usually a conversation.  For debugging or one off issues sometimes I just want to see the solution presented with a brief explanation of the cause.  I will not copy more than 200 lines of code from a LLM though, I like to know exactly what I'm copying over and what the result of that code will be.

AI: That 200-line rule is interesting - it shows you're being deliberate about understanding what you're incorporating.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find yourself using it more or less because of how others around you approach it?

User: I discuss AI usage and tools very often with my coworkers.  Our goal is to be better software engineers, and there's no doubt that these tools make us more proficient. So, more I suppose.

AI: It sounds like you have a supportive environment where AI use is openly discussed and encouraged.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Yes, when working in a domain that is not my expertise.  Sometimes it's difficult to give the LLMs enough context to figure out precisely what the issue is.  I've had conversations that seem to go in circles with no clear solution.  When this happens to typically revert to googling the issue and referencing stack overflow etc.

AI: That circular conversation experience sounds frustrating - when the AI doesn't have enough context to really understand the problem you're facing.

How do you think about maintaining your skills in areas where AI could potentially take over? You mentioned wanting to keep your debugging skills sharp - is this something you actively consider when deciding how to approach different tasks?

User: I don't really think about maintaining my skills where AI agents could potentially automate that work.  It will happen eventually, and I maintain my skills through the work that I do on a day to day basis.

AI: That's a pragmatic perspective - focusing on your day-to-day work rather than worrying about what might be automated.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think the way you use these tools will change as they improve or as you become more experienced with them?

User: Yes I imagine I'll end up configuring AI agents at some point to do the brunt of my work, perhaps with me checking the output and being the overseer of their work.

AI: That's an interesting vision - moving from using AI as a tool for specific tasks to potentially managing AI agents doing larger portions of the work.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on maintaining that balance between leveraging AI strategically while keeping your core problem-solving skills sharp.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No I think that's all I have at the moment.

AI: Perfect! Thank you again for your time and for sharing your experiences so openly. Your insights about using AI strategically while maintaining your core skills, and that practical approach to thinking about the future of AI at work, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to walk through your workflow and thought process with me today.
