# Dialog 00074

**Transcript ID:** science_0085

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: That sounds good and I have no questions

AI: Great! Let's dive in then.

To start, I'd love to hear about your work. Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: Recently I worked on a project that concerned the use of variational autoencoder models on galactic spectra. It has been suggested that models of this type can be used to facilitate novel scientific discovery by focusing on what details a model chooses to learn. The variational autoencoder was then designed and trained on some synthetic galaxy spectra and the results of what it learnt were analysed.

AI: That sounds fascinating - using the model's learned representations as a lens for discovery is a really interesting approach. 

Can you walk me through what the actual process looked like for you? I'm curious about the day-to-day steps - from when you first had this idea about variational autoencoders and galactic spectra, all the way through to analyzing what the model had learned.

User: The first step of the process was learning about variational autoencoders, as I had not used them before. The idea was suggested by a professor in my department who had carried out some earlier work applying the models to other data. Once I had necessary background knowledge I then built a simple variational autoencoder model on the galactic spectra. Once this was working, the focus could then be on refining the model to improve its performance. This included adding more and more complex layers to the model and refining the hyperparameters for training. The final trained model was good at recreating the spectra, as an autoencoder is required to do, and largely successful at disentangling the learned features. The results were analysis by testing how independent the dimensions of the learned representations were, how much the dimensions correlated with physical parameters that were set during the generation of the synthetic data, and exploring how the spectra change by just adjusting one dimension at a time and looking for physical reasoning behind what is happening. The dimensions did not have particularly strong correlations with the physical parameters but the adjusting of one dimension at a time did appear to have some physical grounding. While we did not perform it for this project, further analysis of features the model learns that do not have physical reasoning could be the path towards using these types of models for novel scientific discovery

AI: That's a really comprehensive workflow - from learning the fundamentals all the way through to that intriguing analysis of the learned dimensions. I'm particularly interested in how you approached the learning phase and model building.

Where in that process, if anywhere, have you experimented with using AI tools to help with your work?

User: AI tools are often useful for giving a straightforward explanation of what certain parameters or processes mean when it's hard to find a straight answer on Google. AI tools can also be useful for the coding stage, especially when errors are occurring and you are unsure why. Overall, my use of AI tools in this project were quite limited but they were certainly useful when they needed to be

AI: That's helpful - so AI tools served more as a reference and troubleshooting resource for you. When you mentioned using them for explanations of parameters or processes, tell me more about how you decided to turn to AI versus other sources like papers, documentation, or colleagues.

User: Often using AI in these instances saved time. You could get an answer to your queries straight away, rather than having to comb through a reference manual or waiting for a colleague's response

AI: That makes sense - the immediacy is clearly valuable when you're in the middle of working through something. 

Thinking about the parts of your research where you haven't used AI - like the model design choices, the hyperparameter tuning, or analyzing those learned dimensions for physical meaning - what's kept you from trying AI tools there?

User: The model design and hyperparameter tuning were best performed by actually training the model and seeing what makes a difference. Training machine learning models like this is often very nuanced and the answers that AI might give you to try and improve them are often generic and not applicable to your project, especially one as specialised as this. For this reason, trial and error was the best way to go, rather than blindly trust the suggestions of an AI tool. In terms of analysing the learned dimensions, an AI tool might be helpful but we did not consider using one at the time. This part of the project is where the actual physics comes in, rather than just the technology. I think it's fair to say that the physical analysis is best done by the actual physicists that know the subject inside and out, rather than an AI tool that just predicts what the next word in a sentence should be.

AI: That's a really insightful distinction you're making - between the more generic technical aspects where AI can help versus the domain-specific, nuanced work that requires your deep physics knowledge and intuition.

When you have used AI for those straightforward explanations or coding issues, how do you verify or validate what it produces? What's your process for making sure the information is reliable?

User: Coding issues are easy to test as you can just implement the model's suggestions into your program and check if it does indeed work. More factual information such as explanations are often answered better by the AI tools as they just need to regurgitate information rather than follow a logical process.

AI: That's a practical approach - the immediate feedback from code testing definitely makes validation straightforward there.

We're about halfway through our conversation now. Looking ahead, if you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: Often in scientific research we have a great idea and make progress with said idea but reach a wall where we don't know how to proceed. If an AI model could help with this aspect of research, it would be fantastic. The problem is that often the best way forward is something that has never been done before so it's unrealistic to expect an AI tool to be consistently helpful for this.

AI: That's such a compelling point - you've identified what would be the holy grail of AI assistance, but also precisely why it's so challenging. The very nature of novel research means you're venturing into territory where there isn't existing knowledge for an AI to draw from.

Those are all my questions - your perspectives on the distinction between generic technical help versus domain-specific expertise, and especially that insight about hitting research walls where the path forward is truly novel, were particularly insightful. 

Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: That is all, thanks

AI: Thank you so much for sharing your experiences so openly. Your insights about how AI tools serve as efficient reference resources while the core scientific reasoning remains firmly in the domain of human expertise really help us understand the nuances of how AI fits into real scientific work. That distinction you made between areas where AI can provide generic support versus where deep domain knowledge is irreplaceable was especially valuable.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!

User: No more questions

AI: Perfect! Thank you again for participating in this research - your perspectives have been really valuable for helping us understand how AI integrates into scientific workflows. Have a great day!
