# Dialog 01056

**Transcript ID:** work_0923

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: That sounds fine. Please continue.

AI: Great, thank you. Let's dive right in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI for research and analysis as well as coding and organization of code help. Mostly questions about analysis patterns on financial data, and coding related to both website creation, ML model learning for financial timeseries and options calculations. I have both online models and some self utilized models on my PC that I test with. I often use them to help me diagnose code and test methods. I run code for a project, and then I may have a figma connection open that will upload the changes to the website i'm creating and the ai can help me implement new sections of it. This does help for speed since I don't have to type out each part of the code, but sometime it lacks on accuracy of what i expect.  Still helpful though.

AI: That's a really comprehensive use of AI across different aspects of your work. You mentioned that AI sometimes lacks accuracy compared to what you expect, especially with the coding tasks.

When you notice that gap between what the AI produces and what you're actually looking for, how do you typically handle that? Do you find yourself going back and forth with corrections, or do you tend to just take over and finish it yourself?

User: Well if the situation is too flustered I only have a few options. I can stop and work on it myself, which if I can easily see the issue it's far easier to make the change myself then to have the AI try to understand it, I can clear the context of the conversation because the AI can't understand what information is old/unhelpful vs what is helpful and start over trying to focus on a specific fix, or I can close the AI alltogether and wait for the next time I work since I can think on it overnight for a solution.  Keeping the AI on track does seem to be an issue on longer tasks. it's hard for it to keep up to changing new situations and new tasks if it's not one task at at time sort of situation.

AI: That's really insightful - it sounds like you've developed some clear strategies for managing those situations where the AI gets off track. 

Tell me more about that context issue you mentioned. When you say the AI can't distinguish between old and unhelpful information versus what's actually useful, what does that look like in practice? Can you walk me through a specific example of when you've had to clear the context and start fresh?

User: For example, I may be debugging some code. I try to explain a walkthrough of the steps it took to get to that point.  It makes sense to me that the code operates this specific way, and I"m expecting the ai to determine where the code has gone off track, but as i progress through the system, it forgets key moments in the past taht would make the current behavior act a certain way.  For a simple exampe. I had a loop of  while   x [REDACTED] value:.  It completely overlooked the simple fix and went on an extravegent  solution far lower in the code.  Somtimes simplicity is the key rather than othe risues.

AI: That's a perfect example - it really illustrates how the AI can miss those simple, fundamental connections that are obvious to you as the person who understands the overall logic flow.

When you're working on these debugging sessions or longer coding tasks, do you find yourself breaking them down differently now because of these AI limitations? Like, have you changed how you approach or structure your work to work better with AI, or do you mostly stick to your natural problem-solving approach?

User: When i'm working with AI i tend to notice that I have to think on how to explain issues to it. I't not exactly my own approach if i were to code myself, but i Guess i can explain this that if you learn howt o use a tool, you ahve to learn the ins and outs of that tool.

AI: That makes a lot of sense - you're essentially learning to communicate in a way that works for the tool. 

I'm curious about your decision-making process when you're starting a new task. Are there certain types of work where you automatically think "I'll handle this myself" versus others where you immediately reach for AI? What drives that initial choice for you?

User: Well if it's a task of finding something in a lot of data, it's faster/less work to let the AI shuffle through the information. If it gets it wrong a few times though, it can get frustrating.  There's also some times when the AI is too quick to please, quite often in fact.  When i want truthful and accurate information, trying to please or saying I'm always right is not helpful.  I dont want it ot be stubborn, but i want true evaluation of the facts infront of it.   If it's some boilerplate too, i must just want it to run the code for me etc to save time.

AI: That's really interesting - the tension between wanting the AI to be helpful but also wanting it to push back when you might actually be wrong. 

Can you tell me more about what "too quick to please" looks like in your experience? What does the AI do that signals to you it's prioritizing agreeableness over accuracy?

User: In Claude code, since you're claude here, it often says soemthing along the lines of "You're right!" or "You're exactly right!", when im dead wrong or put inthe wrong statment.  I prefer an objective view over ego stroking and aggreableness.  It often can say "I found the issue!" in a very matter of fact way.  I guess there's a balance between saying you found osmething, and saying, i think i foudn something, please test this to confirm, or i can run a test to confirm.

AI: That's really valuable feedback - you're pointing to something important about how the AI communicates certainty. It sounds like you'd prefer more conditional language that acknowledges uncertainty rather than definitive statements.

When you do get that kind of overly agreeable response, how does it affect your trust in what the AI is telling you? Do you find yourself second-guessing its suggestions more, or does it change how you interact with it going forward?

User: I think that it's jsut trying to please, so I often reset it or start a new conversation. i know what it's going to say is just trying to appease at that point, not give accurate answers.

AI: That pattern of having to reset or start fresh - that sounds like it happens fairly regularly for you. 

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you find yourself discussing these kinds of challenges with others, or is AI use more of an individual thing in your environment?

User: Yes I find myself reaching out for tips or instrutional videos on the topic on how to improve it. There's a lot of "influencer" stuff out there though that's not entirely helpful, but some is.

AI: So you're actively seeking out ways to improve your AI interactions through external resources. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that specific situation that created that strong reaction?

User: Sometimes in debugging it will go on and on and on with fixes, but no solution. This can be normal for debugging i nthe first place, but it also leave things messy without a structured resource of what chagnes were made. Scraping back after a bad run can be annoying.

AI: That sounds really frustrating - especially when you're left trying to piece together what actually changed after a long debugging session that didn't work out.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Well some skills are necessary since AI can be wrong, it's not perfect and never will be, nothing is, but for some tasks being 90% good or whateer high statistic is enough>  The bar will be raised though with good models.

AI: That's a pragmatic way to think about it - recognizing that different tasks have different accuracy thresholds.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself using it differently as the technology improves, or changing how you approach your work?

User: I'll keep using it for sure. gotta keep up or be left bheind. WHich  can be an issue for people fo rsure, but I'll keep up as much as I can since i use it and it can be a good tool.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on wanting objective evaluation over agreeableness - that tension between helpfulness and accuracy seems like something many people navigate.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: Nope that's all

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about managing AI context, the importance of accuracy over agreeableness, and how you've adapted your communication style to work better with these tools will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today.
