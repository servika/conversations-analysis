# Dialog 00813

**Transcript ID:** work_0557

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Sounds good

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I work as a psychologist primarily completing mental health evaluations. As a part of that work I compile background information, details of clients psychological functioning, and test data to provide diagnoses and recommendations associated with those diagnoses.  I often use AI to help me find alternative ways of saying things and to help me formulate recommendations for the evaluation reports I write.

AI: That's really interesting work. When you say you use AI to help find alternative ways of saying things and formulate recommendations - can you walk me through what that process typically looks like for you? How do you actually interact with the AI during report writing?

User: I'm usually writing the report and I'm interpreting test results and I'll come across language provided by the test that is not commonly used, is psychology jargon, or, just orherwise would be unadvisable to use in a report for a particular client (e.g. they have a learning disability). I will speak directly to gemini or pull up chat gpt and ask for synonyms (e.g for a word like self-abasing).  In other cases, I'm completing the recommendation section and I want ideas as well as a quick way to have a set of recommendations without having to write the sentences myself.  For example, I'll ask gemini or chatgpt to provide me a list of recommendations for adults with hyperactivity/impulsivity associated with ADHD.

AI: That sounds like you're using AI as a writing assistant in very specific moments. When you get those recommendations back - like the list for adults with ADHD hyperactivity - what do you do with them? Do you typically use them as-is, or do you find yourself modifying them in some way?

User: I usually end up picking and choosing which ones to use based on the client.  I'm not necessarily changing the wording of a recommendation, just not sellecting the whole list wholesale

AI: That makes sense - you're curating based on what fits each individual client. 

I'm curious about your preferences when working with AI. Are there certain parts of your evaluation process that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: When it come to presenting quantitative data in tables (i.e. the test scores), I already have templates for this, so I don't need to creat anything, just imput the numbers.  Also, in a general sense this information is health data, so I can't just imput everything into an AI model and request a report back.  I think that there are HIPAA compliant models out there, but I haven't looked into those much yet.

AI: That's a really important distinction about the health data and HIPAA compliance. It sounds like you're being quite thoughtful about what information you share with AI tools.

Beyond the privacy considerations, are there other aspects of the evaluation process - maybe the interpretation of test results or forming diagnoses - that you feel should stay in your hands rather than involving AI? What drives those decisions for you?

User: There is a lot of clinical decision-making that goes into conceptualizing problems and labeling them with a diagnosis.  Only I will have sat with the client, observing and interacting.  Nonverbal communication can add a lot to understanding a person. The final decision on diagnoses should be mine, but im open to AI tools that can make the process leading there easier/faster.

AI: That's a really clear way of thinking about it - maintaining ownership of the clinical judgment while being open to tools that can streamline the process. 

When you use AI for those tasks like finding synonyms or generating recommendation lists, could you describe your typical interaction pattern? Are you more likely to go back and forth with the AI, refining what you need, or do you tend to ask for something specific and then work with what it gives you?

User: Sometimes I will also ask for a definition in addition to the synonym or perhaps clarifying an age range for my recommendations request if I didn't do so.  Most of the time Im under a time crunch and I dont have the time to spend reinventing the wheel by formulating my own recommendations,cso I need something quick that i can just grab and go, so to speak

AI: That time pressure really shapes how you use it - needing something you can "grab and go." 

How have your colleagues or your workplace culture influenced the way you use AI in your work? Are others in your field talking about or using these tools, or is this something you've explored more on your own?

User: I know many people are exploring how AI can be helpful with report writing, as it is quite an endeavor, and one that is done regularly (I write 2 to 4 reports a week and they are 10 to 15 pages long). I think some have built a business out of providing AI tools for my specific job.  Talk about this has led me to use AI more and look forward to the time it might save me in the future.

AI: That's a lot of reports! It sounds like there's a real shared interest in your field around finding ways to make that writing process more efficient.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I'm trying to remember details of this, but in the example I mentioned above about asking for recommendations for adults experiencing hyperactivity/impulsivity, I was pleasantly surprised to have a list of items I could use.  I have a lot of recommendations focused on the inattentive symptoms of ADHD, but not as many for the other symptoms, so i think I appreaciated that I qas given a list that I could use and I didnt need to clarify my question or reword the recommendations.

AI: That sounds like a really satisfying experience - getting exactly what you needed without having to go back and forth. It filled a gap in your existing resources too.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider as you use these tools more?

User: Maybe, but I think sometimes it can be helpful to be provided with a way to phrase things. Hopefully, I then can take it and incorporate it into future reports.

AI: That's an interesting way to think about it - using AI as a way to expand your own repertoire rather than replace your skills.

Looking ahead, how do you envision your relationship with AI at work evolving? What would you want to see change or improve?

User: I'd love to be able to provide data and background info and have it spit out a summary. Synthesizing everything takes the most time,  if I could have something written that I could just make small edits too, that would save so much time and mental energy.  I'll be on the lookout for ways to do this ethically.

AI: That would be a significant time-saver - having something handle that synthesis work while you focus on the clinical judgment and final review. The ethical piece clearly remains important to you as you think about future possibilities.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated how you've thought through the boundaries - maintaining the clinical decision-making while being strategic about where AI can help with efficiency.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: This was fun! Thank you!

AI: Thank you so much! I really enjoyed our conversation too. Your insights about balancing efficiency with clinical responsibility, and how you're navigating the privacy considerations while still finding practical ways to use AI, were incredibly valuable for our research.

Thanks again for your time and for sharing your experiences so openly. This will be really helpful for our understanding of how AI is being integrated into professional work, especially in fields with such important ethical considerations like yours.

Take care!
