# Dialog 00069

**Transcript ID:** science_0077

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your research work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer here—we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: That sounds good to me, and I have no questions to ask at the moment.

AI: Perfect, thank you! Let's dive right in then.

I'd love to start by getting a sense of your research background. Could you walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: Are you for asking a research project I've worked on with or without AI?

AI: Great question! I'd like you to just pick any recent research project that comes to mind - whether it involved AI or not. I'm interested in understanding your natural research process first, and then we can explore where AI has or hasn't fit into that workflow.

So just think of a project that's representative of the kind of work you do, and walk me through how it unfolded from start to finish.

User: Recently, I was working through a challenging set of electromagnetism problems for my University Physics II course containing Coulomb's law calculations, vector analysis, and gravitational field problems that we quite complex. Rather than struggling through them alone, I started using tools like Gemini and NotebookLM to help verify my work and understand the methodology. 

What I discovered is the AI would frequently make calculation errors, especially on multi-step problems. So I developed an approach where I'd work through each problem myself first, then use AI to check my process. When we disagreed, I'd have the AI show me its complete step-by-step work, and I'd identify where it went wrong and correct it.

This iterative process actually strengthened my understanding significantly. Instead of just getting answers, I was constantly validating methodology and catching errors - both mine and the AI's. It forced me to really understand the underlying concepts because I had to be able to identify when the AI made mistakes.

I use a similar approach in my Java programming class, where I'll use AI to help debug code or verify my logic, but I always review and understand what it's suggesting before implementing anything.

The result is that I'm much more confident tackling difficult technical problems. I have this powerful tool to help me work through complex calculations and check my reasoning, but I'm still doing the critical thinking and learning. It's enhanced my problem-solving process without replacing my need to truly understand the material.

AI: That's a really interesting approach you've developed - using AI as a verification partner rather than just for answers. I'm curious about that decision-making moment you described.

When you're working on a new problem, tell me more about how you decide whether to tackle it completely on your own first versus bringing AI in at different stages of the process.

User: I always start by working though problems completely on my own first. This helps me identify what I can actively recall and which concepts I genuinely understand versus what I might just think I know. I want to see how far I can get using my own knowledge before bringing in any external help. 

Once I hit a clear roadblock, whether its a calculation I can't figure out or a concept I'm not grasping, that's when I use AI. But I make sure to be strategic about it. I don't just ask for the answer, I ask to help me understand the specific step where I got stuck.

What I find that is helpful, is that I keep track of these problem areas. I'll make notes about the concepts or types of questions that consistently trip me up, and then I use notes as sort of a study guide to create targeted study sessions with NotebookLM. I'll feed it textbook sections or class notes on those specific topics and have it generate practice problems, explanations, and concept videos focused on my weak points.

This approach means I'm not becoming dependent on AI to do my thinking for me. Instead, I'm using it to identify gaps in my understanding and then actively work to fill those gaps. The AI becomes a diagnostic tool as much as a learning aid.

AI: That diagnostic approach is fascinating - you're essentially using AI to map your own knowledge gaps. I'm really curious about something you mentioned earlier about the AI making calculation errors.

Tell me more about how you've learned to identify when the AI is making mistakes, especially in those complex multi-step physics problems.

User: I noticed the AI tended to make more errors whenever a problem had multiple parts, more than 3 but in my case more than 8 steps, from interpreting the concept to writing the correct expressions, finding magnitudes, simplifying, and then applying everything together to find the solution to the final exercise of the question. When I'd submit a screenshot of several parts at once, the AI often missed simple sign conventions, gave numeric answers when only the expression was requested, or even repeated the same wrong result I'd gotten. But when I provided a screenshot of just on part I'd struggled with, its accuracy improved significantly.

Even then, it sometimes insisted on incorrect answers I'd already flagged, as if it was rising to offer a solution rather methodically working through the math. My takeaway is that it doesn't reliably track which of its suggestions have been ruled out and possibly lacks the persistent memory or guardrails to avoid repeating mistakes.

AI: That's a really insightful observation about how AI performance changes with problem complexity and scope. You've clearly developed some sophisticated strategies for working with these limitations.

Thinking about the parts of your coursework where you haven't used AI - are there areas where you've deliberately chosen not to experiment with it, and what's driven those decisions?

User: That's a great question. I set clear boundaries around AI to preserve essential learning steps.
When I'm first encountering new topics in electromagnetics or Java fundamentals, I work through textbook examples and exercises entirely on my own. That initial struggle builds problem-solving intuition and a solid foundation.

I also avoid AI during actual practice tests or timed quizzes; I rely solely on my own recall so I know I can perform under exam conditions.

Once I've mastered the basics, I do turn to AI (especially NotebookLM) to generate targeted study materials. I prompt it to create practice problems, flashcards, and concept summaries using active-memorization techniques tailored to my weak areas. But I only use those AI-generated materials for studying, never during the practice tests themselves.

Similarly, in my Java class, I practice debugging and logic checks independently until I can spot simple errors on my own. Then I'll use AI to help verify more complex code segments and reinforce my understanding.

Overall, AI enters my workflow only after I've given a problem my best effort—it reinforces and accelerates my learning without replacing the core discovery and problem-solving process.

AI: You've really developed a thoughtful framework for balancing independent learning with AI assistance. We're about halfway through our conversation now, and I'd love to explore one more aspect of how you use these tools.

When you do use AI for verification or to check your work, how do you actually validate what it's telling you? Walk me through your process for deciding whether to trust or question what the AI produces.

User: When I use AI to verify my work, I follow a simple three-step check. First I compare its solution to my own notes or the textbook. Next I rework the key steps by hand to see if I reach the same result. Then I submit the AI's answer in the online coursework to confirm it gives a correct result. If it does, I ask the AI to walk me through its method step by step without giving the final answer. If it's wrong, I point out the errors and ask it to try again. Only when I can reproduce its solution myself do I trust it. This process helps me catch mistakes and ensures I understand every step.

AI: That's a really systematic verification process - it sounds like you've become quite skilled at being a critical evaluator of AI output.

For our final question: if you could wave a magic wand and have AI help with one aspect of your coursework that it currently doesn't handle well, what would that be and why?

User: I wish AI could provide truly interactive visualizations and guided thought experiments for any course I'm taking (currently Calculus III, University Chemistry, Java, or Physics II). For example, I'd like to adjust variables in real time and see step-by-step illustrations of how those changes affect the outcome. Right now, AI gives me equations and solutions, but it doesn't bridge the gap between the math or code and the underlying intuition. Having those interactive tools would help me catch misconceptions quickly and build a much stronger conceptual understanding.

AI: Those are all my questions - your perspectives on developing that systematic verification process and using AI as a diagnostic tool for your own learning gaps were particularly insightful. 

Is there anything else about AI in your coursework that we haven't touched on that you think would be important for us to understand?

User: I do not believe so.

AI: Thank you again for sharing your experiences so openly. Your insights about developing that three-step verification process and strategically using AI to identify and fill knowledge gaps rather than replace your own thinking really help us understand the nuances of how AI can fit into rigorous academic work.

Your approach of maintaining clear boundaries while still leveraging AI's strengths shows a level of intentionality that I think will be really valuable for us to understand. If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out.

Thanks again for your time today!

User: Thank you!

AI: You're very welcome! Have a great rest of your day, and best of luck with your Physics II, Calculus III, Chemistry, and Java courses!
