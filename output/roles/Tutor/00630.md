# Dialog 00630

**Transcript ID:** work_0272

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: No questions yet, let's get started!

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: The most frequent use of AI is in drafting emails to my support team at work. Unfortunately, the way my job is structured, I am only paid for actively tutoring students; I don't get paid at all for administrative tasks such as emailing my coaches or support team unless I go through an equally time-consuming process for requesting extra time (which unironically is also NOT paid time). I use AI to draft quick emails to my support team so that I don't have to use my own unpaid time to ask work-related questions. Occasionally, I also use AI to ask more in-depth questions about the work that I do if I have a question about literacy principles, word history, word categorization, or reading level expectations. I have also used AI in the past to create word lists and reading passages for my students, but less so now as the company I work for has switched to a very script-heavy model of tutoring.

AI: That's really interesting - it sounds like AI has become a practical solution for navigating some challenging aspects of your work structure. 

When you use AI to draft those emails to your support team, can you walk me through what that process typically looks like? Do you give it specific information about your situation and let it handle the full email, or is there more back-and-forth involved?

User: If by "challenging" you mean "unpaid labor", yes haha!

AI: Ha, yes - that's exactly what I meant! It sounds like you've found a clever way to handle that unpaid labor situation.

So when you're drafting those emails to your support team, what does that process typically look like for you? Do you give AI the key details and have it write the full email, or is there more back-and-forth between you two?

User: The process is usually providing key details, let the model draft the email, and then copy/paste it into my work platform with minor edits. I can give you an example- I might say "draft an email to my coach requesting 15 minutes of extra time for rescoring the progress monitoring activity on [date] since the scoring platform was down during administration of the assessment". I'll take the created email, plug in names or change verbiage as needed, then send it. It saves me several minutes' worth of time on tasks like that.

AI: That makes perfect sense - you're essentially using it as an efficient first draft generator. Those several minutes really add up when you're not being compensated for that time.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: I prefer to handle actual literacy tutoring decisions myself. While I work for a very data-driven tutoring company, sometimes the personalization, especially struggles that have more to do with attention, confidence, or personality  than actual ability, get "lost" in the numbers. My concern in using AI is that it doesn't capture the nuance and subtleties of working with children, especially children dealing with non-reading struggles such as poverty and challenging living conditions.

AI: That's a really thoughtful distinction. It sounds like you see a clear line between the administrative efficiency tasks and the human-centered aspects of your work with the children.

When you mention those nuances - like attention, confidence, or the impact of challenging living conditions - can you tell me more about how you navigate those situations? What does that personalized decision-making look like in practice?

User: Well, I'm lucky enough to have a background in psychology, both BA and MA degrees. I use my clinical training to essentially observe the "whole child", not just performance on specific metrics, and make my decisions based on observable patterns. Sometimes that looks like backing off of a challenging activity that the child just doesn't have the "spoons" to give on that day, sometimes it looks like stopping our learning activity to address our collaborative relationship.

AI: That clinical training clearly gives you a valuable lens for seeing what's really happening with each child beyond the data points. 

When you do use AI for those literacy-related questions you mentioned - like word history or reading level expectations - how does that interaction typically unfold? Are you using it more as a quick reference tool, or do you find yourself having deeper discussions with it about these concepts?

User: Usually more of a quick reference tool. I've realized, by working with people in the public school sector, that those with Masters degrees in reading have significantly more background knowledge about reading than I do. It doesn't get in the way of my being able to tutor students, but sometimes I'm truly curious about the "why" behind word choices, sequential learning, what fully constitutes a "reading level", that sort of thing.

AI: That's a great example of using AI to fill in knowledge gaps and satisfy your curiosity about the deeper principles behind your work.

When you use AI for work, could you describe your typical interaction pattern? From what you've shared, it sounds like you tend to give it specific tasks - like drafting that email or answering a literacy question - rather than having ongoing conversations. Is that accurate, or do you find yourself collaborating with it more throughout certain tasks?

User: I do tend to give it specific, practical tasks, primarily administrative ones. If I realize that I need to communicate with my support team, I'll ask a model to draft an email or message about a specific subject, provide details such as dates or topics, and let the model work its magic. If I can get the model to make a quick change to the email/message I may get the model to make a minor edit or two, but my conversations don't typically last more  than a few turns. In terms of knowledge-seeking questions I have, I may ask for examples or "why not this [example]" as follow up questions, but again I don't have lengthy conversations about the work that I do.

AI: That's really helpful - so you're using it more as a targeted tool for specific needs rather than as an ongoing collaborator throughout your workday.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you talk about AI use with other tutors, or is this something you've figured out on your own?

User: I've figured it out on my own. The only communication I have with the other tutors on the platform is a heavily policed forum, where toxic positivity rules supreme and we aren't allowed to speak on the challenges of our unpaid labor without losing our jobs. That said, that same workplace culture is the reason I outsource to AI to complete some of my work, as I am not okay with working for free- especially when I've worked for other organizations that have no problem with paying me for administrative and professional development work.

AI: That gives me a much clearer picture of the context you're working in. It sounds like AI has become a way for you to maintain your professional boundaries in a pretty restrictive environment.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I get a lot of satisfaction from the email/message generation that AI provides, as it takes the mental load off of me to create those messages. In terms of frustration, I have had times in the past where specific AI models have really, really dropped the ball on creation of tutoring materials; some models have shown a complete inability to do simple literacy tasks such as counting syllables or creating lists of rhyming words.

AI: That's such a clear contrast - AI handling the administrative communication really well versus struggling with what should be basic literacy tasks that are core to your work.

When those models failed at the syllable counting or rhyming words, what did that experience feel like for you? Did it change how you think about where AI fits in your work?

User: To be honest I got a good laugh at how badly the models bungled simple literacy tasks, particularly phonemic awareness ones. I'm sure the skill sets are improving, but for now I'm perfectly okay with restricting my AI work-related interaction to message generation and knowledge-based questions.

AI: That's a great way to put it - finding the humor in those failures while being clear about your boundaries.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, especially given that you're already delegating some administrative tasks to it?

User: I don't really *actively* consider it, but I'm aware that tutoring, like many other fields, is moving toward automation despite it being an imperfect option for working with live human beings. Current platforms that only use machine-based decision making aren't as effective as live, in-person tutoring (lots of research in the last couple of years supports it), so in the immediate future I'm not too worried.

AI: That's a practical perspective - staying aware of the trends but not losing sleep over it, especially when you can see the research backing up the value of human interaction.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think you'll expand how you use it, or do you expect to keep it pretty much in the same lane it's in now?

User: It's hard to say- if you'd told me 20 years ago that I'd be using AI to set my schedules or draft emails, I would have called you crazy haha! I'll probably use it more in both my professional and personal life, I'm open to new experiences and opportunities, but I'm also humble enough to know that I can't see into the future to fully understand just how helpful AI could truly be.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how you've carved out clear boundaries - using AI as a practical solution for unpaid administrative work while keeping the human-centered tutoring decisions firmly in your own hands.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I can't think of any questions or other information I'd like to share, but thanks for asking!

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about navigating workplace constraints with AI, maintaining professional boundaries, and knowing where the human touch is irreplaceable will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candid you were about both the practical benefits and the limitations you've experienced. Have a great rest of your day!
