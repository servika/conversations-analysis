# Dialog 00898

**Transcript ID:** work_0688

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: That sounds great.

AI: Wonderful! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I'm a software engineer and currently work on a very large, microservice-based financial system. I usually use AI when I get stuck coding, to ask for ideas for coding (e.g. if I have a meeting coming up soon to discuss new architecture or something along those lines), as well as (this is my favorite thing to use it for), repetitive tasks, e.g. updating libraries across microservices or upgrading things like SpringBoot.

AI: That's really interesting - it sounds like AI serves different purposes for you depending on the situation. You mentioned that using it for repetitive tasks like updating libraries is your favorite use case. 

Tell me more about that. What makes those repetitive tasks particularly well-suited for AI compared to the other ways you use it?

User: I've found in coding that repetitive tasks, such as updating pom files for Maven or updating libraries using npm, just take the longest amount of time and then that takes away time from actually implementing new features. So essentially, using AI to do those tasks, frees up my time for finishing JIRAs which the business actually want my team to finish. Because it's great for updating libraries, that also means it's great for passing the security scans (e.g. Sonar) which are part of the company's regulations. Essentially, I'll ask the AI to do something, e.g. update SpringBoot, and then, only if it does it wrongly, do I provide more follow-up info, e.g. you updated these files incorrectly, can you do this instead.

AI: That's a great breakdown of the value you're getting. It sounds like you've developed a pretty efficient workflow where you delegate the task and then only step in if corrections are needed.

When you do need to provide that follow-up - like telling it "you updated these files incorrectly" - how often does that happen? And when it does go wrong, what tends to be the issue?

User: Usually, the issue tends to be that the AI does too much and, in doing too much, accidentally breaks something in the code. However, I feel like the more I learn about how to actually use the AI (the company has been swapping AI constantly, so I have to keep learning how to use the new one), then the less it does things wrong. My company hasn't provided any sort of guidance into how to actually use the AI for software engineering, so it's all guesswork from me and my team, and I think that could be something great to include in future, e.g. some training.

AI: That's a really valuable insight about the learning curve and lack of guidance. It sounds like you're essentially figuring out the best practices through trial and error.

When you say the AI "does too much" - can you walk me through what that looks like? What does it typically add or change beyond what you were expecting?

User: A good example is that the other day, I was updating our internal version of SpringBoot and using AI to do so (e.g. update the SpringBoot version and ensure all tests still passed). However, the AI changed a file that was not supposed to be included in the upgrade (a class that converts PDF to text), and in doing so, it broke the tests, and also didn't run the tests after to check if they still worked. So, I guess, in essence, it actually did too much and too little simultaneously.

AI: That's a perfect example of what you mean - it overstepped by changing something outside the scope, but then didn't follow through on the validation step you needed. 

You mentioned your company keeps switching AI tools and you've had to keep relearning how to use each new one. How has that affected your willingness to rely on AI for these tasks, or has it changed how you approach working with it?

User: Essentially, we have a good AI tool now. But in the past, the AI tools we had (especially when they were plug-ins for intelliJ), were very low quality and broke code in 99% of cases, even simple code. This put me off using them. Now, we have a high-quality AI tool that works very well (most of the time). For me, as soon as we had the high quality tool, I was happy. But for others I know at work, they have been put off by the low quality tools and aren't so willing to use AI.

AI: That's really telling - it sounds like those early negative experiences created lasting impressions for some of your colleagues. 

How do you think your workplace culture has been shaped by those mixed experiences? Do you notice differences in how willing people are to experiment with AI now, or are there any informal rules or attitudes that have developed around AI use?

User: To be honest, the willing/unwillingness of different employees toward AI is the exact same that has happened in the past with new technology. I remember (I think this was in 2018), we were changing our massive database from Oracle to Cassandra as it would be more efficient for our specific use case, and some people were against the change. It's those same sort of people who are against the change of using AI.

AI: That's a fascinating parallel you're drawing between AI adoption and past technology transitions. It sounds like you're seeing familiar patterns in how people respond to change in your workplace.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Honestly, when we changed from a low quality tool (e.g. the intelliJ plugin) to a high quality tool (terminal-based) for AI, that's when I felt so satisfied. And, especially the other day for the SpringBoot upgrade, when it (on the 2nd try) did it extremely quickly. I've done those upgrades before and, especially because of the microservice architecture, it took a long, long time. So, essentially, the efficiency and time-saving is what made me very satisfied.

AI: The time savings really seem to be the key benefit for you. You've mentioned how AI frees up time for the business-priority JIRAs and speeds up those upgrades significantly.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, especially for tasks like library updates or other routine maintenance work?

User: Honestly, I don't really see being able to update libraries or similar routine stuff, e.g. doing deployments to production, as a skill. It's just a checklist I have to do (which actually distracts me from doing proper work). For me, coding, architecture, problem-solving, etc. are the real skills I need in my job. So it's not something I worry about.

AI: That's a clear distinction you're making between what you consider real skills versus routine checklist items. 

Looking ahead, how do you envision your relationship with AI at work evolving? Are there areas where you think you might start using it more, or ways you'd like to see it improve?

User: I'd like to get better at using it, and I'd also like it to get better at helping me. There's a lot of times where I ask for something I think is obvious, e.g. the organization of a UI, but the AI makes something else that I find strange and not user-friendly. But I think that could be fixed by both the AI improving, but also me, as the coder, knowing how to request what I want. Ultimately, I want to work with the AI, not to become over-reliant on it and lose the skills I need to keep and that would affect the business, e.g. communicating with the clients about what tech will be implemented. Overall, I'm excited for the future.

AI: Those are really thoughtful insights about wanting to improve the collaboration while maintaining your core professional skills.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet that might help us understand how people are really using these tools day-to-day?

User: That's all, thank you!

AI: Perfect! Thank you so much for sharing your experiences so openly. You've provided some really valuable insights about your work with AI - I particularly appreciated your perspective on distinguishing between routine tasks that are good for AI delegation versus the core skills you want to maintain, and how past experiences with low-quality tools have shaped your colleagues' attitudes.

Your insights about the importance of learning how to effectively collaborate with AI, and the need for better guidance from companies on AI use in software engineering, will be incredibly helpful for our research on human-AI interaction in professional contexts.

Thanks again for your time today!
