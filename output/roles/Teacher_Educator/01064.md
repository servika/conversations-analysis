# Dialog 01064

**Transcript ID:** work_0935

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments.

Does that sound good? Do you have any questions before we begin?

User: All good"

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I'm an English Teacher in the UK, for students aged from 13-18. I use it sometimes to make worksheets, or provide small samples of creative writing that students can use for activities (e.g. find the 10 errors; learn how to use commas; find all the adjectives in this piece of writing etc). Sometimes I use it to provide model answers, or to simplify a piece of text for differentiation.

AI: That's really interesting - it sounds like you're using AI as a teaching assistant of sorts, helping you create materials and adapt content for different student needs.

When you're creating these worksheets and writing samples, what does that process typically look like? Do you give AI very specific instructions about what you want, or is it more of a back-and-forth conversation to get the right materials?

User: I try to give AI the most specific instructions I can, including paragraph structure (e.g. point-evidence-analyse) or number of questions required, but sometimes I don't realise I need something slightly different until I see the first result, so then there's some back and forth about how to tweak the result.

AI: That makes a lot of sense - you can't always anticipate exactly what you'll need until you see it in action.

I'm curious about your preferences when working with AI. Are there certain tasks in your teaching that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: Yes. I could theoretically ask AI to mark students work or grade tests etc. But (a) this is not particularly accurate due to the subjective nature of my subjects (English Literature and Music) and (b) if I don't read any of my students' work, I can't adapt my teaching effectively to help them make progress, and my students feel I don't know them. It would also make parents' evening really awkward. The other thing that sometimes stops me is that i know exactly what I want and I can't be bothered to go back and forth with AI to get it right. But also, I am reluctant to outsource too much of my thinking, because I feel like it causes brainrot and I become less creative, and my memory for subject knowledge suffers because I'm not using it regularly. I also quite enjoy making resources, so it's a task I don't want to give up completely.

AI: That's really insightful - you've touched on several important considerations there. The point about needing to know your students' work to adapt your teaching really resonates, and I hadn't thought about the parents' evening angle.

You mentioned concerns about "brainrot" and becoming less creative if you outsource too much thinking. Can you tell me more about that? Have you noticed any changes in yourself when you do use AI more frequently, or is this more of a preventative concern?

User: It's mainly a preventative concern. But on the occasions I have used it, I've noticed that I'm not as familiar with the content I'm teaching and therefore don't feel as effective in teaching it. I also think it's important to feel like I'm capable and have the self-belief in my own abilities and my own expertise; as a teacher you need to be the expert in the room. AI isn't going to be teaching the lesson and answering the students' verbal questions about the topic! Something I've noticed in my students as well is that they are reluctant to actually think about a topic, question or problem and they give up easily because they are so used to outsourcing their thinking to an AI or Google and getting an instant answer. In my view this is going to cause serious problems for humanity in the long run because they do not often think to question the validity of the response they are getting and they become overly reliant on technology to tell them how to do absolutely everything in their life. However, also I just think that it's important to maintain my own creativity because isn't that kind of what life is all about?! And I really enjoy it.

AI: That's a really thoughtful perspective, especially your observation about students giving up more easily when they're used to instant answers. It sounds like you're seeing this shift in real-time in your classroom.

When you do use AI for creating materials, how do you think about finding that balance? You mentioned you enjoy making resources but also find AI helpful for certain tasks - how do you decide in the moment which approach to take?

User: I use AI for things like SPaG worksheets, so that I can tailor a specific revision lesson (e.g. if I've just marked an assessment and a lot of students got certain things wrong). The more 'technical' and definitively right/wrong skills are where I find it saves time. It's useful because say my class have lost the ability to use apostrophes, I can tailor a worksheet so that all the exercises reference the topic we're studying and ask AI to include certain key vocabulary that's a focus of the topic as well. The more 'subjective' tasks I do myself.

AI: That's a really smart distinction - using AI for the more technical, rule-based content while keeping the subjective, interpretive work for yourself. The example about apostrophes tied to your current topic is particularly clever.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Are other teachers at your school approaching it similarly, or have you noticed different attitudes?

User: I've just moved from a state school to an independent boarding school and there's a huge distinction in the way they use technology. State schools have no budget for things like ChatGPT Pro subscriptions and are also very time and resource poor - students and teachers have very little access to technology in the classroom and so the majority of activities are still paper based. It can be very useful for creating quick cover lessons for colleagues who are sick, or as I've mentioned for specific resource generation but beyond that it's not overly accessible. However, the new school I've just started working at has a huge amount more resources and funding available (they've just set up an AI taskforce). All students work on OneNote rather than on paper, and the school has the budget to allow staff to access things like perplexity pro and chatgpt paid accounts. So, in this school, because all students are continually online, there's been more of a willingness to engage with AI because staff need to understand it and spot when it's being misused. They've adopted a sort of 'traffic light' system for students to tell them what level of AI assistance they can use for a task, and also switched the focus for homework so that it's more research based and content generation becomes a greater focus within the classroom. It's causing many educators a real headache because of the massive impact it's having on extended writing and the inability to trust the academic honesty of student work that is completed away from the eyes of the classroom teacher.

AI: That's fascinating - what a stark difference between the two environments. The traffic light system sounds like an interesting approach to managing AI use.

You mentioned that the focus has shifted to more research-based homework with content generation happening in class. Can you share a time when using AI at work - whether at the state school or your new position - made you feel particularly satisfied or frustrated? What was happening in that situation?

User: One thing I found satisfying was when I needed a creative writing exercise for students, and I was able to ask ChatGPT to write me a story with very specific criteria, of a certain length, with certain linguistic techniques in. This would have taken me a long time to generate myself (although it also would have been enjoyable!). However, one thing I find really frustrating is when you ask a student to write a paragraph for homework with very strict instructions and they just write out what ChatGPT gave them - they think we can't tell that it's copied because they wrote it by hand. But seriously, guys, we see phrases like 'this is an extended metaphor for the emasculation of contemporary societal norms' or somesuch fluffy nonsense that makes no sense and we know that wasn't your work.

AI: Ha! I can imagine how obvious it must be when a 14-year-old suddenly starts writing about "the emasculation of contemporary societal norms." That disconnect between their usual voice and AI-generated language must be pretty jarring.

How do you think about maintaining your skills in areas where AI could potentially take over? You mentioned wanting to preserve your creativity and subject knowledge - is this something you actively consider or plan for?

User: Yes. I've just taken on a new role that is significantly more academically challenging than my previous role. I am deliberately creating as many resources as I can myself because it's really important for me to maintain and develop my subject knowledge. The physical, active learning of writing out sentences and creating questions and formulating PowerPoint slides is how I get the knowledge to stick.

AI: That's really thoughtful - actively choosing the more challenging role and making your own resources as a way to deepen your expertise. The connection you make between the physical act of creating materials and knowledge retention is interesting.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you think your approach will change as the technology develops or as you settle into your new role?

User: I think inevitably there will have to be some change in the education sector because things like coursework are becoming impossible to manage. Every assessment will have to be done in exam conditions. But I'm hoping that I can figure out ways to use it to streamline e.g. for data management, creating resources for EAL students, or for helping with report writing.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on maintaining that balance between efficiency and preserving your own expertise, and your observations about how different school environments approach AI so differently.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No thanks

AI: Perfect! Thank you again for your time and for sharing your experiences so openly. Your insights about navigating AI in education - from the practical differences between state and independent schools to the challenges of maintaining academic integrity while finding genuine uses for the technology - will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!
