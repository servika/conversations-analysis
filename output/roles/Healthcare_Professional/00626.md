# Dialog 00626

**Transcript ID:** work_0264

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: sounds good

AI: Great! Let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: i mostly use it to find reliable sources. I'm a medical student so i use it to search reputable databases for information about pathophysiology, treatments, getting ideas for differentials, etc

AI: That's really helpful context. When you say you use it to search reputable databases, can you walk me through what that process typically looks like for you? How do you go about finding those reliable sources?

User: I might say "using UpToDate", or ask it to find an article from a particular journal that I know is peer-reviewed

AI: That's interesting - so you're being quite specific about directing it toward particular sources you already trust. Tell me more about that approach. What led you to use AI this way rather than going directly to UpToDate or those journals yourself?

User: sometimes i have a very specific question that is hard to search in those sources themselves. using AI sometimes just helps me format a long question into something concise and searchable, and it also can take info from multiple sources and combine it to answer more complex questions

AI: That makes a lot of sense - it sounds like AI is helping you bridge between your complex clinical questions and the search capabilities of these databases. 

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: I write notes by myself. I may ask AI to help me come up with plans based on a problem list, but I write the HPI myself because I'm the one that gathered the history, so it would actually be slower for me to input all the information into the AI rather than just writing it myself. I also always write my own physical exam findings because it is easy to overlook small details if I let AI write it and I am way too scared of accidentally documenting something inaccurate. I may however use it to ask something like "what is the correct medical way to document a normal funduscopic exam?". does that answer your question?

AI: Absolutely, that's a perfect answer - it really illustrates your thought process. It sounds like you maintain direct control over anything that involves patient-specific information you've personally gathered or observed, but you're comfortable using AI for formatting or standardized language.

When you do use AI for work - like getting help with differential diagnoses or treatment plans - could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout a task, or do you tend to give it a complete question and let it handle that independently?

User: i would say more collaborative, I use OpenEvidence and ask it questions as if I'm talking to a senior resident or attending and asking them questions I'm too nervous to ask in real life.

AI: That's such a vivid way to describe it - using it like a senior resident you can ask those questions you might hesitate to ask in person. That collaborative approach sounds really natural for your learning process.

How have your colleagues or your medical school culture influenced the way you use AI in your work? Do you find yourself adapting your usage based on what's acceptable or expected in your environment?

User: Yes, I only started using it because my classmates do. During the didactic portion of med school some people would upload long powerpoint slides from lecture and ask AI to make them anki cards out of that material. Or you can ask it to quiz you using only that powerpoint slide so you know you're learning directly from the information your professors will be testing you on and you don't have to worry as much about finding reputable sources. it can also save time by pulling out high yield information from those long documents you don't have as much time to review

AI: That's really insightful - it sounds like your classmates introduced you to some practical study strategies that work well within the constraints of medical school. The idea of using it to extract high-yield information from your own course materials is clever.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: sometimes I use it to check over my differential or assessment and plan before presenting to my attending and it makes me feel more confident that what i'm saying makes medical sense

AI: That confidence boost sounds really valuable, especially in high-stakes situations like presenting to an attending. 

On the flip side, have you had any experiences with AI that left you feeling frustrated or unsure? What was going on in those moments?

User: yes, sometimes i catch it making mistakes and when i call it out it responds well and doesn't double down, but then it makes me trust it less and wonder about all the other things it told me and it can be very frustrating

AI: That's such an important observation - that moment when you catch an error and then start questioning everything else it's told you. It sounds like that really shifts your relationship with the tool in that moment.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I think about it, but I view it more as a tool i can work with versus compete against. Ideally AI could write my notes and I would have way more time to spend with patients. I'm also going into a procedural field so at this point I'm not too worried about AI taking over with all of that yet.

AI: That's a really balanced perspective - seeing it as a collaboration rather than competition, and recognizing where your hands-on skills will remain essential.

Looking ahead, how do you envision your relationship with AI at work evolving as you move through residency and into practice?

User: hopefully by then AI is more established and i would be able to use it as a hipaa compliant scribe. i think it may become more helpful in diagnosis, but I think AI will develop faster than patients will become comfortable with doctors using it

AI: That's a really thoughtful point about the patient acceptance piece - that the technology might advance faster than patient comfort levels. 

Those are all the questions I had prepared. You've shared some really insightful perspectives about your experience with AI in medical training. I particularly found your approach of using AI like a senior resident you can ask sensitive questions to really compelling, and your observation about patients potentially lagging behind the technology's development is something I hadn't considered.

Before we wrap up, is there anything else about your experience with AI in your medical studies that you think would be valuable for us to know? Something we haven't covered yet?

User: one other interesting aspect I've seen recently is openevidence is starting to be able to generate board prep questions. I recently took step 2 and used uworld very heavily. openevidence is free and if the questions it's writing end up being representative and helpful I think that could really save students a ton of money. i'm curious how that will all play out and if resources like amboss and uworld may every become obselete. i'm pretty sure amboss has incorporated some sort of ai feature but I'm not completely sure about that

AI: That's a fascinating development - the potential for AI to democratize access to expensive board prep resources. The economics of medical education are such a huge burden for students, so free AI-generated practice questions could be really impactful if they prove effective.

Your point about established companies like UWorld and Amboss potentially needing to adapt or risk obsolescence is really interesting too. It sounds like you're watching this space pretty closely as it evolves.

Thank you again for your time and for sharing your experiences so openly. Your insights about using AI as a learning partner, the trust dynamics when you catch errors, and the broader implications for medical education have been incredibly helpful for our research on human-AI interaction in professional contexts. I really appreciate your thoughtfulness throughout this conversation.

User: thanks!

AI: You're very welcome! Thanks again for participating - your perspective as someone at the front lines of both medical training and AI adoption has been really valuable. Take care!
