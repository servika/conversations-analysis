# Dialog 01264

**Transcript ID:** science_0120

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: That sounds good, I have no questions at this moment.

AI: Perfect! Let's dive in then.

To start, could you walk me through a recent research project you've worked on? I'd love to hear what that process looked like from your initial idea all the way to the final output.

User: A recent project I've worked on is building a 3D model of geologic layers in the subsurface. This kind of model is required (or useful) input for other kinds of models, such as groundwater flow models or carbon sequestration simulations. Most of the data that were collected is old, such as borehole geophysical data from wells drilled for oil and gas exploration or water extraction. I wanted the construction of the model to be scripted so that I could make small changes to my assumptions or methods without needing to manually reprocess data. A big part of the workflow is making subjective choices around how to reconcile existing geologic interpretations. The final product is a series of rasters representing the top elevation of each layer; collectively, these define a 3D geologic model.

AI: That's fascinating work - the idea of creating a scriptable workflow for reconciling those subjective geological interpretations sounds particularly challenging. 

Where in that process, if anywhere, have you experimented with using AI tools? I'm curious about any part of the workflow from handling the old borehole data to making those interpretation decisions to generating the final rasters.

User: I use Python extensively in my work, because it has a lot of support for geospatial processing. From the start I wanted to generalize my processing steps as much as possible and encapsulate them into reusable functions. I am likely to do similar tasks for my job, so I wanted to make as much of this workflow transferable as possible. I primarily used AI to write these functions for me. These functions performed things like conditional filtering of point datasets, manipulating 3D arrays, making interpolated surfaces, and generating visualizations.

AI: That makes a lot of sense - using AI to help build those reusable functions sounds like it could really streamline your workflow. 

For writing those Python functions - the filtering, array manipulation, interpolation, and visualization ones - tell me about how you decided whether to use AI versus writing them yourself from scratch.

User: I found that it was much faster to decompose specific coding problems and communicate what I wanted to an AI rather than writing the code myself. Most of the code was relatively simple and used established libraries, but had complex series of if-then statements. Having AI do the heavy lifting for the code freed up some mental bandwidth for formulating solutions to the problems and reviewing how the code worked in practice, helping me find edge cases.

AI: That's a really interesting way to think about it - using AI to handle the implementation details while you focus on the problem-solving and quality control aspects. 

Thinking about the parts of your research where you haven't used AI - like those subjective choices around reconciling existing geologic interpretations you mentioned - what's kept you from trying AI there?

User: Sometimes decisions are made using information that the AI doesn't have access to. For example, there are often outliers in datasets. I could tell the AI to remove outliers, and it might use some statistical approach. However, imagine I have control points defining an elevation surface, and there's an area where the points are much higher than the surrounding points. I know from experience that this is a real geologic feature, because I have paper maps that show it from more detailed studies for this area. The AI doesn't have this information, so it might remove those points. Sure, I could digitize the map and maybe expose the AI model to this information somehow, but at what cost? Now my 120 hour project has become a 300 hour project. It is much easier to just add a comment line saying "these points are legit, keep them in, refer to this reference for more info".

AI: That's a really compelling example - the idea that incorporating all that contextual knowledge could actually make the project much more complex rather than helpful. It sounds like there's this sweet spot where AI helps with the more standardized coding tasks, but the domain expertise and contextual decision-making is where you add the most value.

When you have used AI for writing those Python functions, how do you verify or validate what it produces? What's your process for making sure the code does what you actually need it to do?

User: I'll often test the functions on small synthetic datasets. Or, I'll test them on my real dataset and use the visualization tools I've developed to ensure that they're working as intended. Other times I'll probe the AI model and give it a theoretical scenario and have it work through the logic.

AI: That's a smart multi-layered approach - synthetic data, real data visualization, and even theoretical testing with the AI itself. 

We're about halfway through our conversation now. I'm curious about your future vision here - if you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: It would be nice if AI could better incorporate the contextual information we discussed earlier. In the geosciences, there is actually much information only available from visual sources of information like maps. Also, it is not uncommon to cite something published decades ago.

AI: That's really insightful - the challenge of all that visual and historical knowledge that's locked away in maps and older publications. It sounds like there's this rich repository of geological understanding that's just not easily accessible to current AI systems.

Those are all my questions - your perspectives on how AI fits into the more technical coding aspects while domain expertise remains crucial for contextual decisions were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: Just one more thing, something I think could be improved. Some AI models remember interactions with the user. I might ask a question about a statistical method to learn about it. Later, I might ask it for advice on how to approach a different problem. The AI models that remember interactions are often biased towards methods I've discussed with it earlier, even if they aren't appropriate for the task at hand.

AI: That's a really valuable insight - the idea that the AI's memory of your past conversations could actually work against you by creating inappropriate biases toward previously discussed methods. It sounds like you'd prefer the AI to evaluate each new problem fresh rather than being influenced by what you've explored before.

Thank you so much for sharing your experiences so openly today. Your insights about the balance between AI for technical implementation versus human expertise for contextual decision-making really help us understand the nuances of how AI fits into real scientific work. And that point about conversational memory potentially creating methodological bias is something we definitely need to consider.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
