# Dialog 01232

**Transcript ID:** science_0062

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: That sounds good to me! No, I am ready to begin.

AI: Wonderful! Let's dive right in.

To start, could you walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: Sure! My overarching research project that I have been working on is not yet completed, but there are many facets of this project that can I can elaborate on.  Recently I have been working on OCT and ERG analysis of ocular structure, and there are many factors at play with this research work.  OCT (Ocular Coherence Tomography) is an imaging technique commonly used for the eyes that allows scientists to see the ocular structure all the way back to the retinal lining all the way from the front of the sclera (As long as you're in the right wavelength).  And ERG (Electroretinograms) show the electrical signals present in an eye.  In order to get this project up to where it currently is, this required a simulation of ERG, 3D modeling for a perfusion chamber and eye holder, code that could transfer OCT data into denoised images that could then be turned into a 3D model, and Faraday Cage building, just to name some tasks and portions of this project that got it to where it is now.

AI: That sounds like a fascinating and complex project! I can really see how many different technical components you've had to bring together - from the imaging and electrical analysis to the physical setup with the perfusion chamber and Faraday cage.

Where in that process, if anywhere, have you experimented with using AI tools?

User: Yes, fantastic question.  AI has certainly helped me get through some of these complex sections of this projects, especially in the beginning when it felt hard to find a place to start.  I utilized AI to help me find scholarly sources and previous studies conducted at other universities that could give me an idea of similar work that has been done, how they handled them, how they set up their perfusion chambers, and to see dimensions and images of eyes to get an idea of what to expect and what proportions to 3D print for.  AI also helped me a lot in the coding/denoising aspect of the image processing, we would ask for different transforms to try aside from the Fourier transform (Ex. Hilbert transform), see if they made sense for our code, tested them out, and reported back to adjust our inputs and maybe try other transforms or denoising strategies like Gaussian distribution noise deductions.  These were some of the more prominent aspects of AI help in the research process.

AI: That's really helpful to understand how AI has been integrated into different phases of your work. You mentioned using AI for literature research early on and then for the coding and image processing work.

For the image processing and denoising work specifically, tell me about how you decided whether to use AI versus your traditional approach for those tasks.

User: For the image processing, we mostly went to AI since we felt like we were stuck where we were and ran out of ideas in that moment in time.  We had spent days altering our Fourier Transform and including different denoising processes like looping through each image in a set of 1000 through each column and using median replacement in pixel 3x3 squares to remove outliers that would be noise caused by the Fourier transform,  but our output seemed to always look sloppy or was hardcoded and did not work for the full dataset.  AI then suggested adding a Hilbert transform or perform a Gaussian distribution on the image and replace all pixels outside of the 2 standard deviation range.  These ideas were implemented and helped, but we are still not at the final solution we would like for the image processing.  But it is useful when all of the people working o your project have similar schooling and have had all of the same professors throughout the years, it is easy to have a group that is inputting similar ideas, whereas AI helped bring in ideas we hadn't previously thought of which was nice and fresh in a time where we felt a little stuck in our work.

AI: That's a really insightful perspective - how AI can bring fresh ideas when you and your team are all coming from similar backgrounds and training. It sounds like it served as a way to break out of the approaches you'd all been taught or naturally gravitated toward.

Thinking about the parts of your research where you haven't used AI yet - like maybe the 3D modeling for the perfusion chamber or the Faraday cage building - what's kept you from trying it there?

User: The Faraday Cage has already been completed so we will not need it much there, but I am interested to try it out with 3D modeling.  Currently I am familiarizing myself with lots of different software in 3D modeling and I am happy to spend this time on my own, exploring different software and their built in functions to find which I like the best personally, which is most user-friendly, which suits my needs best, and as I get more meticulous with the accuracy of these 3D models perhaps I will look for some suggestions from AI to clean up my models.  But, the best way to clean up the 3D models is through the 2D image processing before transforming it, so I am most concerned with this at the moment, which I will continue to use AI when I feel lost or unable to progress in my work.

AI: That makes a lot of sense - wanting to really understand the software capabilities yourself first before introducing AI suggestions. It sounds like you're also being strategic about where the biggest impact would be, focusing on the 2D processing since that's foundational to the 3D models.

When you've used AI for the coding and image processing work, how do you verify or validate what it produces?

User: Very simply, I will make a copy of my script and implement its suggestions, run them both, and compare the images side-by-side either by the naked eye, or in ImageJ or some similar image processing software to see the differences in pixel values and if the specific pixels and formations that are the least accurate for what we are looking to produce are processed out.

AI: That's a very practical approach - running both versions and doing that visual comparison. It sounds like you've developed a good system for validating AI suggestions before fully adopting them.

We're about halfway through our conversation now. I'd love to hear about your future vision: If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: That's a great question.  I really like what AI is helping me with at this moment in time, I feel like there is a great foundation that it is working with and it truly already is very useful to me.  One thing I wish it was better at helping me with would be certain troubleshooting aspects when coding, 3D printing, or simulating.  I feel AI will often repeat its suggestions when I need help or am lost in a software, and I will even sometimes send a screenshot of my screen and ask for keystrokes to get to where I need to be or to perform a specific function, and the response will leave out details or be factually incorrect.  I wish it was more advanced in that aspect where it would be able to tell you keystrokes a lot more accurately when trying to navigate a newer system, once provides a screenshot or video.

AI: That's a really specific and valuable insight - the gap between AI being good at suggesting general approaches versus being able to give you precise, step-by-step guidance when you're actually stuck in the software interface. It sounds like you're looking for more contextual, visual understanding from AI to help with those moment-to-moment navigation challenges.

Those are all my questions - your perspectives on how AI serves as a fresh perspective when your team gets stuck, and your strategic approach to validation, were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: That's mostly everything I can think of! Thank you for the great questions.

AI: Thank you so much for sharing your experiences so openly! Your insights about how AI can break through the "similar backgrounds, similar ideas" problem that research teams face, and your practical approach to validating AI suggestions by running side-by-side comparisons, really help us understand the nuances of how AI fits into real scientific work.

Your point about wanting more accurate, contextual help with software navigation is also something we'll definitely take into consideration. It's clear you've found a thoughtful balance between leveraging AI when you're stuck and maintaining your own hands-on learning process.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
