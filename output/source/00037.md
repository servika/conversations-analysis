# Dialog 00037

**Transcript ID:** science_0015

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: No please go ahead and ask your first question.

AI: Great! Let's dive right in.

Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: I am an undergraduate teacher of bioscience and recently, one of my undergraduate groups was designing criteria for a case study, based on a rare prion disease. Obviously, there are several recognised prion diseases and these cases are rare, so the purpose of the research was to find recent case studies on all prion diseases EXCLUDING Creutzfeld-Jacob disease, countries where the patients resided, which disease was being examined, whether the disease had a genetic origin (with a view to looking at potential familial connections for future case studies) and the age range of patients that had been recorded in these case studies. The students had to peruse case study research ONLY from the past decade and identify: the prion disease most likely to provide a wide pool of potential subjects, the country most likely to provide a suitable patient, the age range most likely to apply to this prion disease and if there was a genetic basis to any form of this disease. This was a three week project and the students were invited to use AI in their research (though not to assume that AI is correct and always check its claims). The students had very mixed results with the AI portion of their research. AI identified a lot of case studies that were either not case studies (instead they were research compilations that mentioned case studies, or wider scale reviews that mentioned several case studies). When asking simple questions such as 'what is the age range of known cases for Familial Fatal Insomnnia identified in the last 10 years', the AI assumed that there were no cases of young patients diagnosed with the disorder when the students' research had proven that cases of teenagers from known FFI families were both documented in review papers and in their own unique case studies. They were given good general points in the right direction in terms of countries to focus their studies on (Italy in FFI and PNG for Kuru) but when it came to specific papers and research (including number of citations on specific sites such as Google Scholar and PubMed) AI was way off and frequently hallucinated. So for general guidance, AI was useful but specifics were ordinarily proven incorrect.

AI: That's a fascinating project, and thank you for sharing those specific details about what worked and what didn't. It sounds like the AI was helpful for broad directional guidance but problematic when students needed precise, verifiable information.

Where in that research process did you and your students experiment with using AI tools beyond what you've already mentioned?

User: Several students used AI to find the best format to present their findings and actually found some good guidance here such as how to format a conference poster displaying criteria that would be easiest to fulfil when finding 'the next big case study', or letters to pharmaceutical companies requesting funding for such research (mentioning currently in-development prion treatments and how they might be relevant to the case studies being sought). My only guidance to them for this area of the research was 'Present it to the appropriate people with an appropriate purpose' so they had a lot of leeway here.

AI: That's really interesting - it sounds like AI was much more reliable for helping with presentation formats and communication strategies than with the specific research content itself.

For the literature review portion where AI struggled with accuracy, tell me about how you and your students decided whether to use AI versus your traditional research approach for finding those case studies.

User: The students were asked to use a trusted, established research engine such as PubMed or Scholar to check claims, or where possible to ask the AI for links to the appropriate articles (which would ordinarily allow PubMed login to read the paper, which they all have). Several students simply used what the AI told them, verbatim, and it showed as they had completely different results to other groups and were quoting details that were inaccurate. The students that approached this the way I would have done, used the AI for initial general direction and then used this to craft search terms for the major databases, which provided articles that filled in the 'blanks' of AI. Ordinarily, we would start from the broadest possible search terms (simply 'Kuru, past 10 years' or 'prions, past 10 years', which give countless results that are not easy to traverse. The students found AI useful to 'whittle down' this initial conventional step.

AI: That's really illuminating - so the students who were most successful treated AI as a kind of initial filter to help narrow down their search strategy rather than as a source of final answers.

Thinking about the parts of this research process where you haven't encouraged AI use - what's kept you from suggesting it for those areas?

User: I told the students to never trust a specific article or finding that is mentioned by AI - ALWAYS to confirm this themselves. As I say, the students who didn't bother to take this step were obvious as they a) were not writing in a literal, scientific way (cutting out all flowery language and descriptors which AI tends to include and b) were claiming research papers that were not case studies and findings from these case studies that were not accurately portrayed. This is why I told the students not to take this pathway. It would be excellent if AI could be trusted as a research scouring tool, but it cannot at this stage

AI: That makes perfect sense - the reliability issue with specific citations and findings is clearly a major barrier. It sounds like verification became a critical step that determined success or failure for your students.

When your students did use AI for those broader directional searches or presentation formats, how did you guide them to verify or validate what it produced in those areas?

User: They are all aware of how to research scientific literature (only use wikipedia for the links at the bottom, only use articles from publications that employ peer review etc) so they were told to always fall back on traditional databases (PubMed above all else) to confirm any specifics mentioned in the AI. AI's strength was in quoting past research that was over 10 years ago and is still being cited today. It is not particularly accurate in quoting recent research or knowing the difference between reviews and case studies etc.

AI: That's a helpful distinction - AI seems stronger with well-established, older research that's been widely cited. We're about halfway through our conversation now.

If you could wave a magic wand and have AI help with one aspect of your research or teaching that it currently doesn't do well, what would that be and why?

User: It would have a comprehensive database of scientific literature available to it. Whilst I understand that the AI cannot be expected to be updated daily with this material, with a connection to PubMed it would certainly be possible to be able to accurately cite research from up to a year ago. I gave the students a broad period of ten years (and compared to other topics such as cancer, prion case studies are extremely rare) and still the AI was quoting inappropriate studies and giving incorrect dates for their publication/inaccurate lead scientists.

AI: That makes complete sense - having real-time or at least more current access to scientific databases would solve the core reliability issues you encountered. It sounds like that gap between AI's training data and current literature is a fundamental limitation for scientific research applications.

Those are all my questions - your perspectives on how AI works best as an initial research filter rather than a final source, and the critical importance of verification in scientific contexts, were particularly insightful. 

Is there anything else about AI in your research or teaching work that we haven't touched on that you think would be important for us to understand?

User: I think the most important think to understand is the limitation of AI presently; although once these limitations are addressed, it would be important to engage science professionals (including students and teachers) to test whether the changes have been made sufficiently. It takes a lot of confidence, particularly in an area such as medicine, to say to students 'you can trust what this AI is saying' so it is likely that there will be considerable pushback until a model has proved itself flawless in this area!

AI: That's such an important point - the stakes are so high in medical and scientific contexts that the bar for trust has to be essentially perfect, and it will take time and extensive validation even after improvements are made.

Thank you so much for sharing your experiences so openly. Your insights about AI's current role as a research filter rather than a definitive source, and especially your point about the need for flawless performance before gaining trust in high-stakes fields like medicine, really help us understand the nuances of how AI fits into real scientific work.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. I really appreciate the time you took to walk me through such specific examples from your classroom experience.
