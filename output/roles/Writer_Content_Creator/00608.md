# Dialog 00608

**Transcript ID:** work_0240

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: No

AI: Great, let's dive in then.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI as a research assistant and outline writer.  I am a technical writer. I have many clients in numerous fields that are very different from each other. Every article I write must be researched in depth. I use AI constantly, all day, to find supporting scholarly articles for me. I give the AI my requirements and the journals I want it to search.  I usually give detailed instructions with many criteria. 

AI usually does good. Not only does it find articles, but I can have the AI take the references page and place all citations and references in any stylebook's style. APA, AP, and so forth. 

I will give the AI a list of the top 5 to 10 articles on a topic and tell the AI to write me an outline that fits the average outline of the combined articles. That is, the AI uses the given citations to look up the articles, compare all the H2 and H3 headers and then suggests to me what the most logical outline would look like, based on the highest ranking pages in Google Search results.

I also do on-page SEO. I don't have to rely on expensive solutions like SEMRush and Ahrefs as much anymore.

AI: That's fascinating - it sounds like AI has become deeply integrated into your research and planning process. You mentioned that AI "usually does good" when finding scholarly articles for you. 

Can you tell me more about what happens when it doesn't do as well as you'd like? What does that look like in practice?

User: Sometimes I don't know an article's title, and I'll tell the AI to "try" and find something close to the criteria I include. I notice when AI tries to guess what I want, when I don't have specific information to give it, sometimes it will make up an article and authors that don't exist. 

I spot check everything though. I would check on a human research assistant too.

AI: That's really insightful - you've developed a verification process that treats AI similar to how you'd work with a human assistant. 

When you're spot-checking AI's work, how do you typically go about that? Do you have a specific method or do you check certain types of results more carefully than others?

User: I check the citations to make sure they are correct, but it is very easy to tell when an article has been made up. Usually the article title is nowhere near close to the topic I have given.

For example, if i send the AI to look for 20 articles on a behavioral  modification technique and it returns an article title about heart surgery, I know something is wrong.  The errors are not easy to overlook. They are also rare.

AI: That makes sense - those kinds of errors would definitely stand out. You mentioned these fabrication errors are rare. 

When they do happen, how does that affect your workflow? Do you adjust your instructions to the AI differently for the next search, or do you handle it some other way?

User: Those errors happen when I use too many criteria or too few. If I am asking for an article that's on an unusual topic, and I want, say, 10 articles and I tell the AI that, if it only can find 9, the AI doesn't tell me it cannot find a 10th. It may make up a 10th.

I get around it like this. I tell the AI to take each citation and tell me the 1st sentence of the the first body paragraph. So far, that always works. The AI doesn't say anything, it just says "I cannot locate a first sentence." That is always, in my experience, a fool-proof way of telling if the result is a hallucination.

I think, and you are the expert, but I think that is because the AI is not actually lying. It has no motive to make up a false second sentence of the body paragraph because it wasn't lying in the first place. 

Unlike a human being, the AI's only agenda is to locate the information I ask it to. It has no motivation to avoid punishment or shame. So, if it cannot locate an article according to the citation it just gave me, it can't find a second sentence because no such thing exists, and the AI always tells me, "I'm sorry, but I cannot find the article at the citation you have provided"

AI: That's a really clever verification method you've developed. Your observation about AI's motivations - or lack thereof - is particularly interesting. You're saying that when you ask for that first sentence, the AI essentially reveals whether the article actually exists because it has no reason to fabricate at that point.

I'm curious about the other side of this - are there certain types of tasks you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: Usually, my clients want my work for them to not appear AI-written, so t I write the actual contents of each paragraph. I want the AI to show me the general flow of what everyone else has written, but remember, SEO conditions have changed from the time those articles were published. I must tailor the contents to meet the needs of the client today.

Also, I usually enhance or punch up whatever AI has given me so it has my "voice." Clients like the way I write, so I use AI to give me facts and general trends, then I fill in the analyses and observations.

AI: That's a really interesting balance you've struck - using AI for the foundational research and structure, but maintaining your own voice and current perspective in the actual writing. 

When you're working with AI on these research and outlining tasks, could you describe your typical interaction pattern? Are you more likely to go back and forth with it throughout the process, or do you tend to give it a complete set of instructions and let it work independently?

User: Both! The first task I give it is to throw a broad net into the information pool and let me see what's showing up on the first few pages of Google Search results. After that, I go back and forth by fine-tuning my desired results.

AI: That's a great collaborative approach - starting broad and then refining together. 

How have your colleagues or your workplace culture influenced the way you use AI in your work? Since you mentioned having multiple clients, I'm curious if different clients have different expectations or attitudes about AI use.

User: They all want me to use AI, but ensure the writing cannot be detected by AI-detecting software. It is a paradoxical situation.

AI: That does sound paradoxical - they want the efficiency benefits of AI but need the output to appear completely human-written. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: The satisfaction occurs daily, because AI gives me neat ordered research plans--and I can edit them before I ask it to do a deep analysis. Frustrations are only with my clients. For example, a client may give me an emergency rush order for a 10,000 word formal article to be done in 2 days. 

I can put the whole idea and the desired outcome into the AI, get a result within 5 minutes, and then start fine-tuning, and I meet the deadline. But usually the client says "Don't use AI" so Im stuck with trying to explain to the client they have given an impossible task, and only with an AIs help, at least a little, can a 1 person business give them what they want.

AI: That tension between what clients say they want and what's actually feasible is really striking. It sounds like AI has fundamentally changed what's possible for your business in terms of turnaround times.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Yes. However, there are very few areas that AI cannot take over anytime soon. Some times of manual labor, like plumbers, won't be taken over by AI soon. Doctors and nurses, people who must physically lay hands on other people to do their job are immune for now.

All of those jobs are highly specialized and I cannot go into to them.

Essentially, no white collar job is free from the threat of AI replacing humans.

So, I use my clinical experience to sell myself as a real person who's had real patients and knows on a human level how to treat humans.

AI: That's a really thoughtful perspective - leveraging your clinical experience as something uniquely human. 

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it changing in the coming months or years?

User: As AI gets better at producing correct results in simple tasks, we will keep giving it more complex tasks. AI will help in improving itself. I think my relationship will evolve by my being able to give AI entire research projects, the results of which I will use my human skills to stitch together and make recommendations to human patients.

I believe Ai will continue to improve.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on that verification method you developed - asking for the first sentence to catch hallucinations - and how you navigate the paradox of clients wanting AI efficiency but human-undetectable output.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about developing verification methods, balancing efficiency with authenticity, and navigating client expectations will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate you taking the time to speak with me today!
