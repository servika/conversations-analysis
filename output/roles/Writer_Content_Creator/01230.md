# Dialog 01230

**Transcript ID:** science_0060

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: Yeah that sounds good, I don't have any questions.

AI: Perfect! Let's dive in then.

To start, could you walk me through a recent research project you've worked on? I'd love to hear what that process looked like from your initial idea all the way to the final output.

User: So my research lab is focused on studying Chronic Wasting Disease. My project is testing to see if we can detect CWD in muscle tissues of experimentally inoculated deer. So we'd have these terminal samples from deer and take muscle biopsies from a bunch of different muscles that are commonly consumed by humans (think rump, shoulder, tongue, etc) and then I'd test them using RT-QuIC and PMCA and IHC. The deer were all infected for different lengths of time with the studies ending at different timepoints, so we could see if there's a correlation between deposition in the muscle tissues depending on how close to clinical the deer were as well.

AI: That's fascinating research with really important implications for food safety. So you're working with these different detection methods - RT-QuIC, PMCA, and IHC - to test muscle samples from deer that were inoculated at different time points to see how the disease progresses into muscle tissue.

Where in that process, if anywhere, have you experimented with using AI tools? Whether that's in the planning stages, during the actual lab work, data analysis, or writing up results?

User: I use it a lot throughout. The planning stages were pretty huge for AI use. Using models like ChatGPT to figure out what research had already been done on CWD research, specifically in muscle tissues. It made it a lot easier to find where the gaps were in research rather than doing all that searching manually. I wouldn't say we've found a way to use it in our actual lab work. We physically are taking samples from deer and running them in our assays. But if a test is going wrong and I just want to talk through different troubleshooting stuff that my coworkers also don't have answers for- I'll use ChatGPT there as well. I used it to write the manuscript as well. Or, I should specify, I put in my rough draft and had the model give me suggestions for improvements to see where things were the least understandable. It's helpful for editing and revising.

AI: That's really interesting - you're using it across multiple stages but in very different ways. You mentioned using ChatGPT for literature review to find research gaps, troubleshooting when lab protocols aren't working, and then for manuscript editing.

Tell me more about how you decided whether to use AI versus your traditional approach for that literature review phase. What made you think to try AI for that instead of doing the searching manually?

User: I use ChatGPT a lot outside of work in daily life as well so it made sense to incorporate here. I think it's really mostly about time. I can spend hours combing through research trying to find what I'm looking for, or I can ask a model that will give me almost instant answers. Sure, there's a lot of times that it wont cite a paper correctly or will be wrong on things, but it's a great starting point, and I can usually find the paper's it's referring to pretty easily even if it cites the authors wrong.

AI: That makes a lot of sense - you're treating it as a starting point that saves you time, even knowing you'll need to verify the citations. 

Thinking about the parts of your research where you haven't used AI - like the actual lab work with the RT-QuIC, PMCA, and IHC assays - what's kept you from trying it there? Is it more about the physical nature of the work, or are there other factors?

User: Yeah I don't think there would be a way to use it there, at least not yet. For RT-QuIC, I'm mixing up a sample of muscle tissue and mixing it with a bunch of different reagents and pipetting it into a well to test the fluorescence. There's not really an application for AI to help with physical lab work like that as far as I can tell. But like I said, it's super helpful if the tests aren't working. I can ask it for opinions about what's going wrong or what to try and fix.

AI: That troubleshooting application is really interesting. When you've used ChatGPT for troubleshooting lab issues or for manuscript editing, how do you verify or validate what it produces? You mentioned checking citations even when they're wrong - what's your process for deciding whether to trust its suggestions?

User: I think it's more about using it as that starting place, similar to the citations. Sure, it could give me a really bad suggestion that doesn't make any sense. I think it's really necessary for the user to have some common sense and logical thinking and not just blindly trust a model. But if I'm coming up blank, can't think of anything that can be going wrong, I can ask the model for ideas. Maybe those ideas won't make any sense or maybe those ideas will be something that I absolutely should have thought of but just couldn't find in my brain.

AI: That's a really thoughtful approach - using your domain expertise to filter what makes sense. We're about halfway through our conversation now.

If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't, what would that be and why?

User: I'd like to see it be able to help more with data analysis. As it is now, we do everything pretty much manually in my lab. We get a readout of the fluorescence of every single well in a 96 well plate every 15 minutes for 60 hours. That's a huge amount of data in an Excel file that we manually convert over to finding a baseline fluorescence, and then calculate when the positive samples fluoresced significantly more than that baseline. Then we manually put that data into a graph that shows the different samples being positive or negative. That's a huge amount of manual work. If we could get a model (that's allowed by the university to handle our data) to be able to just receive the raw data and immediately analyze it into a graph of replicates with positive and negative controls, that would seriously change a lot and save a lot of time.

AI: That sounds like a massive time saver - converting all that raw fluorescence data and doing those baseline calculations manually must be incredibly tedious. You mentioned needing a model that's "allowed by the university to handle your data" - that's an interesting constraint.

Those are all my questions for today. Your perspectives on using AI as a starting point while applying your own expertise to filter the results, and especially your vision for automating that data analysis workflow, were really insightful.

Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: I'd just add that the privacy constraint would be super necessary to think about as a company. We generally all work in public institutions. Honestly, our research doesn't even belong to us, it's always the property of our university. So a contract or some other understanding with the universities would need to be necessary before they'd allow raw unpublished scientific data to be handed over to a third party like that.

AI: That's a really crucial point - the institutional ownership and privacy requirements around unpublished research data. That's definitely something that would need to be addressed at the university level before researchers could fully leverage AI for tasks like that data analysis you described.

Thank you again for sharing your experiences so openly. Your insights about using AI as a starting point for literature review and troubleshooting, while maintaining that critical filter of domain expertise, really help us understand the nuances of how AI fits into real scientific work. And that point about institutional data governance is particularly valuable for us to consider.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
