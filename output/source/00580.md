# Dialog 00580

**Transcript ID:** work_0204

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Nope I am ready to start

AI: Perfect! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use it mostly for researching. Usually for alternative solutions to problems I am having. I also often use AI to double check my work, and to provide an alternative perspective on how the tone of an email or piece of writing might be perceived.

AI: That's really interesting - it sounds like you're using AI as both a research partner and a feedback mechanism. 

Can you walk me through what that research process typically looks like? When you're looking for alternative solutions to problems, how do you usually approach that with AI?

User: I am a computer programmer. And so I often find myself having to implement various algorithms or trying to find tools to use. Especially if I am doing frontend development, I use AI to tell me about different options available to me. Like in Godot, learning about why I would use an Area2D vs a TextureButton if I want an object to be clickable. Or if I am making a website then using AI to help find out if a flexbox or a grid would be more applicable. I don't like using AI to just do the work for me, instead I like to use it to give me the pieces and let me put them together.

AI: That's a fascinating approach - using AI as more of a consultant to help you understand your options rather than having it write the code for you. 

Tell me more about that preference for getting the pieces and putting them together yourself. What drives that choice for you?

User: I suppose there are two parts to that. A subjective, feelings part and a practical part. The subjective part is that I want to feel the sense of accomplishing a task, and if I just get an AI to write it all out, it feels like cheating and as if I haven't really done anything special. Often the journey is far more interesting than the destination. But also practically, if I don't understand how the code is working or what I am doing with the answers given to me by an AI bot, then it becomes much hard to refer back to it, or in the programming context, maintain or update it.

AI: That's really insightful - both the satisfaction aspect and the maintenance concern make a lot of sense. The idea that the journey is more interesting than the destination really stands out to me.

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different?

User: There are tasks that seem to be far from my skillset that I often use AI to fill in like a placeholder. Frontend stuff, database queries, or regex. Stuff that I could probably figure out, but isn't all that interesting to me, and the time to relearn it and debug it is just not something I want to do. It is often small components that aren't critical to the workings of a project, and if needed can be easily swapped with a better version.

AI: That's a really practical approach - using AI for those "placeholder" tasks that aren't core to what interests you or the project's critical functionality.

When you do use AI for those frontend components or database queries, could you describe your typical interaction pattern? Are you more likely to go back and forth with it throughout the task, or do you tend to give it the requirements and let it handle it independently?

User: If it is small then I just dump a bunch of data and give it my requirements. "Heres the tables, heres the columns, I need a query that takes in a name and gives me these pieces of data", or "I need a basic frontend chat system, the backend is at [REDACTED] and the endpoints are /user /newMessage /reply ..." etc. Because it is placeholder, I usually just give it what the input is, and what I need the output to be, and let it handle it. Test it to make sure its working, then use it. If it doesn't pass the tests, then I will iterate a few times. I rarely use it throughout the task, just because I have found in the past that it will try and use chat history which if its not up to date, then I have to keep track of it. I find it easier to just have a boilerplate copy paste of the context it needs, then give it a question with that context.

AI: That makes a lot of sense - having that boilerplate context approach sounds like it saves you from the confusion of outdated chat history. The testing step seems crucial too.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Do you work in an environment where AI use is common, or are you more of an early adopter?

User: I was an early adopter for sure, but it has become fairly widespread. There has definitely been some drama where its clear someone is just phoning it in and using AI to get their work done then leaving early or taking a long lunch even though their work isn't working very well. But overall people have started to recognize that it isn't a replacement, but a tool to be used. And that has been good.

AI: That workplace tension you mentioned is really telling - it sounds like there's been a learning curve around appropriate AI use versus just "phoning it in."

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: The times AI has felt really satisfying is when I need it to look through some git repo or project that I don't know and explain what is happening and how I can use it. Having it as a semantic search instead of a literal search has been extremely useful. But I often find that it's "human-like" conversation when I am trying to use it as a tool to be very annoying. If it makes a mistake then it says "Oops" or it will give me some code and say "This will definitely work" and it just doesn't. I don't want a person helping me the whole value is that it is a machine processing data. Often I just need it to give me an output and then I can tell it the problems. Or at least be less confident in it's output and just say "I think this should work. Let me know".

AI: That's a really compelling distinction - you value it as a machine that processes data, but find the human-like conversational elements actually detract from that utility. The overconfidence issue sounds particularly frustrating when you're trying to get reliable technical output.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: It is something I actively consider and it isn't something that I have a good answer for. Maybe it is a hope but it does seem that we are reaching a certain soft ceiling of capability. It feels as if there are starting to be diminishing returns for the amount of money and power being used to improve the models. I hope that by using AI to learn about things I am passionate about, and not let it just do all the work for me, is allowing me to ride the wave as long as possible. But I think any potential take overs will require society and government as a whole to figure out. At the end of the day, if the goal is to make money, and an AI can do 90% of my job in a fraction of the time then I am screwed. I hope that by moving to a more creative job, or a smaller project that is focused on creating something new, that I will be safe,  job wise, for quite some time. AI is really good at using historical data, so I want to be someone who is creating new data instead of using old data.

AI: That perspective on creating new data versus using historical data is really thoughtful - positioning yourself more as an innovator than someone working with existing patterns.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it changing from how you use it now?

User: I don't see my perspective of it changing. It is a tool to be used. I am sure that I will continue to find ways it helps improve my work, or tools will be created that make parts of my job easier.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI as a research consultant rather than a code writer, and your thoughtful approach to maintaining skills by focusing on creating new data rather than just processing existing patterns.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I can only hope its here to help and not replace. Other than that no

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about using AI as a tool for research and consultation, while maintaining ownership of the creative and problem-solving aspects of your work, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciated your honesty about both the benefits and frustrations, and your thoughtful approach to navigating this evolving landscape. Take care!
