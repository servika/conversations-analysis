# Dialog 01233

**Transcript ID:** science_0064

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your scientific work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: Lets begin.

AI: Perfect! Let's dive right in.

Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: A recent research project that I worked on was understanding the level of flood risk protection that existing flood defences in the central London boroughs of Westminster and City of London will provide, comparative to forecast sea level rise for the tidal portion of the River Thames. The initial idea developed from a point that appeared in a high level 10 year strategy for my department. This initial idea had no level of detail or indices for implementation or delivery, and as such the project began with setting the scope, identifying existing information, relevant stakeholders, project team members etc. Identifying the existing information required, particularly land ownership, existing public policy, future planned development along the Thames etc was the most difficult part. We already held information pertaining to flood risk and defence engineering requirements, but it was this external, often publicly available (but buried deep away in the web) information. The project then involved multiple rounds of stakeholder engagement, various iterations of reports and maps etc, before it was in a usable state to be confirmed as reliable and for use to inform future projects of both our organisation and other public organisations.

AI: That sounds like a complex project with lots of moving pieces - from the initial strategic concept all the way through to stakeholder engagement and final deliverables.

You mentioned that identifying existing information was the most difficult part, especially finding that publicly available but hard-to-locate information buried deep on the web. Where in that process, if anywhere, have you experimented with using AI tools?

User: AI tools, specifically chatbots such as ChatGPT and Gemini, were employed to try and source this information. Unfortunately, as this information is hidden away within versioned PDFs on public organisation websites etc, the AI tools were not particularly useful. They were however useful in the first instance, particularly in identifying or brainstorming stakeholders.

AI: That's really interesting - so you found AI helpful for stakeholder identification and brainstorming, but it hit limitations when you needed those specific documents buried in PDFs on organization websites.

For the stakeholder brainstorming task where AI was useful, tell me about how you decided whether to use AI versus your traditional approach for that part of the work.

User: I decided to use AI primarily for time management reasons, and also to ensure I had considered all options before consulting others within my department. It provided an additional degree of validation to my thought process before I involved others.

AI: That makes a lot of sense - using AI as both a time-saver and a way to validate your own thinking before bringing colleagues into the conversation.

Thinking about the parts of your research where you haven't used AI - like finding those specific buried PDF documents or the stakeholder engagement rounds - what's kept you from trying it there?

User: I have tried it there, but I have had limited success. This is an area that I have over time learnt that current AI models struggle with. This, and keeping up with the nuances of ever changing local and regional flood risk and climate change policy. I am based in the UK, and when conversing to AI tools about policy that impacts my area of expertise, it is often more US centric, or fails to differentiate between strategic policy and more local implementation policy etc. This is an area of specific expertise, so it is understandable.

AI: That's a really valuable insight - so you've actually experimented quite broadly but discovered these specific limitations around accessing current documents and navigating the nuances of UK-specific policy frameworks.

When you've used AI for stakeholder brainstorming where it was successful, how do you verify or validate what it produces?

User: I verify or validate what it produces by applying my own expertise and knowledge of the London locale I work in, and previous projects I have worked on. For specific stakeholder information that might come up in brainstorming, I needed to validate this information myself using web sources. The AI essentially provided me with a springboard to find the information myself in this instance.

AI: That's a great approach - using AI as a springboard while relying on your own expertise and additional research to validate the outputs.

We're about halfway through our conversation now. I'd love to explore one more angle: If you could wave a magic wand and have AI help with one aspect of your flood risk research that it currently doesn't handle well, what would that be and why?

User: I would wish that it was reliable in terms of knowing the ins and outs of the long policy documents that I work with. I am able to provide it with documents for it to peruse and analyse for me, but without the specific professional context and overview that I have in looking at these documents through the lens that I would be looking at it through, I am left unable to fully trust AI to do such tasks for me, without having to do them myself anyway. It is why AI is often a "springboard", as I said. If it could become less of just a "springboard", this would save me more time.

AI: That's such a clear articulation of the gap - you want AI to not just process those policy documents, but to understand and analyze them through the specific professional lens of flood risk management that you bring to the work.

Those are all my questions - your perspectives on how AI serves as a useful springboard but struggles with the specialized context and current information access were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: No, that's great, thank you.

AI: Thank you again for sharing your experiences so openly. Your insights about AI's current role as a "springboard" rather than a full solution - especially for specialized policy analysis in flood risk management - really help us understand the nuances of how AI fits into real scientific work. The distinction you made between AI's ability to brainstorm versus its limitations with current, context-specific document analysis was particularly valuable.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time today!
