# Dialog 00716

**Transcript ID:** work_0399

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: That sounds great, let's continue.

AI: Perfect! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: As a software developer and leader within a company, I use AI for a variety of tasks from coding to corporate documentation. I use Claude Code for help with smaller coding projects, Copilot for code completion, ChatGPT for assistance in writing docs and reviewing general business content. Let's take a typical workday for me as an example. I'm the CTO of a small software company, and recently we've been working through our ISO27001 audit prep. I've needed to create documents that I was very unfamiliar with. AI has helped by providing example templates and document structures that allow me to work on company policies quickly and with more confidence than simply starting from scratch.

AI: That's a really interesting range of applications. I'm curious about the ISO27001 audit prep example you mentioned - when AI provided those templates and document structures, how did you work with that material? Did you find yourself adapting and customizing what it gave you, or were you able to use more of it directly?

User: I wasn't able to use much of it directly. For example, we needed a Vulnerability Management Process. The AI model was able to provide a general structure and explain to me what sort of content would be relevant in each section, but as soon as I asked it to generate content, it would generate all sorts of assumptions and introduce aspects that didn't match our reality. I can see how some users would take that and publish it as the official statements of their company, but if we're going to live, and be audited on, theses process documents, they need to match reality. I did find that while the original generated content was mostly useless, it did help to put my mind in the right place to create content that matched our workflows and support processes. I would then feed this back to the AI model for sense checking.,

AI: That's a really valuable insight - so the AI was most helpful as a structural guide and thinking partner rather than a content generator for that critical work. When you mention feeding your own content back to the AI for "sense checking," what kinds of feedback were you looking for? Was it more about catching gaps, clarity issues, or something else entirely?

User: It was mostly about ensuring the content made sense, was cohesive, and that I wasn't missing anything important that ISO27001 guidelines would expect. This was usually a very productive exercise. For example, where I detailed my breach response process for security events, the AI provided useful feedback on scenarios that would result in reporting breaches to the ICO, and helped me clarify our role as data controller and processor in different scenarios. This feedback led to me shaping our process content in a more structured way.

AI: That sounds like a really effective collaborative approach - using AI as a knowledgeable reviewer who can spot potential gaps or flag important considerations you might not have thought of. 

I'm curious about your preferences when working with AI. Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different from the ones where you're more comfortable using AI assistance?

User: I have a personal philosophy regarding generative AI output. I won't use any content directly without ensuring I fully understand it, for anything that has a critical business function. I find it's always important to use AI as an assistant, augmenting your abilities, than using it to replace aspects of your role. In a business context, this means I am generally happy for AI to take my rough draft emails and give them a professional rewrite, because it's highly unlikely to add anything that isn't already there. However, taking a small prompt and generating larger content is just asking for trouble with hallucinations and inaccuracies.

For example, saying "reply to [REDACTED] and tell him I'm free on Friday" is an acceptable direct output that I would use AI assistance for - but "generate an employee vacation policy" would be unacceptable.

AI: That's a really clear distinction - the level of risk and the amount of content generation seems to be key factors in how you decide when to use AI directly versus when to maintain more control. 

When you do use AI for those lower-risk tasks like email rewrites, could you describe your typical interaction pattern? Are you more likely to collaborate with it throughout the process - maybe going back and forth with revisions - or do you tend to give it a task and let it handle it independently?

User: For the lower-risk tasks like email, my process would be to use ChatGPT or Claude - pasting the email conversation into the chat interface, and then follow it with a simple prompt like "confirm that we can meet on Friday, preferably in the afternoon", then paste back into my email response. I will almost always go through and verify the spelling is valid for my locale (british english) and that any quotes, hyphens, ellipses are to my preference, rather than using the raw AI output.

Simple tasks do tend to be one-shot AI conversations, but there are many scenarios where I'll prefer a series of back and forth discussion before using the final output. As someone who is aware of concepts like AI glazing (the model will always tell me everything is great idea), I try hard to frame my conversions in a way to discover reality as much as possible. For example, when confirming if I have a good idea, I'll start by asking what industry standard techniques would be common to a particular task, and then ask for pros and cons of different approaches. When I see the approach I was planning on taking appear in the list, I'll probe deeper without revealing my personal bias. This helps to give me the reality check on whether I'm going in the right direction.

AI: That's a sophisticated approach to working with AI - actively designing your conversations to counteract the tendency for AI to be overly agreeable. The strategy of probing industry standards first and then exploring pros and cons before revealing your own thinking is really thoughtful.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Have you noticed differences in how your team approaches these tools?

User: My team are all heavy users of AI these days. I have noticed email quality improve significantly amongst my peers. I feel that in this stage of AI adoption, it's become important to preserve your tone of voice and personality, and not let it be lost to generic, and obvious, AI generated content. With that in mind, it's been important for us to have internal policies to guarantee that staff are using AI responsibly. We all need to ensure that realtime face to face discussions can be productive without pausing while someone checks AI. Originally, there was frustration at work where it was obvious that a team member didn't know what they were talking about. One specific example involved an individual who approached some third-parties regarding a potential integration between us, and they used AI to generate the briefing document. This document included many inaccurate details regarding our CI/CD process, which led to embarrassing conversations. We have since needed to ensure that technical content is clearly reviewed by the technical team to ensure we portray ourselves in an accurate manner.

AI: That's a really telling example - it sounds like that incident became a catalyst for establishing clearer guidelines around AI use. When you mention the importance of preserving tone of voice and personality, and ensuring people can engage productively in real-time discussions, it seems like there's a balance you're trying to strike between leveraging AI's benefits while maintaining authentic expertise.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: Sure thing. When working on our secure software development lifecycle policy, I found it deeply satisfying to be able to compare our existing processes against industry standards and identify specific aspects where we were lacking. For example, the AI kept pushing on the concept of an information security working group, where recent security events would be discussed at different stages of the process. I took this and implemented the concept into three stages of our lifecycle effectively - which helped our review processes and documentation take a step up.

AI: That sounds like a really productive collaboration - the AI persistently highlighting a gap that you might not have prioritized, and then you being able to adapt that concept across multiple stages of your process. It seems like the satisfaction came from that back-and-forth refinement where the AI's suggestions actually strengthened your real-world implementation.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: I love the idea that AI can take over specific skills and functions of our roles - this gives more time to higher level strategy, leadership and planning. The more we can automate routine aspects, the better. I feel personally when using AI to augment your role, the focus needs to be on upskilling where possible. For example, if I'm using AI to generate code, then I'm also going to be using it to train me on that code for future maintenance, or recognising where the AI is losing focus.

AI: That's a really forward-looking perspective - seeing AI as freeing you up for higher-level work rather than as a threat. The idea of using AI not just to generate code but also to train you on understanding it is particularly interesting.

Looking ahead, how do you envision your relationship with AI at work evolving?

User: I hope to keep using AI to upskill myself, automate routine tasks and to free me up for higher level functions like quality assurance and business strategy. I will continue to use new AI features to empower myself to perform at new levels.

AI: Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on using AI as a structural guide and thinking partner rather than a direct content generator, and your strategic approach to framing conversations to get honest feedback rather than just validation.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, that's great thanks.

AI: Thank you again for your time and for sharing your experiences so openly. Your insights about maintaining critical oversight while leveraging AI's capabilities, and the importance of establishing responsible usage policies in team environments, will be incredibly helpful for our research on human-AI interaction in professional contexts.

I really appreciate how candid you were about both the successes and the challenges - like that integration briefing incident that led to policy changes. Those real-world examples are exactly the kind of insights that help us understand how AI adoption is actually playing out in workplace settings.

Thanks again, and have a great rest of your day!
