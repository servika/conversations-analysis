# Dialog 00850

**Transcript ID:** work_0613

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers – we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: No, I don't have any questions, we can begin!

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I have two jobs, one is a professional primary caregiver for a disabled adult, and the other is a homeschool teacher for a 5th grader. I will give tasks that I do for both. I mainly use it for lesson plan building, where I will feed the AI some information and have it help me put together a lesson plan. For example, I will give it a topic that I am going to teach and have it help me build some paragraphs that I can use as research reading. This is especially helpful to me as I don't have access to a very good library and sometimes don't have time to scour the internet for age appropriate research. And I don't always have time to take a wikipedia article (for example) and explain all the overly scientific words just to get a basic idea. For my caregiver job, I don't use it very often, but when I do, it's mainly for scheduling, brainstorming events, or building checklists so I can keep track of stuff. It's mostly short, collaborative tasks like "make me a list of…"

AI: That's really helpful to understand how you're using AI across both of your roles. It sounds like you're getting practical support in areas where time and resources are limited.

Tell me more about that lesson planning process. When you're working with AI to create those research paragraphs, what does that collaboration look like step by step?

User: I will usually introduce what research topic I'm going to discuss and give some context, for example, if we were talking about decomposers in a food chain context. Then I will say that I need a specific number of paragraphs about the topic, and see what the AI comes up with. There are always some weird errors that need to be dealt with, such as the AI using weird wording that my student would find condescending (this is a big, common problem), or the AI talking directly to me (the teacher) within the research paragraphs. I will then tell the AI what I would like fixed, and keep iterating from there. Eventually we usually end up with something usable. Sometimes I will then ask the AI to come up with some quiz or thought-provoking questions that can accompany the paragraphs. I will also sometimes feed the AI an article and ask it to reword some of the parts that might be too difficult to understand for my student. Basically making the article more "teaching" focused, and less pure information geared towards adults. Sometimes I will then have my student ask an AI about the topic and then research the responses on her own. The AI gets enough information wrong, often enough, that it's a good teaching tool for my student to learn how to double check and do her own research.

AI: That's fascinating - you've developed quite a sophisticated process there. I'm particularly intrigued by how you're using the AI's imperfections as a teaching tool itself.

When you mention there are "always some weird errors" like condescending wording or the AI talking to you instead of the student - can you give me a specific example of what that looks like? What makes you immediately recognize that the tone or approach isn't right?

User: For example, I was putting together a lesson today (about decomposers) and had asked for 5 paragraphs on a topic, this was the last paragraph (Which was supposed to be part of the information about fungi): 
 "Teaching kids about fungi helps them understand the big picture of life. Fungi may not seem exciting at first, but they're like nature's recyclers. They help keep the environment clean and full of life. When your child sees a mushroom in the yard, it's not just a plant—it's a hard-working decomposer helping the food chain stay strong. Learning about fungi also helps students respect all parts of nature, even the ones we don't always see."
This is addressing the teacher, not my student, which was not what I asked for. 
As far as condescending wording, it's mostly age-relevant. For example, in the same conversation, the AI said this sentence "Fungi (pronounced FUN-guy)", which isn't exactly bad, but it's sentences like this that make every interaction feel like the AI has 3 modes of "slang": Child, Teenager, Adult. No matter how old the child may be, the AI acts like the child is 4 years old and uses words like "Super". No matter how old the teenager is, the AI tries to use "hip" slang. And then there is the "baseline" of Adult. I wish this approach was a little more nuanced, and that every piece of research for my child wasn't riddled with analogies. These analogies can sometimes be interesting and helpful, but other times they don't make a lot of sense. I can't remember any off the top of my head, but I know it's happened in the past.

AI: That's such a clear example - I can see exactly what you mean about the AI slipping into "teacher mode" when you needed student-facing content. And that observation about the three rigid communication modes is really insightful.

It sounds like you've gotten pretty good at spotting these issues and iterating to fix them. When you're in the middle of one of these back-and-forth sessions trying to get the tone right, how does that feel? Is it more frustrating than helpful, or does the time investment still feel worth it?

User: It depends on how much change happens with each iteration and how open to rewrites the AI seems to be. I usually judge this by how much gets changed with a small request like "make it sound more mature", instead of having to itemize out each little issue. I do typically find the time investment worth it, as it does save me time in the long run.

AI: That makes sense - it sounds like you've developed a good sense for when the AI is being responsive to your feedback versus when you're going to have to micromanage every detail.

I'm curious about your preferences when working with AI. Are there certain tasks in either of your jobs that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: I wish I could use the AI to keep track of lessons for my student. But the memory is limited enough that I would end up having to rehash the entire school year to get a good response. Or if I could ask for help putting together a teaching aide, like reminders for when certain topics need to get covered during the year. And for my caregiver job, I wish I could use it more as a journal type helper. For example, tracking medical issues, mental health information, medications, etc would be really helpful to me. But again, the memory is limited and I end up doing them with pen and paper or on a document. I guess, anything that requires a more holistic approach or "seeing the big picture" are tasks I would like help with, but due to the nature of my jobs and the limited scope of present AI, there's not a lot I can really delegate in that way, or if I could, it seems more daunting than helpful. The AI could help me with this, but it would require such an enormous amount of time, that it just isn't currently worth it. What makes these tasks different is they are not "sit down and write a simple response" type tasks, they are involved with my whole job and have many moving parts that the AI could not keep up with.

AI: That's a really thoughtful distinction - you're identifying tasks that need that continuous, accumulated understanding versus the more discrete, contained tasks where AI works well for you now.

It sounds like there's this tension between wanting AI help with the bigger organizational challenges but finding the setup cost too high. When you think about those complex, ongoing tasks like tracking your student's progress or your client's medical information - what would need to change about AI to make it actually useful for those kinds of responsibilities?

User: Honestly, what mainly needs to change is what type of thoughtful questions are asked by the AI in order to glean information, but not have me have to realize each moving piece that needs to be discussed. For example, back to the decomposer conversation, if I were having that conversation with an AI, with the context that it was part of a larger lesson plan, then I would want the AI to ask me things like "Has your student already covered Primary Consumers and Secondary Consumers". Or be able to tie that information in with a larger, sprawling curriculum, instead of a single lesson. A longer memory at a reasonable price point is a key thing that AI will need before it can become truly helpful to me in those ways. Right now AI only focuses on the very surface level information, when it needs to see a bigger picture and reason backwards AND forwards in order to really be a helpful tool for jobs like mine. For example, if (in a conversation 2 weeks ago) I told the AI that my client had sprained their ankle, and I came back to ask for a workout plan for my client, I would want the AI to reason out that maybe nothing involving jumping jacks would be appropriate.

AI: That's such a clear example with the sprained ankle - you're describing AI that would need to connect dots across time and contexts, not just respond to what's right in front of it.

The idea of AI asking you thoughtful probing questions is really interesting too. It sounds like instead of you having to anticipate and provide every piece of relevant context, you'd want AI that could actively identify what it needs to know. 

How have your colleagues or the families you work with influenced the way you think about using AI in your work? Do they have opinions about it, or has their awareness of your AI use affected how you approach it?

User: Mm, not a lot actually. We always talk about the tasks I've worked on with the AI, but it hasn't really been an influencing factor. They're mainly accepting and excited about the fact that it's a time saver for me, as it leaves me more time to do other things with them. So in that way, I guess they've been quite supportive. My student, client, and I all use AI a moderate amount, so there hasn't been any friction surrounding the topic.

AI: That's great to hear that you've got such a supportive environment around it. It sounds like everyone sees the practical benefits.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: One particularly annoying thing that happens sometimes is, I will give context about something, and the AI will ignore that in favor of providing something pretty. For example, the other day I was trying to generate a large list of random items for my student to sort through, and I told the AI that I needed to copy the items onto another program in order to print them off, so to just give them to be plain. So the AI generated an entire list of items, all within a numbered list. This was annoying as I then had to tell the AI to give me the list again, but with no numbers, because they didn't make any sense outside the AI's context of "providing the user with a list of items". It ignored my context of needing to print and rearrange at my later discretion, and gave me a list anyway. It then did exactly the same thing further in the conversation, and I had to tell it again to not list anything. It's the small things like that, that make conversations frustrating and time consuming.

AI: That's such a perfect example of AI prioritizing its own formatting conventions over your actual workflow needs. It's frustrating when you're clear about the context but the AI defaults to what it thinks looks "helpful" rather than what you actually need.

That makes me curious - how do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: It's something that I consider for other professions, but not for my own. Due to the nature of my jobs, it will be a very very long time before an AI will be able to wash someone's hair for them! So I guess I have job security until medical androids become reasonable. For my specific jobs, I am looking forward to AI being able to be a more constant help, which will actually leave me more time to hone my other skills, instead of spending time doing fairly repetitive tasks like making sure my student gets her math test done by winter break. I mainly employ AI for tasks that I am not particularly gifted, like scheduling, so if I can delegate that type of task, I actually gain time to hone a skill I want, instead of having less time to keep a skill sharp because I'm busy making a schedule. As far as rewriting paragraphs of information for students, this is a skill that will stay sharp as I will never fully delegate the entirety of those tasks to an AI. And even if it did take that over entirely, I would keep my writing skills sharp in other ways that might be more enjoyable to me, such as fiction writing or game development. I guess that's a long way of saying, if AI were able to completely come up with a curriculum for my student and I didn't have to ever write another lesson plan, that would be a huge boon and leave me time to plan other things like field trips or hands-on science projects that I have less time for now.

AI: That's a really refreshing perspective - seeing AI as freeing you up for the more creative and hands-on parts of your work rather than replacing your core skills. The hair washing example made me smile!

Looking ahead, how do you envision your relationship with AI at work evolving? What would make the biggest difference for you?

User: I think I will continue to use AI in my work, especially teaching, as AI is constantly and quickly evolving and I enjoy technology and the challenges that it presents. The biggest difference for me would be mainly what I covered in my previous response when I mentioned holistic approaches. I want an AI that has a wider reach of context and can use that context to help me. I'm very very good at my two jobs, and I would like a little partner that can take over areas where I struggle or are too time consuming. As AI continues to evolve and learn, I hope that these become realities and I can just log in every morning and say "Where are we at in social studies today?" and get a comprehensive, thoughtful, good, and helpful answer accompanied by a lesson plan that I know my student can learn from. Bonus points if my student could ask questions about the lesson plan if I were not around to ask, since I am also, not there 24/7 to answer questions. I would like to be able to sit down and work on a lesson plan with an AI and have it contribute more than just quick info.

AI: That vision of logging in and asking "Where are we at in social studies today?" really captures what you're looking for - an AI partner that understands the full scope and flow of your work.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how AI's current limitations with memory and context affect the kinds of tasks you can realistically delegate, and your vision of AI as freeing you up for more creative work rather than replacing your skills.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: No, I think I've taken enough time and covered much of my issues/thoughts. Thank you for the conversation, I enjoyed it, and I hope it was helpful!

AI: Thank you so much for your time and for sharing your experiences so openly. Your insights about the gap between AI's current capabilities and the complex, ongoing nature of caregiving and teaching work have been incredibly valuable. The specific examples you gave - from the condescending tone issues to the vision of a true AI teaching partner - will be really helpful for our research on human-AI interaction in professional contexts.

I really enjoyed our conversation too, and your thoughtful responses will definitely contribute to our understanding of how AI can better serve people in roles like yours. Thanks again!
