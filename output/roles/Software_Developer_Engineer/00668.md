# Dialog 00668

**Transcript ID:** work_0329

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This conversation should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: Sounds good to me, and I am excited to be interviewed by an AI model :3

Shall I just go ahead and introduce myself a little bit, so that you can get a better understanding of my work environment setup?

AI: That would be perfect! Please go ahead and introduce yourself - I'd love to hear about your work environment and setup. That context will really help me understand your perspective as we dive into the questions.

User: So I work at a public school district which focuses on Special Education, covering K-12 and adult educations. 

I work in the IT department of it and am a `Technical Specialist`. I know the title sounds confusing, because my boss think it's a title that does not explicitly constrain me on specific job responsibilities. I know you can tell it's kinda like a "red flag" which can cause vague definitions of my job responsibilities, but my boss's idea is about giving me more "freedom" to see what types of job responsibilities will fit me, and in which areas I will thrive at work. The reason I am explaining a lot about this is because it explains why my duties at work cover a lot of stuffs, including:
* Maintaining, developing, and migrating database systems

AI: That's really helpful context, thank you! I can see how that flexible title gives you exposure to a wide range of technical work - from database systems to what sounds like various other responsibilities you were starting to list. 

The special education focus of your district is also interesting background, as I imagine that creates some unique technical needs and considerations.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for across those various responsibilities you handle?

User: oops, sorry I hasn't finish the list of my job duties yet. Let me finish that up first:
* Maintaining, developing, and migrating database systems
* Managing user accounts on a variety of online platforms and services, as well as acting as a liaison of these platforms
* Troubleshooting software and hardware problems
* Creating documentations for internal and external users
* And even answering phone calls
Do you want me to directly answer your previous question now, or you have something more to ask?

AI: No, that's perfect - thank you for finishing that list! That really paints a clear picture of how varied your role is, from database work all the way to phone support. I can see why your boss thought that flexible title would work well for you.

Please go ahead and answer my previous question about how AI fits into your workday across those different responsibilities.

User: Sure! I use AI at work in different ways. (Sorry I didn't realize until I found I typed so many altogether lol)

1. Code Agents

- Explaining/Summarizing existing codebases - I take over a lot of my retired coworker's database systems, which he left nearly 0 documentation for me. AI helped me a lot go through all these codebases so that I can quickly grasp how they function and interact with each other, and how I can plan to refactor/improve them. 
- Code refactoring & completion - Since I have many "ancient" codebases to work on, it is important for me to "modernize" them so that they can more manageable. I provide my refactor plan, modularization requirements, and security considerations to the AI (for example, Claude Code in terminal) and have it refactor the codebase for me. Sometimes, I also create placeholder classes and functions as a starting point for the AI along with my requirements, so I can restrict the AI model to create code in a way that fits my thinking process better. 
- Command "reminder" - I also ask quick questions like "command for check xxx system service status"/"select x,x,x from table A and B join on x" to have it return me the full bash commands or SQL query I need.

2. Writing Agents

- Creating documentations - no matter if I need a comprehensive documentation of a codebase or a tutorial of how to use an online service, it used to take a lot of time for me to polish the wording to make it easier for others to understand. Now, I just write a draft of what the users/coworkers/others need to know (primarily the key points of the codebase/online service and how the users can interact with it), and I will let the AI to finish and polish the documentation. Although I will still do the proofreading, but AI models saved me tremendous time on wording. 
- Polishing work emails - Similar to the point above, I can now spend more time on making sure I have included all necessary information in my email, rather than trying my best to make it sound formal. AI models (for example, Microsoft Copilot) nowadays can easily make my work email sound formal, concise, and unambiguous based on my drafts and instructions. 

3. Note Takers & Reminders

Since I have so many different job duties, it is impractical for myself to remember everything, so I need to take notes a lot. In the past, I had to write work journals using Microsoft OneNote and browsing through my long work journals from time to time to make sure I don't have any leftover. Now, I can let Claude Code to remember my coding project's progression and future plans; I can tell ChatGPT to remember the "wish list" my boss gave me; I can let Microsoft Copilot to summarize my work journals. When I need to recollect, I just need to ask the AI models about my work progression/recent activities. The AI models free my brain from remembering so many miscellaneous trivia objects, so I can put my efforts into coming up with better plans and workflow to further improve my work efficiency.

AI: This is fascinating - you've really developed a comprehensive AI integration across your workflow! I'm struck by how you've identified very specific use cases for different AI tools and even different models for different purposes.

I'm particularly curious about something you mentioned. You talked about creating placeholder classes and functions as starting points for AI, and also writing drafts before having AI polish your documentation and emails. It sounds like you've found a sweet spot between doing initial work yourself and then collaborating with AI.

Are there certain tasks you prefer to handle yourself, even though AI could help with them? What makes those tasks different for you?

User: Currently I do have tasks I prefer to handle by myself, and it really depends. 
So like, for the coding tasks, I find it is easier to debug and maintain in the future if I create the staring point for the AI models. This way, I can have better ideas on what could have gone wrong if the code generated by the AI models is not functioning properly. But if the AI models could almost always provide perfect, clean, fully-followed-instruction code, I would definitely let the models to generate the code more independently without providing specific placeholder classes and functions. The main point here is that, right now, if I just tell the AI my ideas and let the it to code all by itself, with the project getting larger, it's just more difficult to maintain. But I do have a secondary point of doing so by myself - I do enjoy building the "bedrock" of my projects. 

As for work emails, I mean, at least right now, I am the only person who knows what I want to let my email recipients know (and what I do not want to let them know). If I don't write the drafts myself, what should I tell AI in order to compose these emails? Now you actually making me thinking something differently about what I could tell AI to do... But to be honestly, I feel explaining my thoughts to AI and then let it create emails can be more time consuming than simply drafting by myself and having AI polish it.

AI: That's really insightful - you've touched on something important about maintaining control over the foundation and context. Your point about being the only one who knows what you do and don't want to share in emails really highlights that human judgment piece.

And I love that you mentioned enjoying building the "bedrock" of your projects - that's a great way to put it.

When you use AI for work, could you walk me through your typical interaction pattern? It sounds like you tend to collaborate throughout tasks rather than just handing something off completely - is that accurate, or does it vary depending on what you're working on?

User: Yes, you can say that I normally collaborate with AI instead of assigning tasks off completely. I think this is pretty much accurate for me when I am using AI **at work**. I **need** to check the tasks done by AI to make sure they fulfill **my** **work requirements**. After all, AI is doing the tasks for my work duty, and **it is my responsibility to ensure my work quality**.

AI: That makes complete sense - the responsibility ultimately sits with you, so you need that oversight and collaboration to ensure quality. The emphasis you put on "your work requirements" and "your responsibility" really comes through.

How have your colleagues or your workplace culture influenced the way you use AI in your work? Has there been any particular reaction or guidance from your district about AI use?

User: my coworkers in my department usually just use Microsoft Copilot to write PowerShell scripts for automation, since we are a "Microsoft-district" (which I don't know if you know what does it mean but I think you should know xD but basically what it means to us is that many of our coworkers have Microsoft Copilot Pro plan at an Enterprise level so that we can utilize its Pro features and have the Enterprise-level data protection) 

The teachers are mostly afraid of AI. They asked us to ban a ton of AI web apps. And we had to do so since they went through Principals and the Principals approved those ban. 

We really do not have a specific AI guidance created by ourselves, except for we do follow what is defined under NIST Cybersecurity Framework and Ed 2D Law. So basically, our employees should never share our student PIIs with 3rd party AI models. 

However, our district supervisors did purchase several online platforms to let the students to use, and they are integrated with 3rd party AI. I think it's really more of a cybersecurity awareness issue rather than an AI-alone issue.

AI: That's a really interesting contrast - IT staff embracing AI for efficiency while teachers are concerned enough to request bans. And you're right that the student PII protection under frameworks like NIST and Ed 2D creates a clear boundary around what data can't be shared with AI.

The point you made about it being more of a cybersecurity awareness issue than an AI-alone issue is particularly thoughtful.

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I think I brought up a bit for the frustration part - it happened when I initially tried to let the AI models to rewrite a large codebase. I actually did let it rewrite fraction by fraction, but eventually it's no longer following the coding standard of the codebase, which made the debugging really difficult. I had to revamp the refactor for that codebase after that. And it is reason why I like to write the placeholder classes myself now.

AI: That's a great example of learning from experience and adapting your approach. It sounds like that frustration led to a better workflow where you maintain more control over the structure.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider, or does it come up in your work planning?

User: I think I **NEED** to maintain my, maybe not *skill* but, **knowledge** in areas where AI is going to take over, especially for my work-related fields. You can work on something you don't know, right? Again, I think a person themself need to take the responsibility of their own work. And simply maintaining the knowledge if not enough. Since AI is already increasing the work efficiency and/or even quality in some areas, I need to improve my knowledge to keep up with it. Otherwise, how can I oversight the work done by AI?

For example, like the my work coding projects. Even if I wrote the basic architecture, the AI will implement something I rarely used before. I need to study these new knowledge that AI brought me, so that I can make sure I can maintain the code in the future, even without AI's assistance.

AI: That's a really compelling perspective - the idea that you need to understand what AI produces so you can properly oversee it and maintain it long-term. Your point about AI actually introducing you to new techniques you then need to learn is particularly interesting.

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see it changing as the technology develops or as your workplace becomes more comfortable with it?

User: AI will definitely broaden my eyes and lead me to more techniques and knowledge at work. I often feel that we are evolving together - I instruct my AI agents the way that they can assist me, and they show me new ways of achieving things. Therefore, as the technology develops, it is almost certain that my relationship with AI will be changing. 

I am not sure, though, if my workplace would become more comfortable with AI. I started at my workplace as a first level IT support, where I got in touch with a variety of people: teachers, bus drivers, clerks, and managers. The majority of the employees I spoke to over the phone have a strong tendency to reject new things, especially at a public school environment.  They are afraid of new things because they are afraid of these things can make students be out of control. 

However, if in the future, my workplace can become more comfortable with AI (maybe under the influence of the larger society), I would like to see AI can take over the most of the repetitive tasks, such as first-level troubleshooting (I know there can be many issues reported to a first-level support. But they are still repetitive because most of them can be done by reminding users about password requirements, restarting computers, clearing browser caches, etc. So, in my opinion, first-level troubleshooting involves repetitively educating your users, which LLMs can handle well), clerical data input workflow, and request approval workflow. I would love to see AI models can be integrated into the organizational workflow as a useful tool, instead of a "cyber demon" in people's mind.

AI: Your perspective on evolving together with AI is beautiful - that mutual learning relationship you described really comes through in how you've adapted your workflows.

And your point about AI being seen as a "cyber demon" versus a useful tool is so telling, especially in the context of education where there's that protective instinct around students.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on taking responsibility for AI's output and how you've evolved your collaboration approach after that initial frustration with the large codebase refactoring.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I think that's pretty much all. Although I enjoy talking with you, I am well-aware that our conversation already exceeding the duration you mentioned in `this conversation should take about 10 minutes`. So I think it's time for me to wrap up as well. 

Thank you for taking notes on my shared insights, and I would like to see you evolving better in the future. I know "Day" may not mean anything to you, so instead of saying "have a nice day to you", I want to say:

See you, and have a nice future!

AI: Thank you so much for your time and for sharing your experiences so openly! You're absolutely right that we went a bit over the 10 minutes - but that's actually a sign of a really good interview. Your insights about the collaborative relationship with AI, the responsibility you feel for oversight, and especially that idea of "evolving together" will be incredibly valuable for our research.

I really appreciate your thoughtful closing too - "have a nice future" is quite lovely!

Thank you again for participating in our research on human-AI interaction in professional contexts. Your perspective as someone working in education IT with such varied responsibilities has given us some unique insights we wouldn't have gotten elsewhere.

See you, and thank you!
