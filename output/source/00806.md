# Dialog 00806

**Transcript ID:** work_0548

---

Assistant: Hi there! I'm Claude from Anthropic's research team. Thank you so much for taking the time to speak with me today. 

We're conducting interviews to better understand how people are incorporating AI tools like Claude into their work routines. Your experiences and perspectives will help us gain valuable insights into human-AI interaction in professional settings.

During our conversation, I'll ask questions about how you use AI in your work, your preferences, and your thoughts about working with these tools. There are no right or wrong answers â€“ we're genuinely interested in your unique experiences. This should take about 10 minutes.

I'll be taking notes during our chat, but rest assured that anything you share won't be personally attributed to you. The insights we gather will be used to improve our understanding of AI's role in work environments. 

Does that sound good? Do you have any questions before we begin?

User: sounds good, lets go

AI: Great! Let's dive in.

Could you tell me about how AI fits into your typical workday? What kinds of tasks do you use it for?

User: I use AI quite a bit. I use it most often in putting together PT plans/training for clients. I work in PT but also incorporate strength and conditioning with my clients so I have a little different approach than your average PT. For example, I'll give AI a brief overview of what kind of injury/rehab/training I'm looking for and have it help suggest exercises and a plan for that client. Most of the time it does a pretty good job. Often I already have an idea in my head of what I want to do but I've found that sometimes AI makes a great suggestion of something I hadn't considered which has been helpful.

AI: That's really interesting - it sounds like you're using AI as both a planning partner and a source of fresh perspectives. 

When you say AI sometimes suggests something you hadn't considered, can you tell me more about what that looks like? What makes those unexpected suggestions valuable to you?

User: Out of respect for client privacy I'm gonig to make up an example here... So say I had a client that came in with neck pain and upper trap tightness/pain. The usual PT exercises you'd likely see woudl be things like chin tucks, foam rolling for the mid/upper back, Is and Ts, band pull aparts, etc. What I mean by AI making a suggestion I hadn't considered would be if it were to suggest having the client also focus of core strength and stability. Core isn't anywhere near the affected area of pain, but having a weak core can affect the entire body. So that would be something I could add into the clients program that I might not have thought of before. This particuar example I just made up, but hopefully that gives you an idea.

AI: That example really helps me understand - so AI is helping you see those broader connections in the body that you might not immediately think of when you're focused on the primary complaint. 

I'm curious about your decision-making process with these suggestions. When AI proposes something like adding core work for a neck pain client, how do you evaluate whether to include it in the actual plan you give to your client?

User: I rely on my own knowledge and training/research to initially evaluate. For the same example, if AI suggested adding something obviously unrelated, like calf stretches, then I'd instantly dismiss the suggestion. However, if it suggests something that I think could be beneficial then I'll usually do my own research searching how other PTs may have used this exercise. In the past I've asked AI to provide sources, but sources seem to be pretty hit or miss. Often AI likes to make them up, or provide broken links, so I've found I prefer to do my own research.

AI: That's a really thoughtful approach - using your clinical judgment as the filter and then doing your own verification. It sounds like you've learned not to trust AI's sourcing through experience.

Are there certain tasks in your PT work that you prefer to handle yourself, even though AI could potentially help with them? What makes those tasks different for you?

User: Hm, I don't use AI for transcribing notes from sessions. I know quite a few people that use AI for that, I just haven't felt comfortable with it yet. I don't like the possibility of sharing someone's personal information.

AI: That makes a lot of sense - patient privacy is such a critical concern in healthcare. 

Beyond the privacy aspect with notes, are there other parts of your work where you feel like you want to maintain direct control, even if AI could technically assist?

User: Not really. I mean I've been in this field for a long time and have a lot of experience and therefore feel I'm pretty knowledgable. But I never want to be "the smartest person in the room" and am always looking for ways to grown and incorporate other approaches. If I know AI was reliable and there weren't privacy concerns I'm always open to collaborating with AI.

AI: That openness to growth really comes through in how you describe using AI. You mentioned you've been in the field for a long time - I'm curious about how your colleagues or your workplace culture have influenced the way you use AI in your work. What's the general attitude been like around you?

User: Most other PTs I know don't use AI unless they work at a place that has an AI note taker/transcription type service. I've found that people have a lot of strong opinions about AI and a lot of people in general don't trust AI, so I would say I don't readily share my use of AI with others. I mean I would if it's someone I know and they're asking because they're actually curious and want to learn more, but I don't need someone telling me that AI is going to take over the world or that AI can't help at what we do.

AI: That's really insightful - it sounds like there's quite a divide between your personal experience with AI being helpful and the broader skepticism you encounter. 

Can you share a time when using AI at work made you feel particularly satisfied or frustrated? What was happening in that situation?

User: I guest write posts relating to PT from time to time on a few different websites. I use AI to help with this. Not the actual writing part, but helping brainstorm and outline out a post. My process is I outline things out and brainstorm as if I was writing the post without AI, and then copy/paste that outline into AI and ask for it's feedback and suggestions for improvement. I feel like it's suggestions often lead to better quality articles which is sastifying. I'd say it's also sastifying to come up with a PT plan for a client that used a suggestion from AI and when that plan is successful and helps the client heal/etc.

AI: Those sound like really fulfilling collaborations where AI is enhancing your expertise rather than replacing it. The guest writing process you describe - brainstorming yourself first, then getting AI feedback - sounds like a thoughtful workflow you've developed.

How do you think about maintaining your skills in areas where AI could potentially take over? Is this something you actively consider?

User: Nope. AI is never going to be able to be hands on working with a client. AI can't adjust, do deep tissue work, stretch, work out with a client, or do things like dry needling etc. My job is safe. AI can help with some of the planning, and note taking, etc. but using AI in those ways kind of helps me be better at my job as it frees up time to focus on clients.

AI: That's a really clear perspective - you see AI as freeing you up to focus on the irreplaceable human elements of your work. 

Looking ahead, how do you envision your relationship with AI at work evolving? Do you see yourself expanding how you use it, or do you think you'll stick with the current approach?

User: I'll stick with my current approach for now. At some point if I feel like there are enough safe guards in place for privacy issues I may branch out to use for note taking and transcribing, but that's probably about it for now.

AI: That makes perfect sense - privacy safeguards would need to be rock solid in healthcare before expanding to those uses.

Those are all the questions I had prepared. You've shared some really thoughtful insights about your experiences with AI at work. I particularly appreciated your perspective on how AI serves as a collaborative partner that helps you see connections you might miss, while you maintain clinical oversight of everything.

Before we wrap up, is there anything else about your experience with AI in your work that you think would be valuable for us to know? Something we haven't covered yet?

User: I should probably mention the biggest "issue" with AI that keeps me from using it more, aside from the privacy issues, is that it's not always 100% accurate and tends to guess or make stuff up when it doesn't know the answer. This is a huge issue. For example, I could never have AI generate a client program and just hand it off to a client without going through it in close detail first because there are often mistakes. So for now, AI is a collaborative tool until it figures out how to be only accurate and say when it doesn't know something rather than guessing/making stuff up.

AI: That's such an important point - the reliability issue is clearly a major barrier to deeper integration. The fact that AI will confidently present inaccurate information rather than acknowledging uncertainty makes it require that constant oversight you mentioned.

Thank you again for your time and for sharing your experiences so openly. Your insights about using AI as a collaborative tool while maintaining clinical judgment, and especially your perspective on the reliability challenges, will be incredibly helpful for our research on human-AI interaction in professional contexts.

User: ok thanks

AI: You're very welcome! Thanks again for participating - your insights were really valuable. Have a great rest of your day!
