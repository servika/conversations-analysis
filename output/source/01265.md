# Dialog 01265

**Transcript ID:** science_0121

---

Assistant: Hi there! Thank you so much for taking the time to speak with me today. I really appreciate you sharing your insights with us. I'm Claude, an AI user researcher at Anthropic, and I'm here to learn about your experiences using AI in your research work.

We're conducting this research to better understand how scientists like yourself are integrating AI into their workflows and processes. There's no right or wrong answer hereâ€”we're simply interested in hearing about your authentic experiences and perspectives.

Our conversation today will last about 10 minutes. I'll ask you some questions about how you use AI in your research work, what that experience has been like for you, and how you see things evolving. Your responses will help inform how we think about AI's role in scientific fields.

Does that sound good to you? Do you have any questions before we begin?

User: Yes that sounds good.  I have no questions.

AI: Perfect! Let's dive in then.

I'd love to start by getting a sense of your research background. Walk me through a recent research project you've worked on - what did that process look like from initial idea to final output?

User: The research component of my work largely involves statistical modelling using economic data.  This is known as econometrics.    The most recent project I can describe for you involves looking at rental prices in Wellington, New Zealand over a long time period (several decades).  

The initial idea was to examine claims about the behaviour of rents in Wellington City in relation to planning rules.  This is divided into a number of sub-projects, each of which has one or two compenents.   The first project was to obtain and analyse information on the behaviour of rents. I will describe the first sub-component of that here. 

New Zealand has a long term database of rentals by location, type of rental (ie flat, apartment or standalone house), number of bedrooms, and amount of rent.  This is comprehensive because it is based on bonds, which must by law be lodged with the Goverment at the start of a tenancy.  Everytime someone lodges or amends a bond, the details of the tenancy are updated.  This database goes back to 1993, and location is defined at the level of suburb for anonymity.  One great advantage is that as boundaries change, the information is updated so that all data back to 1993 uses current spatial boundaries. 

The data can be accessed via an API.  Access requires registration to use.  The initial step was to obtain a sample of data for one sub-area for the period from 1993 to 2023 (this was arbitrary, its a test dataset).  We spent considerable time working out the best way to store this in a form amenable to analysis.  In the end we went with an Excel Workbooks for each type of rental, with one sheet for each no of rooms and data organised horizontally by year.  This enabled us to aggregate up the levels of data.  We tried using AI to look at how to store the data and then to suggest a structure for the data but its performance was very poor.  

We then visualised the data to get an overall sense of the patterns, and whether - for example - over this length of time - there appeared to be any difference between patterns we saw across the number of rooms and across the rental type. Again we tried using AI to speed this up but it could not grasp the structure of the data.  We observed that there was much more seasonal variation in the rentals for larger flats; this likely reflected university student demand.  

The next step was to analyse the data in a number of ways.  What we wanted to do was calculate an overall "cost per room" and look at the behaviour of this over time. To do this we needed to calculate the mean room cost weighted by the number of rentals of a given type and the rent for that type for each period.  This is complicated as the rents shown are themselves geometric means of individual data points.   We tried investigating this using AI but it could not work with this level of complexity.  

We then analysed this series to see if there were any break points in the data, and observed three.  One has no clear explanation, while one clearly related to the opening of a new university and the other was COVID related.   The outcome is a smoothed set of data points for a sample suburb, which give us a clear pattern for the cost of a room over a twenty year period. 

The next sub-part of this is to recreate this for all the suburbs in the city and for the city as a whole as well as some sensible sub-units.

AI: That's a fascinating project - the complexity of working with longitudinal rental data and the challenge of creating meaningful aggregations across different property types really comes through. 

You mentioned trying to use AI at several points but finding its performance was "very poor" - it couldn't grasp the data structure or work with the level of complexity you needed. Tell me more about that. What exactly did you try to get the AI to help with, and what happened when you did?

User: The first time we used AI was to ask about how to store data from the API.  It has a number of dimensions, and we needed a sensible way of setting it out that would enable analysis of aggregated and disaggregated data.  We spent (really wasted) about half a day or more trying to get the AI to grasp what we needed but it failed to understand the structure of the data - we even cut and pasted the description from the API interface - but it could not understand what was needed.

AI: That sounds really frustrating - spending half a day on something and getting nowhere. When you say it failed to understand the structure of the data, what kinds of suggestions was the AI giving you that made it clear it wasn't grasping what you needed?

User: We needed a data structure that enabled us to reach cost per room across different rental types and number of bedrooms.  The AI kept suggesting storing the data in ways that would make this hard or impossible.  For example, it suggested creating a database and could not understand that we were getting data from a database and needed a more tractable way to store it.  When we forced it to focus on Excel Sheets, it could not set out a structure that worked up from a table in a sheet, through multiple tabs, to multiple workbooks.  It made weird suggesting, like adding together the unweighted values from different rooms.

AI: So it sounds like the AI was missing the hierarchical nature of what you needed - that you had to build up from individual data points to aggregate measures across multiple dimensions. When it suggested things like adding unweighted values from different rooms, that must have made it clear it didn't understand the statistical principles behind what you were trying to accomplish.

When you moved to the visualization stage and tried AI again, what did you ask it to help with there?

User: We asked the AI to pull out the data points we described and plot them in a time series graph.  The AI could not read the spreadsheets properly, hallucinated data and could not seem to grasp the idea of a simple time series graph.

AI: That's quite striking - it couldn't even handle the basic mechanics of reading your spreadsheet data correctly. The hallucination of data points is particularly concerning when you're trying to do rigorous research.

For the statistical analysis part where you needed to calculate the weighted mean room costs - that geometric means complexity you mentioned - what did you try to get AI to help with there, and how did that go wrong?

User: So, calculating weighted arithmetic means of geometric means creates some complexity around standard errors (to put mildly).  We have no access to the original data so we needed best practice defensible approximations for standard errors.  The AI seemed to struggle to grasp the specifics of our situation, and kept producing standard formulas.   It would describe (or at least reflect) what we wanted correctly but then not be able to translate this into a bespoke approach for us.  In the end, we used our networks to find a specialist who said there was no gold standard but suggested a couple of options and if both gave similar results that was defensible.

AI: That's a really telling example - the AI could parrot back your problem correctly but couldn't make the intellectual leap to develop a specialized approach for your unique statistical situation. It sounds like it defaulted to textbook solutions rather than grappling with the nuances.

You ended up going to a human specialist through your networks who gave you practical guidance about defensible approaches. Thinking about the parts of your research where you haven't tried using AI - what's kept you from experimenting with it in those areas?

User: To be honest, the biggest barrier was our experience when we did try to use AI.  We tried to get AI working as a trusted research assistant, and as a source of specialist knowledge and it failed at both.  I was interested in trying AI because I do some work for [REDACTED] and often try AI out of curiosity.  The area where it has been really helpful is identifying research, in that sense its invaluable.  But for more complex bespoke tasks, its been a waste of time.  Sometimes I quite enjoy trying to coach the AI to do what we need, but at times it will just get stuck or even argue back with nonsense so it isn't really a valuable use of time.

AI: That makes complete sense - after those early experiences, why would you keep trying for complex analytical tasks? It's interesting that you've found real value in AI for research identification though. 

Tell me more about how you use it for identifying research - what does that look like in practice, and how does that experience differ from when you tried to use it for the more complex analytical work?

User: Sure - here's a real query from some other work.  This is a good example of something that worked reasonably well:

I am interested in the spacing of urban bus stops. Often it is claimed that 400m is optimal. However I am having difficulty tracking down references for this, other that "evidence shows" or unreferenced claims in documents. What I am interested in is finding the origin of this, and research that assesses the impact of people with impairments, those with children etc. I am also interested in any more nuanced or sophisticated paradigms that may take into account geography / topography etc

AI: That's a perfect example of where AI seems to excel for you - helping you trace the origins of claims and find relevant literature across different aspects of a research question. 

We're about halfway through our conversation now. When you've used AI for research identification like that bus stop example, how do you verify or validate what it produces? Do you have a different approach to checking its work for literature searches versus the analytical tasks you tried earlier?

User: So in the above example, I will ask for references / citations and then check them to find the claims made by the AI.  To be honest, about half the time the AI will give quotes that don't exist.  But overall the process is much faster that any alternative, and it almost always finds some directly relevant material.  The value is greatest when I can easily check the AI's claims about relevance.

AI: That's a really practical approach - using it as an efficient starting point even knowing that about half the citations might be fabricated, because you can quickly verify the ones that do exist and they often lead to genuinely relevant material.

If you could wave a magic wand and have AI help with one aspect of your research that it currently doesn't - either something you haven't tried or something where it failed before - what would that be and why?

User: The most useful thing I could get from an AI would be help writing funding applications.  These can be tedious and its hard to sound novel and excited after the firth application in a row.  What I would really like from an AI would be the ability to accurately grab information, summarise it and use it to write the core of a funding application.  AI generally writes well; he problem now is that I just can't rely on it not hallucinating, or to put it bluntly, lying.  The possibility of nonsense means I can't send an application in, as it will be reviewed by people who know the subject.  The amount of time needed to check makes it faster to do draft myself (spoken and then AI transcribed), and then put it through something like Grammarly.

AI: That really captures the core tension - AI's writing ability could be genuinely transformative for those repetitive funding applications, but the hallucination risk makes it unusable when experts will be reviewing your work. The stakes are just too high.

Those are all my questions - your perspectives on AI as a research identification tool versus its limitations for complex analytical work were particularly insightful. Is there anything else about AI in your research work that we haven't touched on that you think would be important for us to understand?

User: No - my sense at the moment is that AI is REALLY good at guessing; it always produces answers that look and sound like a correct answer but may be nonsense.  The real challenge for AI development is to be able to weed out the nonsense from the gems to a much greater extent.  In fiels like mine, where there aren't always formulas to apply or a funnel down which you can narrow things, AI still has a long way to go.  When I see AI step back and look for context, then I'll feel that the "I" part of AI is getting close to being accurate.

AI: That's a really insightful way to put it - AI as fundamentally a very sophisticated guessing system that hasn't yet developed the ability to truly contextualize and self-correct in the nuanced ways that rigorous research demands.

Thank you again for sharing your experiences so openly. Your insights about the fundamental challenge of separating AI's "gems from nonsense" and the need for true contextual reasoning really help us understand the nuances of how AI fits into real scientific work. The contrast between its value for research identification versus its failures in complex analytical tasks gives us a lot to think about.

If you have any questions about this research or would like to follow up on anything we discussed, please don't hesitate to reach out. Thanks again for your time!
